[2021-05-14 11:42:50,153] {taskinstance.py:877} INFO - Dependencies all met for <TaskInstance: etl.run_spark_job 2021-05-14T14:41:55.555921+00:00 [queued]>
[2021-05-14 11:42:50,158] {taskinstance.py:877} INFO - Dependencies all met for <TaskInstance: etl.run_spark_job 2021-05-14T14:41:55.555921+00:00 [queued]>
[2021-05-14 11:42:50,158] {taskinstance.py:1068} INFO - 
--------------------------------------------------------------------------------
[2021-05-14 11:42:50,158] {taskinstance.py:1069} INFO - Starting attempt 1 of 1
[2021-05-14 11:42:50,158] {taskinstance.py:1070} INFO - 
--------------------------------------------------------------------------------
[2021-05-14 11:42:50,164] {taskinstance.py:1089} INFO - Executing <Task(DockerOperator): run_spark_job> on 2021-05-14T14:41:55.555921+00:00
[2021-05-14 11:42:50,168] {standard_task_runner.py:52} INFO - Started process 20218 to run task
[2021-05-14 11:42:50,176] {standard_task_runner.py:76} INFO - Running: ['airflow', 'tasks', 'run', 'etl', 'run_spark_job', '2021-05-14T14:41:55.555921+00:00', '--job-id', '413', '--pool', 'default_pool', '--raw', '--subdir', 'DAGS_FOLDER/etl_dag.py', '--cfg-path', '/var/folders/_f/vg3x3jmj23bcz6s88l7v6fb40000gn/T/tmpy4i79nvk', '--error-file', '/var/folders/_f/vg3x3jmj23bcz6s88l7v6fb40000gn/T/tmpush8y2qi']
[2021-05-14 11:42:50,178] {standard_task_runner.py:77} INFO - Job 413: Subtask run_spark_job
[2021-05-14 11:42:50,209] {logging_mixin.py:104} INFO - Running <TaskInstance: etl.run_spark_job 2021-05-14T14:41:55.555921+00:00 [running]> on host 27.2.168.192.in-addr.arpa
[2021-05-14 11:42:50,233] {taskinstance.py:1283} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=udacity
AIRFLOW_CTX_DAG_ID=etl
AIRFLOW_CTX_TASK_ID=run_spark_job
AIRFLOW_CTX_EXECUTION_DATE=2021-05-14T14:41:55.555921+00:00
AIRFLOW_CTX_DAG_RUN_ID=manual__2021-05-14T14:41:55.555921+00:00
[2021-05-14 11:42:50,236] {docker.py:303} INFO - Pulling docker image raphacarvalho/udac_spark
[2021-05-14 11:42:53,126] {docker.py:317} INFO - latest: Pulling from raphacarvalho/udac_spark
[2021-05-14 11:42:53,129] {docker.py:312} INFO - Digest: sha256:59c324d0ea6269fbd4f520bfa9d09121c4dbc9d525570712d6805ba6501a358c
[2021-05-14 11:42:53,129] {docker.py:312} INFO - Status: Image is up to date for raphacarvalho/udac_spark
[2021-05-14 11:42:53,133] {docker.py:232} INFO - Starting docker container from image raphacarvalho/udac_spark
[2021-05-14 11:42:55,266] {docker.py:276} INFO - WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/usr/local/spark-3.1.1-bin-hadoop3.2/jars/spark-unsafe_2.12-3.1.1.jar) to constructor java.nio.DirectByteBuffer(long,int)
WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
[2021-05-14 11:42:55,869] {docker.py:276} INFO - 21/05/14 14:42:55 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[2021-05-14 11:42:58,221] {docker.py:276} INFO - Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
[2021-05-14 11:42:58,236] {docker.py:276} INFO - 21/05/14 14:42:58 INFO SparkContext: Running Spark version 3.1.1
[2021-05-14 11:42:58,305] {docker.py:276} INFO - 21/05/14 14:42:58 INFO ResourceUtils: ==============================================================
[2021-05-14 11:42:58,306] {docker.py:276} INFO - 21/05/14 14:42:58 INFO ResourceUtils: No custom resources configured for spark.driver.
[2021-05-14 11:42:58,306] {docker.py:276} INFO - 21/05/14 14:42:58 INFO ResourceUtils: ==============================================================
[2021-05-14 11:42:58,307] {docker.py:276} INFO - 21/05/14 14:42:58 INFO SparkContext: Submitted application: spark.py
[2021-05-14 11:42:58,344] {docker.py:276} INFO - 21/05/14 14:42:58 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(memoryOverhead -> name: memoryOverhead, amount: 884, script: , vendor: , cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 4096, script: , vendor: , offHeap -> name: offHeap, amount: 500, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
[2021-05-14 11:42:58,365] {docker.py:276} INFO - 21/05/14 14:42:58 INFO ResourceProfile: Limiting resource is cpu
[2021-05-14 11:42:58,367] {docker.py:276} INFO - 21/05/14 14:42:58 INFO ResourceProfileManager: Added ResourceProfile id: 0
[2021-05-14 11:42:58,438] {docker.py:276} INFO - 21/05/14 14:42:58 INFO SecurityManager: Changing view acls to: jovyan
[2021-05-14 11:42:58,438] {docker.py:276} INFO - 21/05/14 14:42:58 INFO SecurityManager: Changing modify acls to: jovyan
[2021-05-14 11:42:58,438] {docker.py:276} INFO - 21/05/14 14:42:58 INFO SecurityManager: Changing view acls groups to:
[2021-05-14 11:42:58,439] {docker.py:276} INFO - 21/05/14 14:42:58 INFO SecurityManager: Changing modify acls groups to:
[2021-05-14 11:42:58,439] {docker.py:276} INFO - 21/05/14 14:42:58 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(jovyan); groups with view permissions: Set(); users  with modify permissions: Set(jovyan); groups with modify permissions: Set()
[2021-05-14 11:42:58,784] {docker.py:276} INFO - 21/05/14 14:42:58 INFO Utils: Successfully started service 'sparkDriver' on port 34709.
[2021-05-14 11:42:58,825] {docker.py:276} INFO - 21/05/14 14:42:58 INFO SparkEnv: Registering MapOutputTracker
[2021-05-14 11:42:58,870] {docker.py:276} INFO - 21/05/14 14:42:58 INFO SparkEnv: Registering BlockManagerMaster
[2021-05-14 11:42:58,903] {docker.py:276} INFO - 21/05/14 14:42:58 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[2021-05-14 11:42:58,904] {docker.py:276} INFO - 21/05/14 14:42:58 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
[2021-05-14 11:42:58,911] {docker.py:276} INFO - 21/05/14 14:42:58 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
[2021-05-14 11:42:58,928] {docker.py:276} INFO - 21/05/14 14:42:58 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-c0f405cc-e743-49c2-ad42-d592877cebf5
[2021-05-14 11:42:58,955] {docker.py:276} INFO - 21/05/14 14:42:58 INFO MemoryStore: MemoryStore started with capacity 934.4 MiB
[2021-05-14 11:42:58,979] {docker.py:276} INFO - 21/05/14 14:42:59 INFO SparkEnv: Registering OutputCommitCoordinator
[2021-05-14 11:42:59,284] {docker.py:276} INFO - 21/05/14 14:42:59 INFO Utils: Successfully started service 'SparkUI' on port 4040.
[2021-05-14 11:42:59,373] {docker.py:276} INFO - 21/05/14 14:42:59 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://f0b8ef7ba22f:4040
[2021-05-14 11:42:59,691] {docker.py:276} INFO - 21/05/14 14:42:59 INFO Executor: Starting executor ID driver on host f0b8ef7ba22f
[2021-05-14 11:42:59,736] {docker.py:276} INFO - 21/05/14 14:42:59 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 44207.
[2021-05-14 11:42:59,736] {docker.py:276} INFO - 21/05/14 14:42:59 INFO NettyBlockTransferService: Server created on f0b8ef7ba22f:44207
[2021-05-14 11:42:59,739] {docker.py:276} INFO - 21/05/14 14:42:59 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[2021-05-14 11:42:59,750] {docker.py:276} INFO - 21/05/14 14:42:59 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, f0b8ef7ba22f, 44207, None)
[2021-05-14 11:42:59,758] {docker.py:276} INFO - 21/05/14 14:42:59 INFO BlockManagerMasterEndpoint: Registering block manager f0b8ef7ba22f:44207 with 934.4 MiB RAM, BlockManagerId(driver, f0b8ef7ba22f, 44207, None)
[2021-05-14 11:42:59,766] {docker.py:276} INFO - 21/05/14 14:42:59 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, f0b8ef7ba22f, 44207, None)
[2021-05-14 11:42:59,768] {docker.py:276} INFO - 21/05/14 14:42:59 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, f0b8ef7ba22f, 44207, None)
[2021-05-14 11:43:00,454] {docker.py:276} INFO - 21/05/14 14:43:00 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/home/jovyan/spark-warehouse').
[2021-05-14 11:43:00,454] {docker.py:276} INFO - 21/05/14 14:43:00 INFO SharedState: Warehouse path is 'file:/home/jovyan/spark-warehouse'.
[2021-05-14 11:43:01,563] {docker.py:276} INFO - 21/05/14 14:43:01 WARN MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties
[2021-05-14 11:43:01,636] {docker.py:276} INFO - 21/05/14 14:43:01 INFO MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
21/05/14 14:43:01 INFO MetricsSystemImpl: s3a-file-system metrics system started
[2021-05-14 11:43:11,590] {docker.py:276} INFO - 21/05/14 14:43:11 INFO HadoopFSUtils: Listing leaf files and directories in parallel under 281 paths. The first several paths are: s3a://udac-forex-project/1/2021-05-14/from_1620916475_to_1620918275.csv, s3a://udac-forex-project/1/2021-05-14/from_1620916930_to_1620918730.csv, s3a://udac-forex-project/1/2021-05-14/from_1620918275_to_1620920075.csv, s3a://udac-forex-project/1/2021-05-14/from_1620918730_to_1620920530.csv, s3a://udac-forex-project/1/2021-05-14/from_1620920075_to_1620921875.csv, s3a://udac-forex-project/1/2021-05-14/from_1620920530_to_1620922330.csv, s3a://udac-forex-project/1/2021-05-14/from_1620921875_to_1620923675.csv, s3a://udac-forex-project/1/2021-05-14/from_1620922330_to_1620924130.csv, s3a://udac-forex-project/1/2021-05-14/from_1620923675_to_1620925475.csv, s3a://udac-forex-project/1/2021-05-14/from_1620924130_to_1620925930.csv.
[2021-05-14 11:43:12,176] {docker.py:276} INFO - 21/05/14 14:43:12 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
[2021-05-14 11:43:12,204] {docker.py:276} INFO - 21/05/14 14:43:12 INFO DAGScheduler: Got job 0 (csv at NativeMethodAccessorImpl.java:0) with 281 output partitions
[2021-05-14 11:43:12,205] {docker.py:276} INFO - 21/05/14 14:43:12 INFO DAGScheduler: Final stage: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0)
[2021-05-14 11:43:12,206] {docker.py:276} INFO - 21/05/14 14:43:12 INFO DAGScheduler: Parents of final stage: List()
[2021-05-14 11:43:12,209] {docker.py:276} INFO - 21/05/14 14:43:12 INFO DAGScheduler: Missing parents: List()
[2021-05-14 11:43:12,217] {docker.py:276} INFO - 21/05/14 14:43:12 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[2] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
[2021-05-14 11:43:12,347] {docker.py:276} INFO - 21/05/14 14:43:12 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 84.8 KiB, free 934.3 MiB)
[2021-05-14 11:43:12,417] {docker.py:276} INFO - 21/05/14 14:43:12 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 30.2 KiB, free 934.3 MiB)
[2021-05-14 11:43:12,420] {docker.py:276} INFO - 21/05/14 14:43:12 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on f0b8ef7ba22f:44207 (size: 30.2 KiB, free: 934.4 MiB)
[2021-05-14 11:43:12,425] {docker.py:276} INFO - 21/05/14 14:43:12 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1383
[2021-05-14 11:43:12,447] {docker.py:276} INFO - 21/05/14 14:43:12 INFO DAGScheduler: Submitting 281 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
[2021-05-14 11:43:12,457] {docker.py:276} INFO - 21/05/14 14:43:12 INFO TaskSchedulerImpl: Adding task set 0.0 with 281 tasks resource profile 0
[2021-05-14 11:43:12,559] {docker.py:276} INFO - 21/05/14 14:43:12 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (f0b8ef7ba22f, executor driver, partition 0, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:12,564] {docker.py:276} INFO - 21/05/14 14:43:12 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1) (f0b8ef7ba22f, executor driver, partition 1, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:12,565] {docker.py:276} INFO - 21/05/14 14:43:12 INFO TaskSetManager: Starting task 2.0 in stage 0.0 (TID 2) (f0b8ef7ba22f, executor driver, partition 2, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:12,566] {docker.py:276} INFO - 21/05/14 14:43:12 INFO TaskSetManager: Starting task 3.0 in stage 0.0 (TID 3) (f0b8ef7ba22f, executor driver, partition 3, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:12,585] {docker.py:276} INFO - 21/05/14 14:43:12 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
[2021-05-14 11:43:12,587] {docker.py:276} INFO - 21/05/14 14:43:12 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
[2021-05-14 11:43:12,588] {docker.py:276} INFO - 21/05/14 14:43:12 INFO Executor: Running task 3.0 in stage 0.0 (TID 3)
[2021-05-14 11:43:12,592] {docker.py:276} INFO - 21/05/14 14:43:12 INFO Executor: Running task 2.0 in stage 0.0 (TID 2)
[2021-05-14 11:43:12,990] {docker.py:276} INFO - 21/05/14 14:43:12 INFO Executor: Finished task 3.0 in stage 0.0 (TID 3). 1868 bytes result sent to driver
[2021-05-14 11:43:12,995] {docker.py:276} INFO - 21/05/14 14:43:12 INFO TaskSetManager: Starting task 4.0 in stage 0.0 (TID 4) (f0b8ef7ba22f, executor driver, partition 4, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:12,997] {docker.py:276} INFO - 21/05/14 14:43:13 INFO Executor: Running task 4.0 in stage 0.0 (TID 4)
[2021-05-14 11:43:13,004] {docker.py:276} INFO - 21/05/14 14:43:13 INFO TaskSetManager: Finished task 3.0 in stage 0.0 (TID 3) in 437 ms on f0b8ef7ba22f (executor driver) (1/281)
[2021-05-14 11:43:13,205] {docker.py:276} INFO - 21/05/14 14:43:13 INFO Executor: Finished task 4.0 in stage 0.0 (TID 4). 1868 bytes result sent to driver
[2021-05-14 11:43:13,208] {docker.py:276} INFO - 21/05/14 14:43:13 INFO TaskSetManager: Starting task 5.0 in stage 0.0 (TID 5) (f0b8ef7ba22f, executor driver, partition 5, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:13,211] {docker.py:276} INFO - 21/05/14 14:43:13 INFO Executor: Running task 5.0 in stage 0.0 (TID 5)
[2021-05-14 11:43:13,212] {docker.py:276} INFO - 21/05/14 14:43:13 INFO TaskSetManager: Finished task 4.0 in stage 0.0 (TID 4) in 218 ms on f0b8ef7ba22f (executor driver) (2/281)
[2021-05-14 11:43:13,413] {docker.py:276} INFO - 21/05/14 14:43:13 INFO Executor: Finished task 5.0 in stage 0.0 (TID 5). 1825 bytes result sent to driver
[2021-05-14 11:43:13,423] {docker.py:276} INFO - 21/05/14 14:43:13 INFO TaskSetManager: Starting task 6.0 in stage 0.0 (TID 6) (f0b8ef7ba22f, executor driver, partition 6, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:13,424] {docker.py:276} INFO - 21/05/14 14:43:13 INFO Executor: Running task 6.0 in stage 0.0 (TID 6)
[2021-05-14 11:43:13,424] {docker.py:276} INFO - 21/05/14 14:43:13 INFO TaskSetManager: Finished task 5.0 in stage 0.0 (TID 5) in 212 ms on f0b8ef7ba22f (executor driver) (3/281)
[2021-05-14 11:43:13,492] {docker.py:276} INFO - 21/05/14 14:43:13 INFO Executor: Finished task 2.0 in stage 0.0 (TID 2). 1868 bytes result sent to driver
[2021-05-14 11:43:13,495] {docker.py:276} INFO - 21/05/14 14:43:13 INFO TaskSetManager: Starting task 7.0 in stage 0.0 (TID 7) (f0b8ef7ba22f, executor driver, partition 7, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:13,497] {docker.py:276} INFO - 21/05/14 14:43:13 INFO TaskSetManager: Finished task 2.0 in stage 0.0 (TID 2) in 933 ms on f0b8ef7ba22f (executor driver) (4/281)
[2021-05-14 11:43:13,498] {docker.py:276} INFO - 21/05/14 14:43:13 INFO Executor: Running task 7.0 in stage 0.0 (TID 7)
[2021-05-14 11:43:13,501] {docker.py:276} INFO - 21/05/14 14:43:13 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1868 bytes result sent to driver
[2021-05-14 11:43:13,514] {docker.py:276} INFO - 21/05/14 14:43:13 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1911 bytes result sent to driver
[2021-05-14 11:43:13,515] {docker.py:276} INFO - 21/05/14 14:43:13 INFO TaskSetManager: Starting task 8.0 in stage 0.0 (TID 8) (f0b8ef7ba22f, executor driver, partition 8, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:13,516] {docker.py:276} INFO - 21/05/14 14:43:13 INFO TaskSetManager: Starting task 9.0 in stage 0.0 (TID 9) (f0b8ef7ba22f, executor driver, partition 9, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:13,516] {docker.py:276} INFO - 21/05/14 14:43:13 INFO Executor: Running task 8.0 in stage 0.0 (TID 8)
[2021-05-14 11:43:13,517] {docker.py:276} INFO - 21/05/14 14:43:13 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 997 ms on f0b8ef7ba22f (executor driver) (5/281)
[2021-05-14 11:43:13,519] {docker.py:276} INFO - 21/05/14 14:43:13 INFO Executor: Running task 9.0 in stage 0.0 (TID 9)
[2021-05-14 11:43:13,519] {docker.py:276} INFO - 21/05/14 14:43:13 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 956 ms on f0b8ef7ba22f (executor driver) (6/281)
[2021-05-14 11:43:13,618] {docker.py:276} INFO - 21/05/14 14:43:13 INFO Executor: Finished task 6.0 in stage 0.0 (TID 6). 1825 bytes result sent to driver
[2021-05-14 11:43:13,620] {docker.py:276} INFO - 21/05/14 14:43:13 INFO TaskSetManager: Starting task 10.0 in stage 0.0 (TID 10) (f0b8ef7ba22f, executor driver, partition 10, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:13,624] {docker.py:276} INFO - 21/05/14 14:43:13 INFO Executor: Running task 10.0 in stage 0.0 (TID 10)
21/05/14 14:43:13 INFO TaskSetManager: Finished task 6.0 in stage 0.0 (TID 6) in 207 ms on f0b8ef7ba22f (executor driver) (7/281)
[2021-05-14 11:43:13,717] {docker.py:276} INFO - 21/05/14 14:43:13 INFO Executor: Finished task 8.0 in stage 0.0 (TID 8). 1825 bytes result sent to driver
[2021-05-14 11:43:13,718] {docker.py:276} INFO - 21/05/14 14:43:13 INFO TaskSetManager: Starting task 11.0 in stage 0.0 (TID 11) (f0b8ef7ba22f, executor driver, partition 11, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:13,720] {docker.py:276} INFO - 21/05/14 14:43:13 INFO TaskSetManager: Finished task 8.0 in stage 0.0 (TID 8) in 207 ms on f0b8ef7ba22f (executor driver) (8/281)
[2021-05-14 11:43:13,721] {docker.py:276} INFO - 21/05/14 14:43:13 INFO Executor: Running task 11.0 in stage 0.0 (TID 11)
[2021-05-14 11:43:13,728] {docker.py:276} INFO - 21/05/14 14:43:13 INFO Executor: Finished task 7.0 in stage 0.0 (TID 7). 1825 bytes result sent to driver
[2021-05-14 11:43:13,730] {docker.py:276} INFO - 21/05/14 14:43:13 INFO TaskSetManager: Starting task 12.0 in stage 0.0 (TID 12) (f0b8ef7ba22f, executor driver, partition 12, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:13,731] {docker.py:276} INFO - 21/05/14 14:43:13 INFO TaskSetManager: Finished task 7.0 in stage 0.0 (TID 7) in 237 ms on f0b8ef7ba22f (executor driver) (9/281)
[2021-05-14 11:43:13,733] {docker.py:276} INFO - 21/05/14 14:43:13 INFO Executor: Running task 12.0 in stage 0.0 (TID 12)
[2021-05-14 11:43:13,738] {docker.py:276} INFO - 21/05/14 14:43:13 INFO Executor: Finished task 9.0 in stage 0.0 (TID 9). 1825 bytes result sent to driver
[2021-05-14 11:43:13,739] {docker.py:276} INFO - 21/05/14 14:43:13 INFO TaskSetManager: Starting task 13.0 in stage 0.0 (TID 13) (f0b8ef7ba22f, executor driver, partition 13, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:13,741] {docker.py:276} INFO - 21/05/14 14:43:13 INFO TaskSetManager: Finished task 9.0 in stage 0.0 (TID 9) in 226 ms on f0b8ef7ba22f (executor driver) (10/281)
[2021-05-14 11:43:13,743] {docker.py:276} INFO - 21/05/14 14:43:13 INFO Executor: Running task 13.0 in stage 0.0 (TID 13)
[2021-05-14 11:43:13,807] {docker.py:276} INFO - 21/05/14 14:43:13 INFO Executor: Finished task 10.0 in stage 0.0 (TID 10). 1825 bytes result sent to driver
[2021-05-14 11:43:13,811] {docker.py:276} INFO - 21/05/14 14:43:13 INFO TaskSetManager: Starting task 14.0 in stage 0.0 (TID 14) (f0b8ef7ba22f, executor driver, partition 14, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:13,811] {docker.py:276} INFO - 21/05/14 14:43:13 INFO Executor: Running task 14.0 in stage 0.0 (TID 14)
[2021-05-14 11:43:13,811] {docker.py:276} INFO - 21/05/14 14:43:13 INFO TaskSetManager: Finished task 10.0 in stage 0.0 (TID 10) in 190 ms on f0b8ef7ba22f (executor driver) (11/281)
[2021-05-14 11:43:13,900] {docker.py:276} INFO - 21/05/14 14:43:13 INFO Executor: Finished task 11.0 in stage 0.0 (TID 11). 1825 bytes result sent to driver
[2021-05-14 11:43:13,902] {docker.py:276} INFO - 21/05/14 14:43:13 INFO TaskSetManager: Starting task 15.0 in stage 0.0 (TID 15) (f0b8ef7ba22f, executor driver, partition 15, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:13,904] {docker.py:276} INFO - 21/05/14 14:43:13 INFO Executor: Running task 15.0 in stage 0.0 (TID 15)
21/05/14 14:43:13 INFO TaskSetManager: Finished task 11.0 in stage 0.0 (TID 11) in 186 ms on f0b8ef7ba22f (executor driver) (12/281)
[2021-05-14 11:43:13,916] {docker.py:276} INFO - 21/05/14 14:43:13 INFO Executor: Finished task 12.0 in stage 0.0 (TID 12). 1825 bytes result sent to driver
[2021-05-14 11:43:13,919] {docker.py:276} INFO - 21/05/14 14:43:13 INFO TaskSetManager: Starting task 16.0 in stage 0.0 (TID 16) (f0b8ef7ba22f, executor driver, partition 16, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:13,920] {docker.py:276} INFO - 21/05/14 14:43:13 INFO Executor: Running task 16.0 in stage 0.0 (TID 16)
21/05/14 14:43:13 INFO TaskSetManager: Finished task 12.0 in stage 0.0 (TID 12) in 190 ms on f0b8ef7ba22f (executor driver) (13/281)
[2021-05-14 11:43:13,928] {docker.py:276} INFO - 21/05/14 14:43:13 INFO Executor: Finished task 13.0 in stage 0.0 (TID 13). 1825 bytes result sent to driver
[2021-05-14 11:43:13,929] {docker.py:276} INFO - 21/05/14 14:43:13 INFO TaskSetManager: Starting task 17.0 in stage 0.0 (TID 17) (f0b8ef7ba22f, executor driver, partition 17, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:13,930] {docker.py:276} INFO - 21/05/14 14:43:13 INFO TaskSetManager: Finished task 13.0 in stage 0.0 (TID 13) in 192 ms on f0b8ef7ba22f (executor driver) (14/281)
[2021-05-14 11:43:13,931] {docker.py:276} INFO - 21/05/14 14:43:13 INFO Executor: Running task 17.0 in stage 0.0 (TID 17)
[2021-05-14 11:43:13,992] {docker.py:276} INFO - 21/05/14 14:43:13 INFO Executor: Finished task 14.0 in stage 0.0 (TID 14). 1868 bytes result sent to driver
[2021-05-14 11:43:13,994] {docker.py:276} INFO - 21/05/14 14:43:13 INFO TaskSetManager: Starting task 18.0 in stage 0.0 (TID 18) (f0b8ef7ba22f, executor driver, partition 18, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:13,996] {docker.py:276} INFO - 21/05/14 14:43:14 INFO Executor: Running task 18.0 in stage 0.0 (TID 18)
[2021-05-14 11:43:13,996] {docker.py:276} INFO - 21/05/14 14:43:14 INFO TaskSetManager: Finished task 14.0 in stage 0.0 (TID 14) in 188 ms on f0b8ef7ba22f (executor driver) (15/281)
[2021-05-14 11:43:14,092] {docker.py:276} INFO - 21/05/14 14:43:14 INFO Executor: Finished task 15.0 in stage 0.0 (TID 15). 1868 bytes result sent to driver
[2021-05-14 11:43:14,094] {docker.py:276} INFO - 21/05/14 14:43:14 INFO TaskSetManager: Starting task 19.0 in stage 0.0 (TID 19) (f0b8ef7ba22f, executor driver, partition 19, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:14,095] {docker.py:276} INFO - 21/05/14 14:43:14 INFO Executor: Running task 19.0 in stage 0.0 (TID 19)
[2021-05-14 11:43:14,096] {docker.py:276} INFO - 21/05/14 14:43:14 INFO TaskSetManager: Finished task 15.0 in stage 0.0 (TID 15) in 195 ms on f0b8ef7ba22f (executor driver) (16/281)
[2021-05-14 11:43:14,113] {docker.py:276} INFO - 21/05/14 14:43:14 INFO Executor: Finished task 17.0 in stage 0.0 (TID 17). 1868 bytes result sent to driver
[2021-05-14 11:43:14,114] {docker.py:276} INFO - 21/05/14 14:43:14 INFO TaskSetManager: Starting task 20.0 in stage 0.0 (TID 20) (f0b8ef7ba22f, executor driver, partition 20, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:14,116] {docker.py:276} INFO - 21/05/14 14:43:14 INFO TaskSetManager: Finished task 17.0 in stage 0.0 (TID 17) in 188 ms on f0b8ef7ba22f (executor driver) (17/281)
[2021-05-14 11:43:14,117] {docker.py:276} INFO - 21/05/14 14:43:14 INFO Executor: Running task 20.0 in stage 0.0 (TID 20)
[2021-05-14 11:43:14,162] {docker.py:276} INFO - 21/05/14 14:43:14 INFO Executor: Finished task 16.0 in stage 0.0 (TID 16). 1868 bytes result sent to driver
[2021-05-14 11:43:14,164] {docker.py:276} INFO - 21/05/14 14:43:14 INFO TaskSetManager: Starting task 21.0 in stage 0.0 (TID 21) (f0b8ef7ba22f, executor driver, partition 21, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:14,166] {docker.py:276} INFO - 21/05/14 14:43:14 INFO Executor: Running task 21.0 in stage 0.0 (TID 21)
[2021-05-14 11:43:14,167] {docker.py:276} INFO - 21/05/14 14:43:14 INFO TaskSetManager: Finished task 16.0 in stage 0.0 (TID 16) in 249 ms on f0b8ef7ba22f (executor driver) (18/281)
[2021-05-14 11:43:14,178] {docker.py:276} INFO - 21/05/14 14:43:14 INFO Executor: Finished task 18.0 in stage 0.0 (TID 18). 1825 bytes result sent to driver
[2021-05-14 11:43:14,178] {docker.py:276} INFO - 21/05/14 14:43:14 INFO TaskSetManager: Starting task 22.0 in stage 0.0 (TID 22) (f0b8ef7ba22f, executor driver, partition 22, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:14,179] {docker.py:276} INFO - 21/05/14 14:43:14 INFO TaskSetManager: Finished task 18.0 in stage 0.0 (TID 18) in 187 ms on f0b8ef7ba22f (executor driver) (19/281)
[2021-05-14 11:43:14,180] {docker.py:276} INFO - 21/05/14 14:43:14 INFO Executor: Running task 22.0 in stage 0.0 (TID 22)
[2021-05-14 11:43:14,276] {docker.py:276} INFO - 21/05/14 14:43:14 INFO Executor: Finished task 19.0 in stage 0.0 (TID 19). 1825 bytes result sent to driver
[2021-05-14 11:43:14,280] {docker.py:276} INFO - 21/05/14 14:43:14 INFO TaskSetManager: Starting task 23.0 in stage 0.0 (TID 23) (f0b8ef7ba22f, executor driver, partition 23, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:14,282] {docker.py:276} INFO - 21/05/14 14:43:14 INFO Executor: Running task 23.0 in stage 0.0 (TID 23)
21/05/14 14:43:14 INFO TaskSetManager: Finished task 19.0 in stage 0.0 (TID 19) in 189 ms on f0b8ef7ba22f (executor driver) (20/281)
[2021-05-14 11:43:14,291] {docker.py:276} INFO - 21/05/14 14:43:14 INFO Executor: Finished task 20.0 in stage 0.0 (TID 20). 1825 bytes result sent to driver
[2021-05-14 11:43:14,293] {docker.py:276} INFO - 21/05/14 14:43:14 INFO TaskSetManager: Starting task 24.0 in stage 0.0 (TID 24) (f0b8ef7ba22f, executor driver, partition 24, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:14,295] {docker.py:276} INFO - 21/05/14 14:43:14 INFO Executor: Running task 24.0 in stage 0.0 (TID 24)
21/05/14 14:43:14 INFO TaskSetManager: Finished task 20.0 in stage 0.0 (TID 20) in 181 ms on f0b8ef7ba22f (executor driver) (21/281)
[2021-05-14 11:43:14,349] {docker.py:276} INFO - 21/05/14 14:43:14 INFO Executor: Finished task 21.0 in stage 0.0 (TID 21). 1825 bytes result sent to driver
[2021-05-14 11:43:14,350] {docker.py:276} INFO - 21/05/14 14:43:14 INFO TaskSetManager: Starting task 25.0 in stage 0.0 (TID 25) (f0b8ef7ba22f, executor driver, partition 25, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:14,351] {docker.py:276} INFO - 21/05/14 14:43:14 INFO Executor: Running task 25.0 in stage 0.0 (TID 25)
21/05/14 14:43:14 INFO TaskSetManager: Finished task 21.0 in stage 0.0 (TID 21) in 188 ms on f0b8ef7ba22f (executor driver) (22/281)
[2021-05-14 11:43:14,358] {docker.py:276} INFO - 21/05/14 14:43:14 INFO Executor: Finished task 22.0 in stage 0.0 (TID 22). 1825 bytes result sent to driver
[2021-05-14 11:43:14,359] {docker.py:276} INFO - 21/05/14 14:43:14 INFO TaskSetManager: Starting task 26.0 in stage 0.0 (TID 26) (f0b8ef7ba22f, executor driver, partition 26, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:14,360] {docker.py:276} INFO - 21/05/14 14:43:14 INFO TaskSetManager: Finished task 22.0 in stage 0.0 (TID 22) in 183 ms on f0b8ef7ba22f (executor driver) (23/281)
[2021-05-14 11:43:14,362] {docker.py:276} INFO - 21/05/14 14:43:14 INFO Executor: Running task 26.0 in stage 0.0 (TID 26)
[2021-05-14 11:43:14,457] {docker.py:276} INFO - 21/05/14 14:43:14 INFO Executor: Finished task 23.0 in stage 0.0 (TID 23). 1825 bytes result sent to driver
[2021-05-14 11:43:14,460] {docker.py:276} INFO - 21/05/14 14:43:14 INFO TaskSetManager: Starting task 27.0 in stage 0.0 (TID 27) (f0b8ef7ba22f, executor driver, partition 27, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:14,462] {docker.py:276} INFO - 21/05/14 14:43:14 INFO Executor: Running task 27.0 in stage 0.0 (TID 27)
[2021-05-14 11:43:14,463] {docker.py:276} INFO - 21/05/14 14:43:14 INFO TaskSetManager: Finished task 23.0 in stage 0.0 (TID 23) in 181 ms on f0b8ef7ba22f (executor driver) (24/281)
[2021-05-14 11:43:14,471] {docker.py:276} INFO - 21/05/14 14:43:14 INFO Executor: Finished task 24.0 in stage 0.0 (TID 24). 1825 bytes result sent to driver
[2021-05-14 11:43:14,472] {docker.py:276} INFO - 21/05/14 14:43:14 INFO TaskSetManager: Starting task 28.0 in stage 0.0 (TID 28) (f0b8ef7ba22f, executor driver, partition 28, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:14,473] {docker.py:276} INFO - 21/05/14 14:43:14 INFO TaskSetManager: Finished task 24.0 in stage 0.0 (TID 24) in 181 ms on f0b8ef7ba22f (executor driver) (25/281)
[2021-05-14 11:43:14,479] {docker.py:276} INFO - 21/05/14 14:43:14 INFO Executor: Running task 28.0 in stage 0.0 (TID 28)
[2021-05-14 11:43:14,530] {docker.py:276} INFO - 21/05/14 14:43:14 INFO Executor: Finished task 25.0 in stage 0.0 (TID 25). 1825 bytes result sent to driver
[2021-05-14 11:43:14,531] {docker.py:276} INFO - 21/05/14 14:43:14 INFO TaskSetManager: Starting task 29.0 in stage 0.0 (TID 29) (f0b8ef7ba22f, executor driver, partition 29, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:14,532] {docker.py:276} INFO - 21/05/14 14:43:14 INFO Executor: Running task 29.0 in stage 0.0 (TID 29)
[2021-05-14 11:43:14,532] {docker.py:276} INFO - 21/05/14 14:43:14 INFO TaskSetManager: Finished task 25.0 in stage 0.0 (TID 25) in 182 ms on f0b8ef7ba22f (executor driver) (26/281)
[2021-05-14 11:43:14,575] {docker.py:276} INFO - 21/05/14 14:43:14 INFO Executor: Finished task 26.0 in stage 0.0 (TID 26). 1825 bytes result sent to driver
[2021-05-14 11:43:14,577] {docker.py:276} INFO - 21/05/14 14:43:14 INFO TaskSetManager: Starting task 30.0 in stage 0.0 (TID 30) (f0b8ef7ba22f, executor driver, partition 30, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:14,578] {docker.py:276} INFO - 21/05/14 14:43:14 INFO Executor: Running task 30.0 in stage 0.0 (TID 30)
[2021-05-14 11:43:14,579] {docker.py:276} INFO - 21/05/14 14:43:14 INFO TaskSetManager: Finished task 26.0 in stage 0.0 (TID 26) in 220 ms on f0b8ef7ba22f (executor driver) (27/281)
[2021-05-14 11:43:14,640] {docker.py:276} INFO - 21/05/14 14:43:14 INFO Executor: Finished task 27.0 in stage 0.0 (TID 27). 1825 bytes result sent to driver
[2021-05-14 11:43:14,641] {docker.py:276} INFO - 21/05/14 14:43:14 INFO TaskSetManager: Starting task 31.0 in stage 0.0 (TID 31) (f0b8ef7ba22f, executor driver, partition 31, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:14,642] {docker.py:276} INFO - 21/05/14 14:43:14 INFO TaskSetManager: Finished task 27.0 in stage 0.0 (TID 27) in 183 ms on f0b8ef7ba22f (executor driver) (28/281)
[2021-05-14 11:43:14,643] {docker.py:276} INFO - 21/05/14 14:43:14 INFO Executor: Running task 31.0 in stage 0.0 (TID 31)
[2021-05-14 11:43:14,655] {docker.py:276} INFO - 21/05/14 14:43:14 INFO Executor: Finished task 28.0 in stage 0.0 (TID 28). 1868 bytes result sent to driver
[2021-05-14 11:43:14,657] {docker.py:276} INFO - 21/05/14 14:43:14 INFO TaskSetManager: Starting task 32.0 in stage 0.0 (TID 32) (f0b8ef7ba22f, executor driver, partition 32, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:14,658] {docker.py:276} INFO - 21/05/14 14:43:14 INFO TaskSetManager: Finished task 28.0 in stage 0.0 (TID 28) in 186 ms on f0b8ef7ba22f (executor driver) (29/281)
[2021-05-14 11:43:14,660] {docker.py:276} INFO - 21/05/14 14:43:14 INFO Executor: Running task 32.0 in stage 0.0 (TID 32)
[2021-05-14 11:43:14,714] {docker.py:276} INFO - 21/05/14 14:43:14 INFO Executor: Finished task 29.0 in stage 0.0 (TID 29). 1868 bytes result sent to driver
[2021-05-14 11:43:14,716] {docker.py:276} INFO - 21/05/14 14:43:14 INFO TaskSetManager: Starting task 33.0 in stage 0.0 (TID 33) (f0b8ef7ba22f, executor driver, partition 33, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:14,718] {docker.py:276} INFO - 21/05/14 14:43:14 INFO TaskSetManager: Finished task 29.0 in stage 0.0 (TID 29) in 187 ms on f0b8ef7ba22f (executor driver) (30/281)
[2021-05-14 11:43:14,718] {docker.py:276} INFO - 21/05/14 14:43:14 INFO Executor: Running task 33.0 in stage 0.0 (TID 33)
[2021-05-14 11:43:14,756] {docker.py:276} INFO - 21/05/14 14:43:14 INFO Executor: Finished task 30.0 in stage 0.0 (TID 30). 1868 bytes result sent to driver
[2021-05-14 11:43:14,757] {docker.py:276} INFO - 21/05/14 14:43:14 INFO TaskSetManager: Finished task 30.0 in stage 0.0 (TID 30) in 181 ms on f0b8ef7ba22f (executor driver) (31/281)
[2021-05-14 11:43:14,760] {docker.py:276} INFO - 21/05/14 14:43:14 INFO TaskSetManager: Starting task 34.0 in stage 0.0 (TID 34) (f0b8ef7ba22f, executor driver, partition 34, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:14,762] {docker.py:276} INFO - 21/05/14 14:43:14 INFO Executor: Running task 34.0 in stage 0.0 (TID 34)
[2021-05-14 11:43:14,822] {docker.py:276} INFO - 21/05/14 14:43:14 INFO Executor: Finished task 31.0 in stage 0.0 (TID 31). 1868 bytes result sent to driver
[2021-05-14 11:43:14,823] {docker.py:276} INFO - 21/05/14 14:43:14 INFO TaskSetManager: Starting task 35.0 in stage 0.0 (TID 35) (f0b8ef7ba22f, executor driver, partition 35, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:14,824] {docker.py:276} INFO - 21/05/14 14:43:14 INFO TaskSetManager: Finished task 31.0 in stage 0.0 (TID 31) in 183 ms on f0b8ef7ba22f (executor driver) (32/281)
[2021-05-14 11:43:14,825] {docker.py:276} INFO - 21/05/14 14:43:14 INFO Executor: Running task 35.0 in stage 0.0 (TID 35)
[2021-05-14 11:43:14,833] {docker.py:276} INFO - 21/05/14 14:43:14 INFO Executor: Finished task 32.0 in stage 0.0 (TID 32). 1825 bytes result sent to driver
[2021-05-14 11:43:14,834] {docker.py:276} INFO - 21/05/14 14:43:14 INFO TaskSetManager: Starting task 36.0 in stage 0.0 (TID 36) (f0b8ef7ba22f, executor driver, partition 36, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:14,836] {docker.py:276} INFO - 21/05/14 14:43:14 INFO TaskSetManager: Finished task 32.0 in stage 0.0 (TID 32) in 179 ms on f0b8ef7ba22f (executor driver) (33/281)
[2021-05-14 11:43:14,836] {docker.py:276} INFO - 21/05/14 14:43:14 INFO Executor: Running task 36.0 in stage 0.0 (TID 36)
[2021-05-14 11:43:14,902] {docker.py:276} INFO - 21/05/14 14:43:14 INFO Executor: Finished task 33.0 in stage 0.0 (TID 33). 1825 bytes result sent to driver
[2021-05-14 11:43:14,903] {docker.py:276} INFO - 21/05/14 14:43:14 INFO TaskSetManager: Starting task 37.0 in stage 0.0 (TID 37) (f0b8ef7ba22f, executor driver, partition 37, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:14,904] {docker.py:276} INFO - 21/05/14 14:43:14 INFO TaskSetManager: Finished task 33.0 in stage 0.0 (TID 33) in 190 ms on f0b8ef7ba22f (executor driver) (34/281)
[2021-05-14 11:43:14,906] {docker.py:276} INFO - 21/05/14 14:43:14 INFO Executor: Running task 37.0 in stage 0.0 (TID 37)
[2021-05-14 11:43:14,943] {docker.py:276} INFO - 21/05/14 14:43:14 INFO Executor: Finished task 34.0 in stage 0.0 (TID 34). 1825 bytes result sent to driver
[2021-05-14 11:43:14,945] {docker.py:276} INFO - 21/05/14 14:43:14 INFO TaskSetManager: Starting task 38.0 in stage 0.0 (TID 38) (f0b8ef7ba22f, executor driver, partition 38, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:14,946] {docker.py:276} INFO - 21/05/14 14:43:14 INFO TaskSetManager: Finished task 34.0 in stage 0.0 (TID 34) in 187 ms on f0b8ef7ba22f (executor driver) (35/281)
[2021-05-14 11:43:14,948] {docker.py:276} INFO - 21/05/14 14:43:14 INFO Executor: Running task 38.0 in stage 0.0 (TID 38)
[2021-05-14 11:43:15,002] {docker.py:276} INFO - 21/05/14 14:43:15 INFO Executor: Finished task 35.0 in stage 0.0 (TID 35). 1825 bytes result sent to driver
[2021-05-14 11:43:15,003] {docker.py:276} INFO - 21/05/14 14:43:15 INFO TaskSetManager: Starting task 39.0 in stage 0.0 (TID 39) (f0b8ef7ba22f, executor driver, partition 39, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:15,004] {docker.py:276} INFO - 21/05/14 14:43:15 INFO TaskSetManager: Finished task 35.0 in stage 0.0 (TID 35) in 182 ms on f0b8ef7ba22f (executor driver) (36/281)
[2021-05-14 11:43:15,006] {docker.py:276} INFO - 21/05/14 14:43:15 INFO Executor: Running task 39.0 in stage 0.0 (TID 39)
[2021-05-14 11:43:15,008] {docker.py:276} INFO - 21/05/14 14:43:15 INFO Executor: Finished task 36.0 in stage 0.0 (TID 36). 1825 bytes result sent to driver
[2021-05-14 11:43:15,010] {docker.py:276} INFO - 21/05/14 14:43:15 INFO TaskSetManager: Starting task 40.0 in stage 0.0 (TID 40) (f0b8ef7ba22f, executor driver, partition 40, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:15,012] {docker.py:276} INFO - 21/05/14 14:43:15 INFO TaskSetManager: Finished task 36.0 in stage 0.0 (TID 36) in 178 ms on f0b8ef7ba22f (executor driver) (37/281)
[2021-05-14 11:43:15,013] {docker.py:276} INFO - 21/05/14 14:43:15 INFO Executor: Running task 40.0 in stage 0.0 (TID 40)
[2021-05-14 11:43:15,088] {docker.py:276} INFO - 21/05/14 14:43:15 INFO Executor: Finished task 37.0 in stage 0.0 (TID 37). 1825 bytes result sent to driver
[2021-05-14 11:43:15,091] {docker.py:276} INFO - 21/05/14 14:43:15 INFO TaskSetManager: Starting task 41.0 in stage 0.0 (TID 41) (f0b8ef7ba22f, executor driver, partition 41, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:15,091] {docker.py:276} INFO - 21/05/14 14:43:15 INFO Executor: Running task 41.0 in stage 0.0 (TID 41)
[2021-05-14 11:43:15,092] {docker.py:276} INFO - 21/05/14 14:43:15 INFO TaskSetManager: Finished task 37.0 in stage 0.0 (TID 37) in 188 ms on f0b8ef7ba22f (executor driver) (38/281)
[2021-05-14 11:43:15,132] {docker.py:276} INFO - 21/05/14 14:43:15 INFO Executor: Finished task 38.0 in stage 0.0 (TID 38). 1825 bytes result sent to driver
[2021-05-14 11:43:15,133] {docker.py:276} INFO - 21/05/14 14:43:15 INFO TaskSetManager: Starting task 42.0 in stage 0.0 (TID 42) (f0b8ef7ba22f, executor driver, partition 42, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:15,134] {docker.py:276} INFO - 21/05/14 14:43:15 INFO Executor: Running task 42.0 in stage 0.0 (TID 42)
[2021-05-14 11:43:15,135] {docker.py:276} INFO - 21/05/14 14:43:15 INFO TaskSetManager: Finished task 38.0 in stage 0.0 (TID 38) in 190 ms on f0b8ef7ba22f (executor driver) (39/281)
[2021-05-14 11:43:15,182] {docker.py:276} INFO - 21/05/14 14:43:15 INFO Executor: Finished task 40.0 in stage 0.0 (TID 40). 1825 bytes result sent to driver
[2021-05-14 11:43:15,185] {docker.py:276} INFO - 21/05/14 14:43:15 INFO TaskSetManager: Starting task 43.0 in stage 0.0 (TID 43) (f0b8ef7ba22f, executor driver, partition 43, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:15,186] {docker.py:276} INFO - 21/05/14 14:43:15 INFO Executor: Finished task 39.0 in stage 0.0 (TID 39). 1825 bytes result sent to driver
[2021-05-14 11:43:15,186] {docker.py:276} INFO - 21/05/14 14:43:15 INFO Executor: Running task 43.0 in stage 0.0 (TID 43)
[2021-05-14 11:43:15,188] {docker.py:276} INFO - 21/05/14 14:43:15 INFO TaskSetManager: Starting task 44.0 in stage 0.0 (TID 44) (f0b8ef7ba22f, executor driver, partition 44, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:15,189] {docker.py:276} INFO - 21/05/14 14:43:15 INFO TaskSetManager: Finished task 39.0 in stage 0.0 (TID 39) in 186 ms on f0b8ef7ba22f (executor driver) (40/281)
[2021-05-14 11:43:15,190] {docker.py:276} INFO - 21/05/14 14:43:15 INFO TaskSetManager: Finished task 40.0 in stage 0.0 (TID 40) in 181 ms on f0b8ef7ba22f (executor driver) (41/281)
[2021-05-14 11:43:15,190] {docker.py:276} INFO - 21/05/14 14:43:15 INFO Executor: Running task 44.0 in stage 0.0 (TID 44)
[2021-05-14 11:43:15,270] {docker.py:276} INFO - 21/05/14 14:43:15 INFO Executor: Finished task 41.0 in stage 0.0 (TID 41). 1825 bytes result sent to driver
[2021-05-14 11:43:15,272] {docker.py:276} INFO - 21/05/14 14:43:15 INFO TaskSetManager: Starting task 45.0 in stage 0.0 (TID 45) (f0b8ef7ba22f, executor driver, partition 45, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
21/05/14 14:43:15 INFO TaskSetManager: Finished task 41.0 in stage 0.0 (TID 41) in 183 ms on f0b8ef7ba22f (executor driver) (42/281)
[2021-05-14 11:43:15,273] {docker.py:276} INFO - 21/05/14 14:43:15 INFO Executor: Running task 45.0 in stage 0.0 (TID 45)
[2021-05-14 11:43:15,312] {docker.py:276} INFO - 21/05/14 14:43:15 INFO Executor: Finished task 42.0 in stage 0.0 (TID 42). 1868 bytes result sent to driver
[2021-05-14 11:43:15,313] {docker.py:276} INFO - 21/05/14 14:43:15 INFO TaskSetManager: Starting task 46.0 in stage 0.0 (TID 46) (f0b8ef7ba22f, executor driver, partition 46, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:15,313] {docker.py:276} INFO - 21/05/14 14:43:15 INFO TaskSetManager: Finished task 42.0 in stage 0.0 (TID 42) in 181 ms on f0b8ef7ba22f (executor driver) (43/281)
[2021-05-14 11:43:15,314] {docker.py:276} INFO - 21/05/14 14:43:15 INFO Executor: Running task 46.0 in stage 0.0 (TID 46)
[2021-05-14 11:43:15,364] {docker.py:276} INFO - 21/05/14 14:43:15 INFO Executor: Finished task 44.0 in stage 0.0 (TID 44). 1868 bytes result sent to driver
[2021-05-14 11:43:15,364] {docker.py:276} INFO - 21/05/14 14:43:15 INFO Executor: Finished task 43.0 in stage 0.0 (TID 43). 1868 bytes result sent to driver
[2021-05-14 11:43:15,365] {docker.py:276} INFO - 21/05/14 14:43:15 INFO TaskSetManager: Starting task 47.0 in stage 0.0 (TID 47) (f0b8ef7ba22f, executor driver, partition 47, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:15,366] {docker.py:276} INFO - 21/05/14 14:43:15 INFO Executor: Running task 47.0 in stage 0.0 (TID 47)
[2021-05-14 11:43:15,367] {docker.py:276} INFO - 21/05/14 14:43:15 INFO TaskSetManager: Finished task 44.0 in stage 0.0 (TID 44) in 180 ms on f0b8ef7ba22f (executor driver) (44/281)
[2021-05-14 11:43:15,368] {docker.py:276} INFO - 21/05/14 14:43:15 INFO TaskSetManager: Starting task 48.0 in stage 0.0 (TID 48) (f0b8ef7ba22f, executor driver, partition 48, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:15,369] {docker.py:276} INFO - 21/05/14 14:43:15 INFO TaskSetManager: Finished task 43.0 in stage 0.0 (TID 43) in 185 ms on f0b8ef7ba22f (executor driver) (45/281)
[2021-05-14 11:43:15,371] {docker.py:276} INFO - 21/05/14 14:43:15 INFO Executor: Running task 48.0 in stage 0.0 (TID 48)
[2021-05-14 11:43:15,456] {docker.py:276} INFO - 21/05/14 14:43:15 INFO Executor: Finished task 45.0 in stage 0.0 (TID 45). 1868 bytes result sent to driver
[2021-05-14 11:43:15,458] {docker.py:276} INFO - 21/05/14 14:43:15 INFO TaskSetManager: Starting task 49.0 in stage 0.0 (TID 49) (f0b8ef7ba22f, executor driver, partition 49, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:15,458] {docker.py:276} INFO - 21/05/14 14:43:15 INFO TaskSetManager: Finished task 45.0 in stage 0.0 (TID 45) in 188 ms on f0b8ef7ba22f (executor driver) (46/281)
[2021-05-14 11:43:15,460] {docker.py:276} INFO - 21/05/14 14:43:15 INFO Executor: Running task 49.0 in stage 0.0 (TID 49)
[2021-05-14 11:43:15,498] {docker.py:276} INFO - 21/05/14 14:43:15 INFO Executor: Finished task 46.0 in stage 0.0 (TID 46). 1825 bytes result sent to driver
[2021-05-14 11:43:15,500] {docker.py:276} INFO - 21/05/14 14:43:15 INFO TaskSetManager: Starting task 50.0 in stage 0.0 (TID 50) (f0b8ef7ba22f, executor driver, partition 50, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:15,501] {docker.py:276} INFO - 21/05/14 14:43:15 INFO Executor: Running task 50.0 in stage 0.0 (TID 50)
[2021-05-14 11:43:15,501] {docker.py:276} INFO - 21/05/14 14:43:15 INFO TaskSetManager: Finished task 46.0 in stage 0.0 (TID 46) in 188 ms on f0b8ef7ba22f (executor driver) (47/281)
[2021-05-14 11:43:15,546] {docker.py:276} INFO - 21/05/14 14:43:15 INFO Executor: Finished task 48.0 in stage 0.0 (TID 48). 1825 bytes result sent to driver
[2021-05-14 11:43:15,547] {docker.py:276} INFO - 21/05/14 14:43:15 INFO Executor: Finished task 47.0 in stage 0.0 (TID 47). 1825 bytes result sent to driver
[2021-05-14 11:43:15,549] {docker.py:276} INFO - 21/05/14 14:43:15 INFO TaskSetManager: Starting task 51.0 in stage 0.0 (TID 51) (f0b8ef7ba22f, executor driver, partition 51, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:15,550] {docker.py:276} INFO - 21/05/14 14:43:15 INFO TaskSetManager: Finished task 48.0 in stage 0.0 (TID 48) in 183 ms on f0b8ef7ba22f (executor driver) (48/281)
[2021-05-14 11:43:15,551] {docker.py:276} INFO - 21/05/14 14:43:15 INFO Executor: Running task 51.0 in stage 0.0 (TID 51)
[2021-05-14 11:43:15,552] {docker.py:276} INFO - 21/05/14 14:43:15 INFO TaskSetManager: Finished task 47.0 in stage 0.0 (TID 47) in 187 ms on f0b8ef7ba22f (executor driver) (49/281)
[2021-05-14 11:43:15,553] {docker.py:276} INFO - 21/05/14 14:43:15 INFO TaskSetManager: Starting task 52.0 in stage 0.0 (TID 52) (f0b8ef7ba22f, executor driver, partition 52, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:15,554] {docker.py:276} INFO - 21/05/14 14:43:15 INFO Executor: Running task 52.0 in stage 0.0 (TID 52)
[2021-05-14 11:43:15,669] {docker.py:276} INFO - 21/05/14 14:43:15 INFO Executor: Finished task 49.0 in stage 0.0 (TID 49). 1825 bytes result sent to driver
[2021-05-14 11:43:15,670] {docker.py:276} INFO - 21/05/14 14:43:15 INFO TaskSetManager: Starting task 53.0 in stage 0.0 (TID 53) (f0b8ef7ba22f, executor driver, partition 53, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:15,671] {docker.py:276} INFO - 21/05/14 14:43:15 INFO TaskSetManager: Finished task 49.0 in stage 0.0 (TID 49) in 215 ms on f0b8ef7ba22f (executor driver) (50/281)
[2021-05-14 11:43:15,673] {docker.py:276} INFO - 21/05/14 14:43:15 INFO Executor: Running task 53.0 in stage 0.0 (TID 53)
[2021-05-14 11:43:15,685] {docker.py:276} INFO - 21/05/14 14:43:15 INFO Executor: Finished task 50.0 in stage 0.0 (TID 50). 1825 bytes result sent to driver
[2021-05-14 11:43:15,686] {docker.py:276} INFO - 21/05/14 14:43:15 INFO TaskSetManager: Starting task 54.0 in stage 0.0 (TID 54) (f0b8ef7ba22f, executor driver, partition 54, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:15,687] {docker.py:276} INFO - 21/05/14 14:43:15 INFO TaskSetManager: Finished task 50.0 in stage 0.0 (TID 50) in 188 ms on f0b8ef7ba22f (executor driver) (51/281)
[2021-05-14 11:43:15,688] {docker.py:276} INFO - 21/05/14 14:43:15 INFO Executor: Running task 54.0 in stage 0.0 (TID 54)
[2021-05-14 11:43:15,728] {docker.py:276} INFO - 21/05/14 14:43:15 INFO Executor: Finished task 51.0 in stage 0.0 (TID 51). 1825 bytes result sent to driver
[2021-05-14 11:43:15,729] {docker.py:276} INFO - 21/05/14 14:43:15 INFO Executor: Finished task 52.0 in stage 0.0 (TID 52). 1825 bytes result sent to driver
[2021-05-14 11:43:15,730] {docker.py:276} INFO - 21/05/14 14:43:15 INFO TaskSetManager: Starting task 55.0 in stage 0.0 (TID 55) (f0b8ef7ba22f, executor driver, partition 55, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:15,732] {docker.py:276} INFO - 21/05/14 14:43:15 INFO TaskSetManager: Finished task 51.0 in stage 0.0 (TID 51) in 184 ms on f0b8ef7ba22f (executor driver) (52/281)
[2021-05-14 11:43:15,733] {docker.py:276} INFO - 21/05/14 14:43:15 INFO Executor: Running task 55.0 in stage 0.0 (TID 55)
[2021-05-14 11:43:15,734] {docker.py:276} INFO - 21/05/14 14:43:15 INFO TaskSetManager: Finished task 52.0 in stage 0.0 (TID 52) in 181 ms on f0b8ef7ba22f (executor driver) (53/281)
[2021-05-14 11:43:15,736] {docker.py:276} INFO - 21/05/14 14:43:15 INFO TaskSetManager: Starting task 56.0 in stage 0.0 (TID 56) (f0b8ef7ba22f, executor driver, partition 56, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:15,737] {docker.py:276} INFO - 21/05/14 14:43:15 INFO Executor: Running task 56.0 in stage 0.0 (TID 56)
[2021-05-14 11:43:15,856] {docker.py:276} INFO - 21/05/14 14:43:15 INFO Executor: Finished task 53.0 in stage 0.0 (TID 53). 1825 bytes result sent to driver
[2021-05-14 11:43:15,858] {docker.py:276} INFO - 21/05/14 14:43:15 INFO TaskSetManager: Starting task 57.0 in stage 0.0 (TID 57) (f0b8ef7ba22f, executor driver, partition 57, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:15,860] {docker.py:276} INFO - 21/05/14 14:43:15 INFO TaskSetManager: Finished task 53.0 in stage 0.0 (TID 53) in 190 ms on f0b8ef7ba22f (executor driver) (54/281)
[2021-05-14 11:43:15,861] {docker.py:276} INFO - 21/05/14 14:43:15 INFO Executor: Running task 57.0 in stage 0.0 (TID 57)
[2021-05-14 11:43:15,865] {docker.py:276} INFO - 21/05/14 14:43:15 INFO Executor: Finished task 54.0 in stage 0.0 (TID 54). 1825 bytes result sent to driver
[2021-05-14 11:43:15,866] {docker.py:276} INFO - 21/05/14 14:43:15 INFO TaskSetManager: Starting task 58.0 in stage 0.0 (TID 58) (f0b8ef7ba22f, executor driver, partition 58, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:15,867] {docker.py:276} INFO - 21/05/14 14:43:15 INFO Executor: Running task 58.0 in stage 0.0 (TID 58)
[2021-05-14 11:43:15,868] {docker.py:276} INFO - 21/05/14 14:43:15 INFO TaskSetManager: Finished task 54.0 in stage 0.0 (TID 54) in 182 ms on f0b8ef7ba22f (executor driver) (55/281)
[2021-05-14 11:43:15,910] {docker.py:276} INFO - 21/05/14 14:43:15 INFO Executor: Finished task 55.0 in stage 0.0 (TID 55). 1825 bytes result sent to driver
[2021-05-14 11:43:15,911] {docker.py:276} INFO - 21/05/14 14:43:15 INFO Executor: Finished task 56.0 in stage 0.0 (TID 56). 1825 bytes result sent to driver
[2021-05-14 11:43:15,912] {docker.py:276} INFO - 21/05/14 14:43:15 INFO TaskSetManager: Starting task 59.0 in stage 0.0 (TID 59) (f0b8ef7ba22f, executor driver, partition 59, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:15,913] {docker.py:276} INFO - 21/05/14 14:43:15 INFO Executor: Running task 59.0 in stage 0.0 (TID 59)
[2021-05-14 11:43:15,913] {docker.py:276} INFO - 21/05/14 14:43:15 INFO TaskSetManager: Starting task 60.0 in stage 0.0 (TID 60) (f0b8ef7ba22f, executor driver, partition 60, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:15,914] {docker.py:276} INFO - 21/05/14 14:43:15 INFO TaskSetManager: Finished task 55.0 in stage 0.0 (TID 55) in 186 ms on f0b8ef7ba22f (executor driver) (56/281)
21/05/14 14:43:15 INFO Executor: Running task 60.0 in stage 0.0 (TID 60)
[2021-05-14 11:43:15,915] {docker.py:276} INFO - 21/05/14 14:43:15 INFO TaskSetManager: Finished task 56.0 in stage 0.0 (TID 56) in 180 ms on f0b8ef7ba22f (executor driver) (57/281)
[2021-05-14 11:43:16,047] {docker.py:276} INFO - 21/05/14 14:43:16 INFO Executor: Finished task 57.0 in stage 0.0 (TID 57). 1868 bytes result sent to driver
[2021-05-14 11:43:16,048] {docker.py:276} INFO - 21/05/14 14:43:16 INFO Executor: Finished task 58.0 in stage 0.0 (TID 58). 1868 bytes result sent to driver
[2021-05-14 11:43:16,049] {docker.py:276} INFO - 21/05/14 14:43:16 INFO TaskSetManager: Starting task 61.0 in stage 0.0 (TID 61) (f0b8ef7ba22f, executor driver, partition 61, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:16,050] {docker.py:276} INFO - 21/05/14 14:43:16 INFO Executor: Running task 61.0 in stage 0.0 (TID 61)
[2021-05-14 11:43:16,052] {docker.py:276} INFO - 21/05/14 14:43:16 INFO TaskSetManager: Starting task 62.0 in stage 0.0 (TID 62) (f0b8ef7ba22f, executor driver, partition 62, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:16,054] {docker.py:276} INFO - 21/05/14 14:43:16 INFO Executor: Running task 62.0 in stage 0.0 (TID 62)
[2021-05-14 11:43:16,054] {docker.py:276} INFO - 21/05/14 14:43:16 INFO TaskSetManager: Finished task 57.0 in stage 0.0 (TID 57) in 197 ms on f0b8ef7ba22f (executor driver) (58/281)
[2021-05-14 11:43:16,055] {docker.py:276} INFO - 21/05/14 14:43:16 INFO TaskSetManager: Finished task 58.0 in stage 0.0 (TID 58) in 189 ms on f0b8ef7ba22f (executor driver) (59/281)
[2021-05-14 11:43:16,097] {docker.py:276} INFO - 21/05/14 14:43:16 INFO Executor: Finished task 60.0 in stage 0.0 (TID 60). 1868 bytes result sent to driver
[2021-05-14 11:43:16,099] {docker.py:276} INFO - 21/05/14 14:43:16 INFO TaskSetManager: Starting task 63.0 in stage 0.0 (TID 63) (f0b8ef7ba22f, executor driver, partition 63, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:16,100] {docker.py:276} INFO - 21/05/14 14:43:16 INFO TaskSetManager: Finished task 60.0 in stage 0.0 (TID 60) in 187 ms on f0b8ef7ba22f (executor driver) (60/281)
[2021-05-14 11:43:16,101] {docker.py:276} INFO - 21/05/14 14:43:16 INFO Executor: Running task 63.0 in stage 0.0 (TID 63)
[2021-05-14 11:43:16,108] {docker.py:276} INFO - 21/05/14 14:43:16 INFO Executor: Finished task 59.0 in stage 0.0 (TID 59). 1868 bytes result sent to driver
[2021-05-14 11:43:16,109] {docker.py:276} INFO - 21/05/14 14:43:16 INFO TaskSetManager: Finished task 59.0 in stage 0.0 (TID 59) in 198 ms on f0b8ef7ba22f (executor driver) (61/281)
[2021-05-14 11:43:16,111] {docker.py:276} INFO - 21/05/14 14:43:16 INFO TaskSetManager: Starting task 64.0 in stage 0.0 (TID 64) (f0b8ef7ba22f, executor driver, partition 64, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:16,112] {docker.py:276} INFO - 21/05/14 14:43:16 INFO Executor: Running task 64.0 in stage 0.0 (TID 64)
[2021-05-14 11:43:16,236] {docker.py:276} INFO - 21/05/14 14:43:16 INFO Executor: Finished task 62.0 in stage 0.0 (TID 62). 1825 bytes result sent to driver
[2021-05-14 11:43:16,238] {docker.py:276} INFO - 21/05/14 14:43:16 INFO Executor: Finished task 61.0 in stage 0.0 (TID 61). 1825 bytes result sent to driver
[2021-05-14 11:43:16,239] {docker.py:276} INFO - 21/05/14 14:43:16 INFO TaskSetManager: Starting task 65.0 in stage 0.0 (TID 65) (f0b8ef7ba22f, executor driver, partition 65, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:16,241] {docker.py:276} INFO - 21/05/14 14:43:16 INFO Executor: Running task 65.0 in stage 0.0 (TID 65)
[2021-05-14 11:43:16,242] {docker.py:276} INFO - 21/05/14 14:43:16 INFO TaskSetManager: Starting task 66.0 in stage 0.0 (TID 66) (f0b8ef7ba22f, executor driver, partition 66, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:16,244] {docker.py:276} INFO - 21/05/14 14:43:16 INFO TaskSetManager: Finished task 61.0 in stage 0.0 (TID 61) in 196 ms on f0b8ef7ba22f (executor driver) (62/281)
[2021-05-14 11:43:16,245] {docker.py:276} INFO - 21/05/14 14:43:16 INFO TaskSetManager: Finished task 62.0 in stage 0.0 (TID 62) in 193 ms on f0b8ef7ba22f (executor driver) (63/281)
[2021-05-14 11:43:16,246] {docker.py:276} INFO - 21/05/14 14:43:16 INFO Executor: Running task 66.0 in stage 0.0 (TID 66)
[2021-05-14 11:43:16,274] {docker.py:276} INFO - 21/05/14 14:43:16 INFO Executor: Finished task 63.0 in stage 0.0 (TID 63). 1825 bytes result sent to driver
[2021-05-14 11:43:16,276] {docker.py:276} INFO - 21/05/14 14:43:16 INFO TaskSetManager: Starting task 67.0 in stage 0.0 (TID 67) (f0b8ef7ba22f, executor driver, partition 67, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:16,277] {docker.py:276} INFO - 21/05/14 14:43:16 INFO Executor: Running task 67.0 in stage 0.0 (TID 67)
21/05/14 14:43:16 INFO TaskSetManager: Finished task 63.0 in stage 0.0 (TID 63) in 180 ms on f0b8ef7ba22f (executor driver) (64/281)
[2021-05-14 11:43:16,282] {docker.py:276} INFO - 21/05/14 14:43:16 INFO Executor: Finished task 64.0 in stage 0.0 (TID 64). 1825 bytes result sent to driver
[2021-05-14 11:43:16,283] {docker.py:276} INFO - 21/05/14 14:43:16 INFO TaskSetManager: Starting task 68.0 in stage 0.0 (TID 68) (f0b8ef7ba22f, executor driver, partition 68, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:16,284] {docker.py:276} INFO - 21/05/14 14:43:16 INFO TaskSetManager: Finished task 64.0 in stage 0.0 (TID 64) in 174 ms on f0b8ef7ba22f (executor driver) (65/281)
21/05/14 14:43:16 INFO Executor: Running task 68.0 in stage 0.0 (TID 68)
[2021-05-14 11:43:16,427] {docker.py:276} INFO - 21/05/14 14:43:16 INFO Executor: Finished task 66.0 in stage 0.0 (TID 66). 1825 bytes result sent to driver
[2021-05-14 11:43:16,429] {docker.py:276} INFO - 21/05/14 14:43:16 INFO TaskSetManager: Starting task 69.0 in stage 0.0 (TID 69) (f0b8ef7ba22f, executor driver, partition 69, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:16,431] {docker.py:276} INFO - 21/05/14 14:43:16 INFO Executor: Finished task 65.0 in stage 0.0 (TID 65). 1825 bytes result sent to driver
[2021-05-14 11:43:16,431] {docker.py:276} INFO - 21/05/14 14:43:16 INFO TaskSetManager: Finished task 66.0 in stage 0.0 (TID 66) in 189 ms on f0b8ef7ba22f (executor driver) (66/281)
[2021-05-14 11:43:16,432] {docker.py:276} INFO - 21/05/14 14:43:16 INFO Executor: Running task 69.0 in stage 0.0 (TID 69)
[2021-05-14 11:43:16,433] {docker.py:276} INFO - 21/05/14 14:43:16 INFO TaskSetManager: Starting task 70.0 in stage 0.0 (TID 70) (f0b8ef7ba22f, executor driver, partition 70, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:16,433] {docker.py:276} INFO - 21/05/14 14:43:16 INFO TaskSetManager: Finished task 65.0 in stage 0.0 (TID 65) in 196 ms on f0b8ef7ba22f (executor driver) (67/281)
[2021-05-14 11:43:16,434] {docker.py:276} INFO - 21/05/14 14:43:16 INFO Executor: Running task 70.0 in stage 0.0 (TID 70)
[2021-05-14 11:43:16,452] {docker.py:276} INFO - 21/05/14 14:43:16 INFO Executor: Finished task 67.0 in stage 0.0 (TID 67). 1825 bytes result sent to driver
[2021-05-14 11:43:16,453] {docker.py:276} INFO - 21/05/14 14:43:16 INFO TaskSetManager: Starting task 71.0 in stage 0.0 (TID 71) (f0b8ef7ba22f, executor driver, partition 71, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:16,454] {docker.py:276} INFO - 21/05/14 14:43:16 INFO TaskSetManager: Finished task 67.0 in stage 0.0 (TID 67) in 179 ms on f0b8ef7ba22f (executor driver) (68/281)
[2021-05-14 11:43:16,455] {docker.py:276} INFO - 21/05/14 14:43:16 INFO Executor: Running task 71.0 in stage 0.0 (TID 71)
[2021-05-14 11:43:16,460] {docker.py:276} INFO - 21/05/14 14:43:16 INFO Executor: Finished task 68.0 in stage 0.0 (TID 68). 1825 bytes result sent to driver
[2021-05-14 11:43:16,461] {docker.py:276} INFO - 21/05/14 14:43:16 INFO TaskSetManager: Starting task 72.0 in stage 0.0 (TID 72) (f0b8ef7ba22f, executor driver, partition 72, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:16,462] {docker.py:276} INFO - 21/05/14 14:43:16 INFO Executor: Running task 72.0 in stage 0.0 (TID 72)
21/05/14 14:43:16 INFO TaskSetManager: Finished task 68.0 in stage 0.0 (TID 68) in 179 ms on f0b8ef7ba22f (executor driver) (69/281)
[2021-05-14 11:43:16,619] {docker.py:276} INFO - 21/05/14 14:43:16 INFO Executor: Finished task 70.0 in stage 0.0 (TID 70). 1825 bytes result sent to driver
[2021-05-14 11:43:16,621] {docker.py:276} INFO - 21/05/14 14:43:16 INFO TaskSetManager: Starting task 73.0 in stage 0.0 (TID 73) (f0b8ef7ba22f, executor driver, partition 73, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:16,623] {docker.py:276} INFO - 21/05/14 14:43:16 INFO Executor: Finished task 69.0 in stage 0.0 (TID 69). 1825 bytes result sent to driver
[2021-05-14 11:43:16,623] {docker.py:276} INFO - 21/05/14 14:43:16 INFO Executor: Running task 73.0 in stage 0.0 (TID 73)
[2021-05-14 11:43:16,623] {docker.py:276} INFO - 21/05/14 14:43:16 INFO TaskSetManager: Finished task 70.0 in stage 0.0 (TID 70) in 190 ms on f0b8ef7ba22f (executor driver) (70/281)
[2021-05-14 11:43:16,625] {docker.py:276} INFO - 21/05/14 14:43:16 INFO TaskSetManager: Starting task 74.0 in stage 0.0 (TID 74) (f0b8ef7ba22f, executor driver, partition 74, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:16,626] {docker.py:276} INFO - 21/05/14 14:43:16 INFO Executor: Running task 74.0 in stage 0.0 (TID 74)
21/05/14 14:43:16 INFO TaskSetManager: Finished task 69.0 in stage 0.0 (TID 69) in 199 ms on f0b8ef7ba22f (executor driver) (71/281)
[2021-05-14 11:43:16,632] {docker.py:276} INFO - 21/05/14 14:43:16 INFO Executor: Finished task 71.0 in stage 0.0 (TID 71). 1825 bytes result sent to driver
[2021-05-14 11:43:16,641] {docker.py:276} INFO - 21/05/14 14:43:16 INFO TaskSetManager: Starting task 75.0 in stage 0.0 (TID 75) (f0b8ef7ba22f, executor driver, partition 75, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:16,642] {docker.py:276} INFO - 21/05/14 14:43:16 INFO TaskSetManager: Finished task 71.0 in stage 0.0 (TID 71) in 188 ms on f0b8ef7ba22f (executor driver) (72/281)
[2021-05-14 11:43:16,643] {docker.py:276} INFO - 21/05/14 14:43:16 INFO Executor: Running task 75.0 in stage 0.0 (TID 75)
[2021-05-14 11:43:16,657] {docker.py:276} INFO - 21/05/14 14:43:16 INFO Executor: Finished task 72.0 in stage 0.0 (TID 72). 1868 bytes result sent to driver
[2021-05-14 11:43:16,659] {docker.py:276} INFO - 21/05/14 14:43:16 INFO TaskSetManager: Starting task 76.0 in stage 0.0 (TID 76) (f0b8ef7ba22f, executor driver, partition 76, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:16,660] {docker.py:276} INFO - 21/05/14 14:43:16 INFO Executor: Running task 76.0 in stage 0.0 (TID 76)
[2021-05-14 11:43:16,662] {docker.py:276} INFO - 21/05/14 14:43:16 INFO TaskSetManager: Finished task 72.0 in stage 0.0 (TID 72) in 200 ms on f0b8ef7ba22f (executor driver) (73/281)
[2021-05-14 11:43:16,817] {docker.py:276} INFO - 21/05/14 14:43:16 INFO Executor: Finished task 74.0 in stage 0.0 (TID 74). 1868 bytes result sent to driver
[2021-05-14 11:43:16,819] {docker.py:276} INFO - 21/05/14 14:43:16 INFO TaskSetManager: Starting task 77.0 in stage 0.0 (TID 77) (f0b8ef7ba22f, executor driver, partition 77, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:16,820] {docker.py:276} INFO - 21/05/14 14:43:16 INFO TaskSetManager: Finished task 74.0 in stage 0.0 (TID 74) in 195 ms on f0b8ef7ba22f (executor driver) (74/281)
[2021-05-14 11:43:16,821] {docker.py:276} INFO - 21/05/14 14:43:16 INFO Executor: Finished task 73.0 in stage 0.0 (TID 73). 1868 bytes result sent to driver
[2021-05-14 11:43:16,823] {docker.py:276} INFO - 21/05/14 14:43:16 INFO Executor: Running task 77.0 in stage 0.0 (TID 77)
[2021-05-14 11:43:16,825] {docker.py:276} INFO - 21/05/14 14:43:16 INFO Executor: Finished task 75.0 in stage 0.0 (TID 75). 1825 bytes result sent to driver
[2021-05-14 11:43:16,826] {docker.py:276} INFO - 21/05/14 14:43:16 INFO TaskSetManager: Starting task 78.0 in stage 0.0 (TID 78) (f0b8ef7ba22f, executor driver, partition 78, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:16,827] {docker.py:276} INFO - 21/05/14 14:43:16 INFO TaskSetManager: Finished task 73.0 in stage 0.0 (TID 73) in 206 ms on f0b8ef7ba22f (executor driver) (75/281)
[2021-05-14 11:43:16,827] {docker.py:276} INFO - 21/05/14 14:43:16 INFO Executor: Running task 78.0 in stage 0.0 (TID 78)
[2021-05-14 11:43:16,828] {docker.py:276} INFO - 21/05/14 14:43:16 INFO TaskSetManager: Starting task 79.0 in stage 0.0 (TID 79) (f0b8ef7ba22f, executor driver, partition 79, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:16,830] {docker.py:276} INFO - 21/05/14 14:43:16 INFO Executor: Running task 79.0 in stage 0.0 (TID 79)
21/05/14 14:43:16 INFO TaskSetManager: Finished task 75.0 in stage 0.0 (TID 75) in 197 ms on f0b8ef7ba22f (executor driver) (76/281)
[2021-05-14 11:43:16,832] {docker.py:276} INFO - 21/05/14 14:43:16 INFO Executor: Finished task 76.0 in stage 0.0 (TID 76). 1825 bytes result sent to driver
[2021-05-14 11:43:16,833] {docker.py:276} INFO - 21/05/14 14:43:16 INFO TaskSetManager: Starting task 80.0 in stage 0.0 (TID 80) (f0b8ef7ba22f, executor driver, partition 80, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:16,834] {docker.py:276} INFO - 21/05/14 14:43:16 INFO TaskSetManager: Finished task 76.0 in stage 0.0 (TID 76) in 176 ms on f0b8ef7ba22f (executor driver) (77/281)
[2021-05-14 11:43:16,835] {docker.py:276} INFO - 21/05/14 14:43:16 INFO Executor: Running task 80.0 in stage 0.0 (TID 80)
[2021-05-14 11:43:17,003] {docker.py:276} INFO - 21/05/14 14:43:17 INFO Executor: Finished task 77.0 in stage 0.0 (TID 77). 1825 bytes result sent to driver
[2021-05-14 11:43:17,005] {docker.py:276} INFO - 21/05/14 14:43:17 INFO TaskSetManager: Starting task 81.0 in stage 0.0 (TID 81) (f0b8ef7ba22f, executor driver, partition 81, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:17,006] {docker.py:276} INFO - 21/05/14 14:43:17 INFO TaskSetManager: Finished task 77.0 in stage 0.0 (TID 77) in 188 ms on f0b8ef7ba22f (executor driver) (78/281)
[2021-05-14 11:43:17,007] {docker.py:276} INFO - 21/05/14 14:43:17 INFO Executor: Running task 81.0 in stage 0.0 (TID 81)
[2021-05-14 11:43:17,008] {docker.py:276} INFO - 21/05/14 14:43:17 INFO Executor: Finished task 78.0 in stage 0.0 (TID 78). 1825 bytes result sent to driver
[2021-05-14 11:43:17,010] {docker.py:276} INFO - 21/05/14 14:43:17 INFO TaskSetManager: Starting task 82.0 in stage 0.0 (TID 82) (f0b8ef7ba22f, executor driver, partition 82, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:17,011] {docker.py:276} INFO - 21/05/14 14:43:17 INFO TaskSetManager: Finished task 78.0 in stage 0.0 (TID 78) in 188 ms on f0b8ef7ba22f (executor driver) (79/281)
[2021-05-14 11:43:17,012] {docker.py:276} INFO - 21/05/14 14:43:17 INFO Executor: Running task 82.0 in stage 0.0 (TID 82)
[2021-05-14 11:43:17,013] {docker.py:276} INFO - 21/05/14 14:43:17 INFO Executor: Finished task 80.0 in stage 0.0 (TID 80). 1825 bytes result sent to driver
[2021-05-14 11:43:17,014] {docker.py:276} INFO - 21/05/14 14:43:17 INFO TaskSetManager: Finished task 80.0 in stage 0.0 (TID 80) in 182 ms on f0b8ef7ba22f (executor driver) (80/281)
[2021-05-14 11:43:17,015] {docker.py:276} INFO - 21/05/14 14:43:17 INFO Executor: Finished task 79.0 in stage 0.0 (TID 79). 1825 bytes result sent to driver
[2021-05-14 11:43:17,016] {docker.py:276} INFO - 21/05/14 14:43:17 INFO TaskSetManager: Starting task 83.0 in stage 0.0 (TID 83) (f0b8ef7ba22f, executor driver, partition 83, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:17,017] {docker.py:276} INFO - 21/05/14 14:43:17 INFO Executor: Running task 83.0 in stage 0.0 (TID 83)
[2021-05-14 11:43:17,018] {docker.py:276} INFO - 21/05/14 14:43:17 INFO TaskSetManager: Starting task 84.0 in stage 0.0 (TID 84) (f0b8ef7ba22f, executor driver, partition 84, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:17,019] {docker.py:276} INFO - 21/05/14 14:43:17 INFO Executor: Running task 84.0 in stage 0.0 (TID 84)
21/05/14 14:43:17 INFO TaskSetManager: Finished task 79.0 in stage 0.0 (TID 79) in 191 ms on f0b8ef7ba22f (executor driver) (81/281)
[2021-05-14 11:43:17,191] {docker.py:276} INFO - 21/05/14 14:43:17 INFO Executor: Finished task 83.0 in stage 0.0 (TID 83). 1825 bytes result sent to driver
[2021-05-14 11:43:17,193] {docker.py:276} INFO - 21/05/14 14:43:17 INFO TaskSetManager: Starting task 85.0 in stage 0.0 (TID 85) (f0b8ef7ba22f, executor driver, partition 85, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:17,194] {docker.py:276} INFO - 21/05/14 14:43:17 INFO TaskSetManager: Finished task 83.0 in stage 0.0 (TID 83) in 178 ms on f0b8ef7ba22f (executor driver) (82/281)
[2021-05-14 11:43:17,200] {docker.py:276} INFO - 21/05/14 14:43:17 INFO Executor: Running task 85.0 in stage 0.0 (TID 85)
[2021-05-14 11:43:17,202] {docker.py:276} INFO - 21/05/14 14:43:17 INFO Executor: Finished task 82.0 in stage 0.0 (TID 82). 1825 bytes result sent to driver
[2021-05-14 11:43:17,202] {docker.py:276} INFO - 21/05/14 14:43:17 INFO Executor: Finished task 84.0 in stage 0.0 (TID 84). 1825 bytes result sent to driver
[2021-05-14 11:43:17,203] {docker.py:276} INFO - 21/05/14 14:43:17 INFO TaskSetManager: Starting task 86.0 in stage 0.0 (TID 86) (f0b8ef7ba22f, executor driver, partition 86, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:17,203] {docker.py:276} INFO - 21/05/14 14:43:17 INFO Executor: Finished task 81.0 in stage 0.0 (TID 81). 1825 bytes result sent to driver
[2021-05-14 11:43:17,204] {docker.py:276} INFO - 21/05/14 14:43:17 INFO TaskSetManager: Starting task 87.0 in stage 0.0 (TID 87) (f0b8ef7ba22f, executor driver, partition 87, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:17,204] {docker.py:276} INFO - 21/05/14 14:43:17 INFO Executor: Running task 86.0 in stage 0.0 (TID 86)
[2021-05-14 11:43:17,205] {docker.py:276} INFO - 21/05/14 14:43:17 INFO TaskSetManager: Finished task 82.0 in stage 0.0 (TID 82) in 194 ms on f0b8ef7ba22f (executor driver) (83/281)
[2021-05-14 11:43:17,212] {docker.py:276} INFO - 21/05/14 14:43:17 INFO TaskSetManager: Starting task 88.0 in stage 0.0 (TID 88) (f0b8ef7ba22f, executor driver, partition 88, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
21/05/14 14:43:17 INFO TaskSetManager: Finished task 84.0 in stage 0.0 (TID 84) in 188 ms on f0b8ef7ba22f (executor driver) (84/281)
21/05/14 14:43:17 INFO TaskSetManager: Finished task 81.0 in stage 0.0 (TID 81) in 202 ms on f0b8ef7ba22f (executor driver) (85/281)
[2021-05-14 11:43:17,214] {docker.py:276} INFO - 21/05/14 14:43:17 INFO Executor: Running task 88.0 in stage 0.0 (TID 88)
[2021-05-14 11:43:17,214] {docker.py:276} INFO - 21/05/14 14:43:17 INFO Executor: Running task 87.0 in stage 0.0 (TID 87)
[2021-05-14 11:43:17,392] {docker.py:276} INFO - 21/05/14 14:43:17 INFO Executor: Finished task 85.0 in stage 0.0 (TID 85). 1825 bytes result sent to driver
[2021-05-14 11:43:17,394] {docker.py:276} INFO - 21/05/14 14:43:17 INFO Executor: Finished task 87.0 in stage 0.0 (TID 87). 1825 bytes result sent to driver
[2021-05-14 11:43:17,396] {docker.py:276} INFO - 21/05/14 14:43:17 INFO TaskSetManager: Starting task 89.0 in stage 0.0 (TID 89) (f0b8ef7ba22f, executor driver, partition 89, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:17,396] {docker.py:276} INFO - 21/05/14 14:43:17 INFO Executor: Finished task 88.0 in stage 0.0 (TID 88). 1825 bytes result sent to driver
[2021-05-14 11:43:17,398] {docker.py:276} INFO - 21/05/14 14:43:17 INFO TaskSetManager: Starting task 90.0 in stage 0.0 (TID 90) (f0b8ef7ba22f, executor driver, partition 90, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:17,399] {docker.py:276} INFO - 21/05/14 14:43:17 INFO Executor: Running task 89.0 in stage 0.0 (TID 89)
[2021-05-14 11:43:17,400] {docker.py:276} INFO - 21/05/14 14:43:17 INFO Executor: Running task 90.0 in stage 0.0 (TID 90)
[2021-05-14 11:43:17,400] {docker.py:276} INFO - 21/05/14 14:43:17 INFO Executor: Finished task 86.0 in stage 0.0 (TID 86). 1868 bytes result sent to driver
21/05/14 14:43:17 INFO TaskSetManager: Starting task 91.0 in stage 0.0 (TID 91) (f0b8ef7ba22f, executor driver, partition 91, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:17,402] {docker.py:276} INFO - 21/05/14 14:43:17 INFO TaskSetManager: Finished task 87.0 in stage 0.0 (TID 87) in 198 ms on f0b8ef7ba22f (executor driver) (86/281)
[2021-05-14 11:43:17,402] {docker.py:276} INFO - 21/05/14 14:43:17 INFO Executor: Running task 91.0 in stage 0.0 (TID 91)
[2021-05-14 11:43:17,403] {docker.py:276} INFO - 21/05/14 14:43:17 INFO TaskSetManager: Starting task 92.0 in stage 0.0 (TID 92) (f0b8ef7ba22f, executor driver, partition 92, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:17,404] {docker.py:276} INFO - 21/05/14 14:43:17 INFO TaskSetManager: Finished task 85.0 in stage 0.0 (TID 85) in 210 ms on f0b8ef7ba22f (executor driver) (87/281)
[2021-05-14 11:43:17,405] {docker.py:276} INFO - 21/05/14 14:43:17 INFO Executor: Running task 92.0 in stage 0.0 (TID 92)
[2021-05-14 11:43:17,406] {docker.py:276} INFO - 21/05/14 14:43:17 INFO TaskSetManager: Finished task 88.0 in stage 0.0 (TID 88) in 200 ms on f0b8ef7ba22f (executor driver) (88/281)
[2021-05-14 11:43:17,406] {docker.py:276} INFO - 21/05/14 14:43:17 INFO TaskSetManager: Finished task 86.0 in stage 0.0 (TID 86) in 205 ms on f0b8ef7ba22f (executor driver) (89/281)
[2021-05-14 11:43:17,589] {docker.py:276} INFO - 21/05/14 14:43:17 INFO Executor: Finished task 89.0 in stage 0.0 (TID 89). 1868 bytes result sent to driver
[2021-05-14 11:43:17,590] {docker.py:276} INFO - 21/05/14 14:43:17 INFO Executor: Finished task 90.0 in stage 0.0 (TID 90). 1868 bytes result sent to driver
[2021-05-14 11:43:17,591] {docker.py:276} INFO - 21/05/14 14:43:17 INFO TaskSetManager: Starting task 93.0 in stage 0.0 (TID 93) (f0b8ef7ba22f, executor driver, partition 93, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:17,593] {docker.py:276} INFO - 21/05/14 14:43:17 INFO Executor: Running task 93.0 in stage 0.0 (TID 93)
[2021-05-14 11:43:17,593] {docker.py:276} INFO - 21/05/14 14:43:17 INFO TaskSetManager: Starting task 94.0 in stage 0.0 (TID 94) (f0b8ef7ba22f, executor driver, partition 94, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:17,595] {docker.py:276} INFO - 21/05/14 14:43:17 INFO TaskSetManager: Finished task 89.0 in stage 0.0 (TID 89) in 203 ms on f0b8ef7ba22f (executor driver) (90/281)
21/05/14 14:43:17 INFO Executor: Running task 94.0 in stage 0.0 (TID 94)
[2021-05-14 11:43:17,601] {docker.py:276} INFO - 21/05/14 14:43:17 INFO TaskSetManager: Finished task 90.0 in stage 0.0 (TID 90) in 205 ms on f0b8ef7ba22f (executor driver) (91/281)
[2021-05-14 11:43:17,605] {docker.py:276} INFO - 21/05/14 14:43:17 INFO Executor: Finished task 92.0 in stage 0.0 (TID 92). 1868 bytes result sent to driver
[2021-05-14 11:43:17,606] {docker.py:276} INFO - 21/05/14 14:43:17 INFO Executor: Finished task 91.0 in stage 0.0 (TID 91). 1825 bytes result sent to driver
[2021-05-14 11:43:17,608] {docker.py:276} INFO - 21/05/14 14:43:17 INFO TaskSetManager: Starting task 95.0 in stage 0.0 (TID 95) (f0b8ef7ba22f, executor driver, partition 95, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:17,610] {docker.py:276} INFO - 21/05/14 14:43:17 INFO Executor: Running task 95.0 in stage 0.0 (TID 95)
[2021-05-14 11:43:17,611] {docker.py:276} INFO - 21/05/14 14:43:17 INFO TaskSetManager: Starting task 96.0 in stage 0.0 (TID 96) (f0b8ef7ba22f, executor driver, partition 96, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:17,617] {docker.py:276} INFO - 21/05/14 14:43:17 INFO TaskSetManager: Finished task 91.0 in stage 0.0 (TID 91) in 217 ms on f0b8ef7ba22f (executor driver) (92/281)
21/05/14 14:43:17 INFO Executor: Running task 96.0 in stage 0.0 (TID 96)
[2021-05-14 11:43:17,618] {docker.py:276} INFO - 21/05/14 14:43:17 INFO TaskSetManager: Finished task 92.0 in stage 0.0 (TID 92) in 217 ms on f0b8ef7ba22f (executor driver) (93/281)
[2021-05-14 11:43:17,797] {docker.py:276} INFO - 21/05/14 14:43:17 INFO Executor: Finished task 93.0 in stage 0.0 (TID 93). 1825 bytes result sent to driver
[2021-05-14 11:43:17,798] {docker.py:276} INFO - 21/05/14 14:43:17 INFO Executor: Finished task 94.0 in stage 0.0 (TID 94). 1825 bytes result sent to driver
[2021-05-14 11:43:17,805] {docker.py:276} INFO - 21/05/14 14:43:17 INFO TaskSetManager: Starting task 97.0 in stage 0.0 (TID 97) (f0b8ef7ba22f, executor driver, partition 97, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:17,817] {docker.py:276} INFO - 21/05/14 14:43:17 INFO TaskSetManager: Finished task 93.0 in stage 0.0 (TID 93) in 203 ms on f0b8ef7ba22f (executor driver) (94/281)
[2021-05-14 11:43:17,818] {docker.py:276} INFO - 21/05/14 14:43:17 INFO Executor: Running task 97.0 in stage 0.0 (TID 97)
[2021-05-14 11:43:17,818] {docker.py:276} INFO - 21/05/14 14:43:17 INFO TaskSetManager: Finished task 94.0 in stage 0.0 (TID 94) in 209 ms on f0b8ef7ba22f (executor driver) (95/281)
[2021-05-14 11:43:17,822] {docker.py:276} INFO - 21/05/14 14:43:17 INFO Executor: Finished task 95.0 in stage 0.0 (TID 95). 1825 bytes result sent to driver
[2021-05-14 11:43:17,823] {docker.py:276} INFO - 21/05/14 14:43:17 INFO TaskSetManager: Starting task 98.0 in stage 0.0 (TID 98) (f0b8ef7ba22f, executor driver, partition 98, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:17,823] {docker.py:276} INFO - 21/05/14 14:43:17 INFO Executor: Running task 98.0 in stage 0.0 (TID 98)
[2021-05-14 11:43:17,824] {docker.py:276} INFO - 21/05/14 14:43:17 INFO TaskSetManager: Starting task 99.0 in stage 0.0 (TID 99) (f0b8ef7ba22f, executor driver, partition 99, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:17,824] {docker.py:276} INFO - 21/05/14 14:43:17 INFO Executor: Running task 99.0 in stage 0.0 (TID 99)
[2021-05-14 11:43:17,824] {docker.py:276} INFO - 21/05/14 14:43:17 INFO TaskSetManager: Finished task 95.0 in stage 0.0 (TID 95) in 199 ms on f0b8ef7ba22f (executor driver) (96/281)
[2021-05-14 11:43:17,841] {docker.py:276} INFO - 21/05/14 14:43:17 INFO Executor: Finished task 96.0 in stage 0.0 (TID 96). 1825 bytes result sent to driver
21/05/14 14:43:17 INFO TaskSetManager: Starting task 100.0 in stage 0.0 (TID 100) (f0b8ef7ba22f, executor driver, partition 100, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:17,842] {docker.py:276} INFO - 21/05/14 14:43:17 INFO TaskSetManager: Finished task 96.0 in stage 0.0 (TID 96) in 222 ms on f0b8ef7ba22f (executor driver) (97/281)
21/05/14 14:43:17 INFO Executor: Running task 100.0 in stage 0.0 (TID 100)
[2021-05-14 11:43:17,992] {docker.py:276} INFO - 21/05/14 14:43:18 INFO Executor: Finished task 99.0 in stage 0.0 (TID 99). 1825 bytes result sent to driver
[2021-05-14 11:43:17,994] {docker.py:276} INFO - 21/05/14 14:43:18 INFO TaskSetManager: Starting task 101.0 in stage 0.0 (TID 101) (f0b8ef7ba22f, executor driver, partition 101, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:17,995] {docker.py:276} INFO - 21/05/14 14:43:18 INFO TaskSetManager: Finished task 99.0 in stage 0.0 (TID 99) in 193 ms on f0b8ef7ba22f (executor driver) (98/281)
[2021-05-14 11:43:17,996] {docker.py:276} INFO - 21/05/14 14:43:18 INFO Executor: Finished task 98.0 in stage 0.0 (TID 98). 1825 bytes result sent to driver
[2021-05-14 11:43:17,998] {docker.py:276} INFO - 21/05/14 14:43:18 INFO TaskSetManager: Finished task 98.0 in stage 0.0 (TID 98) in 196 ms on f0b8ef7ba22f (executor driver) (99/281)
[2021-05-14 11:43:17,999] {docker.py:276} INFO - 21/05/14 14:43:18 INFO Executor: Finished task 97.0 in stage 0.0 (TID 97). 1825 bytes result sent to driver
[2021-05-14 11:43:18,000] {docker.py:276} INFO - 21/05/14 14:43:18 INFO TaskSetManager: Starting task 102.0 in stage 0.0 (TID 102) (f0b8ef7ba22f, executor driver, partition 102, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:18,001] {docker.py:276} INFO - 21/05/14 14:43:18 INFO Executor: Running task 102.0 in stage 0.0 (TID 102)
[2021-05-14 11:43:18,002] {docker.py:276} INFO - 21/05/14 14:43:18 INFO Executor: Running task 101.0 in stage 0.0 (TID 101)
[2021-05-14 11:43:18,002] {docker.py:276} INFO - 21/05/14 14:43:18 INFO TaskSetManager: Starting task 103.0 in stage 0.0 (TID 103) (f0b8ef7ba22f, executor driver, partition 103, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:18,009] {docker.py:276} INFO - 21/05/14 14:43:18 INFO TaskSetManager: Finished task 97.0 in stage 0.0 (TID 97) in 218 ms on f0b8ef7ba22f (executor driver) (100/281)
21/05/14 14:43:18 INFO Executor: Running task 103.0 in stage 0.0 (TID 103)
[2021-05-14 11:43:18,022] {docker.py:276} INFO - 21/05/14 14:43:18 INFO Executor: Finished task 100.0 in stage 0.0 (TID 100). 1825 bytes result sent to driver
[2021-05-14 11:43:18,024] {docker.py:276} INFO - 21/05/14 14:43:18 INFO TaskSetManager: Starting task 104.0 in stage 0.0 (TID 104) (f0b8ef7ba22f, executor driver, partition 104, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:18,025] {docker.py:276} INFO - 21/05/14 14:43:18 INFO TaskSetManager: Finished task 100.0 in stage 0.0 (TID 100) in 195 ms on f0b8ef7ba22f (executor driver) (101/281)
[2021-05-14 11:43:18,025] {docker.py:276} INFO - 21/05/14 14:43:18 INFO Executor: Running task 104.0 in stage 0.0 (TID 104)
[2021-05-14 11:43:18,185] {docker.py:276} INFO - 21/05/14 14:43:18 INFO Executor: Finished task 101.0 in stage 0.0 (TID 101). 1825 bytes result sent to driver
21/05/14 14:43:18 INFO Executor: Finished task 102.0 in stage 0.0 (TID 102). 1825 bytes result sent to driver
21/05/14 14:43:18 INFO Executor: Finished task 103.0 in stage 0.0 (TID 103). 1825 bytes result sent to driver
[2021-05-14 11:43:18,187] {docker.py:276} INFO - 21/05/14 14:43:18 INFO TaskSetManager: Starting task 105.0 in stage 0.0 (TID 105) (f0b8ef7ba22f, executor driver, partition 105, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:18,189] {docker.py:276} INFO - 21/05/14 14:43:18 INFO Executor: Running task 105.0 in stage 0.0 (TID 105)
[2021-05-14 11:43:18,189] {docker.py:276} INFO - 21/05/14 14:43:18 INFO TaskSetManager: Starting task 106.0 in stage 0.0 (TID 106) (f0b8ef7ba22f, executor driver, partition 106, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:18,191] {docker.py:276} INFO - 21/05/14 14:43:18 INFO TaskSetManager: Starting task 107.0 in stage 0.0 (TID 107) (f0b8ef7ba22f, executor driver, partition 107, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:18,192] {docker.py:276} INFO - 21/05/14 14:43:18 INFO TaskSetManager: Finished task 101.0 in stage 0.0 (TID 101) in 198 ms on f0b8ef7ba22f (executor driver) (102/281)
[2021-05-14 11:43:18,193] {docker.py:276} INFO - 21/05/14 14:43:18 INFO Executor: Running task 106.0 in stage 0.0 (TID 106)
[2021-05-14 11:43:18,193] {docker.py:276} INFO - 21/05/14 14:43:18 INFO TaskSetManager: Finished task 103.0 in stage 0.0 (TID 103) in 191 ms on f0b8ef7ba22f (executor driver) (103/281)
[2021-05-14 11:43:18,194] {docker.py:276} INFO - 21/05/14 14:43:18 INFO Executor: Running task 107.0 in stage 0.0 (TID 107)
[2021-05-14 11:43:18,195] {docker.py:276} INFO - 21/05/14 14:43:18 INFO TaskSetManager: Finished task 102.0 in stage 0.0 (TID 102) in 195 ms on f0b8ef7ba22f (executor driver) (104/281)
[2021-05-14 11:43:18,204] {docker.py:276} INFO - 21/05/14 14:43:18 INFO Executor: Finished task 104.0 in stage 0.0 (TID 104). 1868 bytes result sent to driver
[2021-05-14 11:43:18,205] {docker.py:276} INFO - 21/05/14 14:43:18 INFO TaskSetManager: Starting task 108.0 in stage 0.0 (TID 108) (f0b8ef7ba22f, executor driver, partition 108, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:18,206] {docker.py:276} INFO - 21/05/14 14:43:18 INFO TaskSetManager: Finished task 104.0 in stage 0.0 (TID 104) in 183 ms on f0b8ef7ba22f (executor driver) (105/281)
[2021-05-14 11:43:18,206] {docker.py:276} INFO - 21/05/14 14:43:18 INFO Executor: Running task 108.0 in stage 0.0 (TID 108)
[2021-05-14 11:43:18,373] {docker.py:276} INFO - 21/05/14 14:43:18 INFO Executor: Finished task 106.0 in stage 0.0 (TID 106). 1868 bytes result sent to driver
[2021-05-14 11:43:18,379] {docker.py:276} INFO - 21/05/14 14:43:18 INFO TaskSetManager: Starting task 109.0 in stage 0.0 (TID 109) (f0b8ef7ba22f, executor driver, partition 109, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
21/05/14 14:43:18 INFO Executor: Running task 109.0 in stage 0.0 (TID 109)
21/05/14 14:43:18 INFO TaskSetManager: Finished task 106.0 in stage 0.0 (TID 106) in 186 ms on f0b8ef7ba22f (executor driver) (106/281)
[2021-05-14 11:43:18,389] {docker.py:276} INFO - 21/05/14 14:43:18 INFO Executor: Finished task 108.0 in stage 0.0 (TID 108). 1825 bytes result sent to driver
21/05/14 14:43:18 INFO Executor: Finished task 105.0 in stage 0.0 (TID 105). 1868 bytes result sent to driver
21/05/14 14:43:18 INFO TaskSetManager: Starting task 110.0 in stage 0.0 (TID 110) (f0b8ef7ba22f, executor driver, partition 110, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
21/05/14 14:43:18 INFO TaskSetManager: Starting task 111.0 in stage 0.0 (TID 111) (f0b8ef7ba22f, executor driver, partition 111, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
21/05/14 14:43:18 INFO Executor: Running task 110.0 in stage 0.0 (TID 110)
21/05/14 14:43:18 INFO TaskSetManager: Finished task 105.0 in stage 0.0 (TID 105) in 194 ms on f0b8ef7ba22f (executor driver) (107/281)
21/05/14 14:43:18 INFO TaskSetManager: Finished task 108.0 in stage 0.0 (TID 108) in 176 ms on f0b8ef7ba22f (executor driver) (108/281)
[2021-05-14 11:43:18,389] {docker.py:276} INFO - 21/05/14 14:43:18 INFO Executor: Finished task 107.0 in stage 0.0 (TID 107). 1868 bytes result sent to driver
21/05/14 14:43:18 INFO Executor: Running task 111.0 in stage 0.0 (TID 111)
21/05/14 14:43:18 INFO TaskSetManager: Starting task 112.0 in stage 0.0 (TID 112) (f0b8ef7ba22f, executor driver, partition 112, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
21/05/14 14:43:18 INFO TaskSetManager: Finished task 107.0 in stage 0.0 (TID 107) in 195 ms on f0b8ef7ba22f (executor driver) (109/281)
21/05/14 14:43:18 INFO Executor: Running task 112.0 in stage 0.0 (TID 112)
[2021-05-14 11:43:18,556] {docker.py:276} INFO - 21/05/14 14:43:18 INFO Executor: Finished task 110.0 in stage 0.0 (TID 110). 1825 bytes result sent to driver
[2021-05-14 11:43:18,557] {docker.py:276} INFO - 21/05/14 14:43:18 INFO TaskSetManager: Starting task 113.0 in stage 0.0 (TID 113) (f0b8ef7ba22f, executor driver, partition 113, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:18,558] {docker.py:276} INFO - 21/05/14 14:43:18 INFO Executor: Running task 113.0 in stage 0.0 (TID 113)
[2021-05-14 11:43:18,558] {docker.py:276} INFO - 21/05/14 14:43:18 INFO Executor: Finished task 109.0 in stage 0.0 (TID 109). 1825 bytes result sent to driver
[2021-05-14 11:43:18,559] {docker.py:276} INFO - 21/05/14 14:43:18 INFO TaskSetManager: Finished task 110.0 in stage 0.0 (TID 110) in 181 ms on f0b8ef7ba22f (executor driver) (110/281)
[2021-05-14 11:43:18,560] {docker.py:276} INFO - 21/05/14 14:43:18 INFO TaskSetManager: Starting task 114.0 in stage 0.0 (TID 114) (f0b8ef7ba22f, executor driver, partition 114, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:18,561] {docker.py:276} INFO - 21/05/14 14:43:18 INFO Executor: Running task 114.0 in stage 0.0 (TID 114)
[2021-05-14 11:43:18,562] {docker.py:276} INFO - 21/05/14 14:43:18 INFO TaskSetManager: Finished task 109.0 in stage 0.0 (TID 109) in 188 ms on f0b8ef7ba22f (executor driver) (111/281)
[2021-05-14 11:43:18,567] {docker.py:276} INFO - 21/05/14 14:43:18 INFO Executor: Finished task 112.0 in stage 0.0 (TID 112). 1825 bytes result sent to driver
[2021-05-14 11:43:18,569] {docker.py:276} INFO - 21/05/14 14:43:18 INFO Executor: Finished task 111.0 in stage 0.0 (TID 111). 1825 bytes result sent to driver
[2021-05-14 11:43:18,569] {docker.py:276} INFO - 21/05/14 14:43:18 INFO TaskSetManager: Starting task 115.0 in stage 0.0 (TID 115) (f0b8ef7ba22f, executor driver, partition 115, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:18,573] {docker.py:276} INFO - 21/05/14 14:43:18 INFO Executor: Running task 115.0 in stage 0.0 (TID 115)
[2021-05-14 11:43:18,574] {docker.py:276} INFO - 21/05/14 14:43:18 INFO TaskSetManager: Starting task 116.0 in stage 0.0 (TID 116) (f0b8ef7ba22f, executor driver, partition 116, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:18,574] {docker.py:276} INFO - 21/05/14 14:43:18 INFO Executor: Running task 116.0 in stage 0.0 (TID 116)
[2021-05-14 11:43:18,575] {docker.py:276} INFO - 21/05/14 14:43:18 INFO TaskSetManager: Finished task 111.0 in stage 0.0 (TID 111) in 192 ms on f0b8ef7ba22f (executor driver) (112/281)
[2021-05-14 11:43:18,575] {docker.py:276} INFO - 21/05/14 14:43:18 INFO TaskSetManager: Finished task 112.0 in stage 0.0 (TID 112) in 189 ms on f0b8ef7ba22f (executor driver) (113/281)
[2021-05-14 11:43:18,740] {docker.py:276} INFO - 21/05/14 14:43:18 INFO Executor: Finished task 116.0 in stage 0.0 (TID 116). 1825 bytes result sent to driver
[2021-05-14 11:43:18,741] {docker.py:276} INFO - 21/05/14 14:43:18 INFO TaskSetManager: Starting task 117.0 in stage 0.0 (TID 117) (f0b8ef7ba22f, executor driver, partition 117, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:18,742] {docker.py:276} INFO - 21/05/14 14:43:18 INFO TaskSetManager: Finished task 116.0 in stage 0.0 (TID 116) in 172 ms on f0b8ef7ba22f (executor driver) (114/281)
[2021-05-14 11:43:18,743] {docker.py:276} INFO - 21/05/14 14:43:18 INFO Executor: Running task 117.0 in stage 0.0 (TID 117)
[2021-05-14 11:43:18,745] {docker.py:276} INFO - 21/05/14 14:43:18 INFO Executor: Finished task 114.0 in stage 0.0 (TID 114). 1825 bytes result sent to driver
[2021-05-14 11:43:18,747] {docker.py:276} INFO - 21/05/14 14:43:18 INFO TaskSetManager: Starting task 118.0 in stage 0.0 (TID 118) (f0b8ef7ba22f, executor driver, partition 118, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:18,748] {docker.py:276} INFO - 21/05/14 14:43:18 INFO TaskSetManager: Finished task 114.0 in stage 0.0 (TID 114) in 188 ms on f0b8ef7ba22f (executor driver) (115/281)
[2021-05-14 11:43:18,749] {docker.py:276} INFO - 21/05/14 14:43:18 INFO Executor: Running task 118.0 in stage 0.0 (TID 118)
[2021-05-14 11:43:18,751] {docker.py:276} INFO - 21/05/14 14:43:18 INFO Executor: Finished task 115.0 in stage 0.0 (TID 115). 1825 bytes result sent to driver
[2021-05-14 11:43:18,752] {docker.py:276} INFO - 21/05/14 14:43:18 INFO TaskSetManager: Starting task 119.0 in stage 0.0 (TID 119) (f0b8ef7ba22f, executor driver, partition 119, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:18,752] {docker.py:276} INFO - 21/05/14 14:43:18 INFO Executor: Running task 119.0 in stage 0.0 (TID 119)
[2021-05-14 11:43:18,753] {docker.py:276} INFO - 21/05/14 14:43:18 INFO TaskSetManager: Finished task 115.0 in stage 0.0 (TID 115) in 184 ms on f0b8ef7ba22f (executor driver) (116/281)
[2021-05-14 11:43:18,762] {docker.py:276} INFO - 21/05/14 14:43:18 INFO Executor: Finished task 113.0 in stage 0.0 (TID 113). 1825 bytes result sent to driver
[2021-05-14 11:43:18,763] {docker.py:276} INFO - 21/05/14 14:43:18 INFO TaskSetManager: Starting task 120.0 in stage 0.0 (TID 120) (f0b8ef7ba22f, executor driver, partition 120, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:18,764] {docker.py:276} INFO - 21/05/14 14:43:18 INFO Executor: Running task 120.0 in stage 0.0 (TID 120)
[2021-05-14 11:43:18,765] {docker.py:276} INFO - 21/05/14 14:43:18 INFO TaskSetManager: Finished task 113.0 in stage 0.0 (TID 113) in 208 ms on f0b8ef7ba22f (executor driver) (117/281)
[2021-05-14 11:43:18,925] {docker.py:276} INFO - 21/05/14 14:43:18 INFO Executor: Finished task 119.0 in stage 0.0 (TID 119). 1825 bytes result sent to driver
[2021-05-14 11:43:18,926] {docker.py:276} INFO - 21/05/14 14:43:18 INFO TaskSetManager: Starting task 121.0 in stage 0.0 (TID 121) (f0b8ef7ba22f, executor driver, partition 121, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:18,927] {docker.py:276} INFO - 21/05/14 14:43:18 INFO Executor: Running task 121.0 in stage 0.0 (TID 121)
[2021-05-14 11:43:18,929] {docker.py:276} INFO - 21/05/14 14:43:18 INFO TaskSetManager: Finished task 119.0 in stage 0.0 (TID 119) in 177 ms on f0b8ef7ba22f (executor driver) (118/281)
[2021-05-14 11:43:18,930] {docker.py:276} INFO - 21/05/14 14:43:18 INFO Executor: Finished task 117.0 in stage 0.0 (TID 117). 1825 bytes result sent to driver
[2021-05-14 11:43:18,932] {docker.py:276} INFO - 21/05/14 14:43:18 INFO TaskSetManager: Starting task 122.0 in stage 0.0 (TID 122) (f0b8ef7ba22f, executor driver, partition 122, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:18,934] {docker.py:276} INFO - 21/05/14 14:43:18 INFO Executor: Finished task 118.0 in stage 0.0 (TID 118). 1825 bytes result sent to driver
[2021-05-14 11:43:18,934] {docker.py:276} INFO - 21/05/14 14:43:18 INFO TaskSetManager: Finished task 117.0 in stage 0.0 (TID 117) in 194 ms on f0b8ef7ba22f (executor driver) (119/281)
[2021-05-14 11:43:18,935] {docker.py:276} INFO - 21/05/14 14:43:18 INFO Executor: Running task 122.0 in stage 0.0 (TID 122)
[2021-05-14 11:43:18,936] {docker.py:276} INFO - 21/05/14 14:43:18 INFO TaskSetManager: Starting task 123.0 in stage 0.0 (TID 123) (f0b8ef7ba22f, executor driver, partition 123, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:18,936] {docker.py:276} INFO - 21/05/14 14:43:18 INFO TaskSetManager: Finished task 118.0 in stage 0.0 (TID 118) in 190 ms on f0b8ef7ba22f (executor driver) (120/281)
[2021-05-14 11:43:18,937] {docker.py:276} INFO - 21/05/14 14:43:18 INFO Executor: Running task 123.0 in stage 0.0 (TID 123)
[2021-05-14 11:43:18,978] {docker.py:276} INFO - 21/05/14 14:43:18 INFO Executor: Finished task 120.0 in stage 0.0 (TID 120). 1868 bytes result sent to driver
[2021-05-14 11:43:18,980] {docker.py:276} INFO - 21/05/14 14:43:18 INFO TaskSetManager: Starting task 124.0 in stage 0.0 (TID 124) (f0b8ef7ba22f, executor driver, partition 124, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:18,981] {docker.py:276} INFO - 21/05/14 14:43:18 INFO TaskSetManager: Finished task 120.0 in stage 0.0 (TID 120) in 219 ms on f0b8ef7ba22f (executor driver) (121/281)
[2021-05-14 11:43:18,982] {docker.py:276} INFO - 21/05/14 14:43:18 INFO Executor: Running task 124.0 in stage 0.0 (TID 124)
[2021-05-14 11:43:19,122] {docker.py:276} INFO - 21/05/14 14:43:19 INFO Executor: Finished task 122.0 in stage 0.0 (TID 122). 1868 bytes result sent to driver
[2021-05-14 11:43:19,123] {docker.py:276} INFO - 21/05/14 14:43:19 INFO TaskSetManager: Starting task 125.0 in stage 0.0 (TID 125) (f0b8ef7ba22f, executor driver, partition 125, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:19,124] {docker.py:276} INFO - 21/05/14 14:43:19 INFO TaskSetManager: Finished task 122.0 in stage 0.0 (TID 122) in 192 ms on f0b8ef7ba22f (executor driver) (122/281)
[2021-05-14 11:43:19,125] {docker.py:276} INFO - 21/05/14 14:43:19 INFO Executor: Running task 125.0 in stage 0.0 (TID 125)
[2021-05-14 11:43:19,126] {docker.py:276} INFO - 21/05/14 14:43:19 INFO Executor: Finished task 121.0 in stage 0.0 (TID 121). 1868 bytes result sent to driver
[2021-05-14 11:43:19,128] {docker.py:276} INFO - 21/05/14 14:43:19 INFO TaskSetManager: Starting task 126.0 in stage 0.0 (TID 126) (f0b8ef7ba22f, executor driver, partition 126, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:19,129] {docker.py:276} INFO - 21/05/14 14:43:19 INFO Executor: Running task 126.0 in stage 0.0 (TID 126)
21/05/14 14:43:19 INFO TaskSetManager: Finished task 121.0 in stage 0.0 (TID 121) in 204 ms on f0b8ef7ba22f (executor driver) (123/281)
[2021-05-14 11:43:19,134] {docker.py:276} INFO - 21/05/14 14:43:19 INFO Executor: Finished task 123.0 in stage 0.0 (TID 123). 1868 bytes result sent to driver
[2021-05-14 11:43:19,136] {docker.py:276} INFO - 21/05/14 14:43:19 INFO TaskSetManager: Starting task 127.0 in stage 0.0 (TID 127) (f0b8ef7ba22f, executor driver, partition 127, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:19,136] {docker.py:276} INFO - 21/05/14 14:43:19 INFO TaskSetManager: Finished task 123.0 in stage 0.0 (TID 123) in 201 ms on f0b8ef7ba22f (executor driver) (124/281)
[2021-05-14 11:43:19,137] {docker.py:276} INFO - 21/05/14 14:43:19 INFO Executor: Running task 127.0 in stage 0.0 (TID 127)
[2021-05-14 11:43:19,149] {docker.py:276} INFO - 21/05/14 14:43:19 INFO Executor: Finished task 124.0 in stage 0.0 (TID 124). 1825 bytes result sent to driver
[2021-05-14 11:43:19,150] {docker.py:276} INFO - 21/05/14 14:43:19 INFO TaskSetManager: Starting task 128.0 in stage 0.0 (TID 128) (f0b8ef7ba22f, executor driver, partition 128, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:19,151] {docker.py:276} INFO - 21/05/14 14:43:19 INFO TaskSetManager: Finished task 124.0 in stage 0.0 (TID 124) in 172 ms on f0b8ef7ba22f (executor driver) (125/281)
[2021-05-14 11:43:19,153] {docker.py:276} INFO - 21/05/14 14:43:19 INFO Executor: Running task 128.0 in stage 0.0 (TID 128)
[2021-05-14 11:43:19,316] {docker.py:276} INFO - 21/05/14 14:43:19 INFO Executor: Finished task 125.0 in stage 0.0 (TID 125). 1825 bytes result sent to driver
21/05/14 14:43:19 INFO Executor: Finished task 126.0 in stage 0.0 (TID 126). 1825 bytes result sent to driver
[2021-05-14 11:43:19,317] {docker.py:276} INFO - 21/05/14 14:43:19 INFO Executor: Finished task 127.0 in stage 0.0 (TID 127). 1825 bytes result sent to driver
[2021-05-14 11:43:19,318] {docker.py:276} INFO - 21/05/14 14:43:19 INFO TaskSetManager: Starting task 129.0 in stage 0.0 (TID 129) (f0b8ef7ba22f, executor driver, partition 129, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:19,320] {docker.py:276} INFO - 21/05/14 14:43:19 INFO Executor: Running task 129.0 in stage 0.0 (TID 129)
21/05/14 14:43:19 INFO TaskSetManager: Finished task 125.0 in stage 0.0 (TID 125) in 198 ms on f0b8ef7ba22f (executor driver) (126/281)
[2021-05-14 11:43:19,322] {docker.py:276} INFO - 21/05/14 14:43:19 INFO TaskSetManager: Starting task 130.0 in stage 0.0 (TID 130) (f0b8ef7ba22f, executor driver, partition 130, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:19,326] {docker.py:276} INFO - 21/05/14 14:43:19 INFO Executor: Finished task 128.0 in stage 0.0 (TID 128). 1825 bytes result sent to driver
[2021-05-14 11:43:19,327] {docker.py:276} INFO - 21/05/14 14:43:19 INFO Executor: Running task 130.0 in stage 0.0 (TID 130)
[2021-05-14 11:43:19,328] {docker.py:276} INFO - 21/05/14 14:43:19 INFO TaskSetManager: Finished task 127.0 in stage 0.0 (TID 127) in 192 ms on f0b8ef7ba22f (executor driver) (127/281)
[2021-05-14 11:43:19,329] {docker.py:276} INFO - 21/05/14 14:43:19 INFO TaskSetManager: Finished task 126.0 in stage 0.0 (TID 126) in 202 ms on f0b8ef7ba22f (executor driver) (128/281)
[2021-05-14 11:43:19,331] {docker.py:276} INFO - 21/05/14 14:43:19 INFO TaskSetManager: Starting task 131.0 in stage 0.0 (TID 131) (f0b8ef7ba22f, executor driver, partition 131, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:19,332] {docker.py:276} INFO - 21/05/14 14:43:19 INFO TaskSetManager: Starting task 132.0 in stage 0.0 (TID 132) (f0b8ef7ba22f, executor driver, partition 132, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:19,333] {docker.py:276} INFO - 21/05/14 14:43:19 INFO Executor: Running task 132.0 in stage 0.0 (TID 132)
[2021-05-14 11:43:19,334] {docker.py:276} INFO - 21/05/14 14:43:19 INFO TaskSetManager: Finished task 128.0 in stage 0.0 (TID 128) in 183 ms on f0b8ef7ba22f (executor driver) (129/281)
[2021-05-14 11:43:19,338] {docker.py:276} INFO - 21/05/14 14:43:19 INFO Executor: Running task 131.0 in stage 0.0 (TID 131)
[2021-05-14 11:43:19,501] {docker.py:276} INFO - 21/05/14 14:43:19 INFO Executor: Finished task 129.0 in stage 0.0 (TID 129). 1825 bytes result sent to driver
[2021-05-14 11:43:19,504] {docker.py:276} INFO - 21/05/14 14:43:19 INFO TaskSetManager: Starting task 133.0 in stage 0.0 (TID 133) (f0b8ef7ba22f, executor driver, partition 133, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:19,505] {docker.py:276} INFO - 21/05/14 14:43:19 INFO TaskSetManager: Finished task 129.0 in stage 0.0 (TID 129) in 188 ms on f0b8ef7ba22f (executor driver) (130/281)
[2021-05-14 11:43:19,505] {docker.py:276} INFO - 21/05/14 14:43:19 INFO Executor: Running task 133.0 in stage 0.0 (TID 133)
[2021-05-14 11:43:19,509] {docker.py:276} INFO - 21/05/14 14:43:19 INFO Executor: Finished task 132.0 in stage 0.0 (TID 132). 1825 bytes result sent to driver
[2021-05-14 11:43:19,511] {docker.py:276} INFO - 21/05/14 14:43:19 INFO TaskSetManager: Starting task 134.0 in stage 0.0 (TID 134) (f0b8ef7ba22f, executor driver, partition 134, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:19,512] {docker.py:276} INFO - 21/05/14 14:43:19 INFO TaskSetManager: Finished task 132.0 in stage 0.0 (TID 132) in 180 ms on f0b8ef7ba22f (executor driver) (131/281)
[2021-05-14 11:43:19,514] {docker.py:276} INFO - 21/05/14 14:43:19 INFO Executor: Finished task 130.0 in stage 0.0 (TID 130). 1825 bytes result sent to driver
[2021-05-14 11:43:19,515] {docker.py:276} INFO - 21/05/14 14:43:19 INFO Executor: Running task 134.0 in stage 0.0 (TID 134)
21/05/14 14:43:19 INFO Executor: Finished task 131.0 in stage 0.0 (TID 131). 1825 bytes result sent to driver
[2021-05-14 11:43:19,516] {docker.py:276} INFO - 21/05/14 14:43:19 INFO TaskSetManager: Starting task 135.0 in stage 0.0 (TID 135) (f0b8ef7ba22f, executor driver, partition 135, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:19,517] {docker.py:276} INFO - 21/05/14 14:43:19 INFO TaskSetManager: Finished task 130.0 in stage 0.0 (TID 130) in 194 ms on f0b8ef7ba22f (executor driver) (132/281)
[2021-05-14 11:43:19,518] {docker.py:276} INFO - 21/05/14 14:43:19 INFO Executor: Running task 135.0 in stage 0.0 (TID 135)
[2021-05-14 11:43:19,519] {docker.py:276} INFO - 21/05/14 14:43:19 INFO TaskSetManager: Starting task 136.0 in stage 0.0 (TID 136) (f0b8ef7ba22f, executor driver, partition 136, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:19,520] {docker.py:276} INFO - 21/05/14 14:43:19 INFO TaskSetManager: Finished task 131.0 in stage 0.0 (TID 131) in 188 ms on f0b8ef7ba22f (executor driver) (133/281)
[2021-05-14 11:43:19,520] {docker.py:276} INFO - 21/05/14 14:43:19 INFO Executor: Running task 136.0 in stage 0.0 (TID 136)
[2021-05-14 11:43:19,686] {docker.py:276} INFO - 21/05/14 14:43:19 INFO Executor: Finished task 133.0 in stage 0.0 (TID 133). 1825 bytes result sent to driver
[2021-05-14 11:43:19,687] {docker.py:276} INFO - 21/05/14 14:43:19 INFO TaskSetManager: Starting task 137.0 in stage 0.0 (TID 137) (f0b8ef7ba22f, executor driver, partition 137, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:19,688] {docker.py:276} INFO - 21/05/14 14:43:19 INFO TaskSetManager: Finished task 133.0 in stage 0.0 (TID 133) in 185 ms on f0b8ef7ba22f (executor driver) (134/281)
[2021-05-14 11:43:19,689] {docker.py:276} INFO - 21/05/14 14:43:19 INFO Executor: Running task 137.0 in stage 0.0 (TID 137)
[2021-05-14 11:43:19,692] {docker.py:276} INFO - 21/05/14 14:43:19 INFO Executor: Finished task 136.0 in stage 0.0 (TID 136). 1825 bytes result sent to driver
[2021-05-14 11:43:19,693] {docker.py:276} INFO - 21/05/14 14:43:19 INFO TaskSetManager: Starting task 138.0 in stage 0.0 (TID 138) (f0b8ef7ba22f, executor driver, partition 138, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:19,694] {docker.py:276} INFO - 21/05/14 14:43:19 INFO TaskSetManager: Finished task 136.0 in stage 0.0 (TID 136) in 178 ms on f0b8ef7ba22f (executor driver) (135/281)
[2021-05-14 11:43:19,696] {docker.py:276} INFO - 21/05/14 14:43:19 INFO Executor: Finished task 134.0 in stage 0.0 (TID 134). 1825 bytes result sent to driver
[2021-05-14 11:43:19,698] {docker.py:276} INFO - 21/05/14 14:43:19 INFO Executor: Running task 138.0 in stage 0.0 (TID 138)
[2021-05-14 11:43:19,698] {docker.py:276} INFO - 21/05/14 14:43:19 INFO TaskSetManager: Starting task 139.0 in stage 0.0 (TID 139) (f0b8ef7ba22f, executor driver, partition 139, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:19,699] {docker.py:276} INFO - 21/05/14 14:43:19 INFO TaskSetManager: Finished task 134.0 in stage 0.0 (TID 134) in 189 ms on f0b8ef7ba22f (executor driver) (136/281)
[2021-05-14 11:43:19,700] {docker.py:276} INFO - 21/05/14 14:43:19 INFO Executor: Running task 139.0 in stage 0.0 (TID 139)
[2021-05-14 11:43:19,739] {docker.py:276} INFO - 21/05/14 14:43:19 INFO Executor: Finished task 135.0 in stage 0.0 (TID 135). 1868 bytes result sent to driver
[2021-05-14 11:43:19,741] {docker.py:276} INFO - 21/05/14 14:43:19 INFO TaskSetManager: Starting task 140.0 in stage 0.0 (TID 140) (f0b8ef7ba22f, executor driver, partition 140, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:19,742] {docker.py:276} INFO - 21/05/14 14:43:19 INFO TaskSetManager: Finished task 135.0 in stage 0.0 (TID 135) in 226 ms on f0b8ef7ba22f (executor driver) (137/281)
[2021-05-14 11:43:19,742] {docker.py:276} INFO - 21/05/14 14:43:19 INFO Executor: Running task 140.0 in stage 0.0 (TID 140)
[2021-05-14 11:43:19,875] {docker.py:276} INFO - 21/05/14 14:43:19 INFO Executor: Finished task 137.0 in stage 0.0 (TID 137). 1868 bytes result sent to driver
[2021-05-14 11:43:19,875] {docker.py:276} INFO - 21/05/14 14:43:19 INFO Executor: Finished task 138.0 in stage 0.0 (TID 138). 1868 bytes result sent to driver
[2021-05-14 11:43:19,878] {docker.py:276} INFO - 21/05/14 14:43:19 INFO TaskSetManager: Starting task 141.0 in stage 0.0 (TID 141) (f0b8ef7ba22f, executor driver, partition 141, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:19,878] {docker.py:276} INFO - 21/05/14 14:43:19 INFO Executor: Running task 141.0 in stage 0.0 (TID 141)
[2021-05-14 11:43:19,879] {docker.py:276} INFO - 21/05/14 14:43:19 INFO TaskSetManager: Starting task 142.0 in stage 0.0 (TID 142) (f0b8ef7ba22f, executor driver, partition 142, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:19,880] {docker.py:276} INFO - 21/05/14 14:43:19 INFO Executor: Running task 142.0 in stage 0.0 (TID 142)
[2021-05-14 11:43:19,881] {docker.py:276} INFO - 21/05/14 14:43:19 INFO TaskSetManager: Finished task 137.0 in stage 0.0 (TID 137) in 194 ms on f0b8ef7ba22f (executor driver) (138/281)
[2021-05-14 11:43:19,881] {docker.py:276} INFO - 21/05/14 14:43:19 INFO Executor: Finished task 139.0 in stage 0.0 (TID 139). 1868 bytes result sent to driver
[2021-05-14 11:43:19,882] {docker.py:276} INFO - 21/05/14 14:43:19 INFO TaskSetManager: Finished task 138.0 in stage 0.0 (TID 138) in 190 ms on f0b8ef7ba22f (executor driver) (139/281)
[2021-05-14 11:43:19,883] {docker.py:276} INFO - 21/05/14 14:43:19 INFO TaskSetManager: Finished task 139.0 in stage 0.0 (TID 139) in 185 ms on f0b8ef7ba22f (executor driver) (140/281)
[2021-05-14 11:43:19,884] {docker.py:276} INFO - 21/05/14 14:43:19 INFO TaskSetManager: Starting task 143.0 in stage 0.0 (TID 143) (f0b8ef7ba22f, executor driver, partition 143, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:19,886] {docker.py:276} INFO - 21/05/14 14:43:19 INFO Executor: Running task 143.0 in stage 0.0 (TID 143)
[2021-05-14 11:43:19,917] {docker.py:276} INFO - 21/05/14 14:43:19 INFO Executor: Finished task 140.0 in stage 0.0 (TID 140). 1825 bytes result sent to driver
[2021-05-14 11:43:19,919] {docker.py:276} INFO - 21/05/14 14:43:19 INFO TaskSetManager: Starting task 144.0 in stage 0.0 (TID 144) (f0b8ef7ba22f, executor driver, partition 144, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:19,919] {docker.py:276} INFO - 21/05/14 14:43:19 INFO Executor: Running task 144.0 in stage 0.0 (TID 144)
[2021-05-14 11:43:19,920] {docker.py:276} INFO - 21/05/14 14:43:19 INFO TaskSetManager: Finished task 140.0 in stage 0.0 (TID 140) in 181 ms on f0b8ef7ba22f (executor driver) (141/281)
[2021-05-14 11:43:20,065] {docker.py:276} INFO - 21/05/14 14:43:20 INFO Executor: Finished task 141.0 in stage 0.0 (TID 141). 1825 bytes result sent to driver
[2021-05-14 11:43:20,066] {docker.py:276} INFO - 21/05/14 14:43:20 INFO Executor: Finished task 142.0 in stage 0.0 (TID 142). 1825 bytes result sent to driver
[2021-05-14 11:43:20,067] {docker.py:276} INFO - 21/05/14 14:43:20 INFO Executor: Finished task 143.0 in stage 0.0 (TID 143). 1825 bytes result sent to driver
[2021-05-14 11:43:20,068] {docker.py:276} INFO - 21/05/14 14:43:20 INFO TaskSetManager: Starting task 145.0 in stage 0.0 (TID 145) (f0b8ef7ba22f, executor driver, partition 145, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:20,069] {docker.py:276} INFO - 21/05/14 14:43:20 INFO Executor: Running task 145.0 in stage 0.0 (TID 145)
[2021-05-14 11:43:20,070] {docker.py:276} INFO - 21/05/14 14:43:20 INFO TaskSetManager: Starting task 146.0 in stage 0.0 (TID 146) (f0b8ef7ba22f, executor driver, partition 146, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:20,071] {docker.py:276} INFO - 21/05/14 14:43:20 INFO Executor: Running task 146.0 in stage 0.0 (TID 146)
[2021-05-14 11:43:20,072] {docker.py:276} INFO - 21/05/14 14:43:20 INFO TaskSetManager: Starting task 147.0 in stage 0.0 (TID 147) (f0b8ef7ba22f, executor driver, partition 147, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:20,073] {docker.py:276} INFO - 21/05/14 14:43:20 INFO TaskSetManager: Finished task 141.0 in stage 0.0 (TID 141) in 198 ms on f0b8ef7ba22f (executor driver) (142/281)
[2021-05-14 11:43:20,074] {docker.py:276} INFO - 21/05/14 14:43:20 INFO Executor: Running task 147.0 in stage 0.0 (TID 147)
[2021-05-14 11:43:20,074] {docker.py:276} INFO - 21/05/14 14:43:20 INFO TaskSetManager: Finished task 142.0 in stage 0.0 (TID 142) in 196 ms on f0b8ef7ba22f (executor driver) (143/281)
[2021-05-14 11:43:20,075] {docker.py:276} INFO - 21/05/14 14:43:20 INFO TaskSetManager: Finished task 143.0 in stage 0.0 (TID 143) in 192 ms on f0b8ef7ba22f (executor driver) (144/281)
[2021-05-14 11:43:20,086] {docker.py:276} INFO - 21/05/14 14:43:20 INFO Executor: Finished task 144.0 in stage 0.0 (TID 144). 1825 bytes result sent to driver
[2021-05-14 11:43:20,087] {docker.py:276} INFO - 21/05/14 14:43:20 INFO TaskSetManager: Starting task 148.0 in stage 0.0 (TID 148) (f0b8ef7ba22f, executor driver, partition 148, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:20,088] {docker.py:276} INFO - 21/05/14 14:43:20 INFO TaskSetManager: Finished task 144.0 in stage 0.0 (TID 144) in 170 ms on f0b8ef7ba22f (executor driver) (145/281)
21/05/14 14:43:20 INFO Executor: Running task 148.0 in stage 0.0 (TID 148)
[2021-05-14 11:43:20,255] {docker.py:276} INFO - 21/05/14 14:43:20 INFO Executor: Finished task 145.0 in stage 0.0 (TID 145). 1825 bytes result sent to driver
[2021-05-14 11:43:20,257] {docker.py:276} INFO - 21/05/14 14:43:20 INFO TaskSetManager: Starting task 149.0 in stage 0.0 (TID 149) (f0b8ef7ba22f, executor driver, partition 149, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:20,260] {docker.py:276} INFO - 21/05/14 14:43:20 INFO TaskSetManager: Finished task 145.0 in stage 0.0 (TID 145) in 193 ms on f0b8ef7ba22f (executor driver) (146/281)
[2021-05-14 11:43:20,261] {docker.py:276} INFO - 21/05/14 14:43:20 INFO Executor: Running task 149.0 in stage 0.0 (TID 149)
[2021-05-14 11:43:20,264] {docker.py:276} INFO - 21/05/14 14:43:20 INFO Executor: Finished task 148.0 in stage 0.0 (TID 148). 1825 bytes result sent to driver
[2021-05-14 11:43:20,265] {docker.py:276} INFO - 21/05/14 14:43:20 INFO TaskSetManager: Starting task 150.0 in stage 0.0 (TID 150) (f0b8ef7ba22f, executor driver, partition 150, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:20,266] {docker.py:276} INFO - 21/05/14 14:43:20 INFO Executor: Running task 150.0 in stage 0.0 (TID 150)
[2021-05-14 11:43:20,267] {docker.py:276} INFO - 21/05/14 14:43:20 INFO TaskSetManager: Finished task 148.0 in stage 0.0 (TID 148) in 180 ms on f0b8ef7ba22f (executor driver) (147/281)
[2021-05-14 11:43:20,279] {docker.py:276} INFO - 21/05/14 14:43:20 INFO Executor: Finished task 146.0 in stage 0.0 (TID 146). 1825 bytes result sent to driver
21/05/14 14:43:20 INFO Executor: Finished task 147.0 in stage 0.0 (TID 147). 1825 bytes result sent to driver
[2021-05-14 11:43:20,280] {docker.py:276} INFO - 21/05/14 14:43:20 INFO TaskSetManager: Starting task 151.0 in stage 0.0 (TID 151) (f0b8ef7ba22f, executor driver, partition 151, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:20,282] {docker.py:276} INFO - 21/05/14 14:43:20 INFO Executor: Running task 151.0 in stage 0.0 (TID 151)
[2021-05-14 11:43:20,283] {docker.py:276} INFO - 21/05/14 14:43:20 INFO TaskSetManager: Starting task 152.0 in stage 0.0 (TID 152) (f0b8ef7ba22f, executor driver, partition 152, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:20,284] {docker.py:276} INFO - 21/05/14 14:43:20 INFO TaskSetManager: Finished task 146.0 in stage 0.0 (TID 146) in 214 ms on f0b8ef7ba22f (executor driver) (148/281)
[2021-05-14 11:43:20,284] {docker.py:276} INFO - 21/05/14 14:43:20 INFO TaskSetManager: Finished task 147.0 in stage 0.0 (TID 147) in 212 ms on f0b8ef7ba22f (executor driver) (149/281)
[2021-05-14 11:43:20,285] {docker.py:276} INFO - 21/05/14 14:43:20 INFO Executor: Running task 152.0 in stage 0.0 (TID 152)
[2021-05-14 11:43:20,446] {docker.py:276} INFO - 21/05/14 14:43:20 INFO Executor: Finished task 149.0 in stage 0.0 (TID 149). 1825 bytes result sent to driver
[2021-05-14 11:43:20,447] {docker.py:276} INFO - 21/05/14 14:43:20 INFO Executor: Finished task 150.0 in stage 0.0 (TID 150). 1825 bytes result sent to driver
[2021-05-14 11:43:20,449] {docker.py:276} INFO - 21/05/14 14:43:20 INFO TaskSetManager: Starting task 153.0 in stage 0.0 (TID 153) (f0b8ef7ba22f, executor driver, partition 153, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:20,450] {docker.py:276} INFO - 21/05/14 14:43:20 INFO TaskSetManager: Finished task 149.0 in stage 0.0 (TID 149) in 192 ms on f0b8ef7ba22f (executor driver) (150/281)
[2021-05-14 11:43:20,452] {docker.py:276} INFO - 21/05/14 14:43:20 INFO TaskSetManager: Starting task 154.0 in stage 0.0 (TID 154) (f0b8ef7ba22f, executor driver, partition 154, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:20,453] {docker.py:276} INFO - 21/05/14 14:43:20 INFO Executor: Running task 153.0 in stage 0.0 (TID 153)
[2021-05-14 11:43:20,453] {docker.py:276} INFO - 21/05/14 14:43:20 INFO Executor: Running task 154.0 in stage 0.0 (TID 154)
[2021-05-14 11:43:20,454] {docker.py:276} INFO - 21/05/14 14:43:20 INFO TaskSetManager: Finished task 150.0 in stage 0.0 (TID 150) in 190 ms on f0b8ef7ba22f (executor driver) (151/281)
[2021-05-14 11:43:20,456] {docker.py:276} INFO - 21/05/14 14:43:20 INFO Executor: Finished task 151.0 in stage 0.0 (TID 151). 1825 bytes result sent to driver
[2021-05-14 11:43:20,457] {docker.py:276} INFO - 21/05/14 14:43:20 INFO TaskSetManager: Starting task 155.0 in stage 0.0 (TID 155) (f0b8ef7ba22f, executor driver, partition 155, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:20,458] {docker.py:276} INFO - 21/05/14 14:43:20 INFO Executor: Running task 155.0 in stage 0.0 (TID 155)
21/05/14 14:43:20 INFO TaskSetManager: Finished task 151.0 in stage 0.0 (TID 151) in 179 ms on f0b8ef7ba22f (executor driver) (152/281)
[2021-05-14 11:43:20,463] {docker.py:276} INFO - 21/05/14 14:43:20 INFO Executor: Finished task 152.0 in stage 0.0 (TID 152). 1825 bytes result sent to driver
[2021-05-14 11:43:20,465] {docker.py:276} INFO - 21/05/14 14:43:20 INFO TaskSetManager: Starting task 156.0 in stage 0.0 (TID 156) (f0b8ef7ba22f, executor driver, partition 156, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:20,467] {docker.py:276} INFO - 21/05/14 14:43:20 INFO TaskSetManager: Finished task 152.0 in stage 0.0 (TID 152) in 185 ms on f0b8ef7ba22f (executor driver) (153/281)
21/05/14 14:43:20 INFO Executor: Running task 156.0 in stage 0.0 (TID 156)
[2021-05-14 11:43:20,653] {docker.py:276} INFO - 21/05/14 14:43:20 INFO Executor: Finished task 155.0 in stage 0.0 (TID 155). 1868 bytes result sent to driver
[2021-05-14 11:43:20,654] {docker.py:276} INFO - 21/05/14 14:43:20 INFO Executor: Finished task 156.0 in stage 0.0 (TID 156). 1868 bytes result sent to driver
[2021-05-14 11:43:20,655] {docker.py:276} INFO - 21/05/14 14:43:20 INFO Executor: Finished task 153.0 in stage 0.0 (TID 153). 1868 bytes result sent to driver
21/05/14 14:43:20 INFO TaskSetManager: Starting task 157.0 in stage 0.0 (TID 157) (f0b8ef7ba22f, executor driver, partition 157, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:20,655] {docker.py:276} INFO - 21/05/14 14:43:20 INFO Executor: Running task 157.0 in stage 0.0 (TID 157)
[2021-05-14 11:43:20,656] {docker.py:276} INFO - 21/05/14 14:43:20 INFO TaskSetManager: Starting task 158.0 in stage 0.0 (TID 158) (f0b8ef7ba22f, executor driver, partition 158, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:20,657] {docker.py:276} INFO - 21/05/14 14:43:20 INFO TaskSetManager: Finished task 155.0 in stage 0.0 (TID 155) in 196 ms on f0b8ef7ba22f (executor driver) (154/281)
[2021-05-14 11:43:20,658] {docker.py:276} INFO - 21/05/14 14:43:20 INFO TaskSetManager: Starting task 159.0 in stage 0.0 (TID 159) (f0b8ef7ba22f, executor driver, partition 159, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:20,658] {docker.py:276} INFO - 21/05/14 14:43:20 INFO TaskSetManager: Finished task 156.0 in stage 0.0 (TID 156) in 192 ms on f0b8ef7ba22f (executor driver) (155/281)
[2021-05-14 11:43:20,659] {docker.py:276} INFO - 21/05/14 14:43:20 INFO Executor: Running task 159.0 in stage 0.0 (TID 159)
[2021-05-14 11:43:20,660] {docker.py:276} INFO - 21/05/14 14:43:20 INFO Executor: Running task 158.0 in stage 0.0 (TID 158)
[2021-05-14 11:43:20,660] {docker.py:276} INFO - 21/05/14 14:43:20 INFO TaskSetManager: Finished task 153.0 in stage 0.0 (TID 153) in 211 ms on f0b8ef7ba22f (executor driver) (156/281)
[2021-05-14 11:43:20,662] {docker.py:276} INFO - 21/05/14 14:43:20 INFO Executor: Finished task 154.0 in stage 0.0 (TID 154). 1868 bytes result sent to driver
[2021-05-14 11:43:20,664] {docker.py:276} INFO - 21/05/14 14:43:20 INFO TaskSetManager: Starting task 160.0 in stage 0.0 (TID 160) (f0b8ef7ba22f, executor driver, partition 160, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:20,665] {docker.py:276} INFO - 21/05/14 14:43:20 INFO Executor: Running task 160.0 in stage 0.0 (TID 160)
21/05/14 14:43:20 INFO TaskSetManager: Finished task 154.0 in stage 0.0 (TID 154) in 214 ms on f0b8ef7ba22f (executor driver) (157/281)
[2021-05-14 11:43:20,837] {docker.py:276} INFO - 21/05/14 14:43:20 INFO Executor: Finished task 160.0 in stage 0.0 (TID 160). 1825 bytes result sent to driver
[2021-05-14 11:43:20,839] {docker.py:276} INFO - 21/05/14 14:43:20 INFO Executor: Finished task 158.0 in stage 0.0 (TID 158). 1825 bytes result sent to driver
[2021-05-14 11:43:20,840] {docker.py:276} INFO - 21/05/14 14:43:20 INFO TaskSetManager: Starting task 161.0 in stage 0.0 (TID 161) (f0b8ef7ba22f, executor driver, partition 161, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:20,842] {docker.py:276} INFO - 21/05/14 14:43:20 INFO Executor: Running task 161.0 in stage 0.0 (TID 161)
[2021-05-14 11:43:20,843] {docker.py:276} INFO - 21/05/14 14:43:20 INFO TaskSetManager: Starting task 162.0 in stage 0.0 (TID 162) (f0b8ef7ba22f, executor driver, partition 162, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:20,844] {docker.py:276} INFO - 21/05/14 14:43:20 INFO TaskSetManager: Finished task 158.0 in stage 0.0 (TID 158) in 193 ms on f0b8ef7ba22f (executor driver) (158/281)
[2021-05-14 11:43:20,844] {docker.py:276} INFO - 21/05/14 14:43:20 INFO Executor: Finished task 157.0 in stage 0.0 (TID 157). 1825 bytes result sent to driver
21/05/14 14:43:20 INFO Executor: Running task 162.0 in stage 0.0 (TID 162)
[2021-05-14 11:43:20,845] {docker.py:276} INFO - 21/05/14 14:43:20 INFO TaskSetManager: Finished task 160.0 in stage 0.0 (TID 160) in 181 ms on f0b8ef7ba22f (executor driver) (159/281)
[2021-05-14 11:43:20,846] {docker.py:276} INFO - 21/05/14 14:43:20 INFO TaskSetManager: Starting task 163.0 in stage 0.0 (TID 163) (f0b8ef7ba22f, executor driver, partition 163, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:20,847] {docker.py:276} INFO - 21/05/14 14:43:20 INFO TaskSetManager: Finished task 157.0 in stage 0.0 (TID 157) in 197 ms on f0b8ef7ba22f (executor driver) (160/281)
21/05/14 14:43:20 INFO Executor: Running task 163.0 in stage 0.0 (TID 163)
[2021-05-14 11:43:20,849] {docker.py:276} INFO - 21/05/14 14:43:20 INFO Executor: Finished task 159.0 in stage 0.0 (TID 159). 1825 bytes result sent to driver
[2021-05-14 11:43:20,851] {docker.py:276} INFO - 21/05/14 14:43:20 INFO TaskSetManager: Starting task 164.0 in stage 0.0 (TID 164) (f0b8ef7ba22f, executor driver, partition 164, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:20,851] {docker.py:276} INFO - 21/05/14 14:43:20 INFO Executor: Running task 164.0 in stage 0.0 (TID 164)
[2021-05-14 11:43:20,852] {docker.py:276} INFO - 21/05/14 14:43:20 INFO TaskSetManager: Finished task 159.0 in stage 0.0 (TID 159) in 197 ms on f0b8ef7ba22f (executor driver) (161/281)
[2021-05-14 11:43:21,026] {docker.py:276} INFO - 21/05/14 14:43:21 INFO Executor: Finished task 162.0 in stage 0.0 (TID 162). 1825 bytes result sent to driver
[2021-05-14 11:43:21,029] {docker.py:276} INFO - 21/05/14 14:43:21 INFO TaskSetManager: Starting task 165.0 in stage 0.0 (TID 165) (f0b8ef7ba22f, executor driver, partition 165, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
21/05/14 14:43:21 INFO Executor: Finished task 163.0 in stage 0.0 (TID 163). 1825 bytes result sent to driver
[2021-05-14 11:43:21,030] {docker.py:276} INFO - 21/05/14 14:43:21 INFO TaskSetManager: Finished task 162.0 in stage 0.0 (TID 162) in 189 ms on f0b8ef7ba22f (executor driver) (162/281)
[2021-05-14 11:43:21,031] {docker.py:276} INFO - 21/05/14 14:43:21 INFO Executor: Running task 165.0 in stage 0.0 (TID 165)
[2021-05-14 11:43:21,032] {docker.py:276} INFO - 21/05/14 14:43:21 INFO TaskSetManager: Starting task 166.0 in stage 0.0 (TID 166) (f0b8ef7ba22f, executor driver, partition 166, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:21,033] {docker.py:276} INFO - 21/05/14 14:43:21 INFO TaskSetManager: Finished task 163.0 in stage 0.0 (TID 163) in 187 ms on f0b8ef7ba22f (executor driver) (163/281)
[2021-05-14 11:43:21,035] {docker.py:276} INFO - 21/05/14 14:43:21 INFO Executor: Running task 166.0 in stage 0.0 (TID 166)
[2021-05-14 11:43:21,036] {docker.py:276} INFO - 21/05/14 14:43:21 INFO Executor: Finished task 164.0 in stage 0.0 (TID 164). 1825 bytes result sent to driver
[2021-05-14 11:43:21,036] {docker.py:276} INFO - 21/05/14 14:43:21 INFO Executor: Finished task 161.0 in stage 0.0 (TID 161). 1825 bytes result sent to driver
[2021-05-14 11:43:21,036] {docker.py:276} INFO - 21/05/14 14:43:21 INFO TaskSetManager: Starting task 167.0 in stage 0.0 (TID 167) (f0b8ef7ba22f, executor driver, partition 167, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:21,037] {docker.py:276} INFO - 21/05/14 14:43:21 INFO Executor: Running task 167.0 in stage 0.0 (TID 167)
[2021-05-14 11:43:21,038] {docker.py:276} INFO - 21/05/14 14:43:21 INFO TaskSetManager: Starting task 168.0 in stage 0.0 (TID 168) (f0b8ef7ba22f, executor driver, partition 168, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:21,039] {docker.py:276} INFO - 21/05/14 14:43:21 INFO TaskSetManager: Finished task 164.0 in stage 0.0 (TID 164) in 188 ms on f0b8ef7ba22f (executor driver) (164/281)
[2021-05-14 11:43:21,039] {docker.py:276} INFO - 21/05/14 14:43:21 INFO Executor: Running task 168.0 in stage 0.0 (TID 168)
21/05/14 14:43:21 INFO TaskSetManager: Finished task 161.0 in stage 0.0 (TID 161) in 201 ms on f0b8ef7ba22f (executor driver) (165/281)
[2021-05-14 11:43:21,212] {docker.py:276} INFO - 21/05/14 14:43:21 INFO Executor: Finished task 165.0 in stage 0.0 (TID 165). 1825 bytes result sent to driver
[2021-05-14 11:43:21,215] {docker.py:276} INFO - 21/05/14 14:43:21 INFO TaskSetManager: Starting task 169.0 in stage 0.0 (TID 169) (f0b8ef7ba22f, executor driver, partition 169, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:21,217] {docker.py:276} INFO - 21/05/14 14:43:21 INFO Executor: Running task 169.0 in stage 0.0 (TID 169)
[2021-05-14 11:43:21,217] {docker.py:276} INFO - 21/05/14 14:43:21 INFO TaskSetManager: Finished task 165.0 in stage 0.0 (TID 165) in 188 ms on f0b8ef7ba22f (executor driver) (166/281)
[2021-05-14 11:43:21,219] {docker.py:276} INFO - 21/05/14 14:43:21 INFO Executor: Finished task 166.0 in stage 0.0 (TID 166). 1825 bytes result sent to driver
[2021-05-14 11:43:21,220] {docker.py:276} INFO - 21/05/14 14:43:21 INFO Executor: Finished task 168.0 in stage 0.0 (TID 168). 1825 bytes result sent to driver
[2021-05-14 11:43:21,221] {docker.py:276} INFO - 21/05/14 14:43:21 INFO TaskSetManager: Starting task 170.0 in stage 0.0 (TID 170) (f0b8ef7ba22f, executor driver, partition 170, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:21,222] {docker.py:276} INFO - 21/05/14 14:43:21 INFO TaskSetManager: Finished task 166.0 in stage 0.0 (TID 166) in 191 ms on f0b8ef7ba22f (executor driver) (167/281)
[2021-05-14 11:43:21,223] {docker.py:276} INFO - 21/05/14 14:43:21 INFO Executor: Running task 170.0 in stage 0.0 (TID 170)
[2021-05-14 11:43:21,224] {docker.py:276} INFO - 21/05/14 14:43:21 INFO TaskSetManager: Starting task 171.0 in stage 0.0 (TID 171) (f0b8ef7ba22f, executor driver, partition 171, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:21,225] {docker.py:276} INFO - 21/05/14 14:43:21 INFO Executor: Running task 171.0 in stage 0.0 (TID 171)
21/05/14 14:43:21 INFO TaskSetManager: Finished task 168.0 in stage 0.0 (TID 168) in 188 ms on f0b8ef7ba22f (executor driver) (168/281)
[2021-05-14 11:43:21,278] {docker.py:276} INFO - 21/05/14 14:43:21 INFO Executor: Finished task 167.0 in stage 0.0 (TID 167). 1825 bytes result sent to driver
[2021-05-14 11:43:21,279] {docker.py:276} INFO - 21/05/14 14:43:21 INFO TaskSetManager: Starting task 172.0 in stage 0.0 (TID 172) (f0b8ef7ba22f, executor driver, partition 172, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:21,281] {docker.py:276} INFO - 21/05/14 14:43:21 INFO TaskSetManager: Finished task 167.0 in stage 0.0 (TID 167) in 246 ms on f0b8ef7ba22f (executor driver) (169/281)
21/05/14 14:43:21 INFO Executor: Running task 172.0 in stage 0.0 (TID 172)
[2021-05-14 11:43:21,397] {docker.py:276} INFO - 21/05/14 14:43:21 INFO Executor: Finished task 171.0 in stage 0.0 (TID 171). 1868 bytes result sent to driver
[2021-05-14 11:43:21,398] {docker.py:276} INFO - 21/05/14 14:43:21 INFO TaskSetManager: Starting task 173.0 in stage 0.0 (TID 173) (f0b8ef7ba22f, executor driver, partition 173, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:21,399] {docker.py:276} INFO - 21/05/14 14:43:21 INFO Executor: Running task 173.0 in stage 0.0 (TID 173)
[2021-05-14 11:43:21,401] {docker.py:276} INFO - 21/05/14 14:43:21 INFO TaskSetManager: Finished task 171.0 in stage 0.0 (TID 171) in 177 ms on f0b8ef7ba22f (executor driver) (170/281)
[2021-05-14 11:43:21,402] {docker.py:276} INFO - 21/05/14 14:43:21 INFO Executor: Finished task 170.0 in stage 0.0 (TID 170). 1868 bytes result sent to driver
[2021-05-14 11:43:21,404] {docker.py:276} INFO - 21/05/14 14:43:21 INFO TaskSetManager: Starting task 174.0 in stage 0.0 (TID 174) (f0b8ef7ba22f, executor driver, partition 174, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:21,405] {docker.py:276} INFO - 21/05/14 14:43:21 INFO Executor: Finished task 169.0 in stage 0.0 (TID 169). 1911 bytes result sent to driver
[2021-05-14 11:43:21,405] {docker.py:276} INFO - 21/05/14 14:43:21 INFO TaskSetManager: Finished task 170.0 in stage 0.0 (TID 170) in 185 ms on f0b8ef7ba22f (executor driver) (171/281)
[2021-05-14 11:43:21,408] {docker.py:276} INFO - 21/05/14 14:43:21 INFO Executor: Running task 174.0 in stage 0.0 (TID 174)
[2021-05-14 11:43:21,408] {docker.py:276} INFO - 21/05/14 14:43:21 INFO TaskSetManager: Starting task 175.0 in stage 0.0 (TID 175) (f0b8ef7ba22f, executor driver, partition 175, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:21,411] {docker.py:276} INFO - 21/05/14 14:43:21 INFO Executor: Running task 175.0 in stage 0.0 (TID 175)
21/05/14 14:43:21 INFO TaskSetManager: Finished task 169.0 in stage 0.0 (TID 169) in 195 ms on f0b8ef7ba22f (executor driver) (172/281)
[2021-05-14 11:43:21,457] {docker.py:276} INFO - 21/05/14 14:43:21 INFO Executor: Finished task 172.0 in stage 0.0 (TID 172). 1868 bytes result sent to driver
[2021-05-14 11:43:21,458] {docker.py:276} INFO - 21/05/14 14:43:21 INFO TaskSetManager: Starting task 176.0 in stage 0.0 (TID 176) (f0b8ef7ba22f, executor driver, partition 176, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:21,459] {docker.py:276} INFO - 21/05/14 14:43:21 INFO TaskSetManager: Finished task 172.0 in stage 0.0 (TID 172) in 180 ms on f0b8ef7ba22f (executor driver) (173/281)
21/05/14 14:43:21 INFO Executor: Running task 176.0 in stage 0.0 (TID 176)
[2021-05-14 11:43:21,584] {docker.py:276} INFO - 21/05/14 14:43:21 INFO Executor: Finished task 174.0 in stage 0.0 (TID 174). 1825 bytes result sent to driver
[2021-05-14 11:43:21,587] {docker.py:276} INFO - 21/05/14 14:43:21 INFO TaskSetManager: Starting task 177.0 in stage 0.0 (TID 177) (f0b8ef7ba22f, executor driver, partition 177, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
21/05/14 14:43:21 INFO TaskSetManager: Finished task 174.0 in stage 0.0 (TID 174) in 183 ms on f0b8ef7ba22f (executor driver) (174/281)
21/05/14 14:43:21 INFO Executor: Running task 177.0 in stage 0.0 (TID 177)
[2021-05-14 11:43:21,589] {docker.py:276} INFO - 21/05/14 14:43:21 INFO Executor: Finished task 173.0 in stage 0.0 (TID 173). 1825 bytes result sent to driver
[2021-05-14 11:43:21,590] {docker.py:276} INFO - 21/05/14 14:43:21 INFO Executor: Finished task 175.0 in stage 0.0 (TID 175). 1825 bytes result sent to driver
21/05/14 14:43:21 INFO TaskSetManager: Starting task 178.0 in stage 0.0 (TID 178) (f0b8ef7ba22f, executor driver, partition 178, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:21,591] {docker.py:276} INFO - 21/05/14 14:43:21 INFO Executor: Running task 178.0 in stage 0.0 (TID 178)
[2021-05-14 11:43:21,592] {docker.py:276} INFO - 21/05/14 14:43:21 INFO TaskSetManager: Finished task 173.0 in stage 0.0 (TID 173) in 194 ms on f0b8ef7ba22f (executor driver) (175/281)
[2021-05-14 11:43:21,593] {docker.py:276} INFO - 21/05/14 14:43:21 INFO TaskSetManager: Starting task 179.0 in stage 0.0 (TID 179) (f0b8ef7ba22f, executor driver, partition 179, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:21,594] {docker.py:276} INFO - 21/05/14 14:43:21 INFO TaskSetManager: Finished task 175.0 in stage 0.0 (TID 175) in 186 ms on f0b8ef7ba22f (executor driver) (176/281)
[2021-05-14 11:43:21,595] {docker.py:276} INFO - 21/05/14 14:43:21 INFO Executor: Running task 179.0 in stage 0.0 (TID 179)
[2021-05-14 11:43:21,633] {docker.py:276} INFO - 21/05/14 14:43:21 INFO Executor: Finished task 176.0 in stage 0.0 (TID 176). 1825 bytes result sent to driver
[2021-05-14 11:43:21,636] {docker.py:276} INFO - 21/05/14 14:43:21 INFO TaskSetManager: Starting task 180.0 in stage 0.0 (TID 180) (f0b8ef7ba22f, executor driver, partition 180, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:21,637] {docker.py:276} INFO - 21/05/14 14:43:21 INFO TaskSetManager: Finished task 176.0 in stage 0.0 (TID 176) in 179 ms on f0b8ef7ba22f (executor driver) (177/281)
[2021-05-14 11:43:21,638] {docker.py:276} INFO - 21/05/14 14:43:21 INFO Executor: Running task 180.0 in stage 0.0 (TID 180)
[2021-05-14 11:43:21,769] {docker.py:276} INFO - 21/05/14 14:43:21 INFO Executor: Finished task 179.0 in stage 0.0 (TID 179). 1825 bytes result sent to driver
[2021-05-14 11:43:21,771] {docker.py:276} INFO - 21/05/14 14:43:21 INFO TaskSetManager: Starting task 181.0 in stage 0.0 (TID 181) (f0b8ef7ba22f, executor driver, partition 181, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:21,773] {docker.py:276} INFO - 21/05/14 14:43:21 INFO TaskSetManager: Finished task 179.0 in stage 0.0 (TID 179) in 180 ms on f0b8ef7ba22f (executor driver) (178/281)
21/05/14 14:43:21 INFO Executor: Running task 181.0 in stage 0.0 (TID 181)
[2021-05-14 11:43:21,774] {docker.py:276} INFO - 21/05/14 14:43:21 INFO Executor: Finished task 178.0 in stage 0.0 (TID 178). 1825 bytes result sent to driver
[2021-05-14 11:43:21,775] {docker.py:276} INFO - 21/05/14 14:43:21 INFO TaskSetManager: Starting task 182.0 in stage 0.0 (TID 182) (f0b8ef7ba22f, executor driver, partition 182, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:21,776] {docker.py:276} INFO - 21/05/14 14:43:21 INFO TaskSetManager: Finished task 178.0 in stage 0.0 (TID 178) in 186 ms on f0b8ef7ba22f (executor driver) (179/281)
[2021-05-14 11:43:21,777] {docker.py:276} INFO - 21/05/14 14:43:21 INFO Executor: Running task 182.0 in stage 0.0 (TID 182)
[2021-05-14 11:43:21,780] {docker.py:276} INFO - 21/05/14 14:43:21 INFO Executor: Finished task 177.0 in stage 0.0 (TID 177). 1825 bytes result sent to driver
[2021-05-14 11:43:21,781] {docker.py:276} INFO - 21/05/14 14:43:21 INFO TaskSetManager: Starting task 183.0 in stage 0.0 (TID 183) (f0b8ef7ba22f, executor driver, partition 183, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:21,784] {docker.py:276} INFO - 21/05/14 14:43:21 INFO TaskSetManager: Finished task 177.0 in stage 0.0 (TID 177) in 199 ms on f0b8ef7ba22f (executor driver) (180/281)
[2021-05-14 11:43:21,784] {docker.py:276} INFO - 21/05/14 14:43:21 INFO Executor: Running task 183.0 in stage 0.0 (TID 183)
[2021-05-14 11:43:21,811] {docker.py:276} INFO - 21/05/14 14:43:21 INFO Executor: Finished task 180.0 in stage 0.0 (TID 180). 1825 bytes result sent to driver
[2021-05-14 11:43:21,812] {docker.py:276} INFO - 21/05/14 14:43:21 INFO TaskSetManager: Starting task 184.0 in stage 0.0 (TID 184) (f0b8ef7ba22f, executor driver, partition 184, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:21,812] {docker.py:276} INFO - 21/05/14 14:43:21 INFO TaskSetManager: Finished task 180.0 in stage 0.0 (TID 180) in 179 ms on f0b8ef7ba22f (executor driver) (181/281)
[2021-05-14 11:43:21,814] {docker.py:276} INFO - 21/05/14 14:43:21 INFO Executor: Running task 184.0 in stage 0.0 (TID 184)
[2021-05-14 11:43:21,961] {docker.py:276} INFO - 21/05/14 14:43:21 INFO Executor: Finished task 182.0 in stage 0.0 (TID 182). 1825 bytes result sent to driver
21/05/14 14:43:21 INFO Executor: Finished task 181.0 in stage 0.0 (TID 181). 1825 bytes result sent to driver
[2021-05-14 11:43:21,962] {docker.py:276} INFO - 21/05/14 14:43:21 INFO TaskSetManager: Starting task 185.0 in stage 0.0 (TID 185) (f0b8ef7ba22f, executor driver, partition 185, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:21,963] {docker.py:276} INFO - 21/05/14 14:43:21 INFO Executor: Running task 185.0 in stage 0.0 (TID 185)
[2021-05-14 11:43:21,964] {docker.py:276} INFO - 21/05/14 14:43:21 INFO TaskSetManager: Starting task 186.0 in stage 0.0 (TID 186) (f0b8ef7ba22f, executor driver, partition 186, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:21,965] {docker.py:276} INFO - 21/05/14 14:43:21 INFO TaskSetManager: Finished task 182.0 in stage 0.0 (TID 182) in 190 ms on f0b8ef7ba22f (executor driver) (182/281)
[2021-05-14 11:43:21,966] {docker.py:276} INFO - 21/05/14 14:43:21 INFO TaskSetManager: Finished task 181.0 in stage 0.0 (TID 181) in 196 ms on f0b8ef7ba22f (executor driver) (183/281)
[2021-05-14 11:43:21,968] {docker.py:276} INFO - 21/05/14 14:43:21 INFO Executor: Running task 186.0 in stage 0.0 (TID 186)
[2021-05-14 11:43:21,969] {docker.py:276} INFO - 21/05/14 14:43:21 INFO Executor: Finished task 183.0 in stage 0.0 (TID 183). 1868 bytes result sent to driver
[2021-05-14 11:43:21,970] {docker.py:276} INFO - 21/05/14 14:43:21 INFO TaskSetManager: Starting task 187.0 in stage 0.0 (TID 187) (f0b8ef7ba22f, executor driver, partition 187, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:21,971] {docker.py:276} INFO - 21/05/14 14:43:21 INFO TaskSetManager: Finished task 183.0 in stage 0.0 (TID 183) in 190 ms on f0b8ef7ba22f (executor driver) (184/281)
[2021-05-14 11:43:21,972] {docker.py:276} INFO - 21/05/14 14:43:21 INFO Executor: Running task 187.0 in stage 0.0 (TID 187)
[2021-05-14 11:43:21,981] {docker.py:276} INFO - 21/05/14 14:43:21 INFO Executor: Finished task 184.0 in stage 0.0 (TID 184). 1825 bytes result sent to driver
[2021-05-14 11:43:21,981] {docker.py:276} INFO - 21/05/14 14:43:21 INFO TaskSetManager: Starting task 188.0 in stage 0.0 (TID 188) (f0b8ef7ba22f, executor driver, partition 188, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:21,983] {docker.py:276} INFO - 21/05/14 14:43:21 INFO TaskSetManager: Finished task 184.0 in stage 0.0 (TID 184) in 171 ms on f0b8ef7ba22f (executor driver) (185/281)
[2021-05-14 11:43:21,983] {docker.py:276} INFO - 21/05/14 14:43:21 INFO Executor: Running task 188.0 in stage 0.0 (TID 188)
[2021-05-14 11:43:22,142] {docker.py:276} INFO - 21/05/14 14:43:22 INFO Executor: Finished task 186.0 in stage 0.0 (TID 186). 1868 bytes result sent to driver
[2021-05-14 11:43:22,144] {docker.py:276} INFO - 21/05/14 14:43:22 INFO TaskSetManager: Starting task 189.0 in stage 0.0 (TID 189) (f0b8ef7ba22f, executor driver, partition 189, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:22,145] {docker.py:276} INFO - 21/05/14 14:43:22 INFO TaskSetManager: Finished task 186.0 in stage 0.0 (TID 186) in 182 ms on f0b8ef7ba22f (executor driver) (186/281)
[2021-05-14 11:43:22,146] {docker.py:276} INFO - 21/05/14 14:43:22 INFO Executor: Running task 189.0 in stage 0.0 (TID 189)
[2021-05-14 11:43:22,149] {docker.py:276} INFO - 21/05/14 14:43:22 INFO Executor: Finished task 185.0 in stage 0.0 (TID 185). 1868 bytes result sent to driver
[2021-05-14 11:43:22,151] {docker.py:276} INFO - 21/05/14 14:43:22 INFO TaskSetManager: Starting task 190.0 in stage 0.0 (TID 190) (f0b8ef7ba22f, executor driver, partition 190, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:22,153] {docker.py:276} INFO - 21/05/14 14:43:22 INFO Executor: Running task 190.0 in stage 0.0 (TID 190)
[2021-05-14 11:43:22,154] {docker.py:276} INFO - 21/05/14 14:43:22 INFO TaskSetManager: Finished task 185.0 in stage 0.0 (TID 185) in 191 ms on f0b8ef7ba22f (executor driver) (187/281)
[2021-05-14 11:43:22,156] {docker.py:276} INFO - 21/05/14 14:43:22 INFO Executor: Finished task 187.0 in stage 0.0 (TID 187). 1868 bytes result sent to driver
[2021-05-14 11:43:22,157] {docker.py:276} INFO - 21/05/14 14:43:22 INFO TaskSetManager: Starting task 191.0 in stage 0.0 (TID 191) (f0b8ef7ba22f, executor driver, partition 191, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:22,158] {docker.py:276} INFO - 21/05/14 14:43:22 INFO TaskSetManager: Finished task 187.0 in stage 0.0 (TID 187) in 189 ms on f0b8ef7ba22f (executor driver) (188/281)
[2021-05-14 11:43:22,159] {docker.py:276} INFO - 21/05/14 14:43:22 INFO Executor: Running task 191.0 in stage 0.0 (TID 191)
[2021-05-14 11:43:22,160] {docker.py:276} INFO - 21/05/14 14:43:22 INFO Executor: Finished task 188.0 in stage 0.0 (TID 188). 1868 bytes result sent to driver
[2021-05-14 11:43:22,162] {docker.py:276} INFO - 21/05/14 14:43:22 INFO TaskSetManager: Starting task 192.0 in stage 0.0 (TID 192) (f0b8ef7ba22f, executor driver, partition 192, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:22,165] {docker.py:276} INFO - 21/05/14 14:43:22 INFO TaskSetManager: Finished task 188.0 in stage 0.0 (TID 188) in 184 ms on f0b8ef7ba22f (executor driver) (189/281)
21/05/14 14:43:22 INFO Executor: Running task 192.0 in stage 0.0 (TID 192)
[2021-05-14 11:43:22,334] {docker.py:276} INFO - 21/05/14 14:43:22 INFO Executor: Finished task 190.0 in stage 0.0 (TID 190). 1825 bytes result sent to driver
21/05/14 14:43:22 INFO Executor: Finished task 189.0 in stage 0.0 (TID 189). 1825 bytes result sent to driver
[2021-05-14 11:43:22,336] {docker.py:276} INFO - 21/05/14 14:43:22 INFO TaskSetManager: Starting task 193.0 in stage 0.0 (TID 193) (f0b8ef7ba22f, executor driver, partition 193, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:22,337] {docker.py:276} INFO - 21/05/14 14:43:22 INFO TaskSetManager: Finished task 190.0 in stage 0.0 (TID 190) in 186 ms on f0b8ef7ba22f (executor driver) (190/281)
[2021-05-14 11:43:22,338] {docker.py:276} INFO - 21/05/14 14:43:22 INFO Executor: Finished task 192.0 in stage 0.0 (TID 192). 1825 bytes result sent to driver
[2021-05-14 11:43:22,339] {docker.py:276} INFO - 21/05/14 14:43:22 INFO Executor: Running task 193.0 in stage 0.0 (TID 193)
[2021-05-14 11:43:22,340] {docker.py:276} INFO - 21/05/14 14:43:22 INFO TaskSetManager: Starting task 194.0 in stage 0.0 (TID 194) (f0b8ef7ba22f, executor driver, partition 194, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:22,341] {docker.py:276} INFO - 21/05/14 14:43:22 INFO TaskSetManager: Finished task 189.0 in stage 0.0 (TID 189) in 198 ms on f0b8ef7ba22f (executor driver) (191/281)
[2021-05-14 11:43:22,342] {docker.py:276} INFO - 21/05/14 14:43:22 INFO TaskSetManager: Finished task 192.0 in stage 0.0 (TID 192) in 180 ms on f0b8ef7ba22f (executor driver) (192/281)
[2021-05-14 11:43:22,342] {docker.py:276} INFO - 21/05/14 14:43:22 INFO Executor: Running task 194.0 in stage 0.0 (TID 194)
[2021-05-14 11:43:22,343] {docker.py:276} INFO - 21/05/14 14:43:22 INFO Executor: Finished task 191.0 in stage 0.0 (TID 191). 1825 bytes result sent to driver
[2021-05-14 11:43:22,344] {docker.py:276} INFO - 21/05/14 14:43:22 INFO TaskSetManager: Starting task 195.0 in stage 0.0 (TID 195) (f0b8ef7ba22f, executor driver, partition 195, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:22,345] {docker.py:276} INFO - 21/05/14 14:43:22 INFO Executor: Running task 195.0 in stage 0.0 (TID 195)
21/05/14 14:43:22 INFO TaskSetManager: Starting task 196.0 in stage 0.0 (TID 196) (f0b8ef7ba22f, executor driver, partition 196, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:22,346] {docker.py:276} INFO - 21/05/14 14:43:22 INFO TaskSetManager: Finished task 191.0 in stage 0.0 (TID 191) in 190 ms on f0b8ef7ba22f (executor driver) (193/281)
[2021-05-14 11:43:22,347] {docker.py:276} INFO - 21/05/14 14:43:22 INFO Executor: Running task 196.0 in stage 0.0 (TID 196)
[2021-05-14 11:43:22,520] {docker.py:276} INFO - 21/05/14 14:43:22 INFO Executor: Finished task 195.0 in stage 0.0 (TID 195). 1825 bytes result sent to driver
[2021-05-14 11:43:22,521] {docker.py:276} INFO - 21/05/14 14:43:22 INFO TaskSetManager: Starting task 197.0 in stage 0.0 (TID 197) (f0b8ef7ba22f, executor driver, partition 197, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:22,522] {docker.py:276} INFO - 21/05/14 14:43:22 INFO Executor: Running task 197.0 in stage 0.0 (TID 197)
[2021-05-14 11:43:22,523] {docker.py:276} INFO - 21/05/14 14:43:22 INFO TaskSetManager: Finished task 195.0 in stage 0.0 (TID 195) in 180 ms on f0b8ef7ba22f (executor driver) (194/281)
[2021-05-14 11:43:22,525] {docker.py:276} INFO - 21/05/14 14:43:22 INFO Executor: Finished task 193.0 in stage 0.0 (TID 193). 1825 bytes result sent to driver
[2021-05-14 11:43:22,526] {docker.py:276} INFO - 21/05/14 14:43:22 INFO TaskSetManager: Starting task 198.0 in stage 0.0 (TID 198) (f0b8ef7ba22f, executor driver, partition 198, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:22,527] {docker.py:276} INFO - 21/05/14 14:43:22 INFO TaskSetManager: Finished task 193.0 in stage 0.0 (TID 193) in 193 ms on f0b8ef7ba22f (executor driver) (195/281)
[2021-05-14 11:43:22,528] {docker.py:276} INFO - 21/05/14 14:43:22 INFO Executor: Running task 198.0 in stage 0.0 (TID 198)
[2021-05-14 11:43:22,529] {docker.py:276} INFO - 21/05/14 14:43:22 INFO Executor: Finished task 194.0 in stage 0.0 (TID 194). 1825 bytes result sent to driver
[2021-05-14 11:43:22,529] {docker.py:276} INFO - 21/05/14 14:43:22 INFO TaskSetManager: Starting task 199.0 in stage 0.0 (TID 199) (f0b8ef7ba22f, executor driver, partition 199, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:22,530] {docker.py:276} INFO - 21/05/14 14:43:22 INFO Executor: Running task 199.0 in stage 0.0 (TID 199)
[2021-05-14 11:43:22,530] {docker.py:276} INFO - 21/05/14 14:43:22 INFO TaskSetManager: Finished task 194.0 in stage 0.0 (TID 194) in 191 ms on f0b8ef7ba22f (executor driver) (196/281)
[2021-05-14 11:43:22,534] {docker.py:276} INFO - 21/05/14 14:43:22 INFO Executor: Finished task 196.0 in stage 0.0 (TID 196). 1825 bytes result sent to driver
[2021-05-14 11:43:22,535] {docker.py:276} INFO - 21/05/14 14:43:22 INFO TaskSetManager: Starting task 200.0 in stage 0.0 (TID 200) (f0b8ef7ba22f, executor driver, partition 200, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:22,536] {docker.py:276} INFO - 21/05/14 14:43:22 INFO TaskSetManager: Finished task 196.0 in stage 0.0 (TID 196) in 191 ms on f0b8ef7ba22f (executor driver) (197/281)
[2021-05-14 11:43:22,536] {docker.py:276} INFO - 21/05/14 14:43:22 INFO Executor: Running task 200.0 in stage 0.0 (TID 200)
[2021-05-14 11:43:22,706] {docker.py:276} INFO - 21/05/14 14:43:22 INFO Executor: Finished task 197.0 in stage 0.0 (TID 197). 1825 bytes result sent to driver
[2021-05-14 11:43:22,707] {docker.py:276} INFO - 21/05/14 14:43:22 INFO Executor: Finished task 199.0 in stage 0.0 (TID 199). 1825 bytes result sent to driver
21/05/14 14:43:22 INFO TaskSetManager: Starting task 201.0 in stage 0.0 (TID 201) (f0b8ef7ba22f, executor driver, partition 201, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:22,708] {docker.py:276} INFO - 21/05/14 14:43:22 INFO TaskSetManager: Finished task 197.0 in stage 0.0 (TID 197) in 187 ms on f0b8ef7ba22f (executor driver) (198/281)
[2021-05-14 11:43:22,709] {docker.py:276} INFO - 21/05/14 14:43:22 INFO Executor: Finished task 200.0 in stage 0.0 (TID 200). 1825 bytes result sent to driver
[2021-05-14 11:43:22,710] {docker.py:276} INFO - 21/05/14 14:43:22 INFO Executor: Running task 201.0 in stage 0.0 (TID 201)
[2021-05-14 11:43:22,711] {docker.py:276} INFO - 21/05/14 14:43:22 INFO TaskSetManager: Starting task 202.0 in stage 0.0 (TID 202) (f0b8ef7ba22f, executor driver, partition 202, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:22,711] {docker.py:276} INFO - 21/05/14 14:43:22 INFO TaskSetManager: Finished task 200.0 in stage 0.0 (TID 200) in 177 ms on f0b8ef7ba22f (executor driver) (199/281)
[2021-05-14 11:43:22,712] {docker.py:276} INFO - 21/05/14 14:43:22 INFO Executor: Running task 202.0 in stage 0.0 (TID 202)
[2021-05-14 11:43:22,713] {docker.py:276} INFO - 21/05/14 14:43:22 INFO TaskSetManager: Starting task 203.0 in stage 0.0 (TID 203) (f0b8ef7ba22f, executor driver, partition 203, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:22,714] {docker.py:276} INFO - 21/05/14 14:43:22 INFO TaskSetManager: Finished task 199.0 in stage 0.0 (TID 199) in 185 ms on f0b8ef7ba22f (executor driver) (200/281)
[2021-05-14 11:43:22,715] {docker.py:276} INFO - 21/05/14 14:43:22 INFO Executor: Running task 203.0 in stage 0.0 (TID 203)
[2021-05-14 11:43:22,719] {docker.py:276} INFO - 21/05/14 14:43:22 INFO Executor: Finished task 198.0 in stage 0.0 (TID 198). 1825 bytes result sent to driver
[2021-05-14 11:43:22,720] {docker.py:276} INFO - 21/05/14 14:43:22 INFO TaskSetManager: Starting task 204.0 in stage 0.0 (TID 204) (f0b8ef7ba22f, executor driver, partition 204, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:22,720] {docker.py:276} INFO - 21/05/14 14:43:22 INFO TaskSetManager: Finished task 198.0 in stage 0.0 (TID 198) in 194 ms on f0b8ef7ba22f (executor driver) (201/281)
[2021-05-14 11:43:22,720] {docker.py:276} INFO - 21/05/14 14:43:22 INFO Executor: Running task 204.0 in stage 0.0 (TID 204)
[2021-05-14 11:43:22,884] {docker.py:276} INFO - 21/05/14 14:43:22 INFO Executor: Finished task 202.0 in stage 0.0 (TID 202). 1868 bytes result sent to driver
[2021-05-14 11:43:22,885] {docker.py:276} INFO - 21/05/14 14:43:22 INFO TaskSetManager: Starting task 205.0 in stage 0.0 (TID 205) (f0b8ef7ba22f, executor driver, partition 205, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:22,886] {docker.py:276} INFO - 21/05/14 14:43:22 INFO TaskSetManager: Finished task 202.0 in stage 0.0 (TID 202) in 176 ms on f0b8ef7ba22f (executor driver) (202/281)
[2021-05-14 11:43:22,887] {docker.py:276} INFO - 21/05/14 14:43:22 INFO Executor: Running task 205.0 in stage 0.0 (TID 205)
[2021-05-14 11:43:22,892] {docker.py:276} INFO - 21/05/14 14:43:22 INFO Executor: Finished task 201.0 in stage 0.0 (TID 201). 1868 bytes result sent to driver
[2021-05-14 11:43:22,893] {docker.py:276} INFO - 21/05/14 14:43:22 INFO TaskSetManager: Starting task 206.0 in stage 0.0 (TID 206) (f0b8ef7ba22f, executor driver, partition 206, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:22,893] {docker.py:276} INFO - 21/05/14 14:43:22 INFO TaskSetManager: Finished task 201.0 in stage 0.0 (TID 201) in 188 ms on f0b8ef7ba22f (executor driver) (203/281)
[2021-05-14 11:43:22,894] {docker.py:276} INFO - 21/05/14 14:43:22 INFO Executor: Running task 206.0 in stage 0.0 (TID 206)
[2021-05-14 11:43:22,904] {docker.py:276} INFO - 21/05/14 14:43:22 INFO Executor: Finished task 204.0 in stage 0.0 (TID 204). 1868 bytes result sent to driver
[2021-05-14 11:43:22,906] {docker.py:276} INFO - 21/05/14 14:43:22 INFO Executor: Finished task 203.0 in stage 0.0 (TID 203). 1868 bytes result sent to driver
21/05/14 14:43:22 INFO TaskSetManager: Starting task 207.0 in stage 0.0 (TID 207) (f0b8ef7ba22f, executor driver, partition 207, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:22,906] {docker.py:276} INFO - 21/05/14 14:43:22 INFO Executor: Running task 207.0 in stage 0.0 (TID 207)
[2021-05-14 11:43:22,907] {docker.py:276} INFO - 21/05/14 14:43:22 INFO TaskSetManager: Starting task 208.0 in stage 0.0 (TID 208) (f0b8ef7ba22f, executor driver, partition 208, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:22,908] {docker.py:276} INFO - 21/05/14 14:43:22 INFO TaskSetManager: Finished task 204.0 in stage 0.0 (TID 204) in 190 ms on f0b8ef7ba22f (executor driver) (204/281)
[2021-05-14 11:43:22,908] {docker.py:276} INFO - 21/05/14 14:43:22 INFO Executor: Running task 208.0 in stage 0.0 (TID 208)
[2021-05-14 11:43:22,909] {docker.py:276} INFO - 21/05/14 14:43:22 INFO TaskSetManager: Finished task 203.0 in stage 0.0 (TID 203) in 196 ms on f0b8ef7ba22f (executor driver) (205/281)
[2021-05-14 11:43:23,066] {docker.py:276} INFO - 21/05/14 14:43:23 INFO Executor: Finished task 206.0 in stage 0.0 (TID 206). 1825 bytes result sent to driver
[2021-05-14 11:43:23,070] {docker.py:276} INFO - 21/05/14 14:43:23 INFO Executor: Finished task 205.0 in stage 0.0 (TID 205). 1825 bytes result sent to driver
21/05/14 14:43:23 INFO TaskSetManager: Starting task 209.0 in stage 0.0 (TID 209) (f0b8ef7ba22f, executor driver, partition 209, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:23,071] {docker.py:276} INFO - 21/05/14 14:43:23 INFO Executor: Running task 209.0 in stage 0.0 (TID 209)
[2021-05-14 11:43:23,072] {docker.py:276} INFO - 21/05/14 14:43:23 INFO TaskSetManager: Starting task 210.0 in stage 0.0 (TID 210) (f0b8ef7ba22f, executor driver, partition 210, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:23,072] {docker.py:276} INFO - 21/05/14 14:43:23 INFO TaskSetManager: Finished task 206.0 in stage 0.0 (TID 206) in 178 ms on f0b8ef7ba22f (executor driver) (206/281)
[2021-05-14 11:43:23,072] {docker.py:276} INFO - 21/05/14 14:43:23 INFO Executor: Running task 210.0 in stage 0.0 (TID 210)
[2021-05-14 11:43:23,073] {docker.py:276} INFO - 21/05/14 14:43:23 INFO TaskSetManager: Finished task 205.0 in stage 0.0 (TID 205) in 187 ms on f0b8ef7ba22f (executor driver) (207/281)
[2021-05-14 11:43:23,079] {docker.py:276} INFO - 21/05/14 14:43:23 INFO Executor: Finished task 207.0 in stage 0.0 (TID 207). 1825 bytes result sent to driver
[2021-05-14 11:43:23,081] {docker.py:276} INFO - 21/05/14 14:43:23 INFO TaskSetManager: Starting task 211.0 in stage 0.0 (TID 211) (f0b8ef7ba22f, executor driver, partition 211, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:23,081] {docker.py:276} INFO - 21/05/14 14:43:23 INFO Executor: Running task 211.0 in stage 0.0 (TID 211)
[2021-05-14 11:43:23,082] {docker.py:276} INFO - 21/05/14 14:43:23 INFO TaskSetManager: Finished task 207.0 in stage 0.0 (TID 207) in 176 ms on f0b8ef7ba22f (executor driver) (208/281)
[2021-05-14 11:43:23,090] {docker.py:276} INFO - 21/05/14 14:43:23 INFO Executor: Finished task 208.0 in stage 0.0 (TID 208). 1825 bytes result sent to driver
[2021-05-14 11:43:23,090] {docker.py:276} INFO - 21/05/14 14:43:23 INFO TaskSetManager: Starting task 212.0 in stage 0.0 (TID 212) (f0b8ef7ba22f, executor driver, partition 212, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:23,091] {docker.py:276} INFO - 21/05/14 14:43:23 INFO TaskSetManager: Finished task 208.0 in stage 0.0 (TID 208) in 185 ms on f0b8ef7ba22f (executor driver) (209/281)
[2021-05-14 11:43:23,092] {docker.py:276} INFO - 21/05/14 14:43:23 INFO Executor: Running task 212.0 in stage 0.0 (TID 212)
[2021-05-14 11:43:23,247] {docker.py:276} INFO - 21/05/14 14:43:23 INFO Executor: Finished task 210.0 in stage 0.0 (TID 210). 1825 bytes result sent to driver
[2021-05-14 11:43:23,249] {docker.py:276} INFO - 21/05/14 14:43:23 INFO TaskSetManager: Starting task 213.0 in stage 0.0 (TID 213) (f0b8ef7ba22f, executor driver, partition 213, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:23,250] {docker.py:276} INFO - 21/05/14 14:43:23 INFO TaskSetManager: Finished task 210.0 in stage 0.0 (TID 210) in 181 ms on f0b8ef7ba22f (executor driver) (210/281)
[2021-05-14 11:43:23,251] {docker.py:276} INFO - 21/05/14 14:43:23 INFO Executor: Running task 213.0 in stage 0.0 (TID 213)
[2021-05-14 11:43:23,253] {docker.py:276} INFO - 21/05/14 14:43:23 INFO Executor: Finished task 209.0 in stage 0.0 (TID 209). 1825 bytes result sent to driver
[2021-05-14 11:43:23,255] {docker.py:276} INFO - 21/05/14 14:43:23 INFO TaskSetManager: Starting task 214.0 in stage 0.0 (TID 214) (f0b8ef7ba22f, executor driver, partition 214, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:23,256] {docker.py:276} INFO - 21/05/14 14:43:23 INFO TaskSetManager: Finished task 209.0 in stage 0.0 (TID 209) in 188 ms on f0b8ef7ba22f (executor driver) (211/281)
[2021-05-14 11:43:23,257] {docker.py:276} INFO - 21/05/14 14:43:23 INFO Executor: Running task 214.0 in stage 0.0 (TID 214)
[2021-05-14 11:43:23,258] {docker.py:276} INFO - 21/05/14 14:43:23 INFO Executor: Finished task 211.0 in stage 0.0 (TID 211). 1825 bytes result sent to driver
[2021-05-14 11:43:23,259] {docker.py:276} INFO - 21/05/14 14:43:23 INFO TaskSetManager: Starting task 215.0 in stage 0.0 (TID 215) (f0b8ef7ba22f, executor driver, partition 215, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:23,260] {docker.py:276} INFO - 21/05/14 14:43:23 INFO Executor: Running task 215.0 in stage 0.0 (TID 215)
21/05/14 14:43:23 INFO TaskSetManager: Finished task 211.0 in stage 0.0 (TID 211) in 180 ms on f0b8ef7ba22f (executor driver) (212/281)
[2021-05-14 11:43:23,269] {docker.py:276} INFO - 21/05/14 14:43:23 INFO Executor: Finished task 212.0 in stage 0.0 (TID 212). 1825 bytes result sent to driver
[2021-05-14 11:43:23,270] {docker.py:276} INFO - 21/05/14 14:43:23 INFO TaskSetManager: Starting task 216.0 in stage 0.0 (TID 216) (f0b8ef7ba22f, executor driver, partition 216, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:23,270] {docker.py:276} INFO - 21/05/14 14:43:23 INFO TaskSetManager: Finished task 212.0 in stage 0.0 (TID 212) in 180 ms on f0b8ef7ba22f (executor driver) (213/281)
[2021-05-14 11:43:23,271] {docker.py:276} INFO - 21/05/14 14:43:23 INFO Executor: Running task 216.0 in stage 0.0 (TID 216)
[2021-05-14 11:43:23,427] {docker.py:276} INFO - 21/05/14 14:43:23 INFO Executor: Finished task 213.0 in stage 0.0 (TID 213). 1825 bytes result sent to driver
[2021-05-14 11:43:23,430] {docker.py:276} INFO - 21/05/14 14:43:23 INFO TaskSetManager: Starting task 217.0 in stage 0.0 (TID 217) (f0b8ef7ba22f, executor driver, partition 217, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:23,431] {docker.py:276} INFO - 21/05/14 14:43:23 INFO Executor: Running task 217.0 in stage 0.0 (TID 217)
21/05/14 14:43:23 INFO TaskSetManager: Finished task 213.0 in stage 0.0 (TID 213) in 184 ms on f0b8ef7ba22f (executor driver) (214/281)
[2021-05-14 11:43:23,441] {docker.py:276} INFO - 21/05/14 14:43:23 INFO Executor: Finished task 214.0 in stage 0.0 (TID 214). 1825 bytes result sent to driver
[2021-05-14 11:43:23,442] {docker.py:276} INFO - 21/05/14 14:43:23 INFO TaskSetManager: Starting task 218.0 in stage 0.0 (TID 218) (f0b8ef7ba22f, executor driver, partition 218, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:23,442] {docker.py:276} INFO - 21/05/14 14:43:23 INFO TaskSetManager: Finished task 214.0 in stage 0.0 (TID 214) in 188 ms on f0b8ef7ba22f (executor driver) (215/281)
21/05/14 14:43:23 INFO Executor: Running task 218.0 in stage 0.0 (TID 218)
[2021-05-14 11:43:23,443] {docker.py:276} INFO - 21/05/14 14:43:23 INFO Executor: Finished task 216.0 in stage 0.0 (TID 216). 1825 bytes result sent to driver
[2021-05-14 11:43:23,444] {docker.py:276} INFO - 21/05/14 14:43:23 INFO TaskSetManager: Starting task 219.0 in stage 0.0 (TID 219) (f0b8ef7ba22f, executor driver, partition 219, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:23,446] {docker.py:276} INFO - 21/05/14 14:43:23 INFO TaskSetManager: Finished task 216.0 in stage 0.0 (TID 216) in 177 ms on f0b8ef7ba22f (executor driver) (216/281)
21/05/14 14:43:23 INFO Executor: Running task 219.0 in stage 0.0 (TID 219)
[2021-05-14 11:43:23,450] {docker.py:276} INFO - 21/05/14 14:43:23 INFO Executor: Finished task 215.0 in stage 0.0 (TID 215). 1825 bytes result sent to driver
[2021-05-14 11:43:23,451] {docker.py:276} INFO - 21/05/14 14:43:23 INFO TaskSetManager: Starting task 220.0 in stage 0.0 (TID 220) (f0b8ef7ba22f, executor driver, partition 220, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:23,451] {docker.py:276} INFO - 21/05/14 14:43:23 INFO Executor: Running task 220.0 in stage 0.0 (TID 220)
[2021-05-14 11:43:23,452] {docker.py:276} INFO - 21/05/14 14:43:23 INFO TaskSetManager: Finished task 215.0 in stage 0.0 (TID 215) in 194 ms on f0b8ef7ba22f (executor driver) (217/281)
[2021-05-14 11:43:23,609] {docker.py:276} INFO - 21/05/14 14:43:23 INFO Executor: Finished task 217.0 in stage 0.0 (TID 217). 1825 bytes result sent to driver
[2021-05-14 11:43:23,610] {docker.py:276} INFO - 21/05/14 14:43:23 INFO TaskSetManager: Starting task 221.0 in stage 0.0 (TID 221) (f0b8ef7ba22f, executor driver, partition 221, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:23,611] {docker.py:276} INFO - 21/05/14 14:43:23 INFO TaskSetManager: Finished task 217.0 in stage 0.0 (TID 217) in 183 ms on f0b8ef7ba22f (executor driver) (218/281)
[2021-05-14 11:43:23,612] {docker.py:276} INFO - 21/05/14 14:43:23 INFO Executor: Running task 221.0 in stage 0.0 (TID 221)
[2021-05-14 11:43:23,626] {docker.py:276} INFO - 21/05/14 14:43:23 INFO Executor: Finished task 219.0 in stage 0.0 (TID 219). 1868 bytes result sent to driver
[2021-05-14 11:43:23,627] {docker.py:276} INFO - 21/05/14 14:43:23 INFO Executor: Finished task 220.0 in stage 0.0 (TID 220). 1868 bytes result sent to driver
[2021-05-14 11:43:23,628] {docker.py:276} INFO - 21/05/14 14:43:23 INFO TaskSetManager: Starting task 222.0 in stage 0.0 (TID 222) (f0b8ef7ba22f, executor driver, partition 222, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:23,628] {docker.py:276} INFO - 21/05/14 14:43:23 INFO TaskSetManager: Starting task 223.0 in stage 0.0 (TID 223) (f0b8ef7ba22f, executor driver, partition 223, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:23,629] {docker.py:276} INFO - 21/05/14 14:43:23 INFO TaskSetManager: Finished task 220.0 in stage 0.0 (TID 220) in 179 ms on f0b8ef7ba22f (executor driver) (219/281)
[2021-05-14 11:43:23,630] {docker.py:276} INFO - 21/05/14 14:43:23 INFO TaskSetManager: Finished task 219.0 in stage 0.0 (TID 219) in 186 ms on f0b8ef7ba22f (executor driver) (220/281)
[2021-05-14 11:43:23,630] {docker.py:276} INFO - 21/05/14 14:43:23 INFO Executor: Running task 223.0 in stage 0.0 (TID 223)
[2021-05-14 11:43:23,631] {docker.py:276} INFO - 21/05/14 14:43:23 INFO Executor: Finished task 218.0 in stage 0.0 (TID 218). 1868 bytes result sent to driver
[2021-05-14 11:43:23,631] {docker.py:276} INFO - 21/05/14 14:43:23 INFO Executor: Running task 222.0 in stage 0.0 (TID 222)
[2021-05-14 11:43:23,632] {docker.py:276} INFO - 21/05/14 14:43:23 INFO TaskSetManager: Starting task 224.0 in stage 0.0 (TID 224) (f0b8ef7ba22f, executor driver, partition 224, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:23,632] {docker.py:276} INFO - 21/05/14 14:43:23 INFO TaskSetManager: Finished task 218.0 in stage 0.0 (TID 218) in 192 ms on f0b8ef7ba22f (executor driver) (221/281)
[2021-05-14 11:43:23,633] {docker.py:276} INFO - 21/05/14 14:43:23 INFO Executor: Running task 224.0 in stage 0.0 (TID 224)
[2021-05-14 11:43:23,806] {docker.py:276} INFO - 21/05/14 14:43:23 INFO Executor: Finished task 223.0 in stage 0.0 (TID 223). 1825 bytes result sent to driver
[2021-05-14 11:43:23,807] {docker.py:276} INFO - 21/05/14 14:43:23 INFO Executor: Finished task 222.0 in stage 0.0 (TID 222). 1825 bytes result sent to driver
[2021-05-14 11:43:23,808] {docker.py:276} INFO - 21/05/14 14:43:23 INFO TaskSetManager: Starting task 225.0 in stage 0.0 (TID 225) (f0b8ef7ba22f, executor driver, partition 225, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:23,809] {docker.py:276} INFO - 21/05/14 14:43:23 INFO TaskSetManager: Finished task 223.0 in stage 0.0 (TID 223) in 180 ms on f0b8ef7ba22f (executor driver) (222/281)
[2021-05-14 11:43:23,809] {docker.py:276} INFO - 21/05/14 14:43:23 INFO Executor: Running task 225.0 in stage 0.0 (TID 225)
[2021-05-14 11:43:23,810] {docker.py:276} INFO - 21/05/14 14:43:23 INFO TaskSetManager: Starting task 226.0 in stage 0.0 (TID 226) (f0b8ef7ba22f, executor driver, partition 226, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:23,811] {docker.py:276} INFO - 21/05/14 14:43:23 INFO TaskSetManager: Finished task 222.0 in stage 0.0 (TID 222) in 183 ms on f0b8ef7ba22f (executor driver) (223/281)
[2021-05-14 11:43:23,812] {docker.py:276} INFO - 21/05/14 14:43:23 INFO Executor: Running task 226.0 in stage 0.0 (TID 226)
[2021-05-14 11:43:23,814] {docker.py:276} INFO - 21/05/14 14:43:23 INFO Executor: Finished task 221.0 in stage 0.0 (TID 221). 1868 bytes result sent to driver
[2021-05-14 11:43:23,815] {docker.py:276} INFO - 21/05/14 14:43:23 INFO TaskSetManager: Starting task 227.0 in stage 0.0 (TID 227) (f0b8ef7ba22f, executor driver, partition 227, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:23,816] {docker.py:276} INFO - 21/05/14 14:43:23 INFO TaskSetManager: Finished task 221.0 in stage 0.0 (TID 221) in 206 ms on f0b8ef7ba22f (executor driver) (224/281)
[2021-05-14 11:43:23,817] {docker.py:276} INFO - 21/05/14 14:43:23 INFO Executor: Running task 227.0 in stage 0.0 (TID 227)
[2021-05-14 11:43:23,818] {docker.py:276} INFO - 21/05/14 14:43:23 INFO Executor: Finished task 224.0 in stage 0.0 (TID 224). 1825 bytes result sent to driver
[2021-05-14 11:43:23,820] {docker.py:276} INFO - 21/05/14 14:43:23 INFO TaskSetManager: Starting task 228.0 in stage 0.0 (TID 228) (f0b8ef7ba22f, executor driver, partition 228, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:23,821] {docker.py:276} INFO - 21/05/14 14:43:23 INFO Executor: Running task 228.0 in stage 0.0 (TID 228)
[2021-05-14 11:43:23,821] {docker.py:276} INFO - 21/05/14 14:43:23 INFO TaskSetManager: Finished task 224.0 in stage 0.0 (TID 224) in 190 ms on f0b8ef7ba22f (executor driver) (225/281)
[2021-05-14 11:43:23,989] {docker.py:276} INFO - 21/05/14 14:43:24 INFO Executor: Finished task 228.0 in stage 0.0 (TID 228). 1825 bytes result sent to driver
[2021-05-14 11:43:23,990] {docker.py:276} INFO - 21/05/14 14:43:24 INFO TaskSetManager: Starting task 229.0 in stage 0.0 (TID 229) (f0b8ef7ba22f, executor driver, partition 229, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:23,991] {docker.py:276} INFO - 21/05/14 14:43:24 INFO Executor: Finished task 225.0 in stage 0.0 (TID 225). 1825 bytes result sent to driver
[2021-05-14 11:43:23,992] {docker.py:276} INFO - 21/05/14 14:43:24 INFO TaskSetManager: Finished task 228.0 in stage 0.0 (TID 228) in 172 ms on f0b8ef7ba22f (executor driver) (226/281)
[2021-05-14 11:43:23,993] {docker.py:276} INFO - 21/05/14 14:43:24 INFO Executor: Finished task 227.0 in stage 0.0 (TID 227). 1825 bytes result sent to driver
[2021-05-14 11:43:23,994] {docker.py:276} INFO - 21/05/14 14:43:24 INFO Executor: Running task 229.0 in stage 0.0 (TID 229)
[2021-05-14 11:43:23,995] {docker.py:276} INFO - 21/05/14 14:43:24 INFO TaskSetManager: Starting task 230.0 in stage 0.0 (TID 230) (f0b8ef7ba22f, executor driver, partition 230, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:23,996] {docker.py:276} INFO - 21/05/14 14:43:24 INFO Executor: Running task 230.0 in stage 0.0 (TID 230)
[2021-05-14 11:43:23,997] {docker.py:276} INFO - 21/05/14 14:43:24 INFO TaskSetManager: Starting task 231.0 in stage 0.0 (TID 231) (f0b8ef7ba22f, executor driver, partition 231, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:23,998] {docker.py:276} INFO - 21/05/14 14:43:24 INFO TaskSetManager: Finished task 225.0 in stage 0.0 (TID 225) in 191 ms on f0b8ef7ba22f (executor driver) (227/281)
[2021-05-14 11:43:23,998] {docker.py:276} INFO - 21/05/14 14:43:24 INFO Executor: Running task 231.0 in stage 0.0 (TID 231)
[2021-05-14 11:43:23,999] {docker.py:276} INFO - 21/05/14 14:43:24 INFO TaskSetManager: Finished task 227.0 in stage 0.0 (TID 227) in 184 ms on f0b8ef7ba22f (executor driver) (228/281)
[2021-05-14 11:43:24,009] {docker.py:276} INFO - 21/05/14 14:43:24 INFO Executor: Finished task 226.0 in stage 0.0 (TID 226). 1825 bytes result sent to driver
[2021-05-14 11:43:24,010] {docker.py:276} INFO - 21/05/14 14:43:24 INFO TaskSetManager: Starting task 232.0 in stage 0.0 (TID 232) (f0b8ef7ba22f, executor driver, partition 232, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:24,011] {docker.py:276} INFO - 21/05/14 14:43:24 INFO Executor: Running task 232.0 in stage 0.0 (TID 232)
[2021-05-14 11:43:24,011] {docker.py:276} INFO - 21/05/14 14:43:24 INFO TaskSetManager: Finished task 226.0 in stage 0.0 (TID 226) in 202 ms on f0b8ef7ba22f (executor driver) (229/281)
[2021-05-14 11:43:24,171] {docker.py:276} INFO - 21/05/14 14:43:24 INFO Executor: Finished task 230.0 in stage 0.0 (TID 230). 1825 bytes result sent to driver
[2021-05-14 11:43:24,173] {docker.py:276} INFO - 21/05/14 14:43:24 INFO TaskSetManager: Starting task 233.0 in stage 0.0 (TID 233) (f0b8ef7ba22f, executor driver, partition 233, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:24,174] {docker.py:276} INFO - 21/05/14 14:43:24 INFO TaskSetManager: Finished task 230.0 in stage 0.0 (TID 230) in 181 ms on f0b8ef7ba22f (executor driver) (230/281)
[2021-05-14 11:43:24,175] {docker.py:276} INFO - 21/05/14 14:43:24 INFO Executor: Finished task 231.0 in stage 0.0 (TID 231). 1825 bytes result sent to driver
[2021-05-14 11:43:24,176] {docker.py:276} INFO - 21/05/14 14:43:24 INFO Executor: Running task 233.0 in stage 0.0 (TID 233)
[2021-05-14 11:43:24,176] {docker.py:276} INFO - 21/05/14 14:43:24 INFO TaskSetManager: Starting task 234.0 in stage 0.0 (TID 234) (f0b8ef7ba22f, executor driver, partition 234, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:24,177] {docker.py:276} INFO - 21/05/14 14:43:24 INFO TaskSetManager: Finished task 231.0 in stage 0.0 (TID 231) in 182 ms on f0b8ef7ba22f (executor driver) (231/281)
[2021-05-14 11:43:24,178] {docker.py:276} INFO - 21/05/14 14:43:24 INFO Executor: Running task 234.0 in stage 0.0 (TID 234)
[2021-05-14 11:43:24,190] {docker.py:276} INFO - 21/05/14 14:43:24 INFO Executor: Finished task 229.0 in stage 0.0 (TID 229). 1825 bytes result sent to driver
[2021-05-14 11:43:24,191] {docker.py:276} INFO - 21/05/14 14:43:24 INFO TaskSetManager: Starting task 235.0 in stage 0.0 (TID 235) (f0b8ef7ba22f, executor driver, partition 235, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:24,192] {docker.py:276} INFO - 21/05/14 14:43:24 INFO TaskSetManager: Finished task 229.0 in stage 0.0 (TID 229) in 202 ms on f0b8ef7ba22f (executor driver) (232/281)
21/05/14 14:43:24 INFO Executor: Running task 235.0 in stage 0.0 (TID 235)
21/05/14 14:43:24 INFO Executor: Finished task 232.0 in stage 0.0 (TID 232). 1825 bytes result sent to driver
[2021-05-14 11:43:24,193] {docker.py:276} INFO - 21/05/14 14:43:24 INFO TaskSetManager: Starting task 236.0 in stage 0.0 (TID 236) (f0b8ef7ba22f, executor driver, partition 236, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:24,194] {docker.py:276} INFO - 21/05/14 14:43:24 INFO TaskSetManager: Finished task 232.0 in stage 0.0 (TID 232) in 184 ms on f0b8ef7ba22f (executor driver) (233/281)
[2021-05-14 11:43:24,195] {docker.py:276} INFO - 21/05/14 14:43:24 INFO Executor: Running task 236.0 in stage 0.0 (TID 236)
[2021-05-14 11:43:24,353] {docker.py:276} INFO - 21/05/14 14:43:24 INFO Executor: Finished task 233.0 in stage 0.0 (TID 233). 1825 bytes result sent to driver
[2021-05-14 11:43:24,356] {docker.py:276} INFO - 21/05/14 14:43:24 INFO TaskSetManager: Starting task 237.0 in stage 0.0 (TID 237) (f0b8ef7ba22f, executor driver, partition 237, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:24,357] {docker.py:276} INFO - 21/05/14 14:43:24 INFO TaskSetManager: Finished task 233.0 in stage 0.0 (TID 233) in 185 ms on f0b8ef7ba22f (executor driver) (234/281)
[2021-05-14 11:43:24,358] {docker.py:276} INFO - 21/05/14 14:43:24 INFO Executor: Running task 237.0 in stage 0.0 (TID 237)
[2021-05-14 11:43:24,370] {docker.py:276} INFO - 21/05/14 14:43:24 INFO Executor: Finished task 234.0 in stage 0.0 (TID 234). 1868 bytes result sent to driver
[2021-05-14 11:43:24,371] {docker.py:276} INFO - 21/05/14 14:43:24 INFO TaskSetManager: Starting task 238.0 in stage 0.0 (TID 238) (f0b8ef7ba22f, executor driver, partition 238, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:24,372] {docker.py:276} INFO - 21/05/14 14:43:24 INFO Executor: Running task 238.0 in stage 0.0 (TID 238)
[2021-05-14 11:43:24,372] {docker.py:276} INFO - 21/05/14 14:43:24 INFO Executor: Finished task 235.0 in stage 0.0 (TID 235). 1868 bytes result sent to driver
[2021-05-14 11:43:24,373] {docker.py:276} INFO - 21/05/14 14:43:24 INFO TaskSetManager: Finished task 234.0 in stage 0.0 (TID 234) in 196 ms on f0b8ef7ba22f (executor driver) (235/281)
[2021-05-14 11:43:24,374] {docker.py:276} INFO - 21/05/14 14:43:24 INFO TaskSetManager: Starting task 239.0 in stage 0.0 (TID 239) (f0b8ef7ba22f, executor driver, partition 239, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:24,375] {docker.py:276} INFO - 21/05/14 14:43:24 INFO TaskSetManager: Finished task 235.0 in stage 0.0 (TID 235) in 184 ms on f0b8ef7ba22f (executor driver) (236/281)
[2021-05-14 11:43:24,375] {docker.py:276} INFO - 21/05/14 14:43:24 INFO Executor: Running task 239.0 in stage 0.0 (TID 239)
[2021-05-14 11:43:24,543] {docker.py:276} INFO - 21/05/14 14:43:24 INFO Executor: Finished task 237.0 in stage 0.0 (TID 237). 1868 bytes result sent to driver
[2021-05-14 11:43:24,544] {docker.py:276} INFO - 21/05/14 14:43:24 INFO TaskSetManager: Starting task 240.0 in stage 0.0 (TID 240) (f0b8ef7ba22f, executor driver, partition 240, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:24,546] {docker.py:276} INFO - 21/05/14 14:43:24 INFO TaskSetManager: Finished task 237.0 in stage 0.0 (TID 237) in 191 ms on f0b8ef7ba22f (executor driver) (237/281)
[2021-05-14 11:43:24,548] {docker.py:276} INFO - 21/05/14 14:43:24 INFO Executor: Running task 240.0 in stage 0.0 (TID 240)
[2021-05-14 11:43:24,551] {docker.py:276} INFO - 21/05/14 14:43:24 INFO Executor: Finished task 239.0 in stage 0.0 (TID 239). 1825 bytes result sent to driver
[2021-05-14 11:43:24,552] {docker.py:276} INFO - 21/05/14 14:43:24 INFO TaskSetManager: Starting task 241.0 in stage 0.0 (TID 241) (f0b8ef7ba22f, executor driver, partition 241, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:24,553] {docker.py:276} INFO - 21/05/14 14:43:24 INFO TaskSetManager: Finished task 239.0 in stage 0.0 (TID 239) in 178 ms on f0b8ef7ba22f (executor driver) (238/281)
[2021-05-14 11:43:24,554] {docker.py:276} INFO - 21/05/14 14:43:24 INFO Executor: Running task 241.0 in stage 0.0 (TID 241)
[2021-05-14 11:43:24,557] {docker.py:276} INFO - 21/05/14 14:43:24 INFO Executor: Finished task 238.0 in stage 0.0 (TID 238). 1825 bytes result sent to driver
[2021-05-14 11:43:24,558] {docker.py:276} INFO - 21/05/14 14:43:24 INFO TaskSetManager: Starting task 242.0 in stage 0.0 (TID 242) (f0b8ef7ba22f, executor driver, partition 242, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:24,559] {docker.py:276} INFO - 21/05/14 14:43:24 INFO TaskSetManager: Finished task 238.0 in stage 0.0 (TID 238) in 189 ms on f0b8ef7ba22f (executor driver) (239/281)
[2021-05-14 11:43:24,559] {docker.py:276} INFO - 21/05/14 14:43:24 INFO Executor: Running task 242.0 in stage 0.0 (TID 242)
[2021-05-14 11:43:24,731] {docker.py:276} INFO - 21/05/14 14:43:24 INFO Executor: Finished task 241.0 in stage 0.0 (TID 241). 1825 bytes result sent to driver
[2021-05-14 11:43:24,732] {docker.py:276} INFO - 21/05/14 14:43:24 INFO TaskSetManager: Starting task 243.0 in stage 0.0 (TID 243) (f0b8ef7ba22f, executor driver, partition 243, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:24,733] {docker.py:276} INFO - 21/05/14 14:43:24 INFO TaskSetManager: Finished task 241.0 in stage 0.0 (TID 241) in 184 ms on f0b8ef7ba22f (executor driver) (240/281)
[2021-05-14 11:43:24,733] {docker.py:276} INFO - 21/05/14 14:43:24 INFO Executor: Running task 243.0 in stage 0.0 (TID 243)
[2021-05-14 11:43:24,735] {docker.py:276} INFO - 21/05/14 14:43:24 INFO Executor: Finished task 242.0 in stage 0.0 (TID 242). 1825 bytes result sent to driver
[2021-05-14 11:43:24,736] {docker.py:276} INFO - 21/05/14 14:43:24 INFO TaskSetManager: Starting task 244.0 in stage 0.0 (TID 244) (f0b8ef7ba22f, executor driver, partition 244, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:24,737] {docker.py:276} INFO - 21/05/14 14:43:24 INFO TaskSetManager: Finished task 242.0 in stage 0.0 (TID 242) in 179 ms on f0b8ef7ba22f (executor driver) (241/281)
[2021-05-14 11:43:24,737] {docker.py:276} INFO - 21/05/14 14:43:24 INFO Executor: Running task 244.0 in stage 0.0 (TID 244)
[2021-05-14 11:43:24,741] {docker.py:276} INFO - 21/05/14 14:43:24 INFO Executor: Finished task 240.0 in stage 0.0 (TID 240). 1825 bytes result sent to driver
[2021-05-14 11:43:24,742] {docker.py:276} INFO - 21/05/14 14:43:24 INFO TaskSetManager: Starting task 245.0 in stage 0.0 (TID 245) (f0b8ef7ba22f, executor driver, partition 245, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:24,743] {docker.py:276} INFO - 21/05/14 14:43:24 INFO TaskSetManager: Finished task 240.0 in stage 0.0 (TID 240) in 199 ms on f0b8ef7ba22f (executor driver) (242/281)
[2021-05-14 11:43:24,743] {docker.py:276} INFO - 21/05/14 14:43:24 INFO Executor: Running task 245.0 in stage 0.0 (TID 245)
[2021-05-14 11:43:24,870] {docker.py:276} INFO - 21/05/14 14:43:24 INFO Executor: Finished task 236.0 in stage 0.0 (TID 236). 1868 bytes result sent to driver
[2021-05-14 11:43:24,871] {docker.py:276} INFO - 21/05/14 14:43:24 INFO TaskSetManager: Starting task 246.0 in stage 0.0 (TID 246) (f0b8ef7ba22f, executor driver, partition 246, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:24,873] {docker.py:276} INFO - 21/05/14 14:43:24 INFO Executor: Running task 246.0 in stage 0.0 (TID 246)
21/05/14 14:43:24 INFO TaskSetManager: Finished task 236.0 in stage 0.0 (TID 236) in 680 ms on f0b8ef7ba22f (executor driver) (243/281)
[2021-05-14 11:43:24,920] {docker.py:276} INFO - 21/05/14 14:43:24 INFO Executor: Finished task 244.0 in stage 0.0 (TID 244). 1825 bytes result sent to driver
[2021-05-14 11:43:24,922] {docker.py:276} INFO - 21/05/14 14:43:24 INFO Executor: Finished task 243.0 in stage 0.0 (TID 243). 1825 bytes result sent to driver
21/05/14 14:43:24 INFO Executor: Finished task 245.0 in stage 0.0 (TID 245). 1825 bytes result sent to driver
[2021-05-14 11:43:24,923] {docker.py:276} INFO - 21/05/14 14:43:24 INFO TaskSetManager: Starting task 247.0 in stage 0.0 (TID 247) (f0b8ef7ba22f, executor driver, partition 247, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:24,924] {docker.py:276} INFO - 21/05/14 14:43:24 INFO TaskSetManager: Finished task 244.0 in stage 0.0 (TID 244) in 188 ms on f0b8ef7ba22f (executor driver) (244/281)
[2021-05-14 11:43:24,925] {docker.py:276} INFO - 21/05/14 14:43:24 INFO Executor: Running task 247.0 in stage 0.0 (TID 247)
[2021-05-14 11:43:24,925] {docker.py:276} INFO - 21/05/14 14:43:24 INFO TaskSetManager: Starting task 248.0 in stage 0.0 (TID 248) (f0b8ef7ba22f, executor driver, partition 248, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:24,926] {docker.py:276} INFO - 21/05/14 14:43:24 INFO TaskSetManager: Finished task 243.0 in stage 0.0 (TID 243) in 193 ms on f0b8ef7ba22f (executor driver) (245/281)
[2021-05-14 11:43:24,927] {docker.py:276} INFO - 21/05/14 14:43:24 INFO Executor: Running task 248.0 in stage 0.0 (TID 248)
[2021-05-14 11:43:24,928] {docker.py:276} INFO - 21/05/14 14:43:24 INFO TaskSetManager: Starting task 249.0 in stage 0.0 (TID 249) (f0b8ef7ba22f, executor driver, partition 249, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:24,930] {docker.py:276} INFO - 21/05/14 14:43:24 INFO Executor: Running task 249.0 in stage 0.0 (TID 249)
[2021-05-14 11:43:24,930] {docker.py:276} INFO - 21/05/14 14:43:24 INFO TaskSetManager: Finished task 245.0 in stage 0.0 (TID 245) in 187 ms on f0b8ef7ba22f (executor driver) (246/281)
[2021-05-14 11:43:25,049] {docker.py:276} INFO - 21/05/14 14:43:25 INFO Executor: Finished task 246.0 in stage 0.0 (TID 246). 1825 bytes result sent to driver
[2021-05-14 11:43:25,051] {docker.py:276} INFO - 21/05/14 14:43:25 INFO TaskSetManager: Starting task 250.0 in stage 0.0 (TID 250) (f0b8ef7ba22f, executor driver, partition 250, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:25,053] {docker.py:276} INFO - 21/05/14 14:43:25 INFO TaskSetManager: Finished task 246.0 in stage 0.0 (TID 246) in 182 ms on f0b8ef7ba22f (executor driver) (247/281)
[2021-05-14 11:43:25,054] {docker.py:276} INFO - 21/05/14 14:43:25 INFO Executor: Running task 250.0 in stage 0.0 (TID 250)
[2021-05-14 11:43:25,103] {docker.py:276} INFO - 21/05/14 14:43:25 INFO Executor: Finished task 249.0 in stage 0.0 (TID 249). 1825 bytes result sent to driver
[2021-05-14 11:43:25,104] {docker.py:276} INFO - 21/05/14 14:43:25 INFO Executor: Finished task 248.0 in stage 0.0 (TID 248). 1825 bytes result sent to driver
[2021-05-14 11:43:25,105] {docker.py:276} INFO - 21/05/14 14:43:25 INFO TaskSetManager: Starting task 251.0 in stage 0.0 (TID 251) (f0b8ef7ba22f, executor driver, partition 251, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:25,106] {docker.py:276} INFO - 21/05/14 14:43:25 INFO TaskSetManager: Finished task 249.0 in stage 0.0 (TID 249) in 180 ms on f0b8ef7ba22f (executor driver) (248/281)
[2021-05-14 11:43:25,109] {docker.py:276} INFO - 21/05/14 14:43:25 INFO Executor: Running task 251.0 in stage 0.0 (TID 251)
[2021-05-14 11:43:25,110] {docker.py:276} INFO - 21/05/14 14:43:25 INFO TaskSetManager: Starting task 252.0 in stage 0.0 (TID 252) (f0b8ef7ba22f, executor driver, partition 252, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:25,111] {docker.py:276} INFO - 21/05/14 14:43:25 INFO TaskSetManager: Finished task 248.0 in stage 0.0 (TID 248) in 185 ms on f0b8ef7ba22f (executor driver) (249/281)
[2021-05-14 11:43:25,112] {docker.py:276} INFO - 21/05/14 14:43:25 INFO Executor: Running task 252.0 in stage 0.0 (TID 252)
[2021-05-14 11:43:25,112] {docker.py:276} INFO - 21/05/14 14:43:25 INFO Executor: Finished task 247.0 in stage 0.0 (TID 247). 1825 bytes result sent to driver
[2021-05-14 11:43:25,113] {docker.py:276} INFO - 21/05/14 14:43:25 INFO TaskSetManager: Starting task 253.0 in stage 0.0 (TID 253) (f0b8ef7ba22f, executor driver, partition 253, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:25,114] {docker.py:276} INFO - 21/05/14 14:43:25 INFO TaskSetManager: Finished task 247.0 in stage 0.0 (TID 247) in 191 ms on f0b8ef7ba22f (executor driver) (250/281)
[2021-05-14 11:43:25,114] {docker.py:276} INFO - 21/05/14 14:43:25 INFO Executor: Running task 253.0 in stage 0.0 (TID 253)
[2021-05-14 11:43:25,227] {docker.py:276} INFO - 21/05/14 14:43:25 INFO Executor: Finished task 250.0 in stage 0.0 (TID 250). 1825 bytes result sent to driver
[2021-05-14 11:43:25,228] {docker.py:276} INFO - 21/05/14 14:43:25 INFO TaskSetManager: Starting task 254.0 in stage 0.0 (TID 254) (f0b8ef7ba22f, executor driver, partition 254, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:25,229] {docker.py:276} INFO - 21/05/14 14:43:25 INFO TaskSetManager: Finished task 250.0 in stage 0.0 (TID 250) in 179 ms on f0b8ef7ba22f (executor driver) (251/281)
[2021-05-14 11:43:25,230] {docker.py:276} INFO - 21/05/14 14:43:25 INFO Executor: Running task 254.0 in stage 0.0 (TID 254)
[2021-05-14 11:43:25,291] {docker.py:276} INFO - 21/05/14 14:43:25 INFO Executor: Finished task 251.0 in stage 0.0 (TID 251). 1868 bytes result sent to driver
[2021-05-14 11:43:25,292] {docker.py:276} INFO - 21/05/14 14:43:25 INFO TaskSetManager: Starting task 255.0 in stage 0.0 (TID 255) (f0b8ef7ba22f, executor driver, partition 255, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:25,293] {docker.py:276} INFO - 21/05/14 14:43:25 INFO TaskSetManager: Finished task 251.0 in stage 0.0 (TID 251) in 190 ms on f0b8ef7ba22f (executor driver) (252/281)
21/05/14 14:43:25 INFO Executor: Finished task 253.0 in stage 0.0 (TID 253). 1868 bytes result sent to driver
[2021-05-14 11:43:25,294] {docker.py:276} INFO - 21/05/14 14:43:25 INFO Executor: Finished task 252.0 in stage 0.0 (TID 252). 1868 bytes result sent to driver
[2021-05-14 11:43:25,295] {docker.py:276} INFO - 21/05/14 14:43:25 INFO TaskSetManager: Starting task 256.0 in stage 0.0 (TID 256) (f0b8ef7ba22f, executor driver, partition 256, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:25,296] {docker.py:276} INFO - 21/05/14 14:43:25 INFO Executor: Running task 255.0 in stage 0.0 (TID 255)
[2021-05-14 11:43:25,296] {docker.py:276} INFO - 21/05/14 14:43:25 INFO TaskSetManager: Finished task 253.0 in stage 0.0 (TID 253) in 185 ms on f0b8ef7ba22f (executor driver) (253/281)
[2021-05-14 11:43:25,298] {docker.py:276} INFO - 21/05/14 14:43:25 INFO Executor: Running task 256.0 in stage 0.0 (TID 256)
[2021-05-14 11:43:25,299] {docker.py:276} INFO - 21/05/14 14:43:25 INFO TaskSetManager: Starting task 257.0 in stage 0.0 (TID 257) (f0b8ef7ba22f, executor driver, partition 257, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:25,300] {docker.py:276} INFO - 21/05/14 14:43:25 INFO Executor: Running task 257.0 in stage 0.0 (TID 257)
[2021-05-14 11:43:25,300] {docker.py:276} INFO - 21/05/14 14:43:25 INFO TaskSetManager: Finished task 252.0 in stage 0.0 (TID 252) in 193 ms on f0b8ef7ba22f (executor driver) (254/281)
[2021-05-14 11:43:25,409] {docker.py:276} INFO - 21/05/14 14:43:25 INFO Executor: Finished task 254.0 in stage 0.0 (TID 254). 1868 bytes result sent to driver
[2021-05-14 11:43:25,412] {docker.py:276} INFO - 21/05/14 14:43:25 INFO TaskSetManager: Starting task 258.0 in stage 0.0 (TID 258) (f0b8ef7ba22f, executor driver, partition 258, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:25,413] {docker.py:276} INFO - 21/05/14 14:43:25 INFO TaskSetManager: Finished task 254.0 in stage 0.0 (TID 254) in 186 ms on f0b8ef7ba22f (executor driver) (255/281)
[2021-05-14 11:43:25,414] {docker.py:276} INFO - 21/05/14 14:43:25 INFO Executor: Running task 258.0 in stage 0.0 (TID 258)
[2021-05-14 11:43:25,474] {docker.py:276} INFO - 21/05/14 14:43:25 INFO Executor: Finished task 255.0 in stage 0.0 (TID 255). 1825 bytes result sent to driver
[2021-05-14 11:43:25,476] {docker.py:276} INFO - 21/05/14 14:43:25 INFO Executor: Finished task 257.0 in stage 0.0 (TID 257). 1825 bytes result sent to driver
[2021-05-14 11:43:25,477] {docker.py:276} INFO - 21/05/14 14:43:25 INFO TaskSetManager: Starting task 259.0 in stage 0.0 (TID 259) (f0b8ef7ba22f, executor driver, partition 259, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:25,478] {docker.py:276} INFO - 21/05/14 14:43:25 INFO TaskSetManager: Starting task 260.0 in stage 0.0 (TID 260) (f0b8ef7ba22f, executor driver, partition 260, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:25,478] {docker.py:276} INFO - 21/05/14 14:43:25 INFO Executor: Running task 259.0 in stage 0.0 (TID 259)
21/05/14 14:43:25 INFO TaskSetManager: Finished task 255.0 in stage 0.0 (TID 255) in 186 ms on f0b8ef7ba22f (executor driver) (256/281)
[2021-05-14 11:43:25,479] {docker.py:276} INFO - 21/05/14 14:43:25 INFO TaskSetManager: Finished task 257.0 in stage 0.0 (TID 257) in 180 ms on f0b8ef7ba22f (executor driver) (257/281)
[2021-05-14 11:43:25,480] {docker.py:276} INFO - 21/05/14 14:43:25 INFO Executor: Running task 260.0 in stage 0.0 (TID 260)
[2021-05-14 11:43:25,554] {docker.py:276} INFO - 21/05/14 14:43:25 INFO Executor: Finished task 256.0 in stage 0.0 (TID 256). 1825 bytes result sent to driver
[2021-05-14 11:43:25,555] {docker.py:276} INFO - 21/05/14 14:43:25 INFO TaskSetManager: Starting task 261.0 in stage 0.0 (TID 261) (f0b8ef7ba22f, executor driver, partition 261, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:25,557] {docker.py:276} INFO - 21/05/14 14:43:25 INFO Executor: Running task 261.0 in stage 0.0 (TID 261)
21/05/14 14:43:25 INFO TaskSetManager: Finished task 256.0 in stage 0.0 (TID 256) in 263 ms on f0b8ef7ba22f (executor driver) (258/281)
[2021-05-14 11:43:25,584] {docker.py:276} INFO - 21/05/14 14:43:25 INFO Executor: Finished task 258.0 in stage 0.0 (TID 258). 1825 bytes result sent to driver
[2021-05-14 11:43:25,585] {docker.py:276} INFO - 21/05/14 14:43:25 INFO TaskSetManager: Starting task 262.0 in stage 0.0 (TID 262) (f0b8ef7ba22f, executor driver, partition 262, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:25,586] {docker.py:276} INFO - 21/05/14 14:43:25 INFO TaskSetManager: Finished task 258.0 in stage 0.0 (TID 258) in 176 ms on f0b8ef7ba22f (executor driver) (259/281)
[2021-05-14 11:43:25,587] {docker.py:276} INFO - 21/05/14 14:43:25 INFO Executor: Running task 262.0 in stage 0.0 (TID 262)
[2021-05-14 11:43:25,651] {docker.py:276} INFO - 21/05/14 14:43:25 INFO Executor: Finished task 259.0 in stage 0.0 (TID 259). 1825 bytes result sent to driver
[2021-05-14 11:43:25,653] {docker.py:276} INFO - 21/05/14 14:43:25 INFO Executor: Finished task 260.0 in stage 0.0 (TID 260). 1825 bytes result sent to driver
[2021-05-14 11:43:25,654] {docker.py:276} INFO - 21/05/14 14:43:25 INFO TaskSetManager: Starting task 263.0 in stage 0.0 (TID 263) (f0b8ef7ba22f, executor driver, partition 263, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:25,656] {docker.py:276} INFO - 21/05/14 14:43:25 INFO Executor: Running task 263.0 in stage 0.0 (TID 263)
[2021-05-14 11:43:25,657] {docker.py:276} INFO - 21/05/14 14:43:25 INFO TaskSetManager: Starting task 264.0 in stage 0.0 (TID 264) (f0b8ef7ba22f, executor driver, partition 264, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:25,657] {docker.py:276} INFO - 21/05/14 14:43:25 INFO TaskSetManager: Finished task 259.0 in stage 0.0 (TID 259) in 182 ms on f0b8ef7ba22f (executor driver) (260/281)
[2021-05-14 11:43:25,658] {docker.py:276} INFO - 21/05/14 14:43:25 INFO Executor: Running task 264.0 in stage 0.0 (TID 264)
[2021-05-14 11:43:25,658] {docker.py:276} INFO - 21/05/14 14:43:25 INFO TaskSetManager: Finished task 260.0 in stage 0.0 (TID 260) in 181 ms on f0b8ef7ba22f (executor driver) (261/281)
[2021-05-14 11:43:25,742] {docker.py:276} INFO - 21/05/14 14:43:25 INFO Executor: Finished task 261.0 in stage 0.0 (TID 261). 1825 bytes result sent to driver
[2021-05-14 11:43:25,744] {docker.py:276} INFO - 21/05/14 14:43:25 INFO TaskSetManager: Starting task 265.0 in stage 0.0 (TID 265) (f0b8ef7ba22f, executor driver, partition 265, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:25,745] {docker.py:276} INFO - 21/05/14 14:43:25 INFO Executor: Running task 265.0 in stage 0.0 (TID 265)
[2021-05-14 11:43:25,746] {docker.py:276} INFO - 21/05/14 14:43:25 INFO TaskSetManager: Finished task 261.0 in stage 0.0 (TID 261) in 191 ms on f0b8ef7ba22f (executor driver) (262/281)
[2021-05-14 11:43:25,759] {docker.py:276} INFO - 21/05/14 14:43:25 INFO Executor: Finished task 262.0 in stage 0.0 (TID 262). 1825 bytes result sent to driver
[2021-05-14 11:43:25,760] {docker.py:276} INFO - 21/05/14 14:43:25 INFO TaskSetManager: Starting task 266.0 in stage 0.0 (TID 266) (f0b8ef7ba22f, executor driver, partition 266, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:25,761] {docker.py:276} INFO - 21/05/14 14:43:25 INFO TaskSetManager: Finished task 262.0 in stage 0.0 (TID 262) in 177 ms on f0b8ef7ba22f (executor driver) (263/281)
[2021-05-14 11:43:25,762] {docker.py:276} INFO - 21/05/14 14:43:25 INFO Executor: Running task 266.0 in stage 0.0 (TID 266)
[2021-05-14 11:43:25,831] {docker.py:276} INFO - 21/05/14 14:43:25 INFO Executor: Finished task 264.0 in stage 0.0 (TID 264). 1825 bytes result sent to driver
21/05/14 14:43:25 INFO Executor: Finished task 263.0 in stage 0.0 (TID 263). 1825 bytes result sent to driver
[2021-05-14 11:43:25,833] {docker.py:276} INFO - 21/05/14 14:43:25 INFO TaskSetManager: Starting task 267.0 in stage 0.0 (TID 267) (f0b8ef7ba22f, executor driver, partition 267, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:25,834] {docker.py:276} INFO - 21/05/14 14:43:25 INFO Executor: Running task 267.0 in stage 0.0 (TID 267)
[2021-05-14 11:43:25,835] {docker.py:276} INFO - 21/05/14 14:43:25 INFO TaskSetManager: Starting task 268.0 in stage 0.0 (TID 268) (f0b8ef7ba22f, executor driver, partition 268, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:25,836] {docker.py:276} INFO - 21/05/14 14:43:25 INFO TaskSetManager: Finished task 264.0 in stage 0.0 (TID 264) in 181 ms on f0b8ef7ba22f (executor driver) (264/281)
[2021-05-14 11:43:25,837] {docker.py:276} INFO - 21/05/14 14:43:25 INFO TaskSetManager: Finished task 263.0 in stage 0.0 (TID 263) in 185 ms on f0b8ef7ba22f (executor driver) (265/281)
[2021-05-14 11:43:25,839] {docker.py:276} INFO - 21/05/14 14:43:25 INFO Executor: Running task 268.0 in stage 0.0 (TID 268)
[2021-05-14 11:43:25,926] {docker.py:276} INFO - 21/05/14 14:43:25 INFO Executor: Finished task 265.0 in stage 0.0 (TID 265). 1825 bytes result sent to driver
[2021-05-14 11:43:25,928] {docker.py:276} INFO - 21/05/14 14:43:25 INFO TaskSetManager: Starting task 269.0 in stage 0.0 (TID 269) (f0b8ef7ba22f, executor driver, partition 269, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:25,928] {docker.py:276} INFO - 21/05/14 14:43:25 INFO TaskSetManager: Finished task 265.0 in stage 0.0 (TID 265) in 186 ms on f0b8ef7ba22f (executor driver) (266/281)
[2021-05-14 11:43:25,930] {docker.py:276} INFO - 21/05/14 14:43:25 INFO Executor: Running task 269.0 in stage 0.0 (TID 269)
[2021-05-14 11:43:25,934] {docker.py:276} INFO - 21/05/14 14:43:25 INFO Executor: Finished task 266.0 in stage 0.0 (TID 266). 1825 bytes result sent to driver
[2021-05-14 11:43:25,935] {docker.py:276} INFO - 21/05/14 14:43:25 INFO TaskSetManager: Starting task 270.0 in stage 0.0 (TID 270) (f0b8ef7ba22f, executor driver, partition 270, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:25,936] {docker.py:276} INFO - 21/05/14 14:43:25 INFO TaskSetManager: Finished task 266.0 in stage 0.0 (TID 266) in 176 ms on f0b8ef7ba22f (executor driver) (267/281)
[2021-05-14 11:43:25,937] {docker.py:276} INFO - 21/05/14 14:43:25 INFO Executor: Running task 270.0 in stage 0.0 (TID 270)
[2021-05-14 11:43:26,011] {docker.py:276} INFO - 21/05/14 14:43:26 INFO Executor: Finished task 267.0 in stage 0.0 (TID 267). 1868 bytes result sent to driver
[2021-05-14 11:43:26,013] {docker.py:276} INFO - 21/05/14 14:43:26 INFO TaskSetManager: Starting task 271.0 in stage 0.0 (TID 271) (f0b8ef7ba22f, executor driver, partition 271, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:26,014] {docker.py:276} INFO - 21/05/14 14:43:26 INFO Executor: Finished task 268.0 in stage 0.0 (TID 268). 1868 bytes result sent to driver
[2021-05-14 11:43:26,015] {docker.py:276} INFO - 21/05/14 14:43:26 INFO Executor: Running task 271.0 in stage 0.0 (TID 271)
21/05/14 14:43:26 INFO TaskSetManager: Starting task 272.0 in stage 0.0 (TID 272) (f0b8ef7ba22f, executor driver, partition 272, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:26,016] {docker.py:276} INFO - 21/05/14 14:43:26 INFO TaskSetManager: Finished task 267.0 in stage 0.0 (TID 267) in 184 ms on f0b8ef7ba22f (executor driver) (268/281)
[2021-05-14 11:43:26,017] {docker.py:276} INFO - 21/05/14 14:43:26 INFO TaskSetManager: Finished task 268.0 in stage 0.0 (TID 268) in 183 ms on f0b8ef7ba22f (executor driver) (269/281)
[2021-05-14 11:43:26,018] {docker.py:276} INFO - 21/05/14 14:43:26 INFO Executor: Running task 272.0 in stage 0.0 (TID 272)
[2021-05-14 11:43:26,121] {docker.py:276} INFO - 21/05/14 14:43:26 INFO Executor: Finished task 269.0 in stage 0.0 (TID 269). 1868 bytes result sent to driver
[2021-05-14 11:43:26,123] {docker.py:276} INFO - 21/05/14 14:43:26 INFO TaskSetManager: Starting task 273.0 in stage 0.0 (TID 273) (f0b8ef7ba22f, executor driver, partition 273, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:26,124] {docker.py:276} INFO - 21/05/14 14:43:26 INFO TaskSetManager: Finished task 269.0 in stage 0.0 (TID 269) in 197 ms on f0b8ef7ba22f (executor driver) (270/281)
21/05/14 14:43:26 INFO Executor: Finished task 270.0 in stage 0.0 (TID 270). 1868 bytes result sent to driver
[2021-05-14 11:43:26,125] {docker.py:276} INFO - 21/05/14 14:43:26 INFO Executor: Running task 273.0 in stage 0.0 (TID 273)
21/05/14 14:43:26 INFO TaskSetManager: Starting task 274.0 in stage 0.0 (TID 274) (f0b8ef7ba22f, executor driver, partition 274, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:26,126] {docker.py:276} INFO - 21/05/14 14:43:26 INFO TaskSetManager: Finished task 270.0 in stage 0.0 (TID 270) in 191 ms on f0b8ef7ba22f (executor driver) (271/281)
[2021-05-14 11:43:26,128] {docker.py:276} INFO - 21/05/14 14:43:26 INFO Executor: Running task 274.0 in stage 0.0 (TID 274)
[2021-05-14 11:43:26,195] {docker.py:276} INFO - 21/05/14 14:43:26 INFO Executor: Finished task 271.0 in stage 0.0 (TID 271). 1825 bytes result sent to driver
[2021-05-14 11:43:26,196] {docker.py:276} INFO - 21/05/14 14:43:26 INFO TaskSetManager: Starting task 275.0 in stage 0.0 (TID 275) (f0b8ef7ba22f, executor driver, partition 275, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:26,197] {docker.py:276} INFO - 21/05/14 14:43:26 INFO Executor: Running task 275.0 in stage 0.0 (TID 275)
21/05/14 14:43:26 INFO TaskSetManager: Finished task 271.0 in stage 0.0 (TID 271) in 185 ms on f0b8ef7ba22f (executor driver) (272/281)
[2021-05-14 11:43:26,267] {docker.py:276} INFO - 21/05/14 14:43:26 INFO Executor: Finished task 272.0 in stage 0.0 (TID 272). 1825 bytes result sent to driver
[2021-05-14 11:43:26,268] {docker.py:276} INFO - 21/05/14 14:43:26 INFO TaskSetManager: Starting task 276.0 in stage 0.0 (TID 276) (f0b8ef7ba22f, executor driver, partition 276, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:26,270] {docker.py:276} INFO - 21/05/14 14:43:26 INFO Executor: Running task 276.0 in stage 0.0 (TID 276)
21/05/14 14:43:26 INFO TaskSetManager: Finished task 272.0 in stage 0.0 (TID 272) in 256 ms on f0b8ef7ba22f (executor driver) (273/281)
[2021-05-14 11:43:26,304] {docker.py:276} INFO - 21/05/14 14:43:26 INFO Executor: Finished task 273.0 in stage 0.0 (TID 273). 1825 bytes result sent to driver
[2021-05-14 11:43:26,305] {docker.py:276} INFO - 21/05/14 14:43:26 INFO Executor: Finished task 274.0 in stage 0.0 (TID 274). 1825 bytes result sent to driver
21/05/14 14:43:26 INFO TaskSetManager: Starting task 277.0 in stage 0.0 (TID 277) (f0b8ef7ba22f, executor driver, partition 277, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:26,306] {docker.py:276} INFO - 21/05/14 14:43:26 INFO Executor: Running task 277.0 in stage 0.0 (TID 277)
[2021-05-14 11:43:26,307] {docker.py:276} INFO - 21/05/14 14:43:26 INFO TaskSetManager: Starting task 278.0 in stage 0.0 (TID 278) (f0b8ef7ba22f, executor driver, partition 278, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:26,308] {docker.py:276} INFO - 21/05/14 14:43:26 INFO TaskSetManager: Finished task 273.0 in stage 0.0 (TID 273) in 186 ms on f0b8ef7ba22f (executor driver) (274/281)
[2021-05-14 11:43:26,309] {docker.py:276} INFO - 21/05/14 14:43:26 INFO TaskSetManager: Finished task 274.0 in stage 0.0 (TID 274) in 184 ms on f0b8ef7ba22f (executor driver) (275/281)
[2021-05-14 11:43:26,310] {docker.py:276} INFO - 21/05/14 14:43:26 INFO Executor: Running task 278.0 in stage 0.0 (TID 278)
[2021-05-14 11:43:26,375] {docker.py:276} INFO - 21/05/14 14:43:26 INFO Executor: Finished task 275.0 in stage 0.0 (TID 275). 1825 bytes result sent to driver
[2021-05-14 11:43:26,375] {docker.py:276} INFO - 21/05/14 14:43:26 INFO TaskSetManager: Starting task 279.0 in stage 0.0 (TID 279) (f0b8ef7ba22f, executor driver, partition 279, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:26,377] {docker.py:276} INFO - 21/05/14 14:43:26 INFO Executor: Running task 279.0 in stage 0.0 (TID 279)
21/05/14 14:43:26 INFO TaskSetManager: Finished task 275.0 in stage 0.0 (TID 275) in 182 ms on f0b8ef7ba22f (executor driver) (276/281)
[2021-05-14 11:43:26,451] {docker.py:276} INFO - 21/05/14 14:43:26 INFO Executor: Finished task 276.0 in stage 0.0 (TID 276). 1825 bytes result sent to driver
[2021-05-14 11:43:26,453] {docker.py:276} INFO - 21/05/14 14:43:26 INFO TaskSetManager: Starting task 280.0 in stage 0.0 (TID 280) (f0b8ef7ba22f, executor driver, partition 280, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:26,454] {docker.py:276} INFO - 21/05/14 14:43:26 INFO TaskSetManager: Finished task 276.0 in stage 0.0 (TID 276) in 186 ms on f0b8ef7ba22f (executor driver) (277/281)
21/05/14 14:43:26 INFO Executor: Running task 280.0 in stage 0.0 (TID 280)
[2021-05-14 11:43:26,484] {docker.py:276} INFO - 21/05/14 14:43:26 INFO Executor: Finished task 278.0 in stage 0.0 (TID 278). 1825 bytes result sent to driver
[2021-05-14 11:43:26,487] {docker.py:276} INFO - 21/05/14 14:43:26 INFO Executor: Finished task 277.0 in stage 0.0 (TID 277). 1825 bytes result sent to driver
[2021-05-14 11:43:26,495] {docker.py:276} INFO - 21/05/14 14:43:26 INFO TaskSetManager: Finished task 277.0 in stage 0.0 (TID 277) in 191 ms on f0b8ef7ba22f (executor driver) (278/281)
[2021-05-14 11:43:26,496] {docker.py:276} INFO - 21/05/14 14:43:26 INFO TaskSetManager: Finished task 278.0 in stage 0.0 (TID 278) in 189 ms on f0b8ef7ba22f (executor driver) (279/281)
[2021-05-14 11:43:26,553] {docker.py:276} INFO - 21/05/14 14:43:26 INFO Executor: Finished task 279.0 in stage 0.0 (TID 279). 1825 bytes result sent to driver
[2021-05-14 11:43:26,555] {docker.py:276} INFO - 21/05/14 14:43:26 INFO TaskSetManager: Finished task 279.0 in stage 0.0 (TID 279) in 180 ms on f0b8ef7ba22f (executor driver) (280/281)
[2021-05-14 11:43:26,629] {docker.py:276} INFO - 21/05/14 14:43:26 INFO Executor: Finished task 280.0 in stage 0.0 (TID 280). 1825 bytes result sent to driver
[2021-05-14 11:43:26,630] {docker.py:276} INFO - 21/05/14 14:43:26 INFO TaskSetManager: Finished task 280.0 in stage 0.0 (TID 280) in 179 ms on f0b8ef7ba22f (executor driver) (281/281)
[2021-05-14 11:43:26,634] {docker.py:276} INFO - 21/05/14 14:43:26 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool
[2021-05-14 11:43:26,635] {docker.py:276} INFO - 21/05/14 14:43:26 INFO DAGScheduler: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0) finished in 14.393 s
[2021-05-14 11:43:26,642] {docker.py:276} INFO - 21/05/14 14:43:26 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
[2021-05-14 11:43:26,643] {docker.py:276} INFO - 21/05/14 14:43:26 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
[2021-05-14 11:43:26,646] {docker.py:276} INFO - 21/05/14 14:43:26 INFO DAGScheduler: Job 0 finished: csv at NativeMethodAccessorImpl.java:0, took 14.487623 s
[2021-05-14 11:43:26,712] {docker.py:276} INFO - 21/05/14 14:43:26 INFO InMemoryFileIndex: It took 15161 ms to list leaf files for 281 paths.
[2021-05-14 11:43:26,844] {docker.py:276} INFO - 21/05/14 14:43:26 INFO HadoopFSUtils: Listing leaf files and directories in parallel under 281 paths. The first several paths are: s3a://udac-forex-project/1/2021-05-14/from_1620916475_to_1620918275.csv, s3a://udac-forex-project/1/2021-05-14/from_1620916930_to_1620918730.csv, s3a://udac-forex-project/1/2021-05-14/from_1620918275_to_1620920075.csv, s3a://udac-forex-project/1/2021-05-14/from_1620918730_to_1620920530.csv, s3a://udac-forex-project/1/2021-05-14/from_1620920075_to_1620921875.csv, s3a://udac-forex-project/1/2021-05-14/from_1620920530_to_1620922330.csv, s3a://udac-forex-project/1/2021-05-14/from_1620921875_to_1620923675.csv, s3a://udac-forex-project/1/2021-05-14/from_1620922330_to_1620924130.csv, s3a://udac-forex-project/1/2021-05-14/from_1620923675_to_1620925475.csv, s3a://udac-forex-project/1/2021-05-14/from_1620924130_to_1620925930.csv.
[2021-05-14 11:43:26,908] {docker.py:276} INFO - 21/05/14 14:43:26 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
[2021-05-14 11:43:26,912] {docker.py:276} INFO - 21/05/14 14:43:26 INFO DAGScheduler: Got job 1 (csv at NativeMethodAccessorImpl.java:0) with 281 output partitions
21/05/14 14:43:26 INFO DAGScheduler: Final stage: ResultStage 1 (csv at NativeMethodAccessorImpl.java:0)
[2021-05-14 11:43:26,913] {docker.py:276} INFO - 21/05/14 14:43:26 INFO DAGScheduler: Parents of final stage: List()
[2021-05-14 11:43:26,913] {docker.py:276} INFO - 21/05/14 14:43:26 INFO DAGScheduler: Missing parents: List()
[2021-05-14 11:43:26,915] {docker.py:276} INFO - 21/05/14 14:43:26 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[5] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
[2021-05-14 11:43:26,941] {docker.py:276} INFO - 21/05/14 14:43:26 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 84.9 KiB, free 934.2 MiB)
[2021-05-14 11:43:26,944] {docker.py:276} INFO - 21/05/14 14:43:26 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 30.3 KiB, free 934.2 MiB)
[2021-05-14 11:43:26,955] {docker.py:276} INFO - 21/05/14 14:43:26 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on f0b8ef7ba22f:44207 (size: 30.3 KiB, free: 934.3 MiB)
[2021-05-14 11:43:26,956] {docker.py:276} INFO - 21/05/14 14:43:26 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1383
[2021-05-14 11:43:26,962] {docker.py:276} INFO - 21/05/14 14:43:26 INFO DAGScheduler: Submitting 281 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
[2021-05-14 11:43:26,963] {docker.py:276} INFO - 21/05/14 14:43:26 INFO TaskSchedulerImpl: Adding task set 1.0 with 281 tasks resource profile 0
[2021-05-14 11:43:26,966] {docker.py:276} INFO - 21/05/14 14:43:26 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 281) (f0b8ef7ba22f, executor driver, partition 0, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:26,967] {docker.py:276} INFO - 21/05/14 14:43:26 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 282) (f0b8ef7ba22f, executor driver, partition 1, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:26,967] {docker.py:276} INFO - 21/05/14 14:43:26 INFO TaskSetManager: Starting task 2.0 in stage 1.0 (TID 283) (f0b8ef7ba22f, executor driver, partition 2, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:26,968] {docker.py:276} INFO - 21/05/14 14:43:26 INFO TaskSetManager: Starting task 3.0 in stage 1.0 (TID 284) (f0b8ef7ba22f, executor driver, partition 3, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:26,969] {docker.py:276} INFO - 21/05/14 14:43:26 INFO Executor: Running task 0.0 in stage 1.0 (TID 281)
[2021-05-14 11:43:26,969] {docker.py:276} INFO - 21/05/14 14:43:26 INFO Executor: Running task 1.0 in stage 1.0 (TID 282)
21/05/14 14:43:26 INFO Executor: Running task 3.0 in stage 1.0 (TID 284)
[2021-05-14 11:43:26,970] {docker.py:276} INFO - 21/05/14 14:43:26 INFO Executor: Running task 2.0 in stage 1.0 (TID 283)
[2021-05-14 11:43:26,996] {docker.py:276} INFO - 21/05/14 14:43:27 INFO BlockManagerInfo: Removed broadcast_0_piece0 on f0b8ef7ba22f:44207 in memory (size: 30.2 KiB, free: 934.4 MiB)
[2021-05-14 11:43:27,138] {docker.py:276} INFO - 21/05/14 14:43:27 INFO Executor: Finished task 2.0 in stage 1.0 (TID 283). 1825 bytes result sent to driver
[2021-05-14 11:43:27,139] {docker.py:276} INFO - 21/05/14 14:43:27 INFO TaskSetManager: Starting task 4.0 in stage 1.0 (TID 285) (f0b8ef7ba22f, executor driver, partition 4, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:27,140] {docker.py:276} INFO - 21/05/14 14:43:27 INFO TaskSetManager: Finished task 2.0 in stage 1.0 (TID 283) in 173 ms on f0b8ef7ba22f (executor driver) (1/281)
[2021-05-14 11:43:27,143] {docker.py:276} INFO - 21/05/14 14:43:27 INFO Executor: Running task 4.0 in stage 1.0 (TID 285)
[2021-05-14 11:43:27,148] {docker.py:276} INFO - 21/05/14 14:43:27 INFO Executor: Finished task 0.0 in stage 1.0 (TID 281). 1825 bytes result sent to driver
[2021-05-14 11:43:27,149] {docker.py:276} INFO - 21/05/14 14:43:27 INFO TaskSetManager: Starting task 5.0 in stage 1.0 (TID 286) (f0b8ef7ba22f, executor driver, partition 5, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:27,149] {docker.py:276} INFO - 21/05/14 14:43:27 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 281) in 184 ms on f0b8ef7ba22f (executor driver) (2/281)
[2021-05-14 11:43:27,150] {docker.py:276} INFO - 21/05/14 14:43:27 INFO Executor: Running task 5.0 in stage 1.0 (TID 286)
[2021-05-14 11:43:27,152] {docker.py:276} INFO - 21/05/14 14:43:27 INFO Executor: Finished task 1.0 in stage 1.0 (TID 282). 1825 bytes result sent to driver
[2021-05-14 11:43:27,153] {docker.py:276} INFO - 21/05/14 14:43:27 INFO TaskSetManager: Starting task 6.0 in stage 1.0 (TID 287) (f0b8ef7ba22f, executor driver, partition 6, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:27,154] {docker.py:276} INFO - 21/05/14 14:43:27 INFO Executor: Running task 6.0 in stage 1.0 (TID 287)
21/05/14 14:43:27 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 282) in 188 ms on f0b8ef7ba22f (executor driver) (3/281)
[2021-05-14 11:43:27,175] {docker.py:276} INFO - 21/05/14 14:43:27 INFO Executor: Finished task 3.0 in stage 1.0 (TID 284). 1825 bytes result sent to driver
[2021-05-14 11:43:27,176] {docker.py:276} INFO - 21/05/14 14:43:27 INFO TaskSetManager: Starting task 7.0 in stage 1.0 (TID 288) (f0b8ef7ba22f, executor driver, partition 7, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:27,177] {docker.py:276} INFO - 21/05/14 14:43:27 INFO TaskSetManager: Finished task 3.0 in stage 1.0 (TID 284) in 210 ms on f0b8ef7ba22f (executor driver) (4/281)
[2021-05-14 11:43:27,177] {docker.py:276} INFO - 21/05/14 14:43:27 INFO Executor: Running task 7.0 in stage 1.0 (TID 288)
[2021-05-14 11:43:27,314] {docker.py:276} INFO - 21/05/14 14:43:27 INFO Executor: Finished task 4.0 in stage 1.0 (TID 285). 1825 bytes result sent to driver
[2021-05-14 11:43:27,315] {docker.py:276} INFO - 21/05/14 14:43:27 INFO TaskSetManager: Starting task 8.0 in stage 1.0 (TID 289) (f0b8ef7ba22f, executor driver, partition 8, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:27,316] {docker.py:276} INFO - 21/05/14 14:43:27 INFO TaskSetManager: Finished task 4.0 in stage 1.0 (TID 285) in 178 ms on f0b8ef7ba22f (executor driver) (5/281)
[2021-05-14 11:43:27,319] {docker.py:276} INFO - 21/05/14 14:43:27 INFO Executor: Running task 8.0 in stage 1.0 (TID 289)
[2021-05-14 11:43:27,327] {docker.py:276} INFO - 21/05/14 14:43:27 INFO Executor: Finished task 6.0 in stage 1.0 (TID 287). 1825 bytes result sent to driver
[2021-05-14 11:43:27,327] {docker.py:276} INFO - 21/05/14 14:43:27 INFO Executor: Finished task 5.0 in stage 1.0 (TID 286). 1825 bytes result sent to driver
[2021-05-14 11:43:27,328] {docker.py:276} INFO - 21/05/14 14:43:27 INFO TaskSetManager: Starting task 9.0 in stage 1.0 (TID 290) (f0b8ef7ba22f, executor driver, partition 9, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:27,328] {docker.py:276} INFO - 21/05/14 14:43:27 INFO TaskSetManager: Finished task 6.0 in stage 1.0 (TID 287) in 176 ms on f0b8ef7ba22f (executor driver) (6/281)
[2021-05-14 11:43:27,329] {docker.py:276} INFO - 21/05/14 14:43:27 INFO Executor: Running task 9.0 in stage 1.0 (TID 290)
[2021-05-14 11:43:27,330] {docker.py:276} INFO - 21/05/14 14:43:27 INFO TaskSetManager: Finished task 5.0 in stage 1.0 (TID 286) in 181 ms on f0b8ef7ba22f (executor driver) (7/281)
[2021-05-14 11:43:27,330] {docker.py:276} INFO - 21/05/14 14:43:27 INFO TaskSetManager: Starting task 10.0 in stage 1.0 (TID 291) (f0b8ef7ba22f, executor driver, partition 10, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:27,331] {docker.py:276} INFO - 21/05/14 14:43:27 INFO Executor: Running task 10.0 in stage 1.0 (TID 291)
[2021-05-14 11:43:27,357] {docker.py:276} INFO - 21/05/14 14:43:27 INFO Executor: Finished task 7.0 in stage 1.0 (TID 288). 1825 bytes result sent to driver
[2021-05-14 11:43:27,374] {docker.py:276} INFO - 21/05/14 14:43:27 INFO TaskSetManager: Starting task 11.0 in stage 1.0 (TID 292) (f0b8ef7ba22f, executor driver, partition 11, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:27,374] {docker.py:276} INFO - 21/05/14 14:43:27 INFO Executor: Running task 11.0 in stage 1.0 (TID 292)
[2021-05-14 11:43:27,374] {docker.py:276} INFO - 21/05/14 14:43:27 INFO TaskSetManager: Finished task 7.0 in stage 1.0 (TID 288) in 183 ms on f0b8ef7ba22f (executor driver) (8/281)
[2021-05-14 11:43:27,497] {docker.py:276} INFO - 21/05/14 14:43:27 INFO Executor: Finished task 8.0 in stage 1.0 (TID 289). 1825 bytes result sent to driver
[2021-05-14 11:43:27,499] {docker.py:276} INFO - 21/05/14 14:43:27 INFO TaskSetManager: Starting task 12.0 in stage 1.0 (TID 293) (f0b8ef7ba22f, executor driver, partition 12, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:27,500] {docker.py:276} INFO - 21/05/14 14:43:27 INFO Executor: Running task 12.0 in stage 1.0 (TID 293)
[2021-05-14 11:43:27,500] {docker.py:276} INFO - 21/05/14 14:43:27 INFO TaskSetManager: Finished task 8.0 in stage 1.0 (TID 289) in 185 ms on f0b8ef7ba22f (executor driver) (9/281)
[2021-05-14 11:43:27,501] {docker.py:276} INFO - 21/05/14 14:43:27 INFO Executor: Finished task 9.0 in stage 1.0 (TID 290). 1825 bytes result sent to driver
[2021-05-14 11:43:27,503] {docker.py:276} INFO - 21/05/14 14:43:27 INFO TaskSetManager: Starting task 13.0 in stage 1.0 (TID 294) (f0b8ef7ba22f, executor driver, partition 13, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:27,504] {docker.py:276} INFO - 21/05/14 14:43:27 INFO TaskSetManager: Finished task 9.0 in stage 1.0 (TID 290) in 177 ms on f0b8ef7ba22f (executor driver) (10/281)
[2021-05-14 11:43:27,505] {docker.py:276} INFO - 21/05/14 14:43:27 INFO Executor: Running task 13.0 in stage 1.0 (TID 294)
[2021-05-14 11:43:27,519] {docker.py:276} INFO - 21/05/14 14:43:27 INFO Executor: Finished task 10.0 in stage 1.0 (TID 291). 1868 bytes result sent to driver
[2021-05-14 11:43:27,519] {docker.py:276} INFO - 21/05/14 14:43:27 INFO TaskSetManager: Starting task 14.0 in stage 1.0 (TID 295) (f0b8ef7ba22f, executor driver, partition 14, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:27,520] {docker.py:276} INFO - 21/05/14 14:43:27 INFO TaskSetManager: Finished task 10.0 in stage 1.0 (TID 291) in 191 ms on f0b8ef7ba22f (executor driver) (11/281)
[2021-05-14 11:43:27,521] {docker.py:276} INFO - 21/05/14 14:43:27 INFO Executor: Running task 14.0 in stage 1.0 (TID 295)
[2021-05-14 11:43:27,530] {docker.py:276} INFO - 21/05/14 14:43:27 INFO Executor: Finished task 11.0 in stage 1.0 (TID 292). 1868 bytes result sent to driver
[2021-05-14 11:43:27,531] {docker.py:276} INFO - 21/05/14 14:43:27 INFO TaskSetManager: Starting task 15.0 in stage 1.0 (TID 296) (f0b8ef7ba22f, executor driver, partition 15, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:27,532] {docker.py:276} INFO - 21/05/14 14:43:27 INFO TaskSetManager: Finished task 11.0 in stage 1.0 (TID 292) in 174 ms on f0b8ef7ba22f (executor driver) (12/281)
[2021-05-14 11:43:27,532] {docker.py:276} INFO - 21/05/14 14:43:27 INFO Executor: Running task 15.0 in stage 1.0 (TID 296)
[2021-05-14 11:43:27,673] {docker.py:276} INFO - 21/05/14 14:43:27 INFO Executor: Finished task 12.0 in stage 1.0 (TID 293). 1868 bytes result sent to driver
[2021-05-14 11:43:27,675] {docker.py:276} INFO - 21/05/14 14:43:27 INFO TaskSetManager: Starting task 16.0 in stage 1.0 (TID 297) (f0b8ef7ba22f, executor driver, partition 16, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:27,676] {docker.py:276} INFO - 21/05/14 14:43:27 INFO Executor: Running task 16.0 in stage 1.0 (TID 297)
21/05/14 14:43:27 INFO TaskSetManager: Finished task 12.0 in stage 1.0 (TID 293) in 178 ms on f0b8ef7ba22f (executor driver) (13/281)
[2021-05-14 11:43:27,697] {docker.py:276} INFO - 21/05/14 14:43:27 INFO Executor: Finished task 14.0 in stage 1.0 (TID 295). 1825 bytes result sent to driver
[2021-05-14 11:43:27,699] {docker.py:276} INFO - 21/05/14 14:43:27 INFO Executor: Finished task 15.0 in stage 1.0 (TID 296). 1825 bytes result sent to driver
21/05/14 14:43:27 INFO TaskSetManager: Starting task 17.0 in stage 1.0 (TID 298) (f0b8ef7ba22f, executor driver, partition 17, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:27,701] {docker.py:276} INFO - 21/05/14 14:43:27 INFO Executor: Running task 17.0 in stage 1.0 (TID 298)
[2021-05-14 11:43:27,702] {docker.py:276} INFO - 21/05/14 14:43:27 INFO TaskSetManager: Starting task 18.0 in stage 1.0 (TID 299) (f0b8ef7ba22f, executor driver, partition 18, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:27,703] {docker.py:276} INFO - 21/05/14 14:43:27 INFO Executor: Running task 18.0 in stage 1.0 (TID 299)
[2021-05-14 11:43:27,703] {docker.py:276} INFO - 21/05/14 14:43:27 INFO TaskSetManager: Finished task 14.0 in stage 1.0 (TID 295) in 183 ms on f0b8ef7ba22f (executor driver) (14/281)
[2021-05-14 11:43:27,704] {docker.py:276} INFO - 21/05/14 14:43:27 INFO TaskSetManager: Finished task 15.0 in stage 1.0 (TID 296) in 172 ms on f0b8ef7ba22f (executor driver) (15/281)
[2021-05-14 11:43:27,745] {docker.py:276} INFO - 21/05/14 14:43:27 INFO Executor: Finished task 13.0 in stage 1.0 (TID 294). 1868 bytes result sent to driver
[2021-05-14 11:43:27,747] {docker.py:276} INFO - 21/05/14 14:43:27 INFO TaskSetManager: Starting task 19.0 in stage 1.0 (TID 300) (f0b8ef7ba22f, executor driver, partition 19, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:27,749] {docker.py:276} INFO - 21/05/14 14:43:27 INFO Executor: Running task 19.0 in stage 1.0 (TID 300)
[2021-05-14 11:43:27,750] {docker.py:276} INFO - 21/05/14 14:43:27 INFO TaskSetManager: Finished task 13.0 in stage 1.0 (TID 294) in 247 ms on f0b8ef7ba22f (executor driver) (16/281)
[2021-05-14 11:43:27,852] {docker.py:276} INFO - 21/05/14 14:43:27 INFO Executor: Finished task 16.0 in stage 1.0 (TID 297). 1825 bytes result sent to driver
[2021-05-14 11:43:27,853] {docker.py:276} INFO - 21/05/14 14:43:27 INFO TaskSetManager: Starting task 20.0 in stage 1.0 (TID 301) (f0b8ef7ba22f, executor driver, partition 20, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:27,854] {docker.py:276} INFO - 21/05/14 14:43:27 INFO TaskSetManager: Finished task 16.0 in stage 1.0 (TID 297) in 180 ms on f0b8ef7ba22f (executor driver) (17/281)
[2021-05-14 11:43:27,856] {docker.py:276} INFO - 21/05/14 14:43:27 INFO Executor: Running task 20.0 in stage 1.0 (TID 301)
[2021-05-14 11:43:27,874] {docker.py:276} INFO - 21/05/14 14:43:27 INFO Executor: Finished task 18.0 in stage 1.0 (TID 299). 1825 bytes result sent to driver
[2021-05-14 11:43:27,874] {docker.py:276} INFO - 21/05/14 14:43:27 INFO Executor: Finished task 17.0 in stage 1.0 (TID 298). 1825 bytes result sent to driver
[2021-05-14 11:43:27,875] {docker.py:276} INFO - 21/05/14 14:43:27 INFO TaskSetManager: Starting task 21.0 in stage 1.0 (TID 302) (f0b8ef7ba22f, executor driver, partition 21, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:27,876] {docker.py:276} INFO - 21/05/14 14:43:27 INFO Executor: Running task 21.0 in stage 1.0 (TID 302)
[2021-05-14 11:43:27,877] {docker.py:276} INFO - 21/05/14 14:43:27 INFO TaskSetManager: Starting task 22.0 in stage 1.0 (TID 303) (f0b8ef7ba22f, executor driver, partition 22, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:27,878] {docker.py:276} INFO - 21/05/14 14:43:27 INFO TaskSetManager: Finished task 18.0 in stage 1.0 (TID 299) in 177 ms on f0b8ef7ba22f (executor driver) (18/281)
[2021-05-14 11:43:27,878] {docker.py:276} INFO - 21/05/14 14:43:27 INFO Executor: Running task 22.0 in stage 1.0 (TID 303)
[2021-05-14 11:43:27,879] {docker.py:276} INFO - 21/05/14 14:43:27 INFO TaskSetManager: Finished task 17.0 in stage 1.0 (TID 298) in 180 ms on f0b8ef7ba22f (executor driver) (19/281)
[2021-05-14 11:43:27,936] {docker.py:276} INFO - 21/05/14 14:43:27 INFO Executor: Finished task 19.0 in stage 1.0 (TID 300). 1825 bytes result sent to driver
[2021-05-14 11:43:27,937] {docker.py:276} INFO - 21/05/14 14:43:27 INFO TaskSetManager: Starting task 23.0 in stage 1.0 (TID 304) (f0b8ef7ba22f, executor driver, partition 23, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:27,939] {docker.py:276} INFO - 21/05/14 14:43:27 INFO Executor: Running task 23.0 in stage 1.0 (TID 304)
[2021-05-14 11:43:27,939] {docker.py:276} INFO - 21/05/14 14:43:27 INFO TaskSetManager: Finished task 19.0 in stage 1.0 (TID 300) in 193 ms on f0b8ef7ba22f (executor driver) (20/281)
[2021-05-14 11:43:28,031] {docker.py:276} INFO - 21/05/14 14:43:28 INFO Executor: Finished task 20.0 in stage 1.0 (TID 301). 1825 bytes result sent to driver
[2021-05-14 11:43:28,034] {docker.py:276} INFO - 21/05/14 14:43:28 INFO TaskSetManager: Starting task 24.0 in stage 1.0 (TID 305) (f0b8ef7ba22f, executor driver, partition 24, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:28,035] {docker.py:276} INFO - 21/05/14 14:43:28 INFO TaskSetManager: Finished task 20.0 in stage 1.0 (TID 301) in 181 ms on f0b8ef7ba22f (executor driver) (21/281)
[2021-05-14 11:43:28,036] {docker.py:276} INFO - 21/05/14 14:43:28 INFO Executor: Running task 24.0 in stage 1.0 (TID 305)
[2021-05-14 11:43:28,045] {docker.py:276} INFO - 21/05/14 14:43:28 INFO Executor: Finished task 22.0 in stage 1.0 (TID 303). 1825 bytes result sent to driver
[2021-05-14 11:43:28,047] {docker.py:276} INFO - 21/05/14 14:43:28 INFO TaskSetManager: Starting task 25.0 in stage 1.0 (TID 306) (f0b8ef7ba22f, executor driver, partition 25, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:28,050] {docker.py:276} INFO - 21/05/14 14:43:28 INFO Executor: Running task 25.0 in stage 1.0 (TID 306)
[2021-05-14 11:43:28,051] {docker.py:276} INFO - 21/05/14 14:43:28 INFO TaskSetManager: Finished task 22.0 in stage 1.0 (TID 303) in 175 ms on f0b8ef7ba22f (executor driver) (22/281)
[2021-05-14 11:43:28,055] {docker.py:276} INFO - 21/05/14 14:43:28 INFO Executor: Finished task 21.0 in stage 1.0 (TID 302). 1825 bytes result sent to driver
[2021-05-14 11:43:28,056] {docker.py:276} INFO - 21/05/14 14:43:28 INFO TaskSetManager: Starting task 26.0 in stage 1.0 (TID 307) (f0b8ef7ba22f, executor driver, partition 26, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:28,057] {docker.py:276} INFO - 21/05/14 14:43:28 INFO Executor: Running task 26.0 in stage 1.0 (TID 307)
[2021-05-14 11:43:28,057] {docker.py:276} INFO - 21/05/14 14:43:28 INFO TaskSetManager: Finished task 21.0 in stage 1.0 (TID 302) in 182 ms on f0b8ef7ba22f (executor driver) (23/281)
[2021-05-14 11:43:28,122] {docker.py:276} INFO - 21/05/14 14:43:28 INFO Executor: Finished task 23.0 in stage 1.0 (TID 304). 1825 bytes result sent to driver
[2021-05-14 11:43:28,125] {docker.py:276} INFO - 21/05/14 14:43:28 INFO TaskSetManager: Starting task 27.0 in stage 1.0 (TID 308) (f0b8ef7ba22f, executor driver, partition 27, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
21/05/14 14:43:28 INFO TaskSetManager: Finished task 23.0 in stage 1.0 (TID 304) in 187 ms on f0b8ef7ba22f (executor driver) (24/281)
21/05/14 14:43:28 INFO Executor: Running task 27.0 in stage 1.0 (TID 308)
[2021-05-14 11:43:28,218] {docker.py:276} INFO - 21/05/14 14:43:28 INFO Executor: Finished task 24.0 in stage 1.0 (TID 305). 1825 bytes result sent to driver
[2021-05-14 11:43:28,219] {docker.py:276} INFO - 21/05/14 14:43:28 INFO TaskSetManager: Starting task 28.0 in stage 1.0 (TID 309) (f0b8ef7ba22f, executor driver, partition 28, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:28,220] {docker.py:276} INFO - 21/05/14 14:43:28 INFO TaskSetManager: Finished task 24.0 in stage 1.0 (TID 305) in 187 ms on f0b8ef7ba22f (executor driver) (25/281)
[2021-05-14 11:43:28,221] {docker.py:276} INFO - 21/05/14 14:43:28 INFO Executor: Running task 28.0 in stage 1.0 (TID 309)
21/05/14 14:43:28 INFO Executor: Finished task 25.0 in stage 1.0 (TID 306). 1825 bytes result sent to driver
[2021-05-14 11:43:28,222] {docker.py:276} INFO - 21/05/14 14:43:28 INFO TaskSetManager: Starting task 29.0 in stage 1.0 (TID 310) (f0b8ef7ba22f, executor driver, partition 29, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:28,223] {docker.py:276} INFO - 21/05/14 14:43:28 INFO TaskSetManager: Finished task 25.0 in stage 1.0 (TID 306) in 176 ms on f0b8ef7ba22f (executor driver) (26/281)
[2021-05-14 11:43:28,224] {docker.py:276} INFO - 21/05/14 14:43:28 INFO Executor: Running task 29.0 in stage 1.0 (TID 310)
[2021-05-14 11:43:28,238] {docker.py:276} INFO - 21/05/14 14:43:28 INFO Executor: Finished task 26.0 in stage 1.0 (TID 307). 1868 bytes result sent to driver
[2021-05-14 11:43:28,241] {docker.py:276} INFO - 21/05/14 14:43:28 INFO TaskSetManager: Starting task 30.0 in stage 1.0 (TID 311) (f0b8ef7ba22f, executor driver, partition 30, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:28,242] {docker.py:276} INFO - 21/05/14 14:43:28 INFO TaskSetManager: Finished task 26.0 in stage 1.0 (TID 307) in 187 ms on f0b8ef7ba22f (executor driver) (27/281)
[2021-05-14 11:43:28,243] {docker.py:276} INFO - 21/05/14 14:43:28 INFO Executor: Running task 30.0 in stage 1.0 (TID 311)
[2021-05-14 11:43:28,303] {docker.py:276} INFO - 21/05/14 14:43:28 INFO Executor: Finished task 27.0 in stage 1.0 (TID 308). 1868 bytes result sent to driver
[2021-05-14 11:43:28,304] {docker.py:276} INFO - 21/05/14 14:43:28 INFO TaskSetManager: Starting task 31.0 in stage 1.0 (TID 312) (f0b8ef7ba22f, executor driver, partition 31, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:28,305] {docker.py:276} INFO - 21/05/14 14:43:28 INFO TaskSetManager: Finished task 27.0 in stage 1.0 (TID 308) in 183 ms on f0b8ef7ba22f (executor driver) (28/281)
[2021-05-14 11:43:28,306] {docker.py:276} INFO - 21/05/14 14:43:28 INFO Executor: Running task 31.0 in stage 1.0 (TID 312)
[2021-05-14 11:43:28,405] {docker.py:276} INFO - 21/05/14 14:43:28 INFO Executor: Finished task 29.0 in stage 1.0 (TID 310). 1868 bytes result sent to driver
[2021-05-14 11:43:28,406] {docker.py:276} INFO - 21/05/14 14:43:28 INFO Executor: Finished task 28.0 in stage 1.0 (TID 309). 1868 bytes result sent to driver
[2021-05-14 11:43:28,407] {docker.py:276} INFO - 21/05/14 14:43:28 INFO TaskSetManager: Starting task 32.0 in stage 1.0 (TID 313) (f0b8ef7ba22f, executor driver, partition 32, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:28,408] {docker.py:276} INFO - 21/05/14 14:43:28 INFO TaskSetManager: Starting task 33.0 in stage 1.0 (TID 314) (f0b8ef7ba22f, executor driver, partition 33, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:28,409] {docker.py:276} INFO - 21/05/14 14:43:28 INFO Executor: Running task 32.0 in stage 1.0 (TID 313)
[2021-05-14 11:43:28,410] {docker.py:276} INFO - 21/05/14 14:43:28 INFO TaskSetManager: Finished task 28.0 in stage 1.0 (TID 309) in 191 ms on f0b8ef7ba22f (executor driver) (29/281)
[2021-05-14 11:43:28,410] {docker.py:276} INFO - 21/05/14 14:43:28 INFO TaskSetManager: Finished task 29.0 in stage 1.0 (TID 310) in 188 ms on f0b8ef7ba22f (executor driver) (30/281)
[2021-05-14 11:43:28,411] {docker.py:276} INFO - 21/05/14 14:43:28 INFO Executor: Running task 33.0 in stage 1.0 (TID 314)
[2021-05-14 11:43:28,464] {docker.py:276} INFO - 21/05/14 14:43:28 INFO Executor: Finished task 30.0 in stage 1.0 (TID 311). 1825 bytes result sent to driver
[2021-05-14 11:43:28,465] {docker.py:276} INFO - 21/05/14 14:43:28 INFO TaskSetManager: Starting task 34.0 in stage 1.0 (TID 315) (f0b8ef7ba22f, executor driver, partition 34, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:28,466] {docker.py:276} INFO - 21/05/14 14:43:28 INFO TaskSetManager: Finished task 30.0 in stage 1.0 (TID 311) in 226 ms on f0b8ef7ba22f (executor driver) (31/281)
[2021-05-14 11:43:28,466] {docker.py:276} INFO - 21/05/14 14:43:28 INFO Executor: Running task 34.0 in stage 1.0 (TID 315)
[2021-05-14 11:43:28,479] {docker.py:276} INFO - 21/05/14 14:43:28 INFO Executor: Finished task 31.0 in stage 1.0 (TID 312). 1825 bytes result sent to driver
[2021-05-14 11:43:28,481] {docker.py:276} INFO - 21/05/14 14:43:28 INFO TaskSetManager: Starting task 35.0 in stage 1.0 (TID 316) (f0b8ef7ba22f, executor driver, partition 35, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:28,482] {docker.py:276} INFO - 21/05/14 14:43:28 INFO TaskSetManager: Finished task 31.0 in stage 1.0 (TID 312) in 177 ms on f0b8ef7ba22f (executor driver) (32/281)
[2021-05-14 11:43:28,483] {docker.py:276} INFO - 21/05/14 14:43:28 INFO Executor: Running task 35.0 in stage 1.0 (TID 316)
[2021-05-14 11:43:28,583] {docker.py:276} INFO - 21/05/14 14:43:28 INFO Executor: Finished task 32.0 in stage 1.0 (TID 313). 1825 bytes result sent to driver
21/05/14 14:43:28 INFO Executor: Finished task 33.0 in stage 1.0 (TID 314). 1825 bytes result sent to driver
[2021-05-14 11:43:28,588] {docker.py:276} INFO - 21/05/14 14:43:28 INFO TaskSetManager: Starting task 36.0 in stage 1.0 (TID 317) (f0b8ef7ba22f, executor driver, partition 36, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:28,589] {docker.py:276} INFO - 21/05/14 14:43:28 INFO TaskSetManager: Finished task 32.0 in stage 1.0 (TID 313) in 179 ms on f0b8ef7ba22f (executor driver) (33/281)
[2021-05-14 11:43:28,589] {docker.py:276} INFO - 21/05/14 14:43:28 INFO Executor: Running task 36.0 in stage 1.0 (TID 317)
21/05/14 14:43:28 INFO TaskSetManager: Starting task 37.0 in stage 1.0 (TID 318) (f0b8ef7ba22f, executor driver, partition 37, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:28,590] {docker.py:276} INFO - 21/05/14 14:43:28 INFO TaskSetManager: Finished task 33.0 in stage 1.0 (TID 314) in 180 ms on f0b8ef7ba22f (executor driver) (34/281)
[2021-05-14 11:43:28,595] {docker.py:276} INFO - 21/05/14 14:43:28 INFO Executor: Running task 37.0 in stage 1.0 (TID 318)
[2021-05-14 11:43:28,650] {docker.py:276} INFO - 21/05/14 14:43:28 INFO Executor: Finished task 34.0 in stage 1.0 (TID 315). 1825 bytes result sent to driver
[2021-05-14 11:43:28,650] {docker.py:276} INFO - 21/05/14 14:43:28 INFO TaskSetManager: Starting task 38.0 in stage 1.0 (TID 319) (f0b8ef7ba22f, executor driver, partition 38, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:28,651] {docker.py:276} INFO - 21/05/14 14:43:28 INFO TaskSetManager: Finished task 34.0 in stage 1.0 (TID 315) in 179 ms on f0b8ef7ba22f (executor driver) (35/281)
[2021-05-14 11:43:28,651] {docker.py:276} INFO - 21/05/14 14:43:28 INFO Executor: Running task 38.0 in stage 1.0 (TID 319)
[2021-05-14 11:43:28,673] {docker.py:276} INFO - 21/05/14 14:43:28 INFO Executor: Finished task 35.0 in stage 1.0 (TID 316). 1825 bytes result sent to driver
[2021-05-14 11:43:28,675] {docker.py:276} INFO - 21/05/14 14:43:28 INFO TaskSetManager: Starting task 39.0 in stage 1.0 (TID 320) (f0b8ef7ba22f, executor driver, partition 39, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:28,677] {docker.py:276} INFO - 21/05/14 14:43:28 INFO TaskSetManager: Finished task 35.0 in stage 1.0 (TID 316) in 196 ms on f0b8ef7ba22f (executor driver) (36/281)
[2021-05-14 11:43:28,678] {docker.py:276} INFO - 21/05/14 14:43:28 INFO Executor: Running task 39.0 in stage 1.0 (TID 320)
[2021-05-14 11:43:28,757] {docker.py:276} INFO - 21/05/14 14:43:28 INFO Executor: Finished task 36.0 in stage 1.0 (TID 317). 1825 bytes result sent to driver
[2021-05-14 11:43:28,759] {docker.py:276} INFO - 21/05/14 14:43:28 INFO TaskSetManager: Starting task 40.0 in stage 1.0 (TID 321) (f0b8ef7ba22f, executor driver, partition 40, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:28,760] {docker.py:276} INFO - 21/05/14 14:43:28 INFO Executor: Running task 40.0 in stage 1.0 (TID 321)
[2021-05-14 11:43:28,761] {docker.py:276} INFO - 21/05/14 14:43:28 INFO TaskSetManager: Finished task 36.0 in stage 1.0 (TID 317) in 176 ms on f0b8ef7ba22f (executor driver) (37/281)
[2021-05-14 11:43:28,762] {docker.py:276} INFO - 21/05/14 14:43:28 INFO Executor: Finished task 37.0 in stage 1.0 (TID 318). 1825 bytes result sent to driver
[2021-05-14 11:43:28,763] {docker.py:276} INFO - 21/05/14 14:43:28 INFO TaskSetManager: Starting task 41.0 in stage 1.0 (TID 322) (f0b8ef7ba22f, executor driver, partition 41, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:28,764] {docker.py:276} INFO - 21/05/14 14:43:28 INFO Executor: Running task 41.0 in stage 1.0 (TID 322)
21/05/14 14:43:28 INFO TaskSetManager: Finished task 37.0 in stage 1.0 (TID 318) in 178 ms on f0b8ef7ba22f (executor driver) (38/281)
[2021-05-14 11:43:28,817] {docker.py:276} INFO - 21/05/14 14:43:28 INFO Executor: Finished task 38.0 in stage 1.0 (TID 319). 1825 bytes result sent to driver
[2021-05-14 11:43:28,818] {docker.py:276} INFO - 21/05/14 14:43:28 INFO TaskSetManager: Starting task 42.0 in stage 1.0 (TID 323) (f0b8ef7ba22f, executor driver, partition 42, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:28,819] {docker.py:276} INFO - 21/05/14 14:43:28 INFO TaskSetManager: Finished task 38.0 in stage 1.0 (TID 319) in 178 ms on f0b8ef7ba22f (executor driver) (39/281)
[2021-05-14 11:43:28,819] {docker.py:276} INFO - 21/05/14 14:43:28 INFO Executor: Running task 42.0 in stage 1.0 (TID 323)
[2021-05-14 11:43:28,851] {docker.py:276} INFO - 21/05/14 14:43:28 INFO Executor: Finished task 39.0 in stage 1.0 (TID 320). 1825 bytes result sent to driver
[2021-05-14 11:43:28,851] {docker.py:276} INFO - 21/05/14 14:43:28 INFO TaskSetManager: Starting task 43.0 in stage 1.0 (TID 324) (f0b8ef7ba22f, executor driver, partition 43, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:28,853] {docker.py:276} INFO - 21/05/14 14:43:28 INFO TaskSetManager: Finished task 39.0 in stage 1.0 (TID 320) in 180 ms on f0b8ef7ba22f (executor driver) (40/281)
[2021-05-14 11:43:28,853] {docker.py:276} INFO - 21/05/14 14:43:28 INFO Executor: Running task 43.0 in stage 1.0 (TID 324)
[2021-05-14 11:43:28,932] {docker.py:276} INFO - 21/05/14 14:43:28 INFO Executor: Finished task 41.0 in stage 1.0 (TID 322). 1825 bytes result sent to driver
[2021-05-14 11:43:28,933] {docker.py:276} INFO - 21/05/14 14:43:28 INFO TaskSetManager: Starting task 44.0 in stage 1.0 (TID 325) (f0b8ef7ba22f, executor driver, partition 44, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:28,935] {docker.py:276} INFO - 21/05/14 14:43:28 INFO TaskSetManager: Finished task 41.0 in stage 1.0 (TID 322) in 172 ms on f0b8ef7ba22f (executor driver) (41/281)
21/05/14 14:43:28 INFO Executor: Running task 44.0 in stage 1.0 (TID 325)
[2021-05-14 11:43:28,937] {docker.py:276} INFO - 21/05/14 14:43:28 INFO Executor: Finished task 40.0 in stage 1.0 (TID 321). 1825 bytes result sent to driver
[2021-05-14 11:43:28,937] {docker.py:276} INFO - 21/05/14 14:43:28 INFO TaskSetManager: Starting task 45.0 in stage 1.0 (TID 326) (f0b8ef7ba22f, executor driver, partition 45, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:28,938] {docker.py:276} INFO - 21/05/14 14:43:28 INFO Executor: Running task 45.0 in stage 1.0 (TID 326)
[2021-05-14 11:43:28,939] {docker.py:276} INFO - 21/05/14 14:43:28 INFO TaskSetManager: Finished task 40.0 in stage 1.0 (TID 321) in 180 ms on f0b8ef7ba22f (executor driver) (42/281)
[2021-05-14 11:43:28,992] {docker.py:276} INFO - 21/05/14 14:43:29 INFO Executor: Finished task 42.0 in stage 1.0 (TID 323). 1868 bytes result sent to driver
[2021-05-14 11:43:28,993] {docker.py:276} INFO - 21/05/14 14:43:29 INFO TaskSetManager: Starting task 46.0 in stage 1.0 (TID 327) (f0b8ef7ba22f, executor driver, partition 46, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:28,994] {docker.py:276} INFO - 21/05/14 14:43:29 INFO TaskSetManager: Finished task 42.0 in stage 1.0 (TID 323) in 177 ms on f0b8ef7ba22f (executor driver) (43/281)
21/05/14 14:43:29 INFO Executor: Running task 46.0 in stage 1.0 (TID 327)
[2021-05-14 11:43:29,024] {docker.py:276} INFO - 21/05/14 14:43:29 INFO Executor: Finished task 43.0 in stage 1.0 (TID 324). 1868 bytes result sent to driver
[2021-05-14 11:43:29,025] {docker.py:276} INFO - 21/05/14 14:43:29 INFO TaskSetManager: Starting task 47.0 in stage 1.0 (TID 328) (f0b8ef7ba22f, executor driver, partition 47, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:29,027] {docker.py:276} INFO - 21/05/14 14:43:29 INFO TaskSetManager: Finished task 43.0 in stage 1.0 (TID 324) in 175 ms on f0b8ef7ba22f (executor driver) (44/281)
[2021-05-14 11:43:29,027] {docker.py:276} INFO - 21/05/14 14:43:29 INFO Executor: Running task 47.0 in stage 1.0 (TID 328)
[2021-05-14 11:43:29,111] {docker.py:276} INFO - 21/05/14 14:43:29 INFO Executor: Finished task 45.0 in stage 1.0 (TID 326). 1868 bytes result sent to driver
[2021-05-14 11:43:29,112] {docker.py:276} INFO - 21/05/14 14:43:29 INFO TaskSetManager: Starting task 48.0 in stage 1.0 (TID 329) (f0b8ef7ba22f, executor driver, partition 48, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:29,113] {docker.py:276} INFO - 21/05/14 14:43:29 INFO TaskSetManager: Finished task 45.0 in stage 1.0 (TID 326) in 177 ms on f0b8ef7ba22f (executor driver) (45/281)
21/05/14 14:43:29 INFO Executor: Running task 48.0 in stage 1.0 (TID 329)
[2021-05-14 11:43:29,135] {docker.py:276} INFO - 21/05/14 14:43:29 INFO Executor: Finished task 44.0 in stage 1.0 (TID 325). 1868 bytes result sent to driver
[2021-05-14 11:43:29,136] {docker.py:276} INFO - 21/05/14 14:43:29 INFO TaskSetManager: Starting task 49.0 in stage 1.0 (TID 330) (f0b8ef7ba22f, executor driver, partition 49, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:29,137] {docker.py:276} INFO - 21/05/14 14:43:29 INFO TaskSetManager: Finished task 44.0 in stage 1.0 (TID 325) in 204 ms on f0b8ef7ba22f (executor driver) (46/281)
[2021-05-14 11:43:29,137] {docker.py:276} INFO - 21/05/14 14:43:29 INFO Executor: Running task 49.0 in stage 1.0 (TID 330)
[2021-05-14 11:43:29,159] {docker.py:276} INFO - 21/05/14 14:43:29 INFO Executor: Finished task 46.0 in stage 1.0 (TID 327). 1825 bytes result sent to driver
[2021-05-14 11:43:29,160] {docker.py:276} INFO - 21/05/14 14:43:29 INFO TaskSetManager: Starting task 50.0 in stage 1.0 (TID 331) (f0b8ef7ba22f, executor driver, partition 50, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:29,161] {docker.py:276} INFO - 21/05/14 14:43:29 INFO TaskSetManager: Finished task 46.0 in stage 1.0 (TID 327) in 169 ms on f0b8ef7ba22f (executor driver) (47/281)
[2021-05-14 11:43:29,162] {docker.py:276} INFO - 21/05/14 14:43:29 INFO Executor: Running task 50.0 in stage 1.0 (TID 331)
[2021-05-14 11:43:29,200] {docker.py:276} INFO - 21/05/14 14:43:29 INFO Executor: Finished task 47.0 in stage 1.0 (TID 328). 1825 bytes result sent to driver
[2021-05-14 11:43:29,201] {docker.py:276} INFO - 21/05/14 14:43:29 INFO TaskSetManager: Starting task 51.0 in stage 1.0 (TID 332) (f0b8ef7ba22f, executor driver, partition 51, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:29,203] {docker.py:276} INFO - 21/05/14 14:43:29 INFO TaskSetManager: Finished task 47.0 in stage 1.0 (TID 328) in 179 ms on f0b8ef7ba22f (executor driver) (48/281)
21/05/14 14:43:29 INFO Executor: Running task 51.0 in stage 1.0 (TID 332)
[2021-05-14 11:43:29,290] {docker.py:276} INFO - 21/05/14 14:43:29 INFO Executor: Finished task 48.0 in stage 1.0 (TID 329). 1825 bytes result sent to driver
[2021-05-14 11:43:29,291] {docker.py:276} INFO - 21/05/14 14:43:29 INFO TaskSetManager: Starting task 52.0 in stage 1.0 (TID 333) (f0b8ef7ba22f, executor driver, partition 52, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:29,292] {docker.py:276} INFO - 21/05/14 14:43:29 INFO TaskSetManager: Finished task 48.0 in stage 1.0 (TID 329) in 180 ms on f0b8ef7ba22f (executor driver) (49/281)
[2021-05-14 11:43:29,293] {docker.py:276} INFO - 21/05/14 14:43:29 INFO Executor: Running task 52.0 in stage 1.0 (TID 333)
[2021-05-14 11:43:29,329] {docker.py:276} INFO - 21/05/14 14:43:29 INFO Executor: Finished task 49.0 in stage 1.0 (TID 330). 1825 bytes result sent to driver
[2021-05-14 11:43:29,330] {docker.py:276} INFO - 21/05/14 14:43:29 INFO TaskSetManager: Starting task 53.0 in stage 1.0 (TID 334) (f0b8ef7ba22f, executor driver, partition 53, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:29,331] {docker.py:276} INFO - 21/05/14 14:43:29 INFO Executor: Finished task 50.0 in stage 1.0 (TID 331). 1825 bytes result sent to driver
[2021-05-14 11:43:29,332] {docker.py:276} INFO - 21/05/14 14:43:29 INFO Executor: Running task 53.0 in stage 1.0 (TID 334)
[2021-05-14 11:43:29,332] {docker.py:276} INFO - 21/05/14 14:43:29 INFO TaskSetManager: Starting task 54.0 in stage 1.0 (TID 335) (f0b8ef7ba22f, executor driver, partition 54, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:29,333] {docker.py:276} INFO - 21/05/14 14:43:29 INFO Executor: Running task 54.0 in stage 1.0 (TID 335)
[2021-05-14 11:43:29,334] {docker.py:276} INFO - 21/05/14 14:43:29 INFO TaskSetManager: Finished task 50.0 in stage 1.0 (TID 331) in 173 ms on f0b8ef7ba22f (executor driver) (50/281)
[2021-05-14 11:43:29,334] {docker.py:276} INFO - 21/05/14 14:43:29 INFO TaskSetManager: Finished task 49.0 in stage 1.0 (TID 330) in 198 ms on f0b8ef7ba22f (executor driver) (51/281)
[2021-05-14 11:43:29,379] {docker.py:276} INFO - 21/05/14 14:43:29 INFO Executor: Finished task 51.0 in stage 1.0 (TID 332). 1825 bytes result sent to driver
[2021-05-14 11:43:29,380] {docker.py:276} INFO - 21/05/14 14:43:29 INFO TaskSetManager: Starting task 55.0 in stage 1.0 (TID 336) (f0b8ef7ba22f, executor driver, partition 55, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
21/05/14 14:43:29 INFO TaskSetManager: Finished task 51.0 in stage 1.0 (TID 332) in 180 ms on f0b8ef7ba22f (executor driver) (52/281)
21/05/14 14:43:29 INFO Executor: Running task 55.0 in stage 1.0 (TID 336)
[2021-05-14 11:43:29,463] {docker.py:276} INFO - 21/05/14 14:43:29 INFO Executor: Finished task 52.0 in stage 1.0 (TID 333). 1825 bytes result sent to driver
[2021-05-14 11:43:29,465] {docker.py:276} INFO - 21/05/14 14:43:29 INFO TaskSetManager: Starting task 56.0 in stage 1.0 (TID 337) (f0b8ef7ba22f, executor driver, partition 56, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:29,466] {docker.py:276} INFO - 21/05/14 14:43:29 INFO TaskSetManager: Finished task 52.0 in stage 1.0 (TID 333) in 175 ms on f0b8ef7ba22f (executor driver) (53/281)
21/05/14 14:43:29 INFO Executor: Running task 56.0 in stage 1.0 (TID 337)
[2021-05-14 11:43:29,504] {docker.py:276} INFO - 21/05/14 14:43:29 INFO Executor: Finished task 54.0 in stage 1.0 (TID 335). 1825 bytes result sent to driver
21/05/14 14:43:29 INFO Executor: Finished task 53.0 in stage 1.0 (TID 334). 1825 bytes result sent to driver
21/05/14 14:43:29 INFO TaskSetManager: Starting task 57.0 in stage 1.0 (TID 338) (f0b8ef7ba22f, executor driver, partition 57, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:29,505] {docker.py:276} INFO - 21/05/14 14:43:29 INFO Executor: Running task 57.0 in stage 1.0 (TID 338)
[2021-05-14 11:43:29,506] {docker.py:276} INFO - 21/05/14 14:43:29 INFO TaskSetManager: Starting task 58.0 in stage 1.0 (TID 339) (f0b8ef7ba22f, executor driver, partition 58, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:29,507] {docker.py:276} INFO - 21/05/14 14:43:29 INFO Executor: Running task 58.0 in stage 1.0 (TID 339)
21/05/14 14:43:29 INFO TaskSetManager: Finished task 54.0 in stage 1.0 (TID 335) in 175 ms on f0b8ef7ba22f (executor driver) (54/281)
21/05/14 14:43:29 INFO TaskSetManager: Finished task 53.0 in stage 1.0 (TID 334) in 176 ms on f0b8ef7ba22f (executor driver) (55/281)
[2021-05-14 11:43:29,556] {docker.py:276} INFO - 21/05/14 14:43:29 INFO Executor: Finished task 55.0 in stage 1.0 (TID 336). 1825 bytes result sent to driver
[2021-05-14 11:43:29,557] {docker.py:276} INFO - 21/05/14 14:43:29 INFO TaskSetManager: Starting task 59.0 in stage 1.0 (TID 340) (f0b8ef7ba22f, executor driver, partition 59, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:29,558] {docker.py:276} INFO - 21/05/14 14:43:29 INFO TaskSetManager: Finished task 55.0 in stage 1.0 (TID 336) in 178 ms on f0b8ef7ba22f (executor driver) (56/281)
[2021-05-14 11:43:29,559] {docker.py:276} INFO - 21/05/14 14:43:29 INFO Executor: Running task 59.0 in stage 1.0 (TID 340)
[2021-05-14 11:43:29,635] {docker.py:276} INFO - 21/05/14 14:43:29 INFO Executor: Finished task 56.0 in stage 1.0 (TID 337). 1825 bytes result sent to driver
[2021-05-14 11:43:29,636] {docker.py:276} INFO - 21/05/14 14:43:29 INFO TaskSetManager: Starting task 60.0 in stage 1.0 (TID 341) (f0b8ef7ba22f, executor driver, partition 60, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:29,636] {docker.py:276} INFO - 21/05/14 14:43:29 INFO TaskSetManager: Finished task 56.0 in stage 1.0 (TID 337) in 174 ms on f0b8ef7ba22f (executor driver) (57/281)
[2021-05-14 11:43:29,637] {docker.py:276} INFO - 21/05/14 14:43:29 INFO Executor: Running task 60.0 in stage 1.0 (TID 341)
[2021-05-14 11:43:29,676] {docker.py:276} INFO - 21/05/14 14:43:29 INFO Executor: Finished task 58.0 in stage 1.0 (TID 339). 1825 bytes result sent to driver
[2021-05-14 11:43:29,678] {docker.py:276} INFO - 21/05/14 14:43:29 INFO TaskSetManager: Starting task 61.0 in stage 1.0 (TID 342) (f0b8ef7ba22f, executor driver, partition 61, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:29,680] {docker.py:276} INFO - 21/05/14 14:43:29 INFO TaskSetManager: Finished task 58.0 in stage 1.0 (TID 339) in 175 ms on f0b8ef7ba22f (executor driver) (58/281)
[2021-05-14 11:43:29,681] {docker.py:276} INFO - 21/05/14 14:43:29 INFO Executor: Running task 61.0 in stage 1.0 (TID 342)
21/05/14 14:43:29 INFO Executor: Finished task 57.0 in stage 1.0 (TID 338). 1825 bytes result sent to driver
[2021-05-14 11:43:29,682] {docker.py:276} INFO - 21/05/14 14:43:29 INFO TaskSetManager: Starting task 62.0 in stage 1.0 (TID 343) (f0b8ef7ba22f, executor driver, partition 62, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:29,683] {docker.py:276} INFO - 21/05/14 14:43:29 INFO TaskSetManager: Finished task 57.0 in stage 1.0 (TID 338) in 179 ms on f0b8ef7ba22f (executor driver) (59/281)
[2021-05-14 11:43:29,684] {docker.py:276} INFO - 21/05/14 14:43:29 INFO Executor: Running task 62.0 in stage 1.0 (TID 343)
[2021-05-14 11:43:29,748] {docker.py:276} INFO - 21/05/14 14:43:29 INFO Executor: Finished task 59.0 in stage 1.0 (TID 340). 1868 bytes result sent to driver
[2021-05-14 11:43:29,749] {docker.py:276} INFO - 21/05/14 14:43:29 INFO TaskSetManager: Starting task 63.0 in stage 1.0 (TID 344) (f0b8ef7ba22f, executor driver, partition 63, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:29,749] {docker.py:276} INFO - 21/05/14 14:43:29 INFO TaskSetManager: Finished task 59.0 in stage 1.0 (TID 340) in 193 ms on f0b8ef7ba22f (executor driver) (60/281)
[2021-05-14 11:43:29,750] {docker.py:276} INFO - 21/05/14 14:43:29 INFO Executor: Running task 63.0 in stage 1.0 (TID 344)
[2021-05-14 11:43:29,811] {docker.py:276} INFO - 21/05/14 14:43:29 INFO Executor: Finished task 60.0 in stage 1.0 (TID 341). 1868 bytes result sent to driver
[2021-05-14 11:43:29,812] {docker.py:276} INFO - 21/05/14 14:43:29 INFO TaskSetManager: Starting task 64.0 in stage 1.0 (TID 345) (f0b8ef7ba22f, executor driver, partition 64, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:29,813] {docker.py:276} INFO - 21/05/14 14:43:29 INFO Executor: Running task 64.0 in stage 1.0 (TID 345)
21/05/14 14:43:29 INFO TaskSetManager: Finished task 60.0 in stage 1.0 (TID 341) in 178 ms on f0b8ef7ba22f (executor driver) (61/281)
[2021-05-14 11:43:29,860] {docker.py:276} INFO - 21/05/14 14:43:29 INFO Executor: Finished task 61.0 in stage 1.0 (TID 342). 1868 bytes result sent to driver
[2021-05-14 11:43:29,860] {docker.py:276} INFO - 21/05/14 14:43:29 INFO TaskSetManager: Starting task 65.0 in stage 1.0 (TID 346) (f0b8ef7ba22f, executor driver, partition 65, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:29,861] {docker.py:276} INFO - 21/05/14 14:43:29 INFO Executor: Running task 65.0 in stage 1.0 (TID 346)
[2021-05-14 11:43:29,862] {docker.py:276} INFO - 21/05/14 14:43:29 INFO TaskSetManager: Finished task 61.0 in stage 1.0 (TID 342) in 185 ms on f0b8ef7ba22f (executor driver) (62/281)
[2021-05-14 11:43:29,908] {docker.py:276} INFO - 21/05/14 14:43:29 INFO Executor: Finished task 62.0 in stage 1.0 (TID 343). 1868 bytes result sent to driver
[2021-05-14 11:43:29,908] {docker.py:276} INFO - 21/05/14 14:43:29 INFO TaskSetManager: Starting task 66.0 in stage 1.0 (TID 347) (f0b8ef7ba22f, executor driver, partition 66, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:29,909] {docker.py:276} INFO - 21/05/14 14:43:29 INFO TaskSetManager: Finished task 62.0 in stage 1.0 (TID 343) in 228 ms on f0b8ef7ba22f (executor driver) (63/281)
21/05/14 14:43:29 INFO Executor: Running task 66.0 in stage 1.0 (TID 347)
[2021-05-14 11:43:29,926] {docker.py:276} INFO - 21/05/14 14:43:29 INFO Executor: Finished task 63.0 in stage 1.0 (TID 344). 1825 bytes result sent to driver
[2021-05-14 11:43:29,942] {docker.py:276} INFO - 21/05/14 14:43:29 INFO TaskSetManager: Starting task 67.0 in stage 1.0 (TID 348) (f0b8ef7ba22f, executor driver, partition 67, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:29,943] {docker.py:276} INFO - 21/05/14 14:43:29 INFO Executor: Running task 67.0 in stage 1.0 (TID 348)
[2021-05-14 11:43:29,943] {docker.py:276} INFO - 21/05/14 14:43:29 INFO TaskSetManager: Finished task 63.0 in stage 1.0 (TID 344) in 181 ms on f0b8ef7ba22f (executor driver) (64/281)
[2021-05-14 11:43:29,986] {docker.py:276} INFO - 21/05/14 14:43:30 INFO Executor: Finished task 64.0 in stage 1.0 (TID 345). 1825 bytes result sent to driver
[2021-05-14 11:43:29,987] {docker.py:276} INFO - 21/05/14 14:43:30 INFO TaskSetManager: Starting task 68.0 in stage 1.0 (TID 349) (f0b8ef7ba22f, executor driver, partition 68, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:29,987] {docker.py:276} INFO - 21/05/14 14:43:30 INFO TaskSetManager: Finished task 64.0 in stage 1.0 (TID 345) in 175 ms on f0b8ef7ba22f (executor driver) (65/281)
21/05/14 14:43:30 INFO Executor: Running task 68.0 in stage 1.0 (TID 349)
[2021-05-14 11:43:30,033] {docker.py:276} INFO - 21/05/14 14:43:30 INFO Executor: Finished task 65.0 in stage 1.0 (TID 346). 1825 bytes result sent to driver
[2021-05-14 11:43:30,034] {docker.py:276} INFO - 21/05/14 14:43:30 INFO TaskSetManager: Starting task 69.0 in stage 1.0 (TID 350) (f0b8ef7ba22f, executor driver, partition 69, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:30,035] {docker.py:276} INFO - 21/05/14 14:43:30 INFO Executor: Running task 69.0 in stage 1.0 (TID 350)
[2021-05-14 11:43:30,035] {docker.py:276} INFO - 21/05/14 14:43:30 INFO TaskSetManager: Finished task 65.0 in stage 1.0 (TID 346) in 175 ms on f0b8ef7ba22f (executor driver) (66/281)
[2021-05-14 11:43:30,076] {docker.py:276} INFO - 21/05/14 14:43:30 INFO Executor: Finished task 66.0 in stage 1.0 (TID 347). 1825 bytes result sent to driver
[2021-05-14 11:43:30,077] {docker.py:276} INFO - 21/05/14 14:43:30 INFO TaskSetManager: Starting task 70.0 in stage 1.0 (TID 351) (f0b8ef7ba22f, executor driver, partition 70, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:30,077] {docker.py:276} INFO - 21/05/14 14:43:30 INFO TaskSetManager: Finished task 66.0 in stage 1.0 (TID 347) in 169 ms on f0b8ef7ba22f (executor driver) (67/281)
[2021-05-14 11:43:30,078] {docker.py:276} INFO - 21/05/14 14:43:30 INFO Executor: Running task 70.0 in stage 1.0 (TID 351)
[2021-05-14 11:43:30,103] {docker.py:276} INFO - 21/05/14 14:43:30 INFO Executor: Finished task 67.0 in stage 1.0 (TID 348). 1825 bytes result sent to driver
[2021-05-14 11:43:30,104] {docker.py:276} INFO - 21/05/14 14:43:30 INFO TaskSetManager: Starting task 71.0 in stage 1.0 (TID 352) (f0b8ef7ba22f, executor driver, partition 71, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:30,105] {docker.py:276} INFO - 21/05/14 14:43:30 INFO TaskSetManager: Finished task 67.0 in stage 1.0 (TID 348) in 178 ms on f0b8ef7ba22f (executor driver) (68/281)
[2021-05-14 11:43:30,105] {docker.py:276} INFO - 21/05/14 14:43:30 INFO Executor: Running task 71.0 in stage 1.0 (TID 352)
[2021-05-14 11:43:30,164] {docker.py:276} INFO - 21/05/14 14:43:30 INFO Executor: Finished task 68.0 in stage 1.0 (TID 349). 1825 bytes result sent to driver
[2021-05-14 11:43:30,165] {docker.py:276} INFO - 21/05/14 14:43:30 INFO TaskSetManager: Starting task 72.0 in stage 1.0 (TID 353) (f0b8ef7ba22f, executor driver, partition 72, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:30,166] {docker.py:276} INFO - 21/05/14 14:43:30 INFO Executor: Running task 72.0 in stage 1.0 (TID 353)
21/05/14 14:43:30 INFO TaskSetManager: Finished task 68.0 in stage 1.0 (TID 349) in 180 ms on f0b8ef7ba22f (executor driver) (69/281)
[2021-05-14 11:43:30,248] {docker.py:276} INFO - 21/05/14 14:43:30 INFO Executor: Finished task 70.0 in stage 1.0 (TID 351). 1825 bytes result sent to driver
[2021-05-14 11:43:30,249] {docker.py:276} INFO - 21/05/14 14:43:30 INFO TaskSetManager: Starting task 73.0 in stage 1.0 (TID 354) (f0b8ef7ba22f, executor driver, partition 73, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:30,250] {docker.py:276} INFO - 21/05/14 14:43:30 INFO Executor: Running task 73.0 in stage 1.0 (TID 354)
21/05/14 14:43:30 INFO TaskSetManager: Finished task 70.0 in stage 1.0 (TID 351) in 173 ms on f0b8ef7ba22f (executor driver) (70/281)
[2021-05-14 11:43:30,264] {docker.py:276} INFO - 21/05/14 14:43:30 INFO Executor: Finished task 69.0 in stage 1.0 (TID 350). 1825 bytes result sent to driver
[2021-05-14 11:43:30,265] {docker.py:276} INFO - 21/05/14 14:43:30 INFO TaskSetManager: Starting task 74.0 in stage 1.0 (TID 355) (f0b8ef7ba22f, executor driver, partition 74, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:30,266] {docker.py:276} INFO - 21/05/14 14:43:30 INFO TaskSetManager: Finished task 69.0 in stage 1.0 (TID 350) in 232 ms on f0b8ef7ba22f (executor driver) (71/281)
[2021-05-14 11:43:30,267] {docker.py:276} INFO - 21/05/14 14:43:30 INFO Executor: Running task 74.0 in stage 1.0 (TID 355)
[2021-05-14 11:43:30,281] {docker.py:276} INFO - 21/05/14 14:43:30 INFO Executor: Finished task 71.0 in stage 1.0 (TID 352). 1825 bytes result sent to driver
[2021-05-14 11:43:30,282] {docker.py:276} INFO - 21/05/14 14:43:30 INFO TaskSetManager: Starting task 75.0 in stage 1.0 (TID 356) (f0b8ef7ba22f, executor driver, partition 75, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:30,284] {docker.py:276} INFO - 21/05/14 14:43:30 INFO Executor: Running task 75.0 in stage 1.0 (TID 356)
21/05/14 14:43:30 INFO TaskSetManager: Finished task 71.0 in stage 1.0 (TID 352) in 179 ms on f0b8ef7ba22f (executor driver) (72/281)
[2021-05-14 11:43:30,337] {docker.py:276} INFO - 21/05/14 14:43:30 INFO Executor: Finished task 72.0 in stage 1.0 (TID 353). 1825 bytes result sent to driver
[2021-05-14 11:43:30,338] {docker.py:276} INFO - 21/05/14 14:43:30 INFO TaskSetManager: Starting task 76.0 in stage 1.0 (TID 357) (f0b8ef7ba22f, executor driver, partition 76, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:30,338] {docker.py:276} INFO - 21/05/14 14:43:30 INFO Executor: Running task 76.0 in stage 1.0 (TID 357)
[2021-05-14 11:43:30,339] {docker.py:276} INFO - 21/05/14 14:43:30 INFO TaskSetManager: Finished task 72.0 in stage 1.0 (TID 353) in 175 ms on f0b8ef7ba22f (executor driver) (73/281)
[2021-05-14 11:43:30,439] {docker.py:276} INFO - 21/05/14 14:43:30 INFO Executor: Finished task 74.0 in stage 1.0 (TID 355). 1825 bytes result sent to driver
[2021-05-14 11:43:30,440] {docker.py:276} INFO - 21/05/14 14:43:30 INFO TaskSetManager: Starting task 77.0 in stage 1.0 (TID 358) (f0b8ef7ba22f, executor driver, partition 77, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:30,442] {docker.py:276} INFO - 21/05/14 14:43:30 INFO TaskSetManager: Finished task 74.0 in stage 1.0 (TID 355) in 176 ms on f0b8ef7ba22f (executor driver) (74/281)
[2021-05-14 11:43:30,442] {docker.py:276} INFO - 21/05/14 14:43:30 INFO Executor: Running task 77.0 in stage 1.0 (TID 358)
[2021-05-14 11:43:30,461] {docker.py:276} INFO - 21/05/14 14:43:30 INFO Executor: Finished task 75.0 in stage 1.0 (TID 356). 1868 bytes result sent to driver
[2021-05-14 11:43:30,477] {docker.py:276} INFO - 21/05/14 14:43:30 INFO TaskSetManager: Starting task 78.0 in stage 1.0 (TID 359) (f0b8ef7ba22f, executor driver, partition 78, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:30,478] {docker.py:276} INFO - 21/05/14 14:43:30 INFO TaskSetManager: Finished task 75.0 in stage 1.0 (TID 356) in 181 ms on f0b8ef7ba22f (executor driver) (75/281)
[2021-05-14 11:43:30,478] {docker.py:276} INFO - 21/05/14 14:43:30 INFO Executor: Running task 78.0 in stage 1.0 (TID 359)
[2021-05-14 11:43:30,482] {docker.py:276} INFO - 21/05/14 14:43:30 INFO Executor: Finished task 73.0 in stage 1.0 (TID 354). 1868 bytes result sent to driver
[2021-05-14 11:43:30,484] {docker.py:276} INFO - 21/05/14 14:43:30 INFO TaskSetManager: Starting task 79.0 in stage 1.0 (TID 360) (f0b8ef7ba22f, executor driver, partition 79, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:30,485] {docker.py:276} INFO - 21/05/14 14:43:30 INFO TaskSetManager: Finished task 73.0 in stage 1.0 (TID 354) in 237 ms on f0b8ef7ba22f (executor driver) (76/281)
21/05/14 14:43:30 INFO Executor: Running task 79.0 in stage 1.0 (TID 360)
[2021-05-14 11:43:30,506] {docker.py:276} INFO - 21/05/14 14:43:30 INFO Executor: Finished task 76.0 in stage 1.0 (TID 357). 1868 bytes result sent to driver
[2021-05-14 11:43:30,508] {docker.py:276} INFO - 21/05/14 14:43:30 INFO TaskSetManager: Starting task 80.0 in stage 1.0 (TID 361) (f0b8ef7ba22f, executor driver, partition 80, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:30,509] {docker.py:276} INFO - 21/05/14 14:43:30 INFO TaskSetManager: Finished task 76.0 in stage 1.0 (TID 357) in 171 ms on f0b8ef7ba22f (executor driver) (77/281)
[2021-05-14 11:43:30,510] {docker.py:276} INFO - 21/05/14 14:43:30 INFO Executor: Running task 80.0 in stage 1.0 (TID 361)
[2021-05-14 11:43:30,625] {docker.py:276} INFO - 21/05/14 14:43:30 INFO Executor: Finished task 77.0 in stage 1.0 (TID 358). 1868 bytes result sent to driver
[2021-05-14 11:43:30,626] {docker.py:276} INFO - 21/05/14 14:43:30 INFO TaskSetManager: Starting task 81.0 in stage 1.0 (TID 362) (f0b8ef7ba22f, executor driver, partition 81, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:30,628] {docker.py:276} INFO - 21/05/14 14:43:30 INFO Executor: Running task 81.0 in stage 1.0 (TID 362)
21/05/14 14:43:30 INFO TaskSetManager: Finished task 77.0 in stage 1.0 (TID 358) in 188 ms on f0b8ef7ba22f (executor driver) (78/281)
[2021-05-14 11:43:30,642] {docker.py:276} INFO - 21/05/14 14:43:30 INFO Executor: Finished task 78.0 in stage 1.0 (TID 359). 1825 bytes result sent to driver
[2021-05-14 11:43:30,643] {docker.py:276} INFO - 21/05/14 14:43:30 INFO TaskSetManager: Starting task 82.0 in stage 1.0 (TID 363) (f0b8ef7ba22f, executor driver, partition 82, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:30,644] {docker.py:276} INFO - 21/05/14 14:43:30 INFO TaskSetManager: Finished task 78.0 in stage 1.0 (TID 359) in 182 ms on f0b8ef7ba22f (executor driver) (79/281)
[2021-05-14 11:43:30,645] {docker.py:276} INFO - 21/05/14 14:43:30 INFO Executor: Running task 82.0 in stage 1.0 (TID 363)
[2021-05-14 11:43:30,653] {docker.py:276} INFO - 21/05/14 14:43:30 INFO Executor: Finished task 79.0 in stage 1.0 (TID 360). 1825 bytes result sent to driver
[2021-05-14 11:43:30,655] {docker.py:276} INFO - 21/05/14 14:43:30 INFO TaskSetManager: Starting task 83.0 in stage 1.0 (TID 364) (f0b8ef7ba22f, executor driver, partition 83, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:30,655] {docker.py:276} INFO - 21/05/14 14:43:30 INFO Executor: Running task 83.0 in stage 1.0 (TID 364)
[2021-05-14 11:43:30,656] {docker.py:276} INFO - 21/05/14 14:43:30 INFO TaskSetManager: Finished task 79.0 in stage 1.0 (TID 360) in 172 ms on f0b8ef7ba22f (executor driver) (80/281)
[2021-05-14 11:43:30,678] {docker.py:276} INFO - 21/05/14 14:43:30 INFO Executor: Finished task 80.0 in stage 1.0 (TID 361). 1825 bytes result sent to driver
[2021-05-14 11:43:30,679] {docker.py:276} INFO - 21/05/14 14:43:30 INFO TaskSetManager: Starting task 84.0 in stage 1.0 (TID 365) (f0b8ef7ba22f, executor driver, partition 84, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:30,680] {docker.py:276} INFO - 21/05/14 14:43:30 INFO TaskSetManager: Finished task 80.0 in stage 1.0 (TID 361) in 173 ms on f0b8ef7ba22f (executor driver) (81/281)
[2021-05-14 11:43:30,680] {docker.py:276} INFO - 21/05/14 14:43:30 INFO Executor: Running task 84.0 in stage 1.0 (TID 365)
[2021-05-14 11:43:30,800] {docker.py:276} INFO - 21/05/14 14:43:30 INFO Executor: Finished task 81.0 in stage 1.0 (TID 362). 1825 bytes result sent to driver
[2021-05-14 11:43:30,802] {docker.py:276} INFO - 21/05/14 14:43:30 INFO TaskSetManager: Starting task 85.0 in stage 1.0 (TID 366) (f0b8ef7ba22f, executor driver, partition 85, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:30,803] {docker.py:276} INFO - 21/05/14 14:43:30 INFO TaskSetManager: Finished task 81.0 in stage 1.0 (TID 362) in 178 ms on f0b8ef7ba22f (executor driver) (82/281)
[2021-05-14 11:43:30,804] {docker.py:276} INFO - 21/05/14 14:43:30 INFO Executor: Running task 85.0 in stage 1.0 (TID 366)
[2021-05-14 11:43:30,822] {docker.py:276} INFO - 21/05/14 14:43:30 INFO Executor: Finished task 82.0 in stage 1.0 (TID 363). 1825 bytes result sent to driver
[2021-05-14 11:43:30,823] {docker.py:276} INFO - 21/05/14 14:43:30 INFO TaskSetManager: Starting task 86.0 in stage 1.0 (TID 367) (f0b8ef7ba22f, executor driver, partition 86, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:30,824] {docker.py:276} INFO - 21/05/14 14:43:30 INFO TaskSetManager: Finished task 82.0 in stage 1.0 (TID 363) in 182 ms on f0b8ef7ba22f (executor driver) (83/281)
[2021-05-14 11:43:30,824] {docker.py:276} INFO - 21/05/14 14:43:30 INFO Executor: Running task 86.0 in stage 1.0 (TID 367)
[2021-05-14 11:43:30,829] {docker.py:276} INFO - 21/05/14 14:43:30 INFO Executor: Finished task 83.0 in stage 1.0 (TID 364). 1825 bytes result sent to driver
[2021-05-14 11:43:30,830] {docker.py:276} INFO - 21/05/14 14:43:30 INFO TaskSetManager: Starting task 87.0 in stage 1.0 (TID 368) (f0b8ef7ba22f, executor driver, partition 87, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
21/05/14 14:43:30 INFO TaskSetManager: Finished task 83.0 in stage 1.0 (TID 364) in 176 ms on f0b8ef7ba22f (executor driver) (84/281)
21/05/14 14:43:30 INFO Executor: Running task 87.0 in stage 1.0 (TID 368)
[2021-05-14 11:43:30,848] {docker.py:276} INFO - 21/05/14 14:43:30 INFO Executor: Finished task 84.0 in stage 1.0 (TID 365). 1825 bytes result sent to driver
[2021-05-14 11:43:30,850] {docker.py:276} INFO - 21/05/14 14:43:30 INFO TaskSetManager: Starting task 88.0 in stage 1.0 (TID 369) (f0b8ef7ba22f, executor driver, partition 88, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:30,851] {docker.py:276} INFO - 21/05/14 14:43:30 INFO TaskSetManager: Finished task 84.0 in stage 1.0 (TID 365) in 170 ms on f0b8ef7ba22f (executor driver) (85/281)
[2021-05-14 11:43:30,851] {docker.py:276} INFO - 21/05/14 14:43:30 INFO Executor: Running task 88.0 in stage 1.0 (TID 369)
[2021-05-14 11:43:30,986] {docker.py:276} INFO - 21/05/14 14:43:31 INFO Executor: Finished task 85.0 in stage 1.0 (TID 366). 1825 bytes result sent to driver
[2021-05-14 11:43:30,987] {docker.py:276} INFO - 21/05/14 14:43:31 INFO TaskSetManager: Starting task 89.0 in stage 1.0 (TID 370) (f0b8ef7ba22f, executor driver, partition 89, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:30,988] {docker.py:276} INFO - 21/05/14 14:43:31 INFO TaskSetManager: Finished task 85.0 in stage 1.0 (TID 366) in 187 ms on f0b8ef7ba22f (executor driver) (86/281)
[2021-05-14 11:43:30,990] {docker.py:276} INFO - 21/05/14 14:43:31 INFO Executor: Running task 89.0 in stage 1.0 (TID 370)
[2021-05-14 11:43:31,004] {docker.py:276} INFO - 21/05/14 14:43:31 INFO Executor: Finished task 87.0 in stage 1.0 (TID 368). 1825 bytes result sent to driver
[2021-05-14 11:43:31,025] {docker.py:276} INFO - 21/05/14 14:43:31 INFO Executor: Finished task 86.0 in stage 1.0 (TID 367). 1825 bytes result sent to driver
[2021-05-14 11:43:31,025] {docker.py:276} INFO - 21/05/14 14:43:31 INFO TaskSetManager: Starting task 90.0 in stage 1.0 (TID 371) (f0b8ef7ba22f, executor driver, partition 90, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:31,026] {docker.py:276} INFO - 21/05/14 14:43:31 INFO Executor: Running task 90.0 in stage 1.0 (TID 371)
[2021-05-14 11:43:31,026] {docker.py:276} INFO - 21/05/14 14:43:31 INFO TaskSetManager: Finished task 87.0 in stage 1.0 (TID 368) in 177 ms on f0b8ef7ba22f (executor driver) (87/281)
[2021-05-14 11:43:31,026] {docker.py:276} INFO - 21/05/14 14:43:31 INFO TaskSetManager: Starting task 91.0 in stage 1.0 (TID 372) (f0b8ef7ba22f, executor driver, partition 91, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:31,027] {docker.py:276} INFO - 21/05/14 14:43:31 INFO Executor: Running task 91.0 in stage 1.0 (TID 372)
[2021-05-14 11:43:31,027] {docker.py:276} INFO - 21/05/14 14:43:31 INFO TaskSetManager: Finished task 86.0 in stage 1.0 (TID 367) in 185 ms on f0b8ef7ba22f (executor driver) (88/281)
[2021-05-14 11:43:31,027] {docker.py:276} INFO - 21/05/14 14:43:31 INFO Executor: Finished task 88.0 in stage 1.0 (TID 369). 1825 bytes result sent to driver
[2021-05-14 11:43:31,027] {docker.py:276} INFO - 21/05/14 14:43:31 INFO TaskSetManager: Starting task 92.0 in stage 1.0 (TID 373) (f0b8ef7ba22f, executor driver, partition 92, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:31,028] {docker.py:276} INFO - 21/05/14 14:43:31 INFO Executor: Running task 92.0 in stage 1.0 (TID 373)
21/05/14 14:43:31 INFO TaskSetManager: Finished task 88.0 in stage 1.0 (TID 369) in 170 ms on f0b8ef7ba22f (executor driver) (89/281)
[2021-05-14 11:43:31,169] {docker.py:276} INFO - 21/05/14 14:43:31 INFO Executor: Finished task 89.0 in stage 1.0 (TID 370). 1825 bytes result sent to driver
[2021-05-14 11:43:31,171] {docker.py:276} INFO - 21/05/14 14:43:31 INFO TaskSetManager: Starting task 93.0 in stage 1.0 (TID 374) (f0b8ef7ba22f, executor driver, partition 93, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:31,173] {docker.py:276} INFO - 21/05/14 14:43:31 INFO Executor: Running task 93.0 in stage 1.0 (TID 374)
21/05/14 14:43:31 INFO TaskSetManager: Finished task 89.0 in stage 1.0 (TID 370) in 186 ms on f0b8ef7ba22f (executor driver) (90/281)
[2021-05-14 11:43:31,188] {docker.py:276} INFO - 21/05/14 14:43:31 INFO Executor: Finished task 91.0 in stage 1.0 (TID 372). 1868 bytes result sent to driver
[2021-05-14 11:43:31,189] {docker.py:276} INFO - 21/05/14 14:43:31 INFO Executor: Finished task 90.0 in stage 1.0 (TID 371). 1868 bytes result sent to driver
[2021-05-14 11:43:31,190] {docker.py:276} INFO - 21/05/14 14:43:31 INFO TaskSetManager: Starting task 94.0 in stage 1.0 (TID 375) (f0b8ef7ba22f, executor driver, partition 94, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:31,191] {docker.py:276} INFO - 21/05/14 14:43:31 INFO Executor: Running task 94.0 in stage 1.0 (TID 375)
[2021-05-14 11:43:31,192] {docker.py:276} INFO - 21/05/14 14:43:31 INFO TaskSetManager: Starting task 95.0 in stage 1.0 (TID 376) (f0b8ef7ba22f, executor driver, partition 95, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:31,193] {docker.py:276} INFO - 21/05/14 14:43:31 INFO Executor: Running task 95.0 in stage 1.0 (TID 376)
[2021-05-14 11:43:31,194] {docker.py:276} INFO - 21/05/14 14:43:31 INFO TaskSetManager: Finished task 90.0 in stage 1.0 (TID 371) in 188 ms on f0b8ef7ba22f (executor driver) (91/281)
[2021-05-14 11:43:31,194] {docker.py:276} INFO - 21/05/14 14:43:31 INFO TaskSetManager: Finished task 91.0 in stage 1.0 (TID 372) in 186 ms on f0b8ef7ba22f (executor driver) (92/281)
[2021-05-14 11:43:31,264] {docker.py:276} INFO - 21/05/14 14:43:31 INFO Executor: Finished task 92.0 in stage 1.0 (TID 373). 1868 bytes result sent to driver
[2021-05-14 11:43:31,266] {docker.py:276} INFO - 21/05/14 14:43:31 INFO TaskSetManager: Starting task 96.0 in stage 1.0 (TID 377) (f0b8ef7ba22f, executor driver, partition 96, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:31,267] {docker.py:276} INFO - 21/05/14 14:43:31 INFO Executor: Running task 96.0 in stage 1.0 (TID 377)
[2021-05-14 11:43:31,268] {docker.py:276} INFO - 21/05/14 14:43:31 INFO TaskSetManager: Finished task 92.0 in stage 1.0 (TID 373) in 253 ms on f0b8ef7ba22f (executor driver) (93/281)
[2021-05-14 11:43:31,369] {docker.py:276} INFO - 21/05/14 14:43:31 INFO Executor: Finished task 95.0 in stage 1.0 (TID 376). 1825 bytes result sent to driver
[2021-05-14 11:43:31,370] {docker.py:276} INFO - 21/05/14 14:43:31 INFO Executor: Finished task 94.0 in stage 1.0 (TID 375). 1825 bytes result sent to driver
[2021-05-14 11:43:31,371] {docker.py:276} INFO - 21/05/14 14:43:31 INFO TaskSetManager: Starting task 97.0 in stage 1.0 (TID 378) (f0b8ef7ba22f, executor driver, partition 97, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
21/05/14 14:43:31 INFO Executor: Finished task 93.0 in stage 1.0 (TID 374). 1868 bytes result sent to driver
[2021-05-14 11:43:31,372] {docker.py:276} INFO - 21/05/14 14:43:31 INFO Executor: Running task 97.0 in stage 1.0 (TID 378)
[2021-05-14 11:43:31,373] {docker.py:276} INFO - 21/05/14 14:43:31 INFO TaskSetManager: Starting task 98.0 in stage 1.0 (TID 379) (f0b8ef7ba22f, executor driver, partition 98, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:31,376] {docker.py:276} INFO - 21/05/14 14:43:31 INFO TaskSetManager: Finished task 94.0 in stage 1.0 (TID 375) in 185 ms on f0b8ef7ba22f (executor driver) (94/281)
[2021-05-14 11:43:31,377] {docker.py:276} INFO - 21/05/14 14:43:31 INFO TaskSetManager: Finished task 95.0 in stage 1.0 (TID 376) in 183 ms on f0b8ef7ba22f (executor driver) (95/281)
[2021-05-14 11:43:31,378] {docker.py:276} INFO - 21/05/14 14:43:31 INFO Executor: Running task 98.0 in stage 1.0 (TID 379)
[2021-05-14 11:43:31,379] {docker.py:276} INFO - 21/05/14 14:43:31 INFO TaskSetManager: Finished task 93.0 in stage 1.0 (TID 374) in 207 ms on f0b8ef7ba22f (executor driver) (96/281)
[2021-05-14 11:43:31,380] {docker.py:276} INFO - 21/05/14 14:43:31 INFO TaskSetManager: Starting task 99.0 in stage 1.0 (TID 380) (f0b8ef7ba22f, executor driver, partition 99, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:31,380] {docker.py:276} INFO - 21/05/14 14:43:31 INFO Executor: Running task 99.0 in stage 1.0 (TID 380)
[2021-05-14 11:43:31,441] {docker.py:276} INFO - 21/05/14 14:43:31 INFO Executor: Finished task 96.0 in stage 1.0 (TID 377). 1825 bytes result sent to driver
[2021-05-14 11:43:31,445] {docker.py:276} INFO - 21/05/14 14:43:31 INFO TaskSetManager: Starting task 100.0 in stage 1.0 (TID 381) (f0b8ef7ba22f, executor driver, partition 100, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:31,446] {docker.py:276} INFO - 21/05/14 14:43:31 INFO Executor: Running task 100.0 in stage 1.0 (TID 381)
21/05/14 14:43:31 INFO TaskSetManager: Finished task 96.0 in stage 1.0 (TID 377) in 180 ms on f0b8ef7ba22f (executor driver) (97/281)
[2021-05-14 11:43:31,558] {docker.py:276} INFO - 21/05/14 14:43:31 INFO Executor: Finished task 97.0 in stage 1.0 (TID 378). 1825 bytes result sent to driver
[2021-05-14 11:43:31,560] {docker.py:276} INFO - 21/05/14 14:43:31 INFO Executor: Finished task 98.0 in stage 1.0 (TID 379). 1825 bytes result sent to driver
[2021-05-14 11:43:31,561] {docker.py:276} INFO - 21/05/14 14:43:31 INFO Executor: Finished task 99.0 in stage 1.0 (TID 380). 1825 bytes result sent to driver
[2021-05-14 11:43:31,562] {docker.py:276} INFO - 21/05/14 14:43:31 INFO TaskSetManager: Starting task 101.0 in stage 1.0 (TID 382) (f0b8ef7ba22f, executor driver, partition 101, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:31,564] {docker.py:276} INFO - 21/05/14 14:43:31 INFO Executor: Running task 101.0 in stage 1.0 (TID 382)
[2021-05-14 11:43:31,565] {docker.py:276} INFO - 21/05/14 14:43:31 INFO TaskSetManager: Starting task 102.0 in stage 1.0 (TID 383) (f0b8ef7ba22f, executor driver, partition 102, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:31,566] {docker.py:276} INFO - 21/05/14 14:43:31 INFO TaskSetManager: Finished task 97.0 in stage 1.0 (TID 378) in 195 ms on f0b8ef7ba22f (executor driver) (98/281)
[2021-05-14 11:43:31,566] {docker.py:276} INFO - 21/05/14 14:43:31 INFO TaskSetManager: Starting task 103.0 in stage 1.0 (TID 384) (f0b8ef7ba22f, executor driver, partition 103, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:31,567] {docker.py:276} INFO - 21/05/14 14:43:31 INFO TaskSetManager: Finished task 98.0 in stage 1.0 (TID 379) in 194 ms on f0b8ef7ba22f (executor driver) (99/281)
[2021-05-14 11:43:31,567] {docker.py:276} INFO - 21/05/14 14:43:31 INFO Executor: Running task 103.0 in stage 1.0 (TID 384)
[2021-05-14 11:43:31,568] {docker.py:276} INFO - 21/05/14 14:43:31 INFO Executor: Running task 102.0 in stage 1.0 (TID 383)
[2021-05-14 11:43:31,569] {docker.py:276} INFO - 21/05/14 14:43:31 INFO TaskSetManager: Finished task 99.0 in stage 1.0 (TID 380) in 191 ms on f0b8ef7ba22f (executor driver) (100/281)
[2021-05-14 11:43:31,616] {docker.py:276} INFO - 21/05/14 14:43:31 INFO Executor: Finished task 100.0 in stage 1.0 (TID 381). 1825 bytes result sent to driver
[2021-05-14 11:43:31,618] {docker.py:276} INFO - 21/05/14 14:43:31 INFO TaskSetManager: Starting task 104.0 in stage 1.0 (TID 385) (f0b8ef7ba22f, executor driver, partition 104, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:31,619] {docker.py:276} INFO - 21/05/14 14:43:31 INFO TaskSetManager: Finished task 100.0 in stage 1.0 (TID 381) in 176 ms on f0b8ef7ba22f (executor driver) (101/281)
[2021-05-14 11:43:31,620] {docker.py:276} INFO - 21/05/14 14:43:31 INFO Executor: Running task 104.0 in stage 1.0 (TID 385)
[2021-05-14 11:43:31,738] {docker.py:276} INFO - 21/05/14 14:43:31 INFO Executor: Finished task 103.0 in stage 1.0 (TID 384). 1825 bytes result sent to driver
[2021-05-14 11:43:31,739] {docker.py:276} INFO - 21/05/14 14:43:31 INFO TaskSetManager: Starting task 105.0 in stage 1.0 (TID 386) (f0b8ef7ba22f, executor driver, partition 105, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:31,740] {docker.py:276} INFO - 21/05/14 14:43:31 INFO TaskSetManager: Finished task 103.0 in stage 1.0 (TID 384) in 175 ms on f0b8ef7ba22f (executor driver) (102/281)
[2021-05-14 11:43:31,741] {docker.py:276} INFO - 21/05/14 14:43:31 INFO Executor: Running task 105.0 in stage 1.0 (TID 386)
[2021-05-14 11:43:31,743] {docker.py:276} INFO - 21/05/14 14:43:31 INFO Executor: Finished task 101.0 in stage 1.0 (TID 382). 1825 bytes result sent to driver
[2021-05-14 11:43:31,744] {docker.py:276} INFO - 21/05/14 14:43:31 INFO TaskSetManager: Starting task 106.0 in stage 1.0 (TID 387) (f0b8ef7ba22f, executor driver, partition 106, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:31,745] {docker.py:276} INFO - 21/05/14 14:43:31 INFO TaskSetManager: Finished task 101.0 in stage 1.0 (TID 382) in 186 ms on f0b8ef7ba22f (executor driver) (103/281)
[2021-05-14 11:43:31,747] {docker.py:276} INFO - 21/05/14 14:43:31 INFO Executor: Running task 106.0 in stage 1.0 (TID 387)
[2021-05-14 11:43:31,750] {docker.py:276} INFO - 21/05/14 14:43:31 INFO Executor: Finished task 102.0 in stage 1.0 (TID 383). 1825 bytes result sent to driver
[2021-05-14 11:43:31,751] {docker.py:276} INFO - 21/05/14 14:43:31 INFO TaskSetManager: Starting task 107.0 in stage 1.0 (TID 388) (f0b8ef7ba22f, executor driver, partition 107, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:31,752] {docker.py:276} INFO - 21/05/14 14:43:31 INFO TaskSetManager: Finished task 102.0 in stage 1.0 (TID 383) in 189 ms on f0b8ef7ba22f (executor driver) (104/281)
21/05/14 14:43:31 INFO Executor: Running task 107.0 in stage 1.0 (TID 388)
[2021-05-14 11:43:31,791] {docker.py:276} INFO - 21/05/14 14:43:31 INFO Executor: Finished task 104.0 in stage 1.0 (TID 385). 1825 bytes result sent to driver
[2021-05-14 11:43:31,792] {docker.py:276} INFO - 21/05/14 14:43:31 INFO TaskSetManager: Starting task 108.0 in stage 1.0 (TID 389) (f0b8ef7ba22f, executor driver, partition 108, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:31,793] {docker.py:276} INFO - 21/05/14 14:43:31 INFO Executor: Running task 108.0 in stage 1.0 (TID 389)
21/05/14 14:43:31 INFO TaskSetManager: Finished task 104.0 in stage 1.0 (TID 385) in 176 ms on f0b8ef7ba22f (executor driver) (105/281)
[2021-05-14 11:43:31,923] {docker.py:276} INFO - 21/05/14 14:43:31 INFO Executor: Finished task 105.0 in stage 1.0 (TID 386). 1825 bytes result sent to driver
[2021-05-14 11:43:31,925] {docker.py:276} INFO - 21/05/14 14:43:31 INFO Executor: Finished task 106.0 in stage 1.0 (TID 387). 1825 bytes result sent to driver
[2021-05-14 11:43:31,926] {docker.py:276} INFO - 21/05/14 14:43:31 INFO TaskSetManager: Starting task 109.0 in stage 1.0 (TID 390) (f0b8ef7ba22f, executor driver, partition 109, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:31,927] {docker.py:276} INFO - 21/05/14 14:43:31 INFO Executor: Running task 109.0 in stage 1.0 (TID 390)
[2021-05-14 11:43:31,931] {docker.py:276} INFO - 21/05/14 14:43:31 INFO TaskSetManager: Starting task 110.0 in stage 1.0 (TID 391) (f0b8ef7ba22f, executor driver, partition 110, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
21/05/14 14:43:31 INFO Executor: Finished task 107.0 in stage 1.0 (TID 388). 1825 bytes result sent to driver
[2021-05-14 11:43:31,932] {docker.py:276} INFO - 21/05/14 14:43:31 INFO Executor: Running task 110.0 in stage 1.0 (TID 391)
[2021-05-14 11:43:31,943] {docker.py:276} INFO - 21/05/14 14:43:31 INFO TaskSetManager: Starting task 111.0 in stage 1.0 (TID 392) (f0b8ef7ba22f, executor driver, partition 111, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:31,944] {docker.py:276} INFO - 21/05/14 14:43:31 INFO TaskSetManager: Finished task 105.0 in stage 1.0 (TID 386) in 207 ms on f0b8ef7ba22f (executor driver) (106/281)
[2021-05-14 11:43:31,945] {docker.py:276} INFO - 21/05/14 14:43:31 INFO TaskSetManager: Finished task 106.0 in stage 1.0 (TID 387) in 202 ms on f0b8ef7ba22f (executor driver) (107/281)
[2021-05-14 11:43:31,945] {docker.py:276} INFO - 21/05/14 14:43:31 INFO TaskSetManager: Finished task 107.0 in stage 1.0 (TID 388) in 195 ms on f0b8ef7ba22f (executor driver) (108/281)
[2021-05-14 11:43:31,946] {docker.py:276} INFO - 21/05/14 14:43:31 INFO Executor: Running task 111.0 in stage 1.0 (TID 392)
[2021-05-14 11:43:31,979] {docker.py:276} INFO - 21/05/14 14:43:32 INFO Executor: Finished task 108.0 in stage 1.0 (TID 389). 1868 bytes result sent to driver
[2021-05-14 11:43:31,980] {docker.py:276} INFO - 21/05/14 14:43:32 INFO TaskSetManager: Starting task 112.0 in stage 1.0 (TID 393) (f0b8ef7ba22f, executor driver, partition 112, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:31,981] {docker.py:276} INFO - 21/05/14 14:43:32 INFO TaskSetManager: Finished task 108.0 in stage 1.0 (TID 389) in 188 ms on f0b8ef7ba22f (executor driver) (109/281)
[2021-05-14 11:43:31,981] {docker.py:276} INFO - 21/05/14 14:43:32 INFO Executor: Running task 112.0 in stage 1.0 (TID 393)
[2021-05-14 11:43:32,118] {docker.py:276} INFO - 21/05/14 14:43:32 INFO Executor: Finished task 110.0 in stage 1.0 (TID 391). 1868 bytes result sent to driver
[2021-05-14 11:43:32,119] {docker.py:276} INFO - 21/05/14 14:43:32 INFO Executor: Finished task 109.0 in stage 1.0 (TID 390). 1868 bytes result sent to driver
[2021-05-14 11:43:32,120] {docker.py:276} INFO - 21/05/14 14:43:32 INFO TaskSetManager: Starting task 113.0 in stage 1.0 (TID 394) (f0b8ef7ba22f, executor driver, partition 113, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:32,121] {docker.py:276} INFO - 21/05/14 14:43:32 INFO TaskSetManager: Finished task 110.0 in stage 1.0 (TID 391) in 192 ms on f0b8ef7ba22f (executor driver) (110/281)
[2021-05-14 11:43:32,122] {docker.py:276} INFO - 21/05/14 14:43:32 INFO Executor: Running task 113.0 in stage 1.0 (TID 394)
[2021-05-14 11:43:32,123] {docker.py:276} INFO - 21/05/14 14:43:32 INFO TaskSetManager: Starting task 114.0 in stage 1.0 (TID 395) (f0b8ef7ba22f, executor driver, partition 114, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:32,124] {docker.py:276} INFO - 21/05/14 14:43:32 INFO TaskSetManager: Finished task 109.0 in stage 1.0 (TID 390) in 199 ms on f0b8ef7ba22f (executor driver) (111/281)
[2021-05-14 11:43:32,124] {docker.py:276} INFO - 21/05/14 14:43:32 INFO Executor: Running task 114.0 in stage 1.0 (TID 395)
[2021-05-14 11:43:32,156] {docker.py:276} INFO - 21/05/14 14:43:32 INFO Executor: Finished task 111.0 in stage 1.0 (TID 392). 1825 bytes result sent to driver
[2021-05-14 11:43:32,157] {docker.py:276} INFO - 21/05/14 14:43:32 INFO Executor: Finished task 112.0 in stage 1.0 (TID 393). 1825 bytes result sent to driver
[2021-05-14 11:43:32,158] {docker.py:276} INFO - 21/05/14 14:43:32 INFO TaskSetManager: Starting task 115.0 in stage 1.0 (TID 396) (f0b8ef7ba22f, executor driver, partition 115, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:32,159] {docker.py:276} INFO - 21/05/14 14:43:32 INFO Executor: Running task 115.0 in stage 1.0 (TID 396)
[2021-05-14 11:43:32,160] {docker.py:276} INFO - 21/05/14 14:43:32 INFO TaskSetManager: Starting task 116.0 in stage 1.0 (TID 397) (f0b8ef7ba22f, executor driver, partition 116, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:32,160] {docker.py:276} INFO - 21/05/14 14:43:32 INFO Executor: Running task 116.0 in stage 1.0 (TID 397)
[2021-05-14 11:43:32,161] {docker.py:276} INFO - 21/05/14 14:43:32 INFO TaskSetManager: Finished task 112.0 in stage 1.0 (TID 393) in 182 ms on f0b8ef7ba22f (executor driver) (112/281)
[2021-05-14 11:43:32,161] {docker.py:276} INFO - 21/05/14 14:43:32 INFO TaskSetManager: Finished task 111.0 in stage 1.0 (TID 392) in 218 ms on f0b8ef7ba22f (executor driver) (113/281)
[2021-05-14 11:43:32,294] {docker.py:276} INFO - 21/05/14 14:43:32 INFO Executor: Finished task 114.0 in stage 1.0 (TID 395). 1825 bytes result sent to driver
[2021-05-14 11:43:32,295] {docker.py:276} INFO - 21/05/14 14:43:32 INFO TaskSetManager: Starting task 117.0 in stage 1.0 (TID 398) (f0b8ef7ba22f, executor driver, partition 117, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:32,297] {docker.py:276} INFO - 21/05/14 14:43:32 INFO Executor: Running task 117.0 in stage 1.0 (TID 398)
[2021-05-14 11:43:32,298] {docker.py:276} INFO - 21/05/14 14:43:32 INFO TaskSetManager: Finished task 114.0 in stage 1.0 (TID 395) in 176 ms on f0b8ef7ba22f (executor driver) (114/281)
[2021-05-14 11:43:32,299] {docker.py:276} INFO - 21/05/14 14:43:32 INFO Executor: Finished task 113.0 in stage 1.0 (TID 394). 1825 bytes result sent to driver
[2021-05-14 11:43:32,300] {docker.py:276} INFO - 21/05/14 14:43:32 INFO TaskSetManager: Starting task 118.0 in stage 1.0 (TID 399) (f0b8ef7ba22f, executor driver, partition 118, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:32,301] {docker.py:276} INFO - 21/05/14 14:43:32 INFO Executor: Running task 118.0 in stage 1.0 (TID 399)
[2021-05-14 11:43:32,302] {docker.py:276} INFO - 21/05/14 14:43:32 INFO TaskSetManager: Finished task 113.0 in stage 1.0 (TID 394) in 184 ms on f0b8ef7ba22f (executor driver) (115/281)
[2021-05-14 11:43:32,339] {docker.py:276} INFO - 21/05/14 14:43:32 INFO Executor: Finished task 116.0 in stage 1.0 (TID 397). 1825 bytes result sent to driver
[2021-05-14 11:43:32,341] {docker.py:276} INFO - 21/05/14 14:43:32 INFO TaskSetManager: Starting task 119.0 in stage 1.0 (TID 400) (f0b8ef7ba22f, executor driver, partition 119, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:32,342] {docker.py:276} INFO - 21/05/14 14:43:32 INFO TaskSetManager: Finished task 116.0 in stage 1.0 (TID 397) in 183 ms on f0b8ef7ba22f (executor driver) (116/281)
[2021-05-14 11:43:32,343] {docker.py:276} INFO - 21/05/14 14:43:32 INFO Executor: Running task 119.0 in stage 1.0 (TID 400)
[2021-05-14 11:43:32,469] {docker.py:276} INFO - 21/05/14 14:43:32 INFO Executor: Finished task 118.0 in stage 1.0 (TID 399). 1825 bytes result sent to driver
[2021-05-14 11:43:32,470] {docker.py:276} INFO - 21/05/14 14:43:32 INFO TaskSetManager: Starting task 120.0 in stage 1.0 (TID 401) (f0b8ef7ba22f, executor driver, partition 120, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:32,471] {docker.py:276} INFO - 21/05/14 14:43:32 INFO Executor: Running task 120.0 in stage 1.0 (TID 401)
21/05/14 14:43:32 INFO TaskSetManager: Finished task 118.0 in stage 1.0 (TID 399) in 172 ms on f0b8ef7ba22f (executor driver) (117/281)
[2021-05-14 11:43:32,521] {docker.py:276} INFO - 21/05/14 14:43:32 INFO Executor: Finished task 119.0 in stage 1.0 (TID 400). 1825 bytes result sent to driver
[2021-05-14 11:43:32,522] {docker.py:276} INFO - 21/05/14 14:43:32 INFO TaskSetManager: Starting task 121.0 in stage 1.0 (TID 402) (f0b8ef7ba22f, executor driver, partition 121, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:32,524] {docker.py:276} INFO - 21/05/14 14:43:32 INFO TaskSetManager: Finished task 119.0 in stage 1.0 (TID 400) in 183 ms on f0b8ef7ba22f (executor driver) (118/281)
21/05/14 14:43:32 INFO Executor: Running task 121.0 in stage 1.0 (TID 402)
[2021-05-14 11:43:32,640] {docker.py:276} INFO - 21/05/14 14:43:32 INFO Executor: Finished task 120.0 in stage 1.0 (TID 401). 1825 bytes result sent to driver
[2021-05-14 11:43:32,641] {docker.py:276} INFO - 21/05/14 14:43:32 INFO TaskSetManager: Starting task 122.0 in stage 1.0 (TID 403) (f0b8ef7ba22f, executor driver, partition 122, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:32,641] {docker.py:276} INFO - 21/05/14 14:43:32 INFO Executor: Running task 122.0 in stage 1.0 (TID 403)
[2021-05-14 11:43:32,642] {docker.py:276} INFO - 21/05/14 14:43:32 INFO TaskSetManager: Finished task 120.0 in stage 1.0 (TID 401) in 173 ms on f0b8ef7ba22f (executor driver) (119/281)
[2021-05-14 11:43:32,702] {docker.py:276} INFO - 21/05/14 14:43:32 INFO Executor: Finished task 121.0 in stage 1.0 (TID 402). 1825 bytes result sent to driver
[2021-05-14 11:43:32,703] {docker.py:276} INFO - 21/05/14 14:43:32 INFO TaskSetManager: Starting task 123.0 in stage 1.0 (TID 404) (f0b8ef7ba22f, executor driver, partition 123, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:32,705] {docker.py:276} INFO - 21/05/14 14:43:32 INFO Executor: Running task 123.0 in stage 1.0 (TID 404)
21/05/14 14:43:32 INFO TaskSetManager: Finished task 121.0 in stage 1.0 (TID 402) in 184 ms on f0b8ef7ba22f (executor driver) (120/281)
[2021-05-14 11:43:32,821] {docker.py:276} INFO - 21/05/14 14:43:32 INFO Executor: Finished task 122.0 in stage 1.0 (TID 403). 1825 bytes result sent to driver
[2021-05-14 11:43:32,822] {docker.py:276} INFO - 21/05/14 14:43:32 INFO Executor: Finished task 115.0 in stage 1.0 (TID 396). 1825 bytes result sent to driver
21/05/14 14:43:32 INFO TaskSetManager: Starting task 124.0 in stage 1.0 (TID 405) (f0b8ef7ba22f, executor driver, partition 124, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:32,822] {docker.py:276} INFO - 21/05/14 14:43:32 INFO Executor: Running task 124.0 in stage 1.0 (TID 405)
[2021-05-14 11:43:32,823] {docker.py:276} INFO - 21/05/14 14:43:32 INFO TaskSetManager: Starting task 125.0 in stage 1.0 (TID 406) (f0b8ef7ba22f, executor driver, partition 125, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:32,833] {docker.py:276} INFO - 21/05/14 14:43:32 INFO TaskSetManager: Finished task 122.0 in stage 1.0 (TID 403) in 193 ms on f0b8ef7ba22f (executor driver) (121/281)
[2021-05-14 11:43:32,834] {docker.py:276} INFO - 21/05/14 14:43:32 INFO TaskSetManager: Finished task 115.0 in stage 1.0 (TID 396) in 676 ms on f0b8ef7ba22f (executor driver) (122/281)
[2021-05-14 11:43:32,834] {docker.py:276} INFO - 21/05/14 14:43:32 INFO Executor: Running task 125.0 in stage 1.0 (TID 406)
[2021-05-14 11:43:32,963] {docker.py:276} INFO - 21/05/14 14:43:32 INFO Executor: Finished task 117.0 in stage 1.0 (TID 398). 1868 bytes result sent to driver
[2021-05-14 11:43:32,964] {docker.py:276} INFO - 21/05/14 14:43:32 INFO TaskSetManager: Starting task 126.0 in stage 1.0 (TID 407) (f0b8ef7ba22f, executor driver, partition 126, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:32,965] {docker.py:276} INFO - 21/05/14 14:43:32 INFO Executor: Running task 126.0 in stage 1.0 (TID 407)
21/05/14 14:43:32 INFO TaskSetManager: Finished task 117.0 in stage 1.0 (TID 398) in 672 ms on f0b8ef7ba22f (executor driver) (123/281)
[2021-05-14 11:43:33,000] {docker.py:276} INFO - 21/05/14 14:43:33 INFO Executor: Finished task 125.0 in stage 1.0 (TID 406). 1825 bytes result sent to driver
21/05/14 14:43:33 INFO Executor: Finished task 124.0 in stage 1.0 (TID 405). 1868 bytes result sent to driver
[2021-05-14 11:43:33,001] {docker.py:276} INFO - 21/05/14 14:43:33 INFO TaskSetManager: Starting task 127.0 in stage 1.0 (TID 408) (f0b8ef7ba22f, executor driver, partition 127, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:33,003] {docker.py:276} INFO - 21/05/14 14:43:33 INFO Executor: Running task 127.0 in stage 1.0 (TID 408)
21/05/14 14:43:33 INFO TaskSetManager: Starting task 128.0 in stage 1.0 (TID 409) (f0b8ef7ba22f, executor driver, partition 128, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:33,004] {docker.py:276} INFO - 21/05/14 14:43:33 INFO Executor: Running task 128.0 in stage 1.0 (TID 409)
[2021-05-14 11:43:33,004] {docker.py:276} INFO - 21/05/14 14:43:33 INFO TaskSetManager: Finished task 125.0 in stage 1.0 (TID 406) in 183 ms on f0b8ef7ba22f (executor driver) (124/281)
[2021-05-14 11:43:33,005] {docker.py:276} INFO - 21/05/14 14:43:33 INFO TaskSetManager: Finished task 124.0 in stage 1.0 (TID 405) in 185 ms on f0b8ef7ba22f (executor driver) (125/281)
[2021-05-14 11:43:33,136] {docker.py:276} INFO - 21/05/14 14:43:33 INFO Executor: Finished task 126.0 in stage 1.0 (TID 407). 1825 bytes result sent to driver
[2021-05-14 11:43:33,137] {docker.py:276} INFO - 21/05/14 14:43:33 INFO TaskSetManager: Starting task 129.0 in stage 1.0 (TID 410) (f0b8ef7ba22f, executor driver, partition 129, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:33,139] {docker.py:276} INFO - 21/05/14 14:43:33 INFO TaskSetManager: Finished task 126.0 in stage 1.0 (TID 407) in 175 ms on f0b8ef7ba22f (executor driver) (126/281)
[2021-05-14 11:43:33,139] {docker.py:276} INFO - 21/05/14 14:43:33 INFO Executor: Running task 129.0 in stage 1.0 (TID 410)
[2021-05-14 11:43:33,171] {docker.py:276} INFO - 21/05/14 14:43:33 INFO Executor: Finished task 128.0 in stage 1.0 (TID 409). 1825 bytes result sent to driver
[2021-05-14 11:43:33,173] {docker.py:276} INFO - 21/05/14 14:43:33 INFO TaskSetManager: Starting task 130.0 in stage 1.0 (TID 411) (f0b8ef7ba22f, executor driver, partition 130, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:33,173] {docker.py:276} INFO - 21/05/14 14:43:33 INFO Executor: Running task 130.0 in stage 1.0 (TID 411)
[2021-05-14 11:43:33,173] {docker.py:276} INFO - 21/05/14 14:43:33 INFO TaskSetManager: Finished task 128.0 in stage 1.0 (TID 409) in 172 ms on f0b8ef7ba22f (executor driver) (127/281)
[2021-05-14 11:43:33,204] {docker.py:276} INFO - 21/05/14 14:43:33 INFO Executor: Finished task 127.0 in stage 1.0 (TID 408). 1825 bytes result sent to driver
[2021-05-14 11:43:33,205] {docker.py:276} INFO - 21/05/14 14:43:33 INFO TaskSetManager: Starting task 131.0 in stage 1.0 (TID 412) (f0b8ef7ba22f, executor driver, partition 131, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:33,206] {docker.py:276} INFO - 21/05/14 14:43:33 INFO TaskSetManager: Finished task 127.0 in stage 1.0 (TID 408) in 205 ms on f0b8ef7ba22f (executor driver) (128/281)
[2021-05-14 11:43:33,206] {docker.py:276} INFO - 21/05/14 14:43:33 INFO Executor: Running task 131.0 in stage 1.0 (TID 412)
[2021-05-14 11:43:33,309] {docker.py:276} INFO - 21/05/14 14:43:33 INFO Executor: Finished task 129.0 in stage 1.0 (TID 410). 1825 bytes result sent to driver
[2021-05-14 11:43:33,310] {docker.py:276} INFO - 21/05/14 14:43:33 INFO TaskSetManager: Starting task 132.0 in stage 1.0 (TID 413) (f0b8ef7ba22f, executor driver, partition 132, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:33,311] {docker.py:276} INFO - 21/05/14 14:43:33 INFO TaskSetManager: Finished task 129.0 in stage 1.0 (TID 410) in 175 ms on f0b8ef7ba22f (executor driver) (129/281)
[2021-05-14 11:43:33,312] {docker.py:276} INFO - 21/05/14 14:43:33 INFO Executor: Running task 132.0 in stage 1.0 (TID 413)
[2021-05-14 11:43:33,342] {docker.py:276} INFO - 21/05/14 14:43:33 INFO Executor: Finished task 130.0 in stage 1.0 (TID 411). 1825 bytes result sent to driver
[2021-05-14 11:43:33,344] {docker.py:276} INFO - 21/05/14 14:43:33 INFO TaskSetManager: Starting task 133.0 in stage 1.0 (TID 414) (f0b8ef7ba22f, executor driver, partition 133, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:33,347] {docker.py:276} INFO - 21/05/14 14:43:33 INFO Executor: Running task 133.0 in stage 1.0 (TID 414)
21/05/14 14:43:33 INFO TaskSetManager: Finished task 130.0 in stage 1.0 (TID 411) in 173 ms on f0b8ef7ba22f (executor driver) (130/281)
[2021-05-14 11:43:33,375] {docker.py:276} INFO - 21/05/14 14:43:33 INFO Executor: Finished task 131.0 in stage 1.0 (TID 412). 1825 bytes result sent to driver
[2021-05-14 11:43:33,378] {docker.py:276} INFO - 21/05/14 14:43:33 INFO TaskSetManager: Starting task 134.0 in stage 1.0 (TID 415) (f0b8ef7ba22f, executor driver, partition 134, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:33,379] {docker.py:276} INFO - 21/05/14 14:43:33 INFO TaskSetManager: Finished task 131.0 in stage 1.0 (TID 412) in 172 ms on f0b8ef7ba22f (executor driver) (131/281)
[2021-05-14 11:43:33,380] {docker.py:276} INFO - 21/05/14 14:43:33 INFO Executor: Running task 134.0 in stage 1.0 (TID 415)
[2021-05-14 11:43:33,381] {docker.py:276} INFO - 21/05/14 14:43:33 INFO Executor: Finished task 123.0 in stage 1.0 (TID 404). 1868 bytes result sent to driver
[2021-05-14 11:43:33,382] {docker.py:276} INFO - 21/05/14 14:43:33 INFO TaskSetManager: Starting task 135.0 in stage 1.0 (TID 416) (f0b8ef7ba22f, executor driver, partition 135, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:33,383] {docker.py:276} INFO - 21/05/14 14:43:33 INFO Executor: Running task 135.0 in stage 1.0 (TID 416)
[2021-05-14 11:43:33,383] {docker.py:276} INFO - 21/05/14 14:43:33 INFO TaskSetManager: Finished task 123.0 in stage 1.0 (TID 404) in 681 ms on f0b8ef7ba22f (executor driver) (132/281)
[2021-05-14 11:43:33,488] {docker.py:276} INFO - 21/05/14 14:43:33 INFO Executor: Finished task 132.0 in stage 1.0 (TID 413). 1825 bytes result sent to driver
[2021-05-14 11:43:33,490] {docker.py:276} INFO - 21/05/14 14:43:33 INFO TaskSetManager: Starting task 136.0 in stage 1.0 (TID 417) (f0b8ef7ba22f, executor driver, partition 136, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:33,491] {docker.py:276} INFO - 21/05/14 14:43:33 INFO TaskSetManager: Finished task 132.0 in stage 1.0 (TID 413) in 180 ms on f0b8ef7ba22f (executor driver) (133/281)
21/05/14 14:43:33 INFO Executor: Running task 136.0 in stage 1.0 (TID 417)
[2021-05-14 11:43:33,524] {docker.py:276} INFO - 21/05/14 14:43:33 INFO Executor: Finished task 133.0 in stage 1.0 (TID 414). 1825 bytes result sent to driver
[2021-05-14 11:43:33,526] {docker.py:276} INFO - 21/05/14 14:43:33 INFO TaskSetManager: Starting task 137.0 in stage 1.0 (TID 418) (f0b8ef7ba22f, executor driver, partition 137, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:33,527] {docker.py:276} INFO - 21/05/14 14:43:33 INFO Executor: Running task 137.0 in stage 1.0 (TID 418)
[2021-05-14 11:43:33,528] {docker.py:276} INFO - 21/05/14 14:43:33 INFO TaskSetManager: Finished task 133.0 in stage 1.0 (TID 414) in 185 ms on f0b8ef7ba22f (executor driver) (134/281)
[2021-05-14 11:43:33,557] {docker.py:276} INFO - 21/05/14 14:43:33 INFO Executor: Finished task 135.0 in stage 1.0 (TID 416). 1825 bytes result sent to driver
21/05/14 14:43:33 INFO Executor: Finished task 134.0 in stage 1.0 (TID 415). 1825 bytes result sent to driver
[2021-05-14 11:43:33,558] {docker.py:276} INFO - 21/05/14 14:43:33 INFO TaskSetManager: Starting task 138.0 in stage 1.0 (TID 419) (f0b8ef7ba22f, executor driver, partition 138, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:33,559] {docker.py:276} INFO - 21/05/14 14:43:33 INFO TaskSetManager: Finished task 135.0 in stage 1.0 (TID 416) in 178 ms on f0b8ef7ba22f (executor driver) (135/281)
[2021-05-14 11:43:33,560] {docker.py:276} INFO - 21/05/14 14:43:33 INFO Executor: Running task 138.0 in stage 1.0 (TID 419)
[2021-05-14 11:43:33,561] {docker.py:276} INFO - 21/05/14 14:43:33 INFO TaskSetManager: Starting task 139.0 in stage 1.0 (TID 420) (f0b8ef7ba22f, executor driver, partition 139, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:33,562] {docker.py:276} INFO - 21/05/14 14:43:33 INFO TaskSetManager: Finished task 134.0 in stage 1.0 (TID 415) in 186 ms on f0b8ef7ba22f (executor driver) (136/281)
[2021-05-14 11:43:33,563] {docker.py:276} INFO - 21/05/14 14:43:33 INFO Executor: Running task 139.0 in stage 1.0 (TID 420)
[2021-05-14 11:43:33,670] {docker.py:276} INFO - 21/05/14 14:43:33 INFO Executor: Finished task 136.0 in stage 1.0 (TID 417). 1868 bytes result sent to driver
[2021-05-14 11:43:33,672] {docker.py:276} INFO - 21/05/14 14:43:33 INFO TaskSetManager: Starting task 140.0 in stage 1.0 (TID 421) (f0b8ef7ba22f, executor driver, partition 140, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:33,672] {docker.py:276} INFO - 21/05/14 14:43:33 INFO TaskSetManager: Finished task 136.0 in stage 1.0 (TID 417) in 184 ms on f0b8ef7ba22f (executor driver) (137/281)
[2021-05-14 11:43:33,673] {docker.py:276} INFO - 21/05/14 14:43:33 INFO Executor: Running task 140.0 in stage 1.0 (TID 421)
[2021-05-14 11:43:33,696] {docker.py:276} INFO - 21/05/14 14:43:33 INFO Executor: Finished task 137.0 in stage 1.0 (TID 418). 1868 bytes result sent to driver
[2021-05-14 11:43:33,696] {docker.py:276} INFO - 21/05/14 14:43:33 INFO TaskSetManager: Finished task 137.0 in stage 1.0 (TID 418) in 172 ms on f0b8ef7ba22f (executor driver) (138/281)
[2021-05-14 11:43:33,697] {docker.py:276} INFO - 21/05/14 14:43:33 INFO TaskSetManager: Starting task 141.0 in stage 1.0 (TID 422) (f0b8ef7ba22f, executor driver, partition 141, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:33,698] {docker.py:276} INFO - 21/05/14 14:43:33 INFO Executor: Running task 141.0 in stage 1.0 (TID 422)
[2021-05-14 11:43:33,746] {docker.py:276} INFO - 21/05/14 14:43:33 INFO Executor: Finished task 139.0 in stage 1.0 (TID 420). 1868 bytes result sent to driver
[2021-05-14 11:43:33,747] {docker.py:276} INFO - 21/05/14 14:43:33 INFO Executor: Finished task 138.0 in stage 1.0 (TID 419). 1868 bytes result sent to driver
[2021-05-14 11:43:33,748] {docker.py:276} INFO - 21/05/14 14:43:33 INFO TaskSetManager: Starting task 142.0 in stage 1.0 (TID 423) (f0b8ef7ba22f, executor driver, partition 142, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:33,750] {docker.py:276} INFO - 21/05/14 14:43:33 INFO Executor: Running task 142.0 in stage 1.0 (TID 423)
[2021-05-14 11:43:33,751] {docker.py:276} INFO - 21/05/14 14:43:33 INFO TaskSetManager: Starting task 143.0 in stage 1.0 (TID 424) (f0b8ef7ba22f, executor driver, partition 143, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:33,751] {docker.py:276} INFO - 21/05/14 14:43:33 INFO TaskSetManager: Finished task 139.0 in stage 1.0 (TID 420) in 190 ms on f0b8ef7ba22f (executor driver) (139/281)
[2021-05-14 11:43:33,752] {docker.py:276} INFO - 21/05/14 14:43:33 INFO TaskSetManager: Finished task 138.0 in stage 1.0 (TID 419) in 193 ms on f0b8ef7ba22f (executor driver) (140/281)
[2021-05-14 11:43:33,753] {docker.py:276} INFO - 21/05/14 14:43:33 INFO Executor: Running task 143.0 in stage 1.0 (TID 424)
[2021-05-14 11:43:33,846] {docker.py:276} INFO - 21/05/14 14:43:33 INFO Executor: Finished task 140.0 in stage 1.0 (TID 421). 1825 bytes result sent to driver
[2021-05-14 11:43:33,848] {docker.py:276} INFO - 21/05/14 14:43:33 INFO TaskSetManager: Starting task 144.0 in stage 1.0 (TID 425) (f0b8ef7ba22f, executor driver, partition 144, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:33,849] {docker.py:276} INFO - 21/05/14 14:43:33 INFO TaskSetManager: Finished task 140.0 in stage 1.0 (TID 421) in 177 ms on f0b8ef7ba22f (executor driver) (141/281)
21/05/14 14:43:33 INFO Executor: Running task 144.0 in stage 1.0 (TID 425)
[2021-05-14 11:43:33,875] {docker.py:276} INFO - 21/05/14 14:43:33 INFO Executor: Finished task 141.0 in stage 1.0 (TID 422). 1825 bytes result sent to driver
[2021-05-14 11:43:33,876] {docker.py:276} INFO - 21/05/14 14:43:33 INFO TaskSetManager: Starting task 145.0 in stage 1.0 (TID 426) (f0b8ef7ba22f, executor driver, partition 145, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:33,877] {docker.py:276} INFO - 21/05/14 14:43:33 INFO Executor: Running task 145.0 in stage 1.0 (TID 426)
21/05/14 14:43:33 INFO TaskSetManager: Finished task 141.0 in stage 1.0 (TID 422) in 180 ms on f0b8ef7ba22f (executor driver) (142/281)
[2021-05-14 11:43:33,917] {docker.py:276} INFO - 21/05/14 14:43:33 INFO Executor: Finished task 143.0 in stage 1.0 (TID 424). 1825 bytes result sent to driver
[2021-05-14 11:43:33,918] {docker.py:276} INFO - 21/05/14 14:43:33 INFO TaskSetManager: Starting task 146.0 in stage 1.0 (TID 427) (f0b8ef7ba22f, executor driver, partition 146, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:33,920] {docker.py:276} INFO - 21/05/14 14:43:33 INFO TaskSetManager: Finished task 143.0 in stage 1.0 (TID 424) in 170 ms on f0b8ef7ba22f (executor driver) (143/281)
[2021-05-14 11:43:33,921] {docker.py:276} INFO - 21/05/14 14:43:33 INFO Executor: Running task 146.0 in stage 1.0 (TID 427)
[2021-05-14 11:43:33,924] {docker.py:276} INFO - 21/05/14 14:43:33 INFO Executor: Finished task 142.0 in stage 1.0 (TID 423). 1825 bytes result sent to driver
[2021-05-14 11:43:33,925] {docker.py:276} INFO - 21/05/14 14:43:33 INFO TaskSetManager: Starting task 147.0 in stage 1.0 (TID 428) (f0b8ef7ba22f, executor driver, partition 147, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:33,926] {docker.py:276} INFO - 21/05/14 14:43:33 INFO TaskSetManager: Finished task 142.0 in stage 1.0 (TID 423) in 178 ms on f0b8ef7ba22f (executor driver) (144/281)
[2021-05-14 11:43:33,926] {docker.py:276} INFO - 21/05/14 14:43:33 INFO Executor: Running task 147.0 in stage 1.0 (TID 428)
[2021-05-14 11:43:34,024] {docker.py:276} INFO - 21/05/14 14:43:34 INFO Executor: Finished task 144.0 in stage 1.0 (TID 425). 1825 bytes result sent to driver
[2021-05-14 11:43:34,025] {docker.py:276} INFO - 21/05/14 14:43:34 INFO TaskSetManager: Starting task 148.0 in stage 1.0 (TID 429) (f0b8ef7ba22f, executor driver, partition 148, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:34,027] {docker.py:276} INFO - 21/05/14 14:43:34 INFO TaskSetManager: Finished task 144.0 in stage 1.0 (TID 425) in 180 ms on f0b8ef7ba22f (executor driver) (145/281)
21/05/14 14:43:34 INFO Executor: Running task 148.0 in stage 1.0 (TID 429)
[2021-05-14 11:43:34,044] {docker.py:276} INFO - 21/05/14 14:43:34 INFO Executor: Finished task 145.0 in stage 1.0 (TID 426). 1825 bytes result sent to driver
[2021-05-14 11:43:34,045] {docker.py:276} INFO - 21/05/14 14:43:34 INFO TaskSetManager: Starting task 149.0 in stage 1.0 (TID 430) (f0b8ef7ba22f, executor driver, partition 149, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:34,046] {docker.py:276} INFO - 21/05/14 14:43:34 INFO Executor: Running task 149.0 in stage 1.0 (TID 430)
[2021-05-14 11:43:34,047] {docker.py:276} INFO - 21/05/14 14:43:34 INFO TaskSetManager: Finished task 145.0 in stage 1.0 (TID 426) in 171 ms on f0b8ef7ba22f (executor driver) (146/281)
[2021-05-14 11:43:34,095] {docker.py:276} INFO - 21/05/14 14:43:34 INFO Executor: Finished task 147.0 in stage 1.0 (TID 428). 1825 bytes result sent to driver
[2021-05-14 11:43:34,096] {docker.py:276} INFO - 21/05/14 14:43:34 INFO TaskSetManager: Starting task 150.0 in stage 1.0 (TID 431) (f0b8ef7ba22f, executor driver, partition 150, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:34,097] {docker.py:276} INFO - 21/05/14 14:43:34 INFO Executor: Running task 150.0 in stage 1.0 (TID 431)
[2021-05-14 11:43:34,098] {docker.py:276} INFO - 21/05/14 14:43:34 INFO TaskSetManager: Finished task 147.0 in stage 1.0 (TID 428) in 172 ms on f0b8ef7ba22f (executor driver) (147/281)
[2021-05-14 11:43:34,100] {docker.py:276} INFO - 21/05/14 14:43:34 INFO Executor: Finished task 146.0 in stage 1.0 (TID 427). 1825 bytes result sent to driver
[2021-05-14 11:43:34,101] {docker.py:276} INFO - 21/05/14 14:43:34 INFO TaskSetManager: Starting task 151.0 in stage 1.0 (TID 432) (f0b8ef7ba22f, executor driver, partition 151, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:34,102] {docker.py:276} INFO - 21/05/14 14:43:34 INFO TaskSetManager: Finished task 146.0 in stage 1.0 (TID 427) in 184 ms on f0b8ef7ba22f (executor driver) (148/281)
[2021-05-14 11:43:34,103] {docker.py:276} INFO - 21/05/14 14:43:34 INFO Executor: Running task 151.0 in stage 1.0 (TID 432)
[2021-05-14 11:43:34,217] {docker.py:276} INFO - 21/05/14 14:43:34 INFO Executor: Finished task 149.0 in stage 1.0 (TID 430). 1825 bytes result sent to driver
[2021-05-14 11:43:34,218] {docker.py:276} INFO - 21/05/14 14:43:34 INFO TaskSetManager: Starting task 152.0 in stage 1.0 (TID 433) (f0b8ef7ba22f, executor driver, partition 152, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:34,219] {docker.py:276} INFO - 21/05/14 14:43:34 INFO TaskSetManager: Finished task 149.0 in stage 1.0 (TID 430) in 173 ms on f0b8ef7ba22f (executor driver) (149/281)
[2021-05-14 11:43:34,220] {docker.py:276} INFO - 21/05/14 14:43:34 INFO Executor: Running task 152.0 in stage 1.0 (TID 433)
[2021-05-14 11:43:34,234] {docker.py:276} INFO - 21/05/14 14:43:34 INFO Executor: Finished task 148.0 in stage 1.0 (TID 429). 1825 bytes result sent to driver
[2021-05-14 11:43:34,235] {docker.py:276} INFO - 21/05/14 14:43:34 INFO TaskSetManager: Starting task 153.0 in stage 1.0 (TID 434) (f0b8ef7ba22f, executor driver, partition 153, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:34,236] {docker.py:276} INFO - 21/05/14 14:43:34 INFO TaskSetManager: Finished task 148.0 in stage 1.0 (TID 429) in 211 ms on f0b8ef7ba22f (executor driver) (150/281)
[2021-05-14 11:43:34,236] {docker.py:276} INFO - 21/05/14 14:43:34 INFO Executor: Running task 153.0 in stage 1.0 (TID 434)
[2021-05-14 11:43:34,270] {docker.py:276} INFO - 21/05/14 14:43:34 INFO Executor: Finished task 151.0 in stage 1.0 (TID 432). 1825 bytes result sent to driver
[2021-05-14 11:43:34,272] {docker.py:276} INFO - 21/05/14 14:43:34 INFO TaskSetManager: Starting task 154.0 in stage 1.0 (TID 435) (f0b8ef7ba22f, executor driver, partition 154, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
21/05/14 14:43:34 INFO TaskSetManager: Finished task 151.0 in stage 1.0 (TID 432) in 171 ms on f0b8ef7ba22f (executor driver) (151/281)
21/05/14 14:43:34 INFO Executor: Running task 154.0 in stage 1.0 (TID 435)
[2021-05-14 11:43:34,277] {docker.py:276} INFO - 21/05/14 14:43:34 INFO Executor: Finished task 150.0 in stage 1.0 (TID 431). 1825 bytes result sent to driver
[2021-05-14 11:43:34,278] {docker.py:276} INFO - 21/05/14 14:43:34 INFO TaskSetManager: Starting task 155.0 in stage 1.0 (TID 436) (f0b8ef7ba22f, executor driver, partition 155, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:34,278] {docker.py:276} INFO - 21/05/14 14:43:34 INFO TaskSetManager: Finished task 150.0 in stage 1.0 (TID 431) in 183 ms on f0b8ef7ba22f (executor driver) (152/281)
[2021-05-14 11:43:34,279] {docker.py:276} INFO - 21/05/14 14:43:34 INFO Executor: Running task 155.0 in stage 1.0 (TID 436)
[2021-05-14 11:43:34,392] {docker.py:276} INFO - 21/05/14 14:43:34 INFO Executor: Finished task 152.0 in stage 1.0 (TID 433). 1868 bytes result sent to driver
[2021-05-14 11:43:34,394] {docker.py:276} INFO - 21/05/14 14:43:34 INFO TaskSetManager: Starting task 156.0 in stage 1.0 (TID 437) (f0b8ef7ba22f, executor driver, partition 156, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:34,394] {docker.py:276} INFO - 21/05/14 14:43:34 INFO TaskSetManager: Finished task 152.0 in stage 1.0 (TID 433) in 177 ms on f0b8ef7ba22f (executor driver) (153/281)
[2021-05-14 11:43:34,395] {docker.py:276} INFO - 21/05/14 14:43:34 INFO Executor: Running task 156.0 in stage 1.0 (TID 437)
[2021-05-14 11:43:34,408] {docker.py:276} INFO - 21/05/14 14:43:34 INFO Executor: Finished task 153.0 in stage 1.0 (TID 434). 1868 bytes result sent to driver
[2021-05-14 11:43:34,409] {docker.py:276} INFO - 21/05/14 14:43:34 INFO TaskSetManager: Starting task 157.0 in stage 1.0 (TID 438) (f0b8ef7ba22f, executor driver, partition 157, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:34,410] {docker.py:276} INFO - 21/05/14 14:43:34 INFO TaskSetManager: Finished task 153.0 in stage 1.0 (TID 434) in 177 ms on f0b8ef7ba22f (executor driver) (154/281)
[2021-05-14 11:43:34,411] {docker.py:276} INFO - 21/05/14 14:43:34 INFO Executor: Running task 157.0 in stage 1.0 (TID 438)
[2021-05-14 11:43:34,452] {docker.py:276} INFO - 21/05/14 14:43:34 INFO Executor: Finished task 154.0 in stage 1.0 (TID 435). 1868 bytes result sent to driver
[2021-05-14 11:43:34,454] {docker.py:276} INFO - 21/05/14 14:43:34 INFO TaskSetManager: Starting task 158.0 in stage 1.0 (TID 439) (f0b8ef7ba22f, executor driver, partition 158, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:34,454] {docker.py:276} INFO - 21/05/14 14:43:34 INFO TaskSetManager: Finished task 154.0 in stage 1.0 (TID 435) in 184 ms on f0b8ef7ba22f (executor driver) (155/281)
[2021-05-14 11:43:34,455] {docker.py:276} INFO - 21/05/14 14:43:34 INFO Executor: Running task 158.0 in stage 1.0 (TID 439)
[2021-05-14 11:43:34,463] {docker.py:276} INFO - 21/05/14 14:43:34 INFO Executor: Finished task 155.0 in stage 1.0 (TID 436). 1868 bytes result sent to driver
[2021-05-14 11:43:34,464] {docker.py:276} INFO - 21/05/14 14:43:34 INFO TaskSetManager: Starting task 159.0 in stage 1.0 (TID 440) (f0b8ef7ba22f, executor driver, partition 159, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:34,464] {docker.py:276} INFO - 21/05/14 14:43:34 INFO TaskSetManager: Finished task 155.0 in stage 1.0 (TID 436) in 188 ms on f0b8ef7ba22f (executor driver) (156/281)
[2021-05-14 11:43:34,465] {docker.py:276} INFO - 21/05/14 14:43:34 INFO Executor: Running task 159.0 in stage 1.0 (TID 440)
[2021-05-14 11:43:34,566] {docker.py:276} INFO - 21/05/14 14:43:34 INFO Executor: Finished task 156.0 in stage 1.0 (TID 437). 1825 bytes result sent to driver
[2021-05-14 11:43:34,567] {docker.py:276} INFO - 21/05/14 14:43:34 INFO TaskSetManager: Starting task 160.0 in stage 1.0 (TID 441) (f0b8ef7ba22f, executor driver, partition 160, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:34,568] {docker.py:276} INFO - 21/05/14 14:43:34 INFO TaskSetManager: Finished task 156.0 in stage 1.0 (TID 437) in 175 ms on f0b8ef7ba22f (executor driver) (157/281)
[2021-05-14 11:43:34,569] {docker.py:276} INFO - 21/05/14 14:43:34 INFO Executor: Running task 160.0 in stage 1.0 (TID 441)
[2021-05-14 11:43:34,580] {docker.py:276} INFO - 21/05/14 14:43:34 INFO Executor: Finished task 157.0 in stage 1.0 (TID 438). 1825 bytes result sent to driver
[2021-05-14 11:43:34,580] {docker.py:276} INFO - 21/05/14 14:43:34 INFO TaskSetManager: Starting task 161.0 in stage 1.0 (TID 442) (f0b8ef7ba22f, executor driver, partition 161, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:34,581] {docker.py:276} INFO - 21/05/14 14:43:34 INFO TaskSetManager: Finished task 157.0 in stage 1.0 (TID 438) in 172 ms on f0b8ef7ba22f (executor driver) (158/281)
[2021-05-14 11:43:34,582] {docker.py:276} INFO - 21/05/14 14:43:34 INFO Executor: Running task 161.0 in stage 1.0 (TID 442)
[2021-05-14 11:43:34,631] {docker.py:276} INFO - 21/05/14 14:43:34 INFO Executor: Finished task 158.0 in stage 1.0 (TID 439). 1825 bytes result sent to driver
[2021-05-14 11:43:34,633] {docker.py:276} INFO - 21/05/14 14:43:34 INFO TaskSetManager: Starting task 162.0 in stage 1.0 (TID 443) (f0b8ef7ba22f, executor driver, partition 162, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:34,634] {docker.py:276} INFO - 21/05/14 14:43:34 INFO Executor: Running task 162.0 in stage 1.0 (TID 443)
21/05/14 14:43:34 INFO TaskSetManager: Finished task 158.0 in stage 1.0 (TID 439) in 181 ms on f0b8ef7ba22f (executor driver) (159/281)
[2021-05-14 11:43:34,654] {docker.py:276} INFO - 21/05/14 14:43:34 INFO Executor: Finished task 159.0 in stage 1.0 (TID 440). 1825 bytes result sent to driver
[2021-05-14 11:43:34,656] {docker.py:276} INFO - 21/05/14 14:43:34 INFO TaskSetManager: Starting task 163.0 in stage 1.0 (TID 444) (f0b8ef7ba22f, executor driver, partition 163, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:34,656] {docker.py:276} INFO - 21/05/14 14:43:34 INFO Executor: Running task 163.0 in stage 1.0 (TID 444)
21/05/14 14:43:34 INFO TaskSetManager: Finished task 159.0 in stage 1.0 (TID 440) in 193 ms on f0b8ef7ba22f (executor driver) (160/281)
[2021-05-14 11:43:34,751] {docker.py:276} INFO - 21/05/14 14:43:34 INFO Executor: Finished task 161.0 in stage 1.0 (TID 442). 1825 bytes result sent to driver
[2021-05-14 11:43:34,752] {docker.py:276} INFO - 21/05/14 14:43:34 INFO TaskSetManager: Starting task 164.0 in stage 1.0 (TID 445) (f0b8ef7ba22f, executor driver, partition 164, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:34,753] {docker.py:276} INFO - 21/05/14 14:43:34 INFO TaskSetManager: Finished task 161.0 in stage 1.0 (TID 442) in 172 ms on f0b8ef7ba22f (executor driver) (161/281)
21/05/14 14:43:34 INFO Executor: Running task 164.0 in stage 1.0 (TID 445)
[2021-05-14 11:43:34,812] {docker.py:276} INFO - 21/05/14 14:43:34 INFO Executor: Finished task 162.0 in stage 1.0 (TID 443). 1825 bytes result sent to driver
[2021-05-14 11:43:34,814] {docker.py:276} INFO - 21/05/14 14:43:34 INFO TaskSetManager: Starting task 165.0 in stage 1.0 (TID 446) (f0b8ef7ba22f, executor driver, partition 165, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:34,815] {docker.py:276} INFO - 21/05/14 14:43:34 INFO TaskSetManager: Finished task 162.0 in stage 1.0 (TID 443) in 183 ms on f0b8ef7ba22f (executor driver) (162/281)
[2021-05-14 11:43:34,816] {docker.py:276} INFO - 21/05/14 14:43:34 INFO Executor: Running task 165.0 in stage 1.0 (TID 446)
[2021-05-14 11:43:34,828] {docker.py:276} INFO - 21/05/14 14:43:34 INFO Executor: Finished task 163.0 in stage 1.0 (TID 444). 1825 bytes result sent to driver
[2021-05-14 11:43:34,829] {docker.py:276} INFO - 21/05/14 14:43:34 INFO TaskSetManager: Starting task 166.0 in stage 1.0 (TID 447) (f0b8ef7ba22f, executor driver, partition 166, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:34,830] {docker.py:276} INFO - 21/05/14 14:43:34 INFO Executor: Running task 166.0 in stage 1.0 (TID 447)
21/05/14 14:43:34 INFO TaskSetManager: Finished task 163.0 in stage 1.0 (TID 444) in 174 ms on f0b8ef7ba22f (executor driver) (163/281)
[2021-05-14 11:43:34,922] {docker.py:276} INFO - 21/05/14 14:43:34 INFO Executor: Finished task 164.0 in stage 1.0 (TID 445). 1825 bytes result sent to driver
[2021-05-14 11:43:34,923] {docker.py:276} INFO - 21/05/14 14:43:34 INFO TaskSetManager: Starting task 167.0 in stage 1.0 (TID 448) (f0b8ef7ba22f, executor driver, partition 167, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:34,924] {docker.py:276} INFO - 21/05/14 14:43:34 INFO TaskSetManager: Finished task 164.0 in stage 1.0 (TID 445) in 173 ms on f0b8ef7ba22f (executor driver) (164/281)
[2021-05-14 11:43:34,926] {docker.py:276} INFO - 21/05/14 14:43:34 INFO Executor: Running task 167.0 in stage 1.0 (TID 448)
[2021-05-14 11:43:34,996] {docker.py:276} INFO - 21/05/14 14:43:35 INFO Executor: Finished task 160.0 in stage 1.0 (TID 441). 1825 bytes result sent to driver
[2021-05-14 11:43:34,997] {docker.py:276} INFO - 21/05/14 14:43:35 INFO Executor: Finished task 165.0 in stage 1.0 (TID 446). 1825 bytes result sent to driver
[2021-05-14 11:43:34,998] {docker.py:276} INFO - 21/05/14 14:43:35 INFO TaskSetManager: Starting task 168.0 in stage 1.0 (TID 449) (f0b8ef7ba22f, executor driver, partition 168, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:34,999] {docker.py:276} INFO - 21/05/14 14:43:35 INFO Executor: Finished task 166.0 in stage 1.0 (TID 447). 1825 bytes result sent to driver
[2021-05-14 11:43:35,000] {docker.py:276} INFO - 21/05/14 14:43:35 INFO Executor: Running task 168.0 in stage 1.0 (TID 449)
21/05/14 14:43:35 INFO TaskSetManager: Starting task 169.0 in stage 1.0 (TID 450) (f0b8ef7ba22f, executor driver, partition 169, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:35,001] {docker.py:276} INFO - 21/05/14 14:43:35 INFO TaskSetManager: Finished task 165.0 in stage 1.0 (TID 446) in 188 ms on f0b8ef7ba22f (executor driver) (165/281)
[2021-05-14 11:43:35,002] {docker.py:276} INFO - 21/05/14 14:43:35 INFO TaskSetManager: Starting task 170.0 in stage 1.0 (TID 451) (f0b8ef7ba22f, executor driver, partition 170, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:35,003] {docker.py:276} INFO - 21/05/14 14:43:35 INFO Executor: Running task 169.0 in stage 1.0 (TID 450)
[2021-05-14 11:43:35,003] {docker.py:276} INFO - 21/05/14 14:43:35 INFO TaskSetManager: Finished task 166.0 in stage 1.0 (TID 447) in 175 ms on f0b8ef7ba22f (executor driver) (166/281)
[2021-05-14 11:43:35,004] {docker.py:276} INFO - 21/05/14 14:43:35 INFO TaskSetManager: Finished task 160.0 in stage 1.0 (TID 441) in 438 ms on f0b8ef7ba22f (executor driver) (167/281)
[2021-05-14 11:43:35,005] {docker.py:276} INFO - 21/05/14 14:43:35 INFO Executor: Running task 170.0 in stage 1.0 (TID 451)
[2021-05-14 11:43:35,097] {docker.py:276} INFO - 21/05/14 14:43:35 INFO Executor: Finished task 167.0 in stage 1.0 (TID 448). 1825 bytes result sent to driver
[2021-05-14 11:43:35,099] {docker.py:276} INFO - 21/05/14 14:43:35 INFO TaskSetManager: Starting task 171.0 in stage 1.0 (TID 452) (f0b8ef7ba22f, executor driver, partition 171, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:35,100] {docker.py:276} INFO - 21/05/14 14:43:35 INFO TaskSetManager: Finished task 167.0 in stage 1.0 (TID 448) in 178 ms on f0b8ef7ba22f (executor driver) (168/281)
[2021-05-14 11:43:35,101] {docker.py:276} INFO - 21/05/14 14:43:35 INFO Executor: Running task 171.0 in stage 1.0 (TID 452)
[2021-05-14 11:43:35,174] {docker.py:276} INFO - 21/05/14 14:43:35 INFO Executor: Finished task 168.0 in stage 1.0 (TID 449). 1868 bytes result sent to driver
[2021-05-14 11:43:35,176] {docker.py:276} INFO - 21/05/14 14:43:35 INFO TaskSetManager: Starting task 172.0 in stage 1.0 (TID 453) (f0b8ef7ba22f, executor driver, partition 172, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:35,178] {docker.py:276} INFO - 21/05/14 14:43:35 INFO TaskSetManager: Finished task 168.0 in stage 1.0 (TID 449) in 179 ms on f0b8ef7ba22f (executor driver) (169/281)
[2021-05-14 11:43:35,179] {docker.py:276} INFO - 21/05/14 14:43:35 INFO Executor: Running task 172.0 in stage 1.0 (TID 453)
[2021-05-14 11:43:35,180] {docker.py:276} INFO - 21/05/14 14:43:35 INFO Executor: Finished task 170.0 in stage 1.0 (TID 451). 1868 bytes result sent to driver
[2021-05-14 11:43:35,181] {docker.py:276} INFO - 21/05/14 14:43:35 INFO TaskSetManager: Starting task 173.0 in stage 1.0 (TID 454) (f0b8ef7ba22f, executor driver, partition 173, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:35,182] {docker.py:276} INFO - 21/05/14 14:43:35 INFO TaskSetManager: Finished task 170.0 in stage 1.0 (TID 451) in 181 ms on f0b8ef7ba22f (executor driver) (170/281)
[2021-05-14 11:43:35,182] {docker.py:276} INFO - 21/05/14 14:43:35 INFO Executor: Running task 173.0 in stage 1.0 (TID 454)
[2021-05-14 11:43:35,183] {docker.py:276} INFO - 21/05/14 14:43:35 INFO Executor: Finished task 169.0 in stage 1.0 (TID 450). 1868 bytes result sent to driver
[2021-05-14 11:43:35,184] {docker.py:276} INFO - 21/05/14 14:43:35 INFO TaskSetManager: Starting task 174.0 in stage 1.0 (TID 455) (f0b8ef7ba22f, executor driver, partition 174, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:35,185] {docker.py:276} INFO - 21/05/14 14:43:35 INFO Executor: Running task 174.0 in stage 1.0 (TID 455)
[2021-05-14 11:43:35,185] {docker.py:276} INFO - 21/05/14 14:43:35 INFO TaskSetManager: Finished task 169.0 in stage 1.0 (TID 450) in 186 ms on f0b8ef7ba22f (executor driver) (171/281)
[2021-05-14 11:43:35,286] {docker.py:276} INFO - 21/05/14 14:43:35 INFO Executor: Finished task 171.0 in stage 1.0 (TID 452). 1868 bytes result sent to driver
[2021-05-14 11:43:35,288] {docker.py:276} INFO - 21/05/14 14:43:35 INFO TaskSetManager: Starting task 175.0 in stage 1.0 (TID 456) (f0b8ef7ba22f, executor driver, partition 175, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:35,289] {docker.py:276} INFO - 21/05/14 14:43:35 INFO TaskSetManager: Finished task 171.0 in stage 1.0 (TID 452) in 191 ms on f0b8ef7ba22f (executor driver) (172/281)
21/05/14 14:43:35 INFO Executor: Running task 175.0 in stage 1.0 (TID 456)
[2021-05-14 11:43:35,360] {docker.py:276} INFO - 21/05/14 14:43:35 INFO Executor: Finished task 173.0 in stage 1.0 (TID 454). 1825 bytes result sent to driver
[2021-05-14 11:43:35,361] {docker.py:276} INFO - 21/05/14 14:43:35 INFO TaskSetManager: Starting task 176.0 in stage 1.0 (TID 457) (f0b8ef7ba22f, executor driver, partition 176, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:35,362] {docker.py:276} INFO - 21/05/14 14:43:35 INFO TaskSetManager: Finished task 173.0 in stage 1.0 (TID 454) in 178 ms on f0b8ef7ba22f (executor driver) (173/281)
[2021-05-14 11:43:35,363] {docker.py:276} INFO - 21/05/14 14:43:35 INFO Executor: Finished task 174.0 in stage 1.0 (TID 455). 1825 bytes result sent to driver
[2021-05-14 11:43:35,364] {docker.py:276} INFO - 21/05/14 14:43:35 INFO Executor: Running task 176.0 in stage 1.0 (TID 457)
[2021-05-14 11:43:35,365] {docker.py:276} INFO - 21/05/14 14:43:35 INFO TaskSetManager: Starting task 177.0 in stage 1.0 (TID 458) (f0b8ef7ba22f, executor driver, partition 177, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:35,366] {docker.py:276} INFO - 21/05/14 14:43:35 INFO Executor: Running task 177.0 in stage 1.0 (TID 458)
[2021-05-14 11:43:35,366] {docker.py:276} INFO - 21/05/14 14:43:35 INFO TaskSetManager: Finished task 174.0 in stage 1.0 (TID 455) in 181 ms on f0b8ef7ba22f (executor driver) (174/281)
[2021-05-14 11:43:35,367] {docker.py:276} INFO - 21/05/14 14:43:35 INFO Executor: Finished task 172.0 in stage 1.0 (TID 453). 1825 bytes result sent to driver
[2021-05-14 11:43:35,368] {docker.py:276} INFO - 21/05/14 14:43:35 INFO TaskSetManager: Starting task 178.0 in stage 1.0 (TID 459) (f0b8ef7ba22f, executor driver, partition 178, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:35,369] {docker.py:276} INFO - 21/05/14 14:43:35 INFO TaskSetManager: Finished task 172.0 in stage 1.0 (TID 453) in 194 ms on f0b8ef7ba22f (executor driver) (175/281)
[2021-05-14 11:43:35,370] {docker.py:276} INFO - 21/05/14 14:43:35 INFO Executor: Running task 178.0 in stage 1.0 (TID 459)
[2021-05-14 11:43:35,460] {docker.py:276} INFO - 21/05/14 14:43:35 INFO Executor: Finished task 175.0 in stage 1.0 (TID 456). 1825 bytes result sent to driver
[2021-05-14 11:43:35,462] {docker.py:276} INFO - 21/05/14 14:43:35 INFO TaskSetManager: Starting task 179.0 in stage 1.0 (TID 460) (f0b8ef7ba22f, executor driver, partition 179, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:35,464] {docker.py:276} INFO - 21/05/14 14:43:35 INFO TaskSetManager: Finished task 175.0 in stage 1.0 (TID 456) in 176 ms on f0b8ef7ba22f (executor driver) (176/281)
[2021-05-14 11:43:35,465] {docker.py:276} INFO - 21/05/14 14:43:35 INFO Executor: Running task 179.0 in stage 1.0 (TID 460)
[2021-05-14 11:43:35,540] {docker.py:276} INFO - 21/05/14 14:43:35 INFO Executor: Finished task 176.0 in stage 1.0 (TID 457). 1825 bytes result sent to driver
[2021-05-14 11:43:35,541] {docker.py:276} INFO - 21/05/14 14:43:35 INFO TaskSetManager: Starting task 180.0 in stage 1.0 (TID 461) (f0b8ef7ba22f, executor driver, partition 180, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:35,543] {docker.py:276} INFO - 21/05/14 14:43:35 INFO TaskSetManager: Finished task 176.0 in stage 1.0 (TID 457) in 184 ms on f0b8ef7ba22f (executor driver) (177/281)
21/05/14 14:43:35 INFO Executor: Running task 180.0 in stage 1.0 (TID 461)
[2021-05-14 11:43:35,552] {docker.py:276} INFO - 21/05/14 14:43:35 INFO Executor: Finished task 178.0 in stage 1.0 (TID 459). 1825 bytes result sent to driver
[2021-05-14 11:43:35,553] {docker.py:276} INFO - 21/05/14 14:43:35 INFO Executor: Finished task 177.0 in stage 1.0 (TID 458). 1825 bytes result sent to driver
[2021-05-14 11:43:35,554] {docker.py:276} INFO - 21/05/14 14:43:35 INFO TaskSetManager: Starting task 181.0 in stage 1.0 (TID 462) (f0b8ef7ba22f, executor driver, partition 181, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:35,555] {docker.py:276} INFO - 21/05/14 14:43:35 INFO Executor: Running task 181.0 in stage 1.0 (TID 462)
21/05/14 14:43:35 INFO TaskSetManager: Starting task 182.0 in stage 1.0 (TID 463) (f0b8ef7ba22f, executor driver, partition 182, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:35,556] {docker.py:276} INFO - 21/05/14 14:43:35 INFO TaskSetManager: Finished task 177.0 in stage 1.0 (TID 458) in 193 ms on f0b8ef7ba22f (executor driver) (178/281)
[2021-05-14 11:43:35,557] {docker.py:276} INFO - 21/05/14 14:43:35 INFO Executor: Running task 182.0 in stage 1.0 (TID 463)
[2021-05-14 11:43:35,557] {docker.py:276} INFO - 21/05/14 14:43:35 INFO TaskSetManager: Finished task 178.0 in stage 1.0 (TID 459) in 189 ms on f0b8ef7ba22f (executor driver) (179/281)
[2021-05-14 11:43:35,638] {docker.py:276} INFO - 21/05/14 14:43:35 INFO Executor: Finished task 179.0 in stage 1.0 (TID 460). 1825 bytes result sent to driver
[2021-05-14 11:43:35,640] {docker.py:276} INFO - 21/05/14 14:43:35 INFO TaskSetManager: Starting task 183.0 in stage 1.0 (TID 464) (f0b8ef7ba22f, executor driver, partition 183, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:35,641] {docker.py:276} INFO - 21/05/14 14:43:35 INFO Executor: Running task 183.0 in stage 1.0 (TID 464)
[2021-05-14 11:43:35,641] {docker.py:276} INFO - 21/05/14 14:43:35 INFO TaskSetManager: Finished task 179.0 in stage 1.0 (TID 460) in 179 ms on f0b8ef7ba22f (executor driver) (180/281)
[2021-05-14 11:43:35,725] {docker.py:276} INFO - 21/05/14 14:43:35 INFO Executor: Finished task 180.0 in stage 1.0 (TID 461). 1825 bytes result sent to driver
[2021-05-14 11:43:35,727] {docker.py:276} INFO - 21/05/14 14:43:35 INFO TaskSetManager: Starting task 184.0 in stage 1.0 (TID 465) (f0b8ef7ba22f, executor driver, partition 184, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:35,728] {docker.py:276} INFO - 21/05/14 14:43:35 INFO Executor: Running task 184.0 in stage 1.0 (TID 465)
[2021-05-14 11:43:35,728] {docker.py:276} INFO - 21/05/14 14:43:35 INFO Executor: Finished task 182.0 in stage 1.0 (TID 463). 1825 bytes result sent to driver
[2021-05-14 11:43:35,729] {docker.py:276} INFO - 21/05/14 14:43:35 INFO TaskSetManager: Finished task 180.0 in stage 1.0 (TID 461) in 188 ms on f0b8ef7ba22f (executor driver) (181/281)
[2021-05-14 11:43:35,730] {docker.py:276} INFO - 21/05/14 14:43:35 INFO TaskSetManager: Starting task 185.0 in stage 1.0 (TID 466) (f0b8ef7ba22f, executor driver, partition 185, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:35,731] {docker.py:276} INFO - 21/05/14 14:43:35 INFO TaskSetManager: Finished task 182.0 in stage 1.0 (TID 463) in 176 ms on f0b8ef7ba22f (executor driver) (182/281)
[2021-05-14 11:43:35,732] {docker.py:276} INFO - 21/05/14 14:43:35 INFO Executor: Running task 185.0 in stage 1.0 (TID 466)
[2021-05-14 11:43:35,733] {docker.py:276} INFO - 21/05/14 14:43:35 INFO Executor: Finished task 181.0 in stage 1.0 (TID 462). 1825 bytes result sent to driver
[2021-05-14 11:43:35,735] {docker.py:276} INFO - 21/05/14 14:43:35 INFO TaskSetManager: Starting task 186.0 in stage 1.0 (TID 467) (f0b8ef7ba22f, executor driver, partition 186, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:35,736] {docker.py:276} INFO - 21/05/14 14:43:35 INFO TaskSetManager: Finished task 181.0 in stage 1.0 (TID 462) in 182 ms on f0b8ef7ba22f (executor driver) (183/281)
[2021-05-14 11:43:35,736] {docker.py:276} INFO - 21/05/14 14:43:35 INFO Executor: Running task 186.0 in stage 1.0 (TID 467)
[2021-05-14 11:43:35,819] {docker.py:276} INFO - 21/05/14 14:43:35 INFO Executor: Finished task 183.0 in stage 1.0 (TID 464). 1825 bytes result sent to driver
[2021-05-14 11:43:35,821] {docker.py:276} INFO - 21/05/14 14:43:35 INFO TaskSetManager: Starting task 187.0 in stage 1.0 (TID 468) (f0b8ef7ba22f, executor driver, partition 187, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:35,821] {docker.py:276} INFO - 21/05/14 14:43:35 INFO Executor: Running task 187.0 in stage 1.0 (TID 468)
[2021-05-14 11:43:35,822] {docker.py:276} INFO - 21/05/14 14:43:35 INFO TaskSetManager: Finished task 183.0 in stage 1.0 (TID 464) in 183 ms on f0b8ef7ba22f (executor driver) (184/281)
[2021-05-14 11:43:35,902] {docker.py:276} INFO - 21/05/14 14:43:35 INFO Executor: Finished task 186.0 in stage 1.0 (TID 467). 1868 bytes result sent to driver
[2021-05-14 11:43:35,903] {docker.py:276} INFO - 21/05/14 14:43:35 INFO TaskSetManager: Starting task 188.0 in stage 1.0 (TID 469) (f0b8ef7ba22f, executor driver, partition 188, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:35,904] {docker.py:276} INFO - 21/05/14 14:43:35 INFO Executor: Running task 188.0 in stage 1.0 (TID 469)
21/05/14 14:43:35 INFO TaskSetManager: Finished task 186.0 in stage 1.0 (TID 467) in 170 ms on f0b8ef7ba22f (executor driver) (185/281)
[2021-05-14 11:43:35,905] {docker.py:276} INFO - 21/05/14 14:43:35 INFO Executor: Finished task 185.0 in stage 1.0 (TID 466). 1868 bytes result sent to driver
[2021-05-14 11:43:35,906] {docker.py:276} INFO - 21/05/14 14:43:35 INFO TaskSetManager: Starting task 189.0 in stage 1.0 (TID 470) (f0b8ef7ba22f, executor driver, partition 189, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:35,907] {docker.py:276} INFO - 21/05/14 14:43:35 INFO Executor: Running task 189.0 in stage 1.0 (TID 470)
[2021-05-14 11:43:35,908] {docker.py:276} INFO - 21/05/14 14:43:35 INFO TaskSetManager: Finished task 185.0 in stage 1.0 (TID 466) in 179 ms on f0b8ef7ba22f (executor driver) (186/281)
[2021-05-14 11:43:35,913] {docker.py:276} INFO - 21/05/14 14:43:35 INFO Executor: Finished task 184.0 in stage 1.0 (TID 465). 1868 bytes result sent to driver
[2021-05-14 11:43:35,914] {docker.py:276} INFO - 21/05/14 14:43:35 INFO TaskSetManager: Starting task 190.0 in stage 1.0 (TID 471) (f0b8ef7ba22f, executor driver, partition 190, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:35,915] {docker.py:276} INFO - 21/05/14 14:43:35 INFO TaskSetManager: Finished task 184.0 in stage 1.0 (TID 465) in 190 ms on f0b8ef7ba22f (executor driver) (187/281)
[2021-05-14 11:43:35,915] {docker.py:276} INFO - 21/05/14 14:43:35 INFO Executor: Running task 190.0 in stage 1.0 (TID 471)
[2021-05-14 11:43:35,999] {docker.py:276} INFO - 21/05/14 14:43:36 INFO Executor: Finished task 187.0 in stage 1.0 (TID 468). 1868 bytes result sent to driver
[2021-05-14 11:43:36,000] {docker.py:276} INFO - 21/05/14 14:43:36 INFO TaskSetManager: Starting task 191.0 in stage 1.0 (TID 472) (f0b8ef7ba22f, executor driver, partition 191, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:36,001] {docker.py:276} INFO - 21/05/14 14:43:36 INFO Executor: Running task 191.0 in stage 1.0 (TID 472)
[2021-05-14 11:43:36,001] {docker.py:276} INFO - 21/05/14 14:43:36 INFO TaskSetManager: Finished task 187.0 in stage 1.0 (TID 468) in 181 ms on f0b8ef7ba22f (executor driver) (188/281)
[2021-05-14 11:43:36,077] {docker.py:276} INFO - 21/05/14 14:43:36 INFO Executor: Finished task 189.0 in stage 1.0 (TID 470). 1825 bytes result sent to driver
[2021-05-14 11:43:36,079] {docker.py:276} INFO - 21/05/14 14:43:36 INFO TaskSetManager: Starting task 192.0 in stage 1.0 (TID 473) (f0b8ef7ba22f, executor driver, partition 192, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:36,080] {docker.py:276} INFO - 21/05/14 14:43:36 INFO TaskSetManager: Finished task 189.0 in stage 1.0 (TID 470) in 174 ms on f0b8ef7ba22f (executor driver) (189/281)
[2021-05-14 11:43:36,081] {docker.py:276} INFO - 21/05/14 14:43:36 INFO Executor: Running task 192.0 in stage 1.0 (TID 473)
[2021-05-14 11:43:36,083] {docker.py:276} INFO - 21/05/14 14:43:36 INFO Executor: Finished task 188.0 in stage 1.0 (TID 469). 1825 bytes result sent to driver
21/05/14 14:43:36 INFO Executor: Finished task 190.0 in stage 1.0 (TID 471). 1825 bytes result sent to driver
[2021-05-14 11:43:36,084] {docker.py:276} INFO - 21/05/14 14:43:36 INFO TaskSetManager: Starting task 193.0 in stage 1.0 (TID 474) (f0b8ef7ba22f, executor driver, partition 193, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:36,085] {docker.py:276} INFO - 21/05/14 14:43:36 INFO TaskSetManager: Finished task 188.0 in stage 1.0 (TID 469) in 182 ms on f0b8ef7ba22f (executor driver) (190/281)
[2021-05-14 11:43:36,086] {docker.py:276} INFO - 21/05/14 14:43:36 INFO Executor: Running task 193.0 in stage 1.0 (TID 474)
[2021-05-14 11:43:36,087] {docker.py:276} INFO - 21/05/14 14:43:36 INFO TaskSetManager: Starting task 194.0 in stage 1.0 (TID 475) (f0b8ef7ba22f, executor driver, partition 194, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:36,088] {docker.py:276} INFO - 21/05/14 14:43:36 INFO TaskSetManager: Finished task 190.0 in stage 1.0 (TID 471) in 175 ms on f0b8ef7ba22f (executor driver) (191/281)
[2021-05-14 11:43:36,089] {docker.py:276} INFO - 21/05/14 14:43:36 INFO Executor: Running task 194.0 in stage 1.0 (TID 475)
[2021-05-14 11:43:36,177] {docker.py:276} INFO - 21/05/14 14:43:36 INFO Executor: Finished task 191.0 in stage 1.0 (TID 472). 1825 bytes result sent to driver
[2021-05-14 11:43:36,178] {docker.py:276} INFO - 21/05/14 14:43:36 INFO TaskSetManager: Starting task 195.0 in stage 1.0 (TID 476) (f0b8ef7ba22f, executor driver, partition 195, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:36,179] {docker.py:276} INFO - 21/05/14 14:43:36 INFO Executor: Running task 195.0 in stage 1.0 (TID 476)
[2021-05-14 11:43:36,180] {docker.py:276} INFO - 21/05/14 14:43:36 INFO TaskSetManager: Finished task 191.0 in stage 1.0 (TID 472) in 181 ms on f0b8ef7ba22f (executor driver) (192/281)
[2021-05-14 11:43:36,256] {docker.py:276} INFO - 21/05/14 14:43:36 INFO Executor: Finished task 193.0 in stage 1.0 (TID 474). 1825 bytes result sent to driver
[2021-05-14 11:43:36,258] {docker.py:276} INFO - 21/05/14 14:43:36 INFO TaskSetManager: Starting task 196.0 in stage 1.0 (TID 477) (f0b8ef7ba22f, executor driver, partition 196, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:36,259] {docker.py:276} INFO - 21/05/14 14:43:36 INFO Executor: Running task 196.0 in stage 1.0 (TID 477)
[2021-05-14 11:43:36,260] {docker.py:276} INFO - 21/05/14 14:43:36 INFO TaskSetManager: Finished task 193.0 in stage 1.0 (TID 474) in 176 ms on f0b8ef7ba22f (executor driver) (193/281)
[2021-05-14 11:43:36,263] {docker.py:276} INFO - 21/05/14 14:43:36 INFO Executor: Finished task 192.0 in stage 1.0 (TID 473). 1825 bytes result sent to driver
[2021-05-14 11:43:36,264] {docker.py:276} INFO - 21/05/14 14:43:36 INFO TaskSetManager: Starting task 197.0 in stage 1.0 (TID 478) (f0b8ef7ba22f, executor driver, partition 197, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:36,265] {docker.py:276} INFO - 21/05/14 14:43:36 INFO TaskSetManager: Finished task 192.0 in stage 1.0 (TID 473) in 187 ms on f0b8ef7ba22f (executor driver) (194/281)
[2021-05-14 11:43:36,266] {docker.py:276} INFO - 21/05/14 14:43:36 INFO Executor: Running task 197.0 in stage 1.0 (TID 478)
[2021-05-14 11:43:36,268] {docker.py:276} INFO - 21/05/14 14:43:36 INFO Executor: Finished task 194.0 in stage 1.0 (TID 475). 1825 bytes result sent to driver
[2021-05-14 11:43:36,269] {docker.py:276} INFO - 21/05/14 14:43:36 INFO TaskSetManager: Starting task 198.0 in stage 1.0 (TID 479) (f0b8ef7ba22f, executor driver, partition 198, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:36,271] {docker.py:276} INFO - 21/05/14 14:43:36 INFO Executor: Running task 198.0 in stage 1.0 (TID 479)
[2021-05-14 11:43:36,271] {docker.py:276} INFO - 21/05/14 14:43:36 INFO TaskSetManager: Finished task 194.0 in stage 1.0 (TID 475) in 184 ms on f0b8ef7ba22f (executor driver) (195/281)
[2021-05-14 11:43:36,359] {docker.py:276} INFO - 21/05/14 14:43:36 INFO Executor: Finished task 195.0 in stage 1.0 (TID 476). 1825 bytes result sent to driver
[2021-05-14 11:43:36,361] {docker.py:276} INFO - 21/05/14 14:43:36 INFO TaskSetManager: Starting task 199.0 in stage 1.0 (TID 480) (f0b8ef7ba22f, executor driver, partition 199, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:36,362] {docker.py:276} INFO - 21/05/14 14:43:36 INFO TaskSetManager: Finished task 195.0 in stage 1.0 (TID 476) in 185 ms on f0b8ef7ba22f (executor driver) (196/281)
21/05/14 14:43:36 INFO Executor: Running task 199.0 in stage 1.0 (TID 480)
[2021-05-14 11:43:36,438] {docker.py:276} INFO - 21/05/14 14:43:36 INFO Executor: Finished task 197.0 in stage 1.0 (TID 478). 1825 bytes result sent to driver
[2021-05-14 11:43:36,440] {docker.py:276} INFO - 21/05/14 14:43:36 INFO TaskSetManager: Starting task 200.0 in stage 1.0 (TID 481) (f0b8ef7ba22f, executor driver, partition 200, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:36,441] {docker.py:276} INFO - 21/05/14 14:43:36 INFO TaskSetManager: Finished task 197.0 in stage 1.0 (TID 478) in 177 ms on f0b8ef7ba22f (executor driver) (197/281)
[2021-05-14 11:43:36,442] {docker.py:276} INFO - 21/05/14 14:43:36 INFO Executor: Running task 200.0 in stage 1.0 (TID 481)
[2021-05-14 11:43:36,443] {docker.py:276} INFO - 21/05/14 14:43:36 INFO Executor: Finished task 196.0 in stage 1.0 (TID 477). 1825 bytes result sent to driver
[2021-05-14 11:43:36,444] {docker.py:276} INFO - 21/05/14 14:43:36 INFO TaskSetManager: Starting task 201.0 in stage 1.0 (TID 482) (f0b8ef7ba22f, executor driver, partition 201, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:36,445] {docker.py:276} INFO - 21/05/14 14:43:36 INFO TaskSetManager: Finished task 196.0 in stage 1.0 (TID 477) in 187 ms on f0b8ef7ba22f (executor driver) (198/281)
[2021-05-14 11:43:36,448] {docker.py:276} INFO - 21/05/14 14:43:36 INFO Executor: Finished task 198.0 in stage 1.0 (TID 479). 1825 bytes result sent to driver
[2021-05-14 11:43:36,449] {docker.py:276} INFO - 21/05/14 14:43:36 INFO TaskSetManager: Starting task 202.0 in stage 1.0 (TID 483) (f0b8ef7ba22f, executor driver, partition 202, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:36,450] {docker.py:276} INFO - 21/05/14 14:43:36 INFO Executor: Running task 201.0 in stage 1.0 (TID 482)
[2021-05-14 11:43:36,450] {docker.py:276} INFO - 21/05/14 14:43:36 INFO Executor: Running task 202.0 in stage 1.0 (TID 483)
[2021-05-14 11:43:36,451] {docker.py:276} INFO - 21/05/14 14:43:36 INFO TaskSetManager: Finished task 198.0 in stage 1.0 (TID 479) in 182 ms on f0b8ef7ba22f (executor driver) (199/281)
[2021-05-14 11:43:36,553] {docker.py:276} INFO - 21/05/14 14:43:36 INFO Executor: Finished task 199.0 in stage 1.0 (TID 480). 1825 bytes result sent to driver
[2021-05-14 11:43:36,554] {docker.py:276} INFO - 21/05/14 14:43:36 INFO TaskSetManager: Starting task 203.0 in stage 1.0 (TID 484) (f0b8ef7ba22f, executor driver, partition 203, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:36,563] {docker.py:276} INFO - 21/05/14 14:43:36 INFO TaskSetManager: Finished task 199.0 in stage 1.0 (TID 480) in 203 ms on f0b8ef7ba22f (executor driver) (200/281)
21/05/14 14:43:36 INFO Executor: Running task 203.0 in stage 1.0 (TID 484)
[2021-05-14 11:43:36,617] {docker.py:276} INFO - 21/05/14 14:43:36 INFO Executor: Finished task 201.0 in stage 1.0 (TID 482). 1868 bytes result sent to driver
[2021-05-14 11:43:36,618] {docker.py:276} INFO - 21/05/14 14:43:36 INFO TaskSetManager: Starting task 204.0 in stage 1.0 (TID 485) (f0b8ef7ba22f, executor driver, partition 204, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:36,619] {docker.py:276} INFO - 21/05/14 14:43:36 INFO Executor: Finished task 200.0 in stage 1.0 (TID 481). 1868 bytes result sent to driver
[2021-05-14 11:43:36,620] {docker.py:276} INFO - 21/05/14 14:43:36 INFO Executor: Running task 204.0 in stage 1.0 (TID 485)
[2021-05-14 11:43:36,620] {docker.py:276} INFO - 21/05/14 14:43:36 INFO TaskSetManager: Starting task 205.0 in stage 1.0 (TID 486) (f0b8ef7ba22f, executor driver, partition 205, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:36,621] {docker.py:276} INFO - 21/05/14 14:43:36 INFO TaskSetManager: Finished task 200.0 in stage 1.0 (TID 481) in 183 ms on f0b8ef7ba22f (executor driver) (201/281)
[2021-05-14 11:43:36,622] {docker.py:276} INFO - 21/05/14 14:43:36 INFO TaskSetManager: Finished task 201.0 in stage 1.0 (TID 482) in 179 ms on f0b8ef7ba22f (executor driver) (202/281)
[2021-05-14 11:43:36,623] {docker.py:276} INFO - 21/05/14 14:43:36 INFO Executor: Running task 205.0 in stage 1.0 (TID 486)
[2021-05-14 11:43:36,628] {docker.py:276} INFO - 21/05/14 14:43:36 INFO Executor: Finished task 202.0 in stage 1.0 (TID 483). 1868 bytes result sent to driver
[2021-05-14 11:43:36,629] {docker.py:276} INFO - 21/05/14 14:43:36 INFO TaskSetManager: Starting task 206.0 in stage 1.0 (TID 487) (f0b8ef7ba22f, executor driver, partition 206, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:36,630] {docker.py:276} INFO - 21/05/14 14:43:36 INFO TaskSetManager: Finished task 202.0 in stage 1.0 (TID 483) in 182 ms on f0b8ef7ba22f (executor driver) (203/281)
[2021-05-14 11:43:36,630] {docker.py:276} INFO - 21/05/14 14:43:36 INFO Executor: Running task 206.0 in stage 1.0 (TID 487)
[2021-05-14 11:43:36,733] {docker.py:276} INFO - 21/05/14 14:43:36 INFO Executor: Finished task 203.0 in stage 1.0 (TID 484). 1825 bytes result sent to driver
[2021-05-14 11:43:36,734] {docker.py:276} INFO - 21/05/14 14:43:36 INFO TaskSetManager: Starting task 207.0 in stage 1.0 (TID 488) (f0b8ef7ba22f, executor driver, partition 207, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:36,735] {docker.py:276} INFO - 21/05/14 14:43:36 INFO Executor: Running task 207.0 in stage 1.0 (TID 488)
21/05/14 14:43:36 INFO TaskSetManager: Finished task 203.0 in stage 1.0 (TID 484) in 182 ms on f0b8ef7ba22f (executor driver) (204/281)
[2021-05-14 11:43:36,792] {docker.py:276} INFO - 21/05/14 14:43:36 INFO Executor: Finished task 204.0 in stage 1.0 (TID 485). 1825 bytes result sent to driver
[2021-05-14 11:43:36,794] {docker.py:276} INFO - 21/05/14 14:43:36 INFO TaskSetManager: Starting task 208.0 in stage 1.0 (TID 489) (f0b8ef7ba22f, executor driver, partition 208, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:36,795] {docker.py:276} INFO - 21/05/14 14:43:36 INFO Executor: Running task 208.0 in stage 1.0 (TID 489)
[2021-05-14 11:43:36,796] {docker.py:276} INFO - 21/05/14 14:43:36 INFO TaskSetManager: Finished task 204.0 in stage 1.0 (TID 485) in 177 ms on f0b8ef7ba22f (executor driver) (205/281)
[2021-05-14 11:43:36,800] {docker.py:276} INFO - 21/05/14 14:43:36 INFO Executor: Finished task 205.0 in stage 1.0 (TID 486). 1825 bytes result sent to driver
[2021-05-14 11:43:36,800] {docker.py:276} INFO - 21/05/14 14:43:36 INFO Executor: Finished task 206.0 in stage 1.0 (TID 487). 1825 bytes result sent to driver
[2021-05-14 11:43:36,801] {docker.py:276} INFO - 21/05/14 14:43:36 INFO TaskSetManager: Starting task 209.0 in stage 1.0 (TID 490) (f0b8ef7ba22f, executor driver, partition 209, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:36,802] {docker.py:276} INFO - 21/05/14 14:43:36 INFO Executor: Running task 209.0 in stage 1.0 (TID 490)
[2021-05-14 11:43:36,802] {docker.py:276} INFO - 21/05/14 14:43:36 INFO TaskSetManager: Starting task 210.0 in stage 1.0 (TID 491) (f0b8ef7ba22f, executor driver, partition 210, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:36,803] {docker.py:276} INFO - 21/05/14 14:43:36 INFO TaskSetManager: Finished task 206.0 in stage 1.0 (TID 487) in 174 ms on f0b8ef7ba22f (executor driver) (206/281)
[2021-05-14 11:43:36,804] {docker.py:276} INFO - 21/05/14 14:43:36 INFO TaskSetManager: Finished task 205.0 in stage 1.0 (TID 486) in 185 ms on f0b8ef7ba22f (executor driver) (207/281)
[2021-05-14 11:43:36,804] {docker.py:276} INFO - 21/05/14 14:43:36 INFO Executor: Running task 210.0 in stage 1.0 (TID 491)
[2021-05-14 11:43:36,907] {docker.py:276} INFO - 21/05/14 14:43:36 INFO Executor: Finished task 207.0 in stage 1.0 (TID 488). 1825 bytes result sent to driver
[2021-05-14 11:43:36,910] {docker.py:276} INFO - 21/05/14 14:43:36 INFO TaskSetManager: Starting task 211.0 in stage 1.0 (TID 492) (f0b8ef7ba22f, executor driver, partition 211, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:36,912] {docker.py:276} INFO - 21/05/14 14:43:36 INFO Executor: Running task 211.0 in stage 1.0 (TID 492)
[2021-05-14 11:43:36,913] {docker.py:276} INFO - 21/05/14 14:43:36 INFO TaskSetManager: Finished task 207.0 in stage 1.0 (TID 488) in 178 ms on f0b8ef7ba22f (executor driver) (208/281)
[2021-05-14 11:43:36,968] {docker.py:276} INFO - 21/05/14 14:43:37 INFO Executor: Finished task 208.0 in stage 1.0 (TID 489). 1825 bytes result sent to driver
[2021-05-14 11:43:36,969] {docker.py:276} INFO - 21/05/14 14:43:37 INFO TaskSetManager: Starting task 212.0 in stage 1.0 (TID 493) (f0b8ef7ba22f, executor driver, partition 212, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:36,970] {docker.py:276} INFO - 21/05/14 14:43:37 INFO TaskSetManager: Finished task 208.0 in stage 1.0 (TID 489) in 177 ms on f0b8ef7ba22f (executor driver) (209/281)
[2021-05-14 11:43:36,971] {docker.py:276} INFO - 21/05/14 14:43:37 INFO Executor: Running task 212.0 in stage 1.0 (TID 493)
[2021-05-14 11:43:36,972] {docker.py:276} INFO - 21/05/14 14:43:37 INFO Executor: Finished task 210.0 in stage 1.0 (TID 491). 1825 bytes result sent to driver
[2021-05-14 11:43:36,974] {docker.py:276} INFO - 21/05/14 14:43:37 INFO TaskSetManager: Starting task 213.0 in stage 1.0 (TID 494) (f0b8ef7ba22f, executor driver, partition 213, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:36,974] {docker.py:276} INFO - 21/05/14 14:43:37 INFO TaskSetManager: Finished task 210.0 in stage 1.0 (TID 491) in 173 ms on f0b8ef7ba22f (executor driver) (210/281)
[2021-05-14 11:43:36,975] {docker.py:276} INFO - 21/05/14 14:43:37 INFO Executor: Running task 213.0 in stage 1.0 (TID 494)
[2021-05-14 11:43:36,977] {docker.py:276} INFO - 21/05/14 14:43:37 INFO Executor: Finished task 209.0 in stage 1.0 (TID 490). 1825 bytes result sent to driver
[2021-05-14 11:43:36,978] {docker.py:276} INFO - 21/05/14 14:43:37 INFO TaskSetManager: Starting task 214.0 in stage 1.0 (TID 495) (f0b8ef7ba22f, executor driver, partition 214, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:36,978] {docker.py:276} INFO - 21/05/14 14:43:37 INFO TaskSetManager: Finished task 209.0 in stage 1.0 (TID 490) in 178 ms on f0b8ef7ba22f (executor driver) (211/281)
[2021-05-14 11:43:36,979] {docker.py:276} INFO - 21/05/14 14:43:37 INFO Executor: Running task 214.0 in stage 1.0 (TID 495)
[2021-05-14 11:43:37,104] {docker.py:276} INFO - 21/05/14 14:43:37 INFO Executor: Finished task 211.0 in stage 1.0 (TID 492). 1825 bytes result sent to driver
[2021-05-14 11:43:37,106] {docker.py:276} INFO - 21/05/14 14:43:37 INFO TaskSetManager: Starting task 215.0 in stage 1.0 (TID 496) (f0b8ef7ba22f, executor driver, partition 215, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:37,107] {docker.py:276} INFO - 21/05/14 14:43:37 INFO Executor: Running task 215.0 in stage 1.0 (TID 496)
[2021-05-14 11:43:37,108] {docker.py:276} INFO - 21/05/14 14:43:37 INFO TaskSetManager: Finished task 211.0 in stage 1.0 (TID 492) in 199 ms on f0b8ef7ba22f (executor driver) (212/281)
[2021-05-14 11:43:37,151] {docker.py:276} INFO - 21/05/14 14:43:37 INFO Executor: Finished task 213.0 in stage 1.0 (TID 494). 1825 bytes result sent to driver
[2021-05-14 11:43:37,153] {docker.py:276} INFO - 21/05/14 14:43:37 INFO TaskSetManager: Starting task 216.0 in stage 1.0 (TID 497) (f0b8ef7ba22f, executor driver, partition 216, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:37,154] {docker.py:276} INFO - 21/05/14 14:43:37 INFO TaskSetManager: Finished task 213.0 in stage 1.0 (TID 494) in 181 ms on f0b8ef7ba22f (executor driver) (213/281)
[2021-05-14 11:43:37,155] {docker.py:276} INFO - 21/05/14 14:43:37 INFO Executor: Running task 216.0 in stage 1.0 (TID 497)
[2021-05-14 11:43:37,158] {docker.py:276} INFO - 21/05/14 14:43:37 INFO Executor: Finished task 214.0 in stage 1.0 (TID 495). 1825 bytes result sent to driver
[2021-05-14 11:43:37,159] {docker.py:276} INFO - 21/05/14 14:43:37 INFO Executor: Finished task 212.0 in stage 1.0 (TID 493). 1825 bytes result sent to driver
[2021-05-14 11:43:37,160] {docker.py:276} INFO - 21/05/14 14:43:37 INFO TaskSetManager: Starting task 217.0 in stage 1.0 (TID 498) (f0b8ef7ba22f, executor driver, partition 217, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:37,161] {docker.py:276} INFO - 21/05/14 14:43:37 INFO TaskSetManager: Finished task 214.0 in stage 1.0 (TID 495) in 183 ms on f0b8ef7ba22f (executor driver) (214/281)
[2021-05-14 11:43:37,161] {docker.py:276} INFO - 21/05/14 14:43:37 INFO TaskSetManager: Finished task 212.0 in stage 1.0 (TID 493) in 192 ms on f0b8ef7ba22f (executor driver) (215/281)
[2021-05-14 11:43:37,162] {docker.py:276} INFO - 21/05/14 14:43:37 INFO Executor: Running task 217.0 in stage 1.0 (TID 498)
[2021-05-14 11:43:37,163] {docker.py:276} INFO - 21/05/14 14:43:37 INFO TaskSetManager: Starting task 218.0 in stage 1.0 (TID 499) (f0b8ef7ba22f, executor driver, partition 218, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:37,165] {docker.py:276} INFO - 21/05/14 14:43:37 INFO Executor: Running task 218.0 in stage 1.0 (TID 499)
[2021-05-14 11:43:37,280] {docker.py:276} INFO - 21/05/14 14:43:37 INFO Executor: Finished task 215.0 in stage 1.0 (TID 496). 1868 bytes result sent to driver
[2021-05-14 11:43:37,282] {docker.py:276} INFO - 21/05/14 14:43:37 INFO TaskSetManager: Starting task 219.0 in stage 1.0 (TID 500) (f0b8ef7ba22f, executor driver, partition 219, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:37,283] {docker.py:276} INFO - 21/05/14 14:43:37 INFO Executor: Running task 219.0 in stage 1.0 (TID 500)
[2021-05-14 11:43:37,284] {docker.py:276} INFO - 21/05/14 14:43:37 INFO TaskSetManager: Finished task 215.0 in stage 1.0 (TID 496) in 177 ms on f0b8ef7ba22f (executor driver) (216/281)
[2021-05-14 11:43:37,333] {docker.py:276} INFO - 21/05/14 14:43:37 INFO Executor: Finished task 217.0 in stage 1.0 (TID 498). 1868 bytes result sent to driver
[2021-05-14 11:43:37,335] {docker.py:276} INFO - 21/05/14 14:43:37 INFO TaskSetManager: Starting task 220.0 in stage 1.0 (TID 501) (f0b8ef7ba22f, executor driver, partition 220, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:37,336] {docker.py:276} INFO - 21/05/14 14:43:37 INFO Executor: Running task 220.0 in stage 1.0 (TID 501)
21/05/14 14:43:37 INFO TaskSetManager: Finished task 217.0 in stage 1.0 (TID 498) in 177 ms on f0b8ef7ba22f (executor driver) (217/281)
[2021-05-14 11:43:37,337] {docker.py:276} INFO - 21/05/14 14:43:37 INFO Executor: Finished task 216.0 in stage 1.0 (TID 497). 1868 bytes result sent to driver
[2021-05-14 11:43:37,338] {docker.py:276} INFO - 21/05/14 14:43:37 INFO TaskSetManager: Starting task 221.0 in stage 1.0 (TID 502) (f0b8ef7ba22f, executor driver, partition 221, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:37,339] {docker.py:276} INFO - 21/05/14 14:43:37 INFO TaskSetManager: Finished task 216.0 in stage 1.0 (TID 497) in 188 ms on f0b8ef7ba22f (executor driver) (218/281)
[2021-05-14 11:43:37,340] {docker.py:276} INFO - 21/05/14 14:43:37 INFO Executor: Running task 221.0 in stage 1.0 (TID 502)
[2021-05-14 11:43:37,347] {docker.py:276} INFO - 21/05/14 14:43:37 INFO Executor: Finished task 218.0 in stage 1.0 (TID 499). 1868 bytes result sent to driver
[2021-05-14 11:43:37,348] {docker.py:276} INFO - 21/05/14 14:43:37 INFO TaskSetManager: Starting task 222.0 in stage 1.0 (TID 503) (f0b8ef7ba22f, executor driver, partition 222, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:37,348] {docker.py:276} INFO - 21/05/14 14:43:37 INFO TaskSetManager: Finished task 218.0 in stage 1.0 (TID 499) in 185 ms on f0b8ef7ba22f (executor driver) (219/281)
[2021-05-14 11:43:37,349] {docker.py:276} INFO - 21/05/14 14:43:37 INFO Executor: Running task 222.0 in stage 1.0 (TID 503)
[2021-05-14 11:43:37,458] {docker.py:276} INFO - 21/05/14 14:43:37 INFO Executor: Finished task 219.0 in stage 1.0 (TID 500). 1825 bytes result sent to driver
[2021-05-14 11:43:37,459] {docker.py:276} INFO - 21/05/14 14:43:37 INFO TaskSetManager: Starting task 223.0 in stage 1.0 (TID 504) (f0b8ef7ba22f, executor driver, partition 223, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:37,460] {docker.py:276} INFO - 21/05/14 14:43:37 INFO Executor: Running task 223.0 in stage 1.0 (TID 504)
[2021-05-14 11:43:37,460] {docker.py:276} INFO - 21/05/14 14:43:37 INFO TaskSetManager: Finished task 219.0 in stage 1.0 (TID 500) in 179 ms on f0b8ef7ba22f (executor driver) (220/281)
[2021-05-14 11:43:37,517] {docker.py:276} INFO - 21/05/14 14:43:37 INFO Executor: Finished task 220.0 in stage 1.0 (TID 501). 1825 bytes result sent to driver
[2021-05-14 11:43:37,518] {docker.py:276} INFO - 21/05/14 14:43:37 INFO TaskSetManager: Starting task 224.0 in stage 1.0 (TID 505) (f0b8ef7ba22f, executor driver, partition 224, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:37,519] {docker.py:276} INFO - 21/05/14 14:43:37 INFO Executor: Running task 224.0 in stage 1.0 (TID 505)
21/05/14 14:43:37 INFO TaskSetManager: Finished task 220.0 in stage 1.0 (TID 501) in 185 ms on f0b8ef7ba22f (executor driver) (221/281)
[2021-05-14 11:43:37,520] {docker.py:276} INFO - 21/05/14 14:43:37 INFO Executor: Finished task 222.0 in stage 1.0 (TID 503). 1825 bytes result sent to driver
[2021-05-14 11:43:37,522] {docker.py:276} INFO - 21/05/14 14:43:37 INFO TaskSetManager: Starting task 225.0 in stage 1.0 (TID 506) (f0b8ef7ba22f, executor driver, partition 225, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:37,522] {docker.py:276} INFO - 21/05/14 14:43:37 INFO Executor: Finished task 221.0 in stage 1.0 (TID 502). 1825 bytes result sent to driver
[2021-05-14 11:43:37,523] {docker.py:276} INFO - 21/05/14 14:43:37 INFO TaskSetManager: Finished task 222.0 in stage 1.0 (TID 503) in 176 ms on f0b8ef7ba22f (executor driver) (222/281)
[2021-05-14 11:43:37,524] {docker.py:276} INFO - 21/05/14 14:43:37 INFO Executor: Running task 225.0 in stage 1.0 (TID 506)
[2021-05-14 11:43:37,525] {docker.py:276} INFO - 21/05/14 14:43:37 INFO TaskSetManager: Starting task 226.0 in stage 1.0 (TID 507) (f0b8ef7ba22f, executor driver, partition 226, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:37,526] {docker.py:276} INFO - 21/05/14 14:43:37 INFO TaskSetManager: Finished task 221.0 in stage 1.0 (TID 502) in 189 ms on f0b8ef7ba22f (executor driver) (223/281)
[2021-05-14 11:43:37,527] {docker.py:276} INFO - 21/05/14 14:43:37 INFO Executor: Running task 226.0 in stage 1.0 (TID 507)
[2021-05-14 11:43:37,634] {docker.py:276} INFO - 21/05/14 14:43:37 INFO Executor: Finished task 223.0 in stage 1.0 (TID 504). 1825 bytes result sent to driver
[2021-05-14 11:43:37,636] {docker.py:276} INFO - 21/05/14 14:43:37 INFO TaskSetManager: Starting task 227.0 in stage 1.0 (TID 508) (f0b8ef7ba22f, executor driver, partition 227, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:37,637] {docker.py:276} INFO - 21/05/14 14:43:37 INFO Executor: Running task 227.0 in stage 1.0 (TID 508)
21/05/14 14:43:37 INFO TaskSetManager: Finished task 223.0 in stage 1.0 (TID 504) in 179 ms on f0b8ef7ba22f (executor driver) (224/281)
[2021-05-14 11:43:37,693] {docker.py:276} INFO - 21/05/14 14:43:37 INFO Executor: Finished task 225.0 in stage 1.0 (TID 506). 1825 bytes result sent to driver
[2021-05-14 11:43:37,695] {docker.py:276} INFO - 21/05/14 14:43:37 INFO TaskSetManager: Starting task 228.0 in stage 1.0 (TID 509) (f0b8ef7ba22f, executor driver, partition 228, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:37,696] {docker.py:276} INFO - 21/05/14 14:43:37 INFO TaskSetManager: Finished task 225.0 in stage 1.0 (TID 506) in 175 ms on f0b8ef7ba22f (executor driver) (225/281)
[2021-05-14 11:43:37,698] {docker.py:276} INFO - 21/05/14 14:43:37 INFO Executor: Running task 228.0 in stage 1.0 (TID 509)
[2021-05-14 11:43:37,703] {docker.py:276} INFO - 21/05/14 14:43:37 INFO Executor: Finished task 226.0 in stage 1.0 (TID 507). 1825 bytes result sent to driver
[2021-05-14 11:43:37,704] {docker.py:276} INFO - 21/05/14 14:43:37 INFO TaskSetManager: Starting task 229.0 in stage 1.0 (TID 510) (f0b8ef7ba22f, executor driver, partition 229, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:37,705] {docker.py:276} INFO - 21/05/14 14:43:37 INFO TaskSetManager: Finished task 226.0 in stage 1.0 (TID 507) in 181 ms on f0b8ef7ba22f (executor driver) (226/281)
[2021-05-14 11:43:37,706] {docker.py:276} INFO - 21/05/14 14:43:37 INFO Executor: Running task 229.0 in stage 1.0 (TID 510)
[2021-05-14 11:43:37,711] {docker.py:276} INFO - 21/05/14 14:43:37 INFO Executor: Finished task 224.0 in stage 1.0 (TID 505). 1825 bytes result sent to driver
[2021-05-14 11:43:37,712] {docker.py:276} INFO - 21/05/14 14:43:37 INFO TaskSetManager: Starting task 230.0 in stage 1.0 (TID 511) (f0b8ef7ba22f, executor driver, partition 230, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:37,713] {docker.py:276} INFO - 21/05/14 14:43:37 INFO TaskSetManager: Finished task 224.0 in stage 1.0 (TID 505) in 197 ms on f0b8ef7ba22f (executor driver) (227/281)
[2021-05-14 11:43:37,714] {docker.py:276} INFO - 21/05/14 14:43:37 INFO Executor: Running task 230.0 in stage 1.0 (TID 511)
[2021-05-14 11:43:37,812] {docker.py:276} INFO - 21/05/14 14:43:37 INFO Executor: Finished task 227.0 in stage 1.0 (TID 508). 1825 bytes result sent to driver
[2021-05-14 11:43:37,815] {docker.py:276} INFO - 21/05/14 14:43:37 INFO TaskSetManager: Starting task 231.0 in stage 1.0 (TID 512) (f0b8ef7ba22f, executor driver, partition 231, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:37,823] {docker.py:276} INFO - 21/05/14 14:43:37 INFO TaskSetManager: Finished task 227.0 in stage 1.0 (TID 508) in 181 ms on f0b8ef7ba22f (executor driver) (228/281)
[2021-05-14 11:43:37,824] {docker.py:276} INFO - 21/05/14 14:43:37 INFO Executor: Running task 231.0 in stage 1.0 (TID 512)
[2021-05-14 11:43:37,879] {docker.py:276} INFO - 21/05/14 14:43:37 INFO Executor: Finished task 229.0 in stage 1.0 (TID 510). 1825 bytes result sent to driver
[2021-05-14 11:43:37,881] {docker.py:276} INFO - 21/05/14 14:43:37 INFO TaskSetManager: Starting task 232.0 in stage 1.0 (TID 513) (f0b8ef7ba22f, executor driver, partition 232, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:37,883] {docker.py:276} INFO - 21/05/14 14:43:37 INFO TaskSetManager: Finished task 229.0 in stage 1.0 (TID 510) in 178 ms on f0b8ef7ba22f (executor driver) (229/281)
[2021-05-14 11:43:37,883] {docker.py:276} INFO - 21/05/14 14:43:37 INFO Executor: Running task 232.0 in stage 1.0 (TID 513)
[2021-05-14 11:43:37,885] {docker.py:276} INFO - 21/05/14 14:43:37 INFO Executor: Finished task 230.0 in stage 1.0 (TID 511). 1825 bytes result sent to driver
[2021-05-14 11:43:37,887] {docker.py:276} INFO - 21/05/14 14:43:37 INFO TaskSetManager: Starting task 233.0 in stage 1.0 (TID 514) (f0b8ef7ba22f, executor driver, partition 233, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:37,887] {docker.py:276} INFO - 21/05/14 14:43:37 INFO TaskSetManager: Finished task 230.0 in stage 1.0 (TID 511) in 175 ms on f0b8ef7ba22f (executor driver) (230/281)
[2021-05-14 11:43:37,889] {docker.py:276} INFO - 21/05/14 14:43:37 INFO Executor: Running task 233.0 in stage 1.0 (TID 514)
[2021-05-14 11:43:37,902] {docker.py:276} INFO - 21/05/14 14:43:37 INFO Executor: Finished task 228.0 in stage 1.0 (TID 509). 1825 bytes result sent to driver
[2021-05-14 11:43:37,903] {docker.py:276} INFO - 21/05/14 14:43:37 INFO TaskSetManager: Starting task 234.0 in stage 1.0 (TID 515) (f0b8ef7ba22f, executor driver, partition 234, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:37,904] {docker.py:276} INFO - 21/05/14 14:43:37 INFO Executor: Running task 234.0 in stage 1.0 (TID 515)
[2021-05-14 11:43:37,905] {docker.py:276} INFO - 21/05/14 14:43:37 INFO TaskSetManager: Finished task 228.0 in stage 1.0 (TID 509) in 211 ms on f0b8ef7ba22f (executor driver) (231/281)
[2021-05-14 11:43:38,021] {docker.py:276} INFO - 21/05/14 14:43:38 INFO Executor: Finished task 231.0 in stage 1.0 (TID 512). 1868 bytes result sent to driver
[2021-05-14 11:43:38,023] {docker.py:276} INFO - 21/05/14 14:43:38 INFO TaskSetManager: Starting task 235.0 in stage 1.0 (TID 516) (f0b8ef7ba22f, executor driver, partition 235, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:38,024] {docker.py:276} INFO - 21/05/14 14:43:38 INFO Executor: Running task 235.0 in stage 1.0 (TID 516)
[2021-05-14 11:43:38,025] {docker.py:276} INFO - 21/05/14 14:43:38 INFO TaskSetManager: Finished task 231.0 in stage 1.0 (TID 512) in 211 ms on f0b8ef7ba22f (executor driver) (232/281)
[2021-05-14 11:43:38,057] {docker.py:276} INFO - 21/05/14 14:43:38 INFO Executor: Finished task 233.0 in stage 1.0 (TID 514). 1868 bytes result sent to driver
21/05/14 14:43:38 INFO Executor: Finished task 232.0 in stage 1.0 (TID 513). 1868 bytes result sent to driver
[2021-05-14 11:43:38,058] {docker.py:276} INFO - 21/05/14 14:43:38 INFO TaskSetManager: Starting task 236.0 in stage 1.0 (TID 517) (f0b8ef7ba22f, executor driver, partition 236, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:38,059] {docker.py:276} INFO - 21/05/14 14:43:38 INFO TaskSetManager: Finished task 233.0 in stage 1.0 (TID 514) in 173 ms on f0b8ef7ba22f (executor driver) (233/281)
[2021-05-14 11:43:38,059] {docker.py:276} INFO - 21/05/14 14:43:38 INFO Executor: Running task 236.0 in stage 1.0 (TID 517)
[2021-05-14 11:43:38,060] {docker.py:276} INFO - 21/05/14 14:43:38 INFO TaskSetManager: Starting task 237.0 in stage 1.0 (TID 518) (f0b8ef7ba22f, executor driver, partition 237, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:38,060] {docker.py:276} INFO - 21/05/14 14:43:38 INFO Executor: Running task 237.0 in stage 1.0 (TID 518)
21/05/14 14:43:38 INFO TaskSetManager: Finished task 232.0 in stage 1.0 (TID 513) in 180 ms on f0b8ef7ba22f (executor driver) (234/281)
[2021-05-14 11:43:38,089] {docker.py:276} INFO - 21/05/14 14:43:38 INFO Executor: Finished task 234.0 in stage 1.0 (TID 515). 1868 bytes result sent to driver
[2021-05-14 11:43:38,091] {docker.py:276} INFO - 21/05/14 14:43:38 INFO TaskSetManager: Starting task 238.0 in stage 1.0 (TID 519) (f0b8ef7ba22f, executor driver, partition 238, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:38,092] {docker.py:276} INFO - 21/05/14 14:43:38 INFO Executor: Running task 238.0 in stage 1.0 (TID 519)
[2021-05-14 11:43:38,092] {docker.py:276} INFO - 21/05/14 14:43:38 INFO TaskSetManager: Finished task 234.0 in stage 1.0 (TID 515) in 189 ms on f0b8ef7ba22f (executor driver) (235/281)
[2021-05-14 11:43:38,200] {docker.py:276} INFO - 21/05/14 14:43:38 INFO Executor: Finished task 235.0 in stage 1.0 (TID 516). 1825 bytes result sent to driver
[2021-05-14 11:43:38,201] {docker.py:276} INFO - 21/05/14 14:43:38 INFO TaskSetManager: Starting task 239.0 in stage 1.0 (TID 520) (f0b8ef7ba22f, executor driver, partition 239, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:38,201] {docker.py:276} INFO - 21/05/14 14:43:38 INFO TaskSetManager: Finished task 235.0 in stage 1.0 (TID 516) in 178 ms on f0b8ef7ba22f (executor driver) (236/281)
[2021-05-14 11:43:38,202] {docker.py:276} INFO - 21/05/14 14:43:38 INFO Executor: Running task 239.0 in stage 1.0 (TID 520)
[2021-05-14 11:43:38,230] {docker.py:276} INFO - 21/05/14 14:43:38 INFO Executor: Finished task 236.0 in stage 1.0 (TID 517). 1825 bytes result sent to driver
[2021-05-14 11:43:38,232] {docker.py:276} INFO - 21/05/14 14:43:38 INFO Executor: Finished task 237.0 in stage 1.0 (TID 518). 1825 bytes result sent to driver
[2021-05-14 11:43:38,232] {docker.py:276} INFO - 21/05/14 14:43:38 INFO TaskSetManager: Starting task 240.0 in stage 1.0 (TID 521) (f0b8ef7ba22f, executor driver, partition 240, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:38,233] {docker.py:276} INFO - 21/05/14 14:43:38 INFO Executor: Running task 240.0 in stage 1.0 (TID 521)
[2021-05-14 11:43:38,235] {docker.py:276} INFO - 21/05/14 14:43:38 INFO TaskSetManager: Starting task 241.0 in stage 1.0 (TID 522) (f0b8ef7ba22f, executor driver, partition 241, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:38,235] {docker.py:276} INFO - 21/05/14 14:43:38 INFO Executor: Running task 241.0 in stage 1.0 (TID 522)
[2021-05-14 11:43:38,236] {docker.py:276} INFO - 21/05/14 14:43:38 INFO TaskSetManager: Finished task 236.0 in stage 1.0 (TID 517) in 178 ms on f0b8ef7ba22f (executor driver) (237/281)
[2021-05-14 11:43:38,237] {docker.py:276} INFO - 21/05/14 14:43:38 INFO TaskSetManager: Finished task 237.0 in stage 1.0 (TID 518) in 177 ms on f0b8ef7ba22f (executor driver) (238/281)
[2021-05-14 11:43:38,273] {docker.py:276} INFO - 21/05/14 14:43:38 INFO Executor: Finished task 238.0 in stage 1.0 (TID 519). 1825 bytes result sent to driver
[2021-05-14 11:43:38,274] {docker.py:276} INFO - 21/05/14 14:43:38 INFO TaskSetManager: Starting task 242.0 in stage 1.0 (TID 523) (f0b8ef7ba22f, executor driver, partition 242, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:38,275] {docker.py:276} INFO - 21/05/14 14:43:38 INFO Executor: Running task 242.0 in stage 1.0 (TID 523)
[2021-05-14 11:43:38,275] {docker.py:276} INFO - 21/05/14 14:43:38 INFO TaskSetManager: Finished task 238.0 in stage 1.0 (TID 519) in 184 ms on f0b8ef7ba22f (executor driver) (239/281)
[2021-05-14 11:43:38,374] {docker.py:276} INFO - 21/05/14 14:43:38 INFO Executor: Finished task 239.0 in stage 1.0 (TID 520). 1825 bytes result sent to driver
[2021-05-14 11:43:38,382] {docker.py:276} INFO - 21/05/14 14:43:38 INFO TaskSetManager: Starting task 243.0 in stage 1.0 (TID 524) (f0b8ef7ba22f, executor driver, partition 243, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:38,383] {docker.py:276} INFO - 21/05/14 14:43:38 INFO TaskSetManager: Finished task 239.0 in stage 1.0 (TID 520) in 177 ms on f0b8ef7ba22f (executor driver) (240/281)
21/05/14 14:43:38 INFO Executor: Running task 243.0 in stage 1.0 (TID 524)
[2021-05-14 11:43:38,406] {docker.py:276} INFO - 21/05/14 14:43:38 INFO Executor: Finished task 241.0 in stage 1.0 (TID 522). 1825 bytes result sent to driver
[2021-05-14 11:43:38,407] {docker.py:276} INFO - 21/05/14 14:43:38 INFO TaskSetManager: Starting task 244.0 in stage 1.0 (TID 525) (f0b8ef7ba22f, executor driver, partition 244, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:38,408] {docker.py:276} INFO - 21/05/14 14:43:38 INFO Executor: Running task 244.0 in stage 1.0 (TID 525)
[2021-05-14 11:43:38,410] {docker.py:276} INFO - 21/05/14 14:43:38 INFO TaskSetManager: Finished task 241.0 in stage 1.0 (TID 522) in 176 ms on f0b8ef7ba22f (executor driver) (241/281)
[2021-05-14 11:43:38,411] {docker.py:276} INFO - 21/05/14 14:43:38 INFO Executor: Finished task 240.0 in stage 1.0 (TID 521). 1825 bytes result sent to driver
[2021-05-14 11:43:38,413] {docker.py:276} INFO - 21/05/14 14:43:38 INFO TaskSetManager: Starting task 245.0 in stage 1.0 (TID 526) (f0b8ef7ba22f, executor driver, partition 245, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:38,414] {docker.py:276} INFO - 21/05/14 14:43:38 INFO Executor: Running task 245.0 in stage 1.0 (TID 526)
21/05/14 14:43:38 INFO TaskSetManager: Finished task 240.0 in stage 1.0 (TID 521) in 183 ms on f0b8ef7ba22f (executor driver) (242/281)
[2021-05-14 11:43:38,455] {docker.py:276} INFO - 21/05/14 14:43:38 INFO Executor: Finished task 242.0 in stage 1.0 (TID 523). 1825 bytes result sent to driver
[2021-05-14 11:43:38,456] {docker.py:276} INFO - 21/05/14 14:43:38 INFO TaskSetManager: Starting task 246.0 in stage 1.0 (TID 527) (f0b8ef7ba22f, executor driver, partition 246, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:38,457] {docker.py:276} INFO - 21/05/14 14:43:38 INFO TaskSetManager: Finished task 242.0 in stage 1.0 (TID 523) in 183 ms on f0b8ef7ba22f (executor driver) (243/281)
[2021-05-14 11:43:38,458] {docker.py:276} INFO - 21/05/14 14:43:38 INFO Executor: Running task 246.0 in stage 1.0 (TID 527)
[2021-05-14 11:43:38,551] {docker.py:276} INFO - 21/05/14 14:43:38 INFO Executor: Finished task 243.0 in stage 1.0 (TID 524). 1825 bytes result sent to driver
[2021-05-14 11:43:38,554] {docker.py:276} INFO - 21/05/14 14:43:38 INFO TaskSetManager: Starting task 247.0 in stage 1.0 (TID 528) (f0b8ef7ba22f, executor driver, partition 247, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:38,555] {docker.py:276} INFO - 21/05/14 14:43:38 INFO TaskSetManager: Finished task 243.0 in stage 1.0 (TID 524) in 179 ms on f0b8ef7ba22f (executor driver) (244/281)
[2021-05-14 11:43:38,555] {docker.py:276} INFO - 21/05/14 14:43:38 INFO Executor: Running task 247.0 in stage 1.0 (TID 528)
[2021-05-14 11:43:38,579] {docker.py:276} INFO - 21/05/14 14:43:38 INFO Executor: Finished task 245.0 in stage 1.0 (TID 526). 1825 bytes result sent to driver
[2021-05-14 11:43:38,581] {docker.py:276} INFO - 21/05/14 14:43:38 INFO TaskSetManager: Starting task 248.0 in stage 1.0 (TID 529) (f0b8ef7ba22f, executor driver, partition 248, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:38,582] {docker.py:276} INFO - 21/05/14 14:43:38 INFO TaskSetManager: Finished task 245.0 in stage 1.0 (TID 526) in 170 ms on f0b8ef7ba22f (executor driver) (245/281)
21/05/14 14:43:38 INFO Executor: Running task 248.0 in stage 1.0 (TID 529)
[2021-05-14 11:43:38,586] {docker.py:276} INFO - 21/05/14 14:43:38 INFO Executor: Finished task 244.0 in stage 1.0 (TID 525). 1825 bytes result sent to driver
[2021-05-14 11:43:38,588] {docker.py:276} INFO - 21/05/14 14:43:38 INFO TaskSetManager: Starting task 249.0 in stage 1.0 (TID 530) (f0b8ef7ba22f, executor driver, partition 249, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:38,588] {docker.py:276} INFO - 21/05/14 14:43:38 INFO TaskSetManager: Finished task 244.0 in stage 1.0 (TID 525) in 182 ms on f0b8ef7ba22f (executor driver) (246/281)
21/05/14 14:43:38 INFO Executor: Running task 249.0 in stage 1.0 (TID 530)
[2021-05-14 11:43:38,631] {docker.py:276} INFO - 21/05/14 14:43:38 INFO Executor: Finished task 246.0 in stage 1.0 (TID 527). 1825 bytes result sent to driver
[2021-05-14 11:43:38,638] {docker.py:276} INFO - 21/05/14 14:43:38 INFO TaskSetManager: Starting task 250.0 in stage 1.0 (TID 531) (f0b8ef7ba22f, executor driver, partition 250, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:38,639] {docker.py:276} INFO - 21/05/14 14:43:38 INFO TaskSetManager: Finished task 246.0 in stage 1.0 (TID 527) in 179 ms on f0b8ef7ba22f (executor driver) (247/281)
[2021-05-14 11:43:38,639] {docker.py:276} INFO - 21/05/14 14:43:38 INFO Executor: Running task 250.0 in stage 1.0 (TID 531)
[2021-05-14 11:43:38,720] {docker.py:276} INFO - 21/05/14 14:43:38 INFO Executor: Finished task 247.0 in stage 1.0 (TID 528). 1868 bytes result sent to driver
[2021-05-14 11:43:38,721] {docker.py:276} INFO - 21/05/14 14:43:38 INFO TaskSetManager: Starting task 251.0 in stage 1.0 (TID 532) (f0b8ef7ba22f, executor driver, partition 251, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:38,721] {docker.py:276} INFO - 21/05/14 14:43:38 INFO Executor: Running task 251.0 in stage 1.0 (TID 532)
[2021-05-14 11:43:38,722] {docker.py:276} INFO - 21/05/14 14:43:38 INFO TaskSetManager: Finished task 247.0 in stage 1.0 (TID 528) in 170 ms on f0b8ef7ba22f (executor driver) (248/281)
[2021-05-14 11:43:38,755] {docker.py:276} INFO - 21/05/14 14:43:38 INFO Executor: Finished task 248.0 in stage 1.0 (TID 529). 1868 bytes result sent to driver
21/05/14 14:43:38 INFO Executor: Finished task 249.0 in stage 1.0 (TID 530). 1868 bytes result sent to driver
[2021-05-14 11:43:38,757] {docker.py:276} INFO - 21/05/14 14:43:38 INFO TaskSetManager: Starting task 252.0 in stage 1.0 (TID 533) (f0b8ef7ba22f, executor driver, partition 252, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:38,758] {docker.py:276} INFO - 21/05/14 14:43:38 INFO Executor: Running task 252.0 in stage 1.0 (TID 533)
[2021-05-14 11:43:38,759] {docker.py:276} INFO - 21/05/14 14:43:38 INFO TaskSetManager: Starting task 253.0 in stage 1.0 (TID 534) (f0b8ef7ba22f, executor driver, partition 253, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:38,760] {docker.py:276} INFO - 21/05/14 14:43:38 INFO TaskSetManager: Finished task 249.0 in stage 1.0 (TID 530) in 172 ms on f0b8ef7ba22f (executor driver) (249/281)
[2021-05-14 11:43:38,760] {docker.py:276} INFO - 21/05/14 14:43:38 INFO TaskSetManager: Finished task 248.0 in stage 1.0 (TID 529) in 180 ms on f0b8ef7ba22f (executor driver) (250/281)
[2021-05-14 11:43:38,761] {docker.py:276} INFO - 21/05/14 14:43:38 INFO Executor: Running task 253.0 in stage 1.0 (TID 534)
[2021-05-14 11:43:38,833] {docker.py:276} INFO - 21/05/14 14:43:38 INFO Executor: Finished task 250.0 in stage 1.0 (TID 531). 1868 bytes result sent to driver
[2021-05-14 11:43:38,834] {docker.py:276} INFO - 21/05/14 14:43:38 INFO TaskSetManager: Starting task 254.0 in stage 1.0 (TID 535) (f0b8ef7ba22f, executor driver, partition 254, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:38,835] {docker.py:276} INFO - 21/05/14 14:43:38 INFO Executor: Running task 254.0 in stage 1.0 (TID 535)
[2021-05-14 11:43:38,835] {docker.py:276} INFO - 21/05/14 14:43:38 INFO TaskSetManager: Finished task 250.0 in stage 1.0 (TID 531) in 167 ms on f0b8ef7ba22f (executor driver) (251/281)
[2021-05-14 11:43:38,896] {docker.py:276} INFO - 21/05/14 14:43:38 INFO Executor: Finished task 251.0 in stage 1.0 (TID 532). 1825 bytes result sent to driver
[2021-05-14 11:43:38,897] {docker.py:276} INFO - 21/05/14 14:43:38 INFO TaskSetManager: Starting task 255.0 in stage 1.0 (TID 536) (f0b8ef7ba22f, executor driver, partition 255, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:38,898] {docker.py:276} INFO - 21/05/14 14:43:38 INFO Executor: Running task 255.0 in stage 1.0 (TID 536)
[2021-05-14 11:43:38,899] {docker.py:276} INFO - 21/05/14 14:43:38 INFO TaskSetManager: Finished task 251.0 in stage 1.0 (TID 532) in 141 ms on f0b8ef7ba22f (executor driver) (252/281)
[2021-05-14 11:43:38,930] {docker.py:276} INFO - 21/05/14 14:43:38 INFO Executor: Finished task 252.0 in stage 1.0 (TID 533). 1825 bytes result sent to driver
[2021-05-14 11:43:38,931] {docker.py:276} INFO - 21/05/14 14:43:38 INFO Executor: Finished task 253.0 in stage 1.0 (TID 534). 1825 bytes result sent to driver
[2021-05-14 11:43:38,932] {docker.py:276} INFO - 21/05/14 14:43:38 INFO TaskSetManager: Starting task 256.0 in stage 1.0 (TID 537) (f0b8ef7ba22f, executor driver, partition 256, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:38,934] {docker.py:276} INFO - 21/05/14 14:43:38 INFO TaskSetManager: Finished task 252.0 in stage 1.0 (TID 533) in 141 ms on f0b8ef7ba22f (executor driver) (253/281)
21/05/14 14:43:38 INFO Executor: Running task 256.0 in stage 1.0 (TID 537)
[2021-05-14 11:43:38,935] {docker.py:276} INFO - 21/05/14 14:43:38 INFO TaskSetManager: Starting task 257.0 in stage 1.0 (TID 538) (f0b8ef7ba22f, executor driver, partition 257, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:38,936] {docker.py:276} INFO - 21/05/14 14:43:38 INFO Executor: Running task 257.0 in stage 1.0 (TID 538)
[2021-05-14 11:43:38,937] {docker.py:276} INFO - 21/05/14 14:43:38 INFO TaskSetManager: Finished task 253.0 in stage 1.0 (TID 534) in 143 ms on f0b8ef7ba22f (executor driver) (254/281)
[2021-05-14 11:43:39,018] {docker.py:276} INFO - 21/05/14 14:43:39 INFO Executor: Finished task 254.0 in stage 1.0 (TID 535). 1825 bytes result sent to driver
[2021-05-14 11:43:39,019] {docker.py:276} INFO - 21/05/14 14:43:39 INFO TaskSetManager: Starting task 258.0 in stage 1.0 (TID 539) (f0b8ef7ba22f, executor driver, partition 258, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:39,020] {docker.py:276} INFO - 21/05/14 14:43:39 INFO TaskSetManager: Finished task 254.0 in stage 1.0 (TID 535) in 186 ms on f0b8ef7ba22f (executor driver) (255/281)
[2021-05-14 11:43:39,021] {docker.py:276} INFO - 21/05/14 14:43:39 INFO Executor: Running task 258.0 in stage 1.0 (TID 539)
[2021-05-14 11:43:39,076] {docker.py:276} INFO - 21/05/14 14:43:39 INFO Executor: Finished task 255.0 in stage 1.0 (TID 536). 1825 bytes result sent to driver
[2021-05-14 11:43:39,077] {docker.py:276} INFO - 21/05/14 14:43:39 INFO TaskSetManager: Starting task 259.0 in stage 1.0 (TID 540) (f0b8ef7ba22f, executor driver, partition 259, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:39,079] {docker.py:276} INFO - 21/05/14 14:43:39 INFO Executor: Running task 259.0 in stage 1.0 (TID 540)
21/05/14 14:43:39 INFO TaskSetManager: Finished task 255.0 in stage 1.0 (TID 536) in 181 ms on f0b8ef7ba22f (executor driver) (256/281)
[2021-05-14 11:43:39,113] {docker.py:276} INFO - 21/05/14 14:43:39 INFO Executor: Finished task 257.0 in stage 1.0 (TID 538). 1825 bytes result sent to driver
[2021-05-14 11:43:39,114] {docker.py:276} INFO - 21/05/14 14:43:39 INFO TaskSetManager: Starting task 260.0 in stage 1.0 (TID 541) (f0b8ef7ba22f, executor driver, partition 260, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:39,116] {docker.py:276} INFO - 21/05/14 14:43:39 INFO Executor: Running task 260.0 in stage 1.0 (TID 541)
21/05/14 14:43:39 INFO TaskSetManager: Finished task 257.0 in stage 1.0 (TID 538) in 181 ms on f0b8ef7ba22f (executor driver) (257/281)
[2021-05-14 11:43:39,117] {docker.py:276} INFO - 21/05/14 14:43:39 INFO Executor: Finished task 256.0 in stage 1.0 (TID 537). 1825 bytes result sent to driver
[2021-05-14 11:43:39,118] {docker.py:276} INFO - 21/05/14 14:43:39 INFO TaskSetManager: Starting task 261.0 in stage 1.0 (TID 542) (f0b8ef7ba22f, executor driver, partition 261, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:39,119] {docker.py:276} INFO - 21/05/14 14:43:39 INFO TaskSetManager: Finished task 256.0 in stage 1.0 (TID 537) in 187 ms on f0b8ef7ba22f (executor driver) (258/281)
[2021-05-14 11:43:39,120] {docker.py:276} INFO - 21/05/14 14:43:39 INFO Executor: Running task 261.0 in stage 1.0 (TID 542)
[2021-05-14 11:43:39,202] {docker.py:276} INFO - 21/05/14 14:43:39 INFO Executor: Finished task 258.0 in stage 1.0 (TID 539). 1825 bytes result sent to driver
[2021-05-14 11:43:39,203] {docker.py:276} INFO - 21/05/14 14:43:39 INFO TaskSetManager: Starting task 262.0 in stage 1.0 (TID 543) (f0b8ef7ba22f, executor driver, partition 262, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:39,205] {docker.py:276} INFO - 21/05/14 14:43:39 INFO TaskSetManager: Finished task 258.0 in stage 1.0 (TID 539) in 187 ms on f0b8ef7ba22f (executor driver) (259/281)
[2021-05-14 11:43:39,205] {docker.py:276} INFO - 21/05/14 14:43:39 INFO Executor: Running task 262.0 in stage 1.0 (TID 543)
[2021-05-14 11:43:39,293] {docker.py:276} INFO - 21/05/14 14:43:39 INFO Executor: Finished task 260.0 in stage 1.0 (TID 541). 1825 bytes result sent to driver
[2021-05-14 11:43:39,296] {docker.py:276} INFO - 21/05/14 14:43:39 INFO TaskSetManager: Starting task 263.0 in stage 1.0 (TID 544) (f0b8ef7ba22f, executor driver, partition 263, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
21/05/14 14:43:39 INFO Executor: Running task 263.0 in stage 1.0 (TID 544)
21/05/14 14:43:39 INFO TaskSetManager: Finished task 260.0 in stage 1.0 (TID 541) in 182 ms on f0b8ef7ba22f (executor driver) (260/281)
[2021-05-14 11:43:39,297] {docker.py:276} INFO - 21/05/14 14:43:39 INFO Executor: Finished task 261.0 in stage 1.0 (TID 542). 1825 bytes result sent to driver
[2021-05-14 11:43:39,298] {docker.py:276} INFO - 21/05/14 14:43:39 INFO TaskSetManager: Starting task 264.0 in stage 1.0 (TID 545) (f0b8ef7ba22f, executor driver, partition 264, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:39,299] {docker.py:276} INFO - 21/05/14 14:43:39 INFO Executor: Running task 264.0 in stage 1.0 (TID 545)
21/05/14 14:43:39 INFO TaskSetManager: Finished task 261.0 in stage 1.0 (TID 542) in 182 ms on f0b8ef7ba22f (executor driver) (261/281)
[2021-05-14 11:43:39,313] {docker.py:276} INFO - 21/05/14 14:43:39 INFO Executor: Finished task 259.0 in stage 1.0 (TID 540). 1825 bytes result sent to driver
[2021-05-14 11:43:39,315] {docker.py:276} INFO - 21/05/14 14:43:39 INFO TaskSetManager: Starting task 265.0 in stage 1.0 (TID 546) (f0b8ef7ba22f, executor driver, partition 265, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:39,317] {docker.py:276} INFO - 21/05/14 14:43:39 INFO TaskSetManager: Finished task 259.0 in stage 1.0 (TID 540) in 240 ms on f0b8ef7ba22f (executor driver) (262/281)
[2021-05-14 11:43:39,318] {docker.py:276} INFO - 21/05/14 14:43:39 INFO Executor: Running task 265.0 in stage 1.0 (TID 546)
[2021-05-14 11:43:39,386] {docker.py:276} INFO - 21/05/14 14:43:39 INFO Executor: Finished task 262.0 in stage 1.0 (TID 543). 1825 bytes result sent to driver
[2021-05-14 11:43:39,388] {docker.py:276} INFO - 21/05/14 14:43:39 INFO TaskSetManager: Starting task 266.0 in stage 1.0 (TID 547) (f0b8ef7ba22f, executor driver, partition 266, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:39,389] {docker.py:276} INFO - 21/05/14 14:43:39 INFO TaskSetManager: Finished task 262.0 in stage 1.0 (TID 543) in 186 ms on f0b8ef7ba22f (executor driver) (263/281)
[2021-05-14 11:43:39,390] {docker.py:276} INFO - 21/05/14 14:43:39 INFO Executor: Running task 266.0 in stage 1.0 (TID 547)
[2021-05-14 11:43:39,472] {docker.py:276} INFO - 21/05/14 14:43:39 INFO Executor: Finished task 263.0 in stage 1.0 (TID 544). 1868 bytes result sent to driver
[2021-05-14 11:43:39,474] {docker.py:276} INFO - 21/05/14 14:43:39 INFO TaskSetManager: Starting task 267.0 in stage 1.0 (TID 548) (f0b8ef7ba22f, executor driver, partition 267, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:39,475] {docker.py:276} INFO - 21/05/14 14:43:39 INFO TaskSetManager: Finished task 263.0 in stage 1.0 (TID 544) in 181 ms on f0b8ef7ba22f (executor driver) (264/281)
[2021-05-14 11:43:39,476] {docker.py:276} INFO - 21/05/14 14:43:39 INFO Executor: Running task 267.0 in stage 1.0 (TID 548)
[2021-05-14 11:43:39,477] {docker.py:276} INFO - 21/05/14 14:43:39 INFO Executor: Finished task 264.0 in stage 1.0 (TID 545). 1868 bytes result sent to driver
[2021-05-14 11:43:39,478] {docker.py:276} INFO - 21/05/14 14:43:39 INFO TaskSetManager: Starting task 268.0 in stage 1.0 (TID 549) (f0b8ef7ba22f, executor driver, partition 268, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:39,479] {docker.py:276} INFO - 21/05/14 14:43:39 INFO TaskSetManager: Finished task 264.0 in stage 1.0 (TID 545) in 181 ms on f0b8ef7ba22f (executor driver) (265/281)
[2021-05-14 11:43:39,480] {docker.py:276} INFO - 21/05/14 14:43:39 INFO Executor: Running task 268.0 in stage 1.0 (TID 549)
[2021-05-14 11:43:39,494] {docker.py:276} INFO - 21/05/14 14:43:39 INFO Executor: Finished task 265.0 in stage 1.0 (TID 546). 1868 bytes result sent to driver
[2021-05-14 11:43:39,495] {docker.py:276} INFO - 21/05/14 14:43:39 INFO TaskSetManager: Starting task 269.0 in stage 1.0 (TID 550) (f0b8ef7ba22f, executor driver, partition 269, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:39,495] {docker.py:276} INFO - 21/05/14 14:43:39 INFO Executor: Running task 269.0 in stage 1.0 (TID 550)
[2021-05-14 11:43:39,496] {docker.py:276} INFO - 21/05/14 14:43:39 INFO TaskSetManager: Finished task 265.0 in stage 1.0 (TID 546) in 183 ms on f0b8ef7ba22f (executor driver) (266/281)
[2021-05-14 11:43:39,576] {docker.py:276} INFO - 21/05/14 14:43:39 INFO Executor: Finished task 266.0 in stage 1.0 (TID 547). 1868 bytes result sent to driver
[2021-05-14 11:43:39,577] {docker.py:276} INFO - 21/05/14 14:43:39 INFO TaskSetManager: Starting task 270.0 in stage 1.0 (TID 551) (f0b8ef7ba22f, executor driver, partition 270, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:39,578] {docker.py:276} INFO - 21/05/14 14:43:39 INFO Executor: Running task 270.0 in stage 1.0 (TID 551)
[2021-05-14 11:43:39,580] {docker.py:276} INFO - 21/05/14 14:43:39 INFO TaskSetManager: Finished task 266.0 in stage 1.0 (TID 547) in 192 ms on f0b8ef7ba22f (executor driver) (267/281)
[2021-05-14 11:43:39,657] {docker.py:276} INFO - 21/05/14 14:43:39 INFO Executor: Finished task 268.0 in stage 1.0 (TID 549). 1825 bytes result sent to driver
[2021-05-14 11:43:39,658] {docker.py:276} INFO - 21/05/14 14:43:39 INFO TaskSetManager: Starting task 271.0 in stage 1.0 (TID 552) (f0b8ef7ba22f, executor driver, partition 271, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:39,660] {docker.py:276} INFO - 21/05/14 14:43:39 INFO Executor: Running task 271.0 in stage 1.0 (TID 552)
[2021-05-14 11:43:39,661] {docker.py:276} INFO - 21/05/14 14:43:39 INFO TaskSetManager: Finished task 268.0 in stage 1.0 (TID 549) in 182 ms on f0b8ef7ba22f (executor driver) (268/281)
21/05/14 14:43:39 INFO Executor: Finished task 267.0 in stage 1.0 (TID 548). 1825 bytes result sent to driver
[2021-05-14 11:43:39,662] {docker.py:276} INFO - 21/05/14 14:43:39 INFO TaskSetManager: Starting task 272.0 in stage 1.0 (TID 553) (f0b8ef7ba22f, executor driver, partition 272, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:39,663] {docker.py:276} INFO - 21/05/14 14:43:39 INFO Executor: Running task 272.0 in stage 1.0 (TID 553)
21/05/14 14:43:39 INFO TaskSetManager: Finished task 267.0 in stage 1.0 (TID 548) in 190 ms on f0b8ef7ba22f (executor driver) (269/281)
[2021-05-14 11:43:39,664] {docker.py:276} INFO - 21/05/14 14:43:39 INFO Executor: Finished task 269.0 in stage 1.0 (TID 550). 1825 bytes result sent to driver
[2021-05-14 11:43:39,664] {docker.py:276} INFO - 21/05/14 14:43:39 INFO TaskSetManager: Starting task 273.0 in stage 1.0 (TID 554) (f0b8ef7ba22f, executor driver, partition 273, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:39,665] {docker.py:276} INFO - 21/05/14 14:43:39 INFO Executor: Running task 273.0 in stage 1.0 (TID 554)
[2021-05-14 11:43:39,667] {docker.py:276} INFO - 21/05/14 14:43:39 INFO TaskSetManager: Finished task 269.0 in stage 1.0 (TID 550) in 171 ms on f0b8ef7ba22f (executor driver) (270/281)
[2021-05-14 11:43:39,761] {docker.py:276} INFO - 21/05/14 14:43:39 INFO Executor: Finished task 270.0 in stage 1.0 (TID 551). 1825 bytes result sent to driver
[2021-05-14 11:43:39,762] {docker.py:276} INFO - 21/05/14 14:43:39 INFO TaskSetManager: Starting task 274.0 in stage 1.0 (TID 555) (f0b8ef7ba22f, executor driver, partition 274, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:39,763] {docker.py:276} INFO - 21/05/14 14:43:39 INFO Executor: Running task 274.0 in stage 1.0 (TID 555)
[2021-05-14 11:43:39,764] {docker.py:276} INFO - 21/05/14 14:43:39 INFO TaskSetManager: Finished task 270.0 in stage 1.0 (TID 551) in 187 ms on f0b8ef7ba22f (executor driver) (271/281)
[2021-05-14 11:43:39,837] {docker.py:276} INFO - 21/05/14 14:43:39 INFO Executor: Finished task 273.0 in stage 1.0 (TID 554). 1825 bytes result sent to driver
[2021-05-14 11:43:39,839] {docker.py:276} INFO - 21/05/14 14:43:39 INFO TaskSetManager: Starting task 275.0 in stage 1.0 (TID 556) (f0b8ef7ba22f, executor driver, partition 275, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:39,840] {docker.py:276} INFO - 21/05/14 14:43:39 INFO Executor: Running task 275.0 in stage 1.0 (TID 556)
[2021-05-14 11:43:39,841] {docker.py:276} INFO - 21/05/14 14:43:39 INFO Executor: Finished task 271.0 in stage 1.0 (TID 552). 1825 bytes result sent to driver
21/05/14 14:43:39 INFO TaskSetManager: Finished task 273.0 in stage 1.0 (TID 554) in 176 ms on f0b8ef7ba22f (executor driver) (272/281)
[2021-05-14 11:43:39,842] {docker.py:276} INFO - 21/05/14 14:43:39 INFO TaskSetManager: Starting task 276.0 in stage 1.0 (TID 557) (f0b8ef7ba22f, executor driver, partition 276, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:39,843] {docker.py:276} INFO - 21/05/14 14:43:39 INFO TaskSetManager: Finished task 271.0 in stage 1.0 (TID 552) in 185 ms on f0b8ef7ba22f (executor driver) (273/281)
[2021-05-14 11:43:39,844] {docker.py:276} INFO - 21/05/14 14:43:39 INFO Executor: Running task 276.0 in stage 1.0 (TID 557)
[2021-05-14 11:43:39,845] {docker.py:276} INFO - 21/05/14 14:43:39 INFO Executor: Finished task 272.0 in stage 1.0 (TID 553). 1825 bytes result sent to driver
[2021-05-14 11:43:39,846] {docker.py:276} INFO - 21/05/14 14:43:39 INFO TaskSetManager: Starting task 277.0 in stage 1.0 (TID 558) (f0b8ef7ba22f, executor driver, partition 277, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:39,847] {docker.py:276} INFO - 21/05/14 14:43:39 INFO TaskSetManager: Finished task 272.0 in stage 1.0 (TID 553) in 186 ms on f0b8ef7ba22f (executor driver) (274/281)
21/05/14 14:43:39 INFO Executor: Running task 277.0 in stage 1.0 (TID 558)
[2021-05-14 11:43:39,941] {docker.py:276} INFO - 21/05/14 14:43:39 INFO Executor: Finished task 274.0 in stage 1.0 (TID 555). 1825 bytes result sent to driver
[2021-05-14 11:43:39,942] {docker.py:276} INFO - 21/05/14 14:43:39 INFO TaskSetManager: Starting task 278.0 in stage 1.0 (TID 559) (f0b8ef7ba22f, executor driver, partition 278, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:39,943] {docker.py:276} INFO - 21/05/14 14:43:39 INFO TaskSetManager: Finished task 274.0 in stage 1.0 (TID 555) in 182 ms on f0b8ef7ba22f (executor driver) (275/281)
[2021-05-14 11:43:39,944] {docker.py:276} INFO - 21/05/14 14:43:39 INFO Executor: Running task 278.0 in stage 1.0 (TID 559)
[2021-05-14 11:43:40,013] {docker.py:276} INFO - 21/05/14 14:43:40 INFO Executor: Finished task 277.0 in stage 1.0 (TID 558). 1825 bytes result sent to driver
21/05/14 14:43:40 INFO TaskSetManager: Starting task 279.0 in stage 1.0 (TID 560) (f0b8ef7ba22f, executor driver, partition 279, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:40,014] {docker.py:276} INFO - 21/05/14 14:43:40 INFO TaskSetManager: Finished task 277.0 in stage 1.0 (TID 558) in 167 ms on f0b8ef7ba22f (executor driver) (276/281)
[2021-05-14 11:43:40,014] {docker.py:276} INFO - 21/05/14 14:43:40 INFO Executor: Running task 279.0 in stage 1.0 (TID 560)
[2021-05-14 11:43:40,016] {docker.py:276} INFO - 21/05/14 14:43:40 INFO Executor: Finished task 276.0 in stage 1.0 (TID 557). 1825 bytes result sent to driver
21/05/14 14:43:40 INFO Executor: Finished task 275.0 in stage 1.0 (TID 556). 1825 bytes result sent to driver
[2021-05-14 11:43:40,017] {docker.py:276} INFO - 21/05/14 14:43:40 INFO TaskSetManager: Starting task 280.0 in stage 1.0 (TID 561) (f0b8ef7ba22f, executor driver, partition 280, PROCESS_LOCAL, 4551 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:40,019] {docker.py:276} INFO - 21/05/14 14:43:40 INFO TaskSetManager: Finished task 276.0 in stage 1.0 (TID 557) in 176 ms on f0b8ef7ba22f (executor driver) (277/281)
21/05/14 14:43:40 INFO Executor: Running task 280.0 in stage 1.0 (TID 561)
21/05/14 14:43:40 INFO TaskSetManager: Finished task 275.0 in stage 1.0 (TID 556) in 180 ms on f0b8ef7ba22f (executor driver) (278/281)
[2021-05-14 11:43:40,122] {docker.py:276} INFO - 21/05/14 14:43:40 INFO Executor: Finished task 278.0 in stage 1.0 (TID 559). 1825 bytes result sent to driver
[2021-05-14 11:43:40,123] {docker.py:276} INFO - 21/05/14 14:43:40 INFO TaskSetManager: Finished task 278.0 in stage 1.0 (TID 559) in 180 ms on f0b8ef7ba22f (executor driver) (279/281)
[2021-05-14 11:43:40,190] {docker.py:276} INFO - 21/05/14 14:43:40 INFO Executor: Finished task 279.0 in stage 1.0 (TID 560). 1825 bytes result sent to driver
21/05/14 14:43:40 INFO Executor: Finished task 280.0 in stage 1.0 (TID 561). 1825 bytes result sent to driver
[2021-05-14 11:43:40,192] {docker.py:276} INFO - 21/05/14 14:43:40 INFO TaskSetManager: Finished task 279.0 in stage 1.0 (TID 560) in 180 ms on f0b8ef7ba22f (executor driver) (280/281)
[2021-05-14 11:43:40,193] {docker.py:276} INFO - 21/05/14 14:43:40 INFO TaskSetManager: Finished task 280.0 in stage 1.0 (TID 561) in 177 ms on f0b8ef7ba22f (executor driver) (281/281)
[2021-05-14 11:43:40,193] {docker.py:276} INFO - 21/05/14 14:43:40 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool
[2021-05-14 11:43:40,195] {docker.py:276} INFO - 21/05/14 14:43:40 INFO DAGScheduler: ResultStage 1 (csv at NativeMethodAccessorImpl.java:0) finished in 13.247 s
[2021-05-14 11:43:40,196] {docker.py:276} INFO - 21/05/14 14:43:40 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
[2021-05-14 11:43:40,197] {docker.py:276} INFO - 21/05/14 14:43:40 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
[2021-05-14 11:43:40,198] {docker.py:276} INFO - 21/05/14 14:43:40 INFO DAGScheduler: Job 1 finished: csv at NativeMethodAccessorImpl.java:0, took 13.305135 s
[2021-05-14 11:43:40,219] {docker.py:276} INFO - 21/05/14 14:43:40 INFO InMemoryFileIndex: It took 13392 ms to list leaf files for 281 paths.
[2021-05-14 11:43:40,298] {docker.py:276} INFO - 21/05/14 14:43:40 INFO BlockManagerInfo: Removed broadcast_1_piece0 on f0b8ef7ba22f:44207 in memory (size: 30.3 KiB, free: 934.4 MiB)
[2021-05-14 11:43:43,062] {docker.py:276} INFO - 21/05/14 14:43:43 INFO FileSourceStrategy: Pushed Filters:
[2021-05-14 11:43:43,068] {docker.py:276} INFO - 21/05/14 14:43:43 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
[2021-05-14 11:43:43,072] {docker.py:276} INFO - 21/05/14 14:43:43 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
[2021-05-14 11:43:43,586] {docker.py:276} INFO - 21/05/14 14:43:43 INFO CodeGenerator: Code generated in 279.2068 ms
[2021-05-14 11:43:43,603] {docker.py:276} INFO - 21/05/14 14:43:43 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 177.4 KiB, free 934.2 MiB)
[2021-05-14 11:43:43,624] {docker.py:276} INFO - 21/05/14 14:43:43 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 28.2 KiB, free 934.2 MiB)
[2021-05-14 11:43:43,625] {docker.py:276} INFO - 21/05/14 14:43:43 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on f0b8ef7ba22f:44207 (size: 28.2 KiB, free: 934.4 MiB)
[2021-05-14 11:43:43,625] {docker.py:276} INFO - 21/05/14 14:43:43 INFO SparkContext: Created broadcast 2 from csv at NativeMethodAccessorImpl.java:0
[2021-05-14 11:43:43,644] {docker.py:276} INFO - 21/05/14 14:43:43 INFO FileSourceScanExec: Planning scan with bin packing, max size: 134217728 bytes, open cost is considered as scanning 4194304 bytes.
[2021-05-14 11:43:43,763] {docker.py:276} INFO - 21/05/14 14:43:43 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
[2021-05-14 11:43:43,774] {docker.py:276} INFO - 21/05/14 14:43:43 INFO DAGScheduler: Got job 2 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2021-05-14 11:43:43,774] {docker.py:276} INFO - 21/05/14 14:43:43 INFO DAGScheduler: Final stage: ResultStage 2 (csv at NativeMethodAccessorImpl.java:0)
[2021-05-14 11:43:43,775] {docker.py:276} INFO - 21/05/14 14:43:43 INFO DAGScheduler: Parents of final stage: List()
[2021-05-14 11:43:43,775] {docker.py:276} INFO - 21/05/14 14:43:43 INFO DAGScheduler: Missing parents: List()
[2021-05-14 11:43:43,775] {docker.py:276} INFO - 21/05/14 14:43:43 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[9] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
[2021-05-14 11:43:43,802] {docker.py:276} INFO - 21/05/14 14:43:43 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 10.8 KiB, free 934.2 MiB)
[2021-05-14 11:43:43,820] {docker.py:276} INFO - 21/05/14 14:43:43 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 934.2 MiB)
[2021-05-14 11:43:43,821] {docker.py:276} INFO - 21/05/14 14:43:43 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on f0b8ef7ba22f:44207 (size: 5.4 KiB, free: 934.4 MiB)
[2021-05-14 11:43:43,822] {docker.py:276} INFO - 21/05/14 14:43:43 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1383
[2021-05-14 11:43:43,824] {docker.py:276} INFO - 21/05/14 14:43:43 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[9] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2021-05-14 11:43:43,825] {docker.py:276} INFO - 21/05/14 14:43:43 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0
[2021-05-14 11:43:43,828] {docker.py:276} INFO - 21/05/14 14:43:43 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 562) (f0b8ef7ba22f, executor driver, partition 0, PROCESS_LOCAL, 8027 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:43,829] {docker.py:276} INFO - 21/05/14 14:43:43 INFO Executor: Running task 0.0 in stage 2.0 (TID 562)
[2021-05-14 11:43:43,959] {docker.py:276} INFO - 21/05/14 14:43:43 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/3/2021-05-14/from_1620941675_to_1620943475.csv, range: 0-111642, partition values: [empty row]
[2021-05-14 11:43:44,010] {docker.py:276} INFO - 21/05/14 14:43:44 INFO CodeGenerator: Code generated in 42.3483 ms
[2021-05-14 11:43:44,440] {docker.py:276} INFO - 21/05/14 14:43:44 INFO Executor: Finished task 0.0 in stage 2.0 (TID 562). 1607 bytes result sent to driver
[2021-05-14 11:43:44,443] {docker.py:276} INFO - 21/05/14 14:43:44 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 562) in 617 ms on f0b8ef7ba22f (executor driver) (1/1)
[2021-05-14 11:43:44,443] {docker.py:276} INFO - 21/05/14 14:43:44 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool
[2021-05-14 11:43:44,444] {docker.py:276} INFO - 21/05/14 14:43:44 INFO DAGScheduler: ResultStage 2 (csv at NativeMethodAccessorImpl.java:0) finished in 0.674 s
[2021-05-14 11:43:44,445] {docker.py:276} INFO - 21/05/14 14:43:44 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
[2021-05-14 11:43:44,445] {docker.py:276} INFO - 21/05/14 14:43:44 INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished
[2021-05-14 11:43:44,446] {docker.py:276} INFO - 21/05/14 14:43:44 INFO DAGScheduler: Job 2 finished: csv at NativeMethodAccessorImpl.java:0, took 0.682254 s
[2021-05-14 11:43:44,479] {docker.py:276} INFO - 21/05/14 14:43:44 INFO CodeGenerator: Code generated in 16.1511 ms
[2021-05-14 11:43:44,559] {docker.py:276} INFO - 21/05/14 14:43:44 INFO FileSourceStrategy: Pushed Filters: 
21/05/14 14:43:44 INFO FileSourceStrategy: Post-Scan Filters:
[2021-05-14 11:43:44,559] {docker.py:276} INFO - 21/05/14 14:43:44 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
[2021-05-14 11:43:44,565] {docker.py:276} INFO - 21/05/14 14:43:44 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 177.4 KiB, free 934.0 MiB)
[2021-05-14 11:43:44,596] {docker.py:276} INFO - 21/05/14 14:43:44 INFO BlockManagerInfo: Removed broadcast_3_piece0 on f0b8ef7ba22f:44207 in memory (size: 5.4 KiB, free: 934.4 MiB)
[2021-05-14 11:43:44,598] {docker.py:276} INFO - 21/05/14 14:43:44 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 28.2 KiB, free 934.0 MiB)
[2021-05-14 11:43:44,599] {docker.py:276} INFO - 21/05/14 14:43:44 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on f0b8ef7ba22f:44207 (size: 28.2 KiB, free: 934.3 MiB)
[2021-05-14 11:43:44,601] {docker.py:276} INFO - 21/05/14 14:43:44 INFO SparkContext: Created broadcast 4 from csv at NativeMethodAccessorImpl.java:0
[2021-05-14 11:43:44,612] {docker.py:276} INFO - 21/05/14 14:43:44 INFO FileSourceScanExec: Planning scan with bin packing, max size: 134217728 bytes, open cost is considered as scanning 4194304 bytes.
[2021-05-14 11:43:45,416] {docker.py:276} INFO - 21/05/14 14:43:45 INFO FileSourceStrategy: Pushed Filters:
[2021-05-14 11:43:45,417] {docker.py:276} INFO - 21/05/14 14:43:45 INFO FileSourceStrategy: Post-Scan Filters:
[2021-05-14 11:43:45,417] {docker.py:276} INFO - 21/05/14 14:43:45 INFO FileSourceStrategy: Output Data Schema: struct<ts: string, n: string, bid: string, ask: string, value: string ... 7 more fields>
[2021-05-14 11:43:46,039] {docker.py:276} INFO - 21/05/14 14:43:46 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:43:46 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2021-05-14 11:43:46,043] {docker.py:276} INFO - 21/05/14 14:43:46 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
[2021-05-14 11:43:46,044] {docker.py:276} INFO - 21/05/14 14:43:46 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443457583537712105147781_0000_m_000000_0, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443457583537712105147781_0000_m_000000_0}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443457583537712105147781_0000}; taskId=attempt_202105141443457583537712105147781_0000_m_000000_0, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@2e56958a}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
[2021-05-14 11:43:46,044] {docker.py:276} INFO - 21/05/14 14:43:46 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
[2021-05-14 11:43:46,084] {docker.py:276} INFO - 21/05/14 14:43:46 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2021-05-14 11:43:46,183] {docker.py:276} INFO - 21/05/14 14:43:46 INFO CodeGenerator: Code generated in 66.5505 ms
[2021-05-14 11:43:46,211] {docker.py:276} INFO - 21/05/14 14:43:46 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2021-05-14 11:43:46,258] {docker.py:276} INFO - 21/05/14 14:43:46 INFO CodeGenerator: Code generated in 37.6915 ms
[2021-05-14 11:43:46,260] {docker.py:276} INFO - 21/05/14 14:43:46 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 177.3 KiB, free 933.8 MiB)
[2021-05-14 11:43:46,268] {docker.py:276} INFO - 21/05/14 14:43:46 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 28.1 KiB, free 933.8 MiB)
[2021-05-14 11:43:46,270] {docker.py:276} INFO - 21/05/14 14:43:46 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on f0b8ef7ba22f:44207 (size: 28.1 KiB, free: 934.3 MiB)
[2021-05-14 11:43:46,270] {docker.py:276} INFO - 21/05/14 14:43:46 INFO SparkContext: Created broadcast 5 from csv at NativeMethodAccessorImpl.java:0
[2021-05-14 11:43:46,281] {docker.py:276} INFO - 21/05/14 14:43:46 INFO FileSourceScanExec: Planning scan with bin packing, max size: 134217728 bytes, open cost is considered as scanning 4194304 bytes.
[2021-05-14 11:43:46,338] {docker.py:276} INFO - 21/05/14 14:43:46 INFO BlockManagerInfo: Removed broadcast_2_piece0 on f0b8ef7ba22f:44207 in memory (size: 28.2 KiB, free: 934.3 MiB)
[2021-05-14 11:43:46,448] {docker.py:276} INFO - 21/05/14 14:43:46 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
[2021-05-14 11:43:46,452] {docker.py:276} INFO - 21/05/14 14:43:46 INFO DAGScheduler: Registering RDD 19 (csv at NativeMethodAccessorImpl.java:0) as input to shuffle 0
[2021-05-14 11:43:46,454] {docker.py:276} INFO - 21/05/14 14:43:46 INFO DAGScheduler: Got job 3 (csv at NativeMethodAccessorImpl.java:0) with 200 output partitions
[2021-05-14 11:43:46,455] {docker.py:276} INFO - 21/05/14 14:43:46 INFO DAGScheduler: Final stage: ResultStage 4 (csv at NativeMethodAccessorImpl.java:0)
[2021-05-14 11:43:46,455] {docker.py:276} INFO - 21/05/14 14:43:46 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)
[2021-05-14 11:43:46,456] {docker.py:276} INFO - 21/05/14 14:43:46 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 3)
[2021-05-14 11:43:46,458] {docker.py:276} INFO - 21/05/14 14:43:46 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[19] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
[2021-05-14 11:43:46,476] {docker.py:276} INFO - 21/05/14 14:43:46 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 27.9 KiB, free 934.0 MiB)
[2021-05-14 11:43:46,486] {docker.py:276} INFO - 21/05/14 14:43:46 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 12.0 KiB, free 934.0 MiB)
[2021-05-14 11:43:46,487] {docker.py:276} INFO - 21/05/14 14:43:46 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on f0b8ef7ba22f:44207 (size: 12.0 KiB, free: 934.3 MiB)
[2021-05-14 11:43:46,488] {docker.py:276} INFO - 21/05/14 14:43:46 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1383
[2021-05-14 11:43:46,491] {docker.py:276} INFO - 21/05/14 14:43:46 INFO DAGScheduler: Submitting 9 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[19] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8))
21/05/14 14:43:46 INFO TaskSchedulerImpl: Adding task set 3.0 with 9 tasks resource profile 0
[2021-05-14 11:43:46,493] {docker.py:276} INFO - 21/05/14 14:43:46 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 563) (f0b8ef7ba22f, executor driver, partition 0, PROCESS_LOCAL, 8016 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:46,494] {docker.py:276} INFO - 21/05/14 14:43:46 INFO TaskSetManager: Starting task 1.0 in stage 3.0 (TID 564) (f0b8ef7ba22f, executor driver, partition 1, PROCESS_LOCAL, 8016 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:46,495] {docker.py:276} INFO - 21/05/14 14:43:46 INFO TaskSetManager: Starting task 2.0 in stage 3.0 (TID 565) (f0b8ef7ba22f, executor driver, partition 2, PROCESS_LOCAL, 8016 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:46,499] {docker.py:276} INFO - 21/05/14 14:43:46 INFO TaskSetManager: Starting task 3.0 in stage 3.0 (TID 566) (f0b8ef7ba22f, executor driver, partition 3, PROCESS_LOCAL, 8016 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:46,501] {docker.py:276} INFO - 21/05/14 14:43:46 INFO Executor: Running task 0.0 in stage 3.0 (TID 563)
21/05/14 14:43:46 INFO Executor: Running task 1.0 in stage 3.0 (TID 564)
[2021-05-14 11:43:46,503] {docker.py:276} INFO - 21/05/14 14:43:46 INFO Executor: Running task 2.0 in stage 3.0 (TID 565)
[2021-05-14 11:43:46,506] {docker.py:276} INFO - 21/05/14 14:43:46 INFO Executor: Running task 3.0 in stage 3.0 (TID 566)
[2021-05-14 11:43:46,633] {docker.py:276} INFO - 21/05/14 14:43:46 INFO CodeGenerator: Code generated in 38.4506 ms
[2021-05-14 11:43:46,677] {docker.py:276} INFO - 21/05/14 14:43:46 INFO BlockManagerInfo: Removed broadcast_4_piece0 on f0b8ef7ba22f:44207 in memory (size: 28.2 KiB, free: 934.4 MiB)
[2021-05-14 11:43:46,701] {docker.py:276} INFO - 21/05/14 14:43:46 INFO CodeGenerator: Code generated in 14.6885 ms
[2021-05-14 11:43:46,742] {docker.py:276} INFO - 21/05/14 14:43:46 INFO CodeGenerator: Code generated in 29.6467 ms
[2021-05-14 11:43:46,763] {docker.py:276} INFO - 21/05/14 14:43:46 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/3/2021-05-14/from_1620941675_to_1620943475.csv, range: 0-111642, partition values: [empty row]
[2021-05-14 11:43:46,764] {docker.py:276} INFO - 21/05/14 14:43:46 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/3/2021-05-14/from_1620927275_to_1620929075.csv, range: 0-104304, partition values: [empty row]
[2021-05-14 11:43:46,765] {docker.py:276} INFO - 21/05/14 14:43:46 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/3/2021-05-14/from_1620918730_to_1620920530.csv, range: 0-104217, partition values: [empty row]
[2021-05-14 11:43:46,766] {docker.py:276} INFO - 21/05/14 14:43:46 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/2/2021-05-14/from_1620994330_to_1620996130.csv, range: 0-104253, partition values: [empty row]
[2021-05-14 11:43:47,587] {docker.py:276} INFO - 21/05/14 14:43:47 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/3/2021-05-14/from_1620942130_to_1620943930.csv, range: 0-111639, partition values: [empty row]
[2021-05-14 11:43:48,099] {docker.py:276} INFO - 21/05/14 14:43:48 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/2/2021-05-14/from_1620965530_to_1620967330.csv, range: 0-104296, partition values: [empty row]
[2021-05-14 11:43:48,103] {docker.py:276} INFO - 21/05/14 14:43:48 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/3/2021-05-14/from_1620938530_to_1620940330.csv, range: 0-111637, partition values: [empty row]
[2021-05-14 11:43:48,170] {docker.py:276} INFO - 21/05/14 14:43:48 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/3/2021-05-14/from_1620979475_to_1620981275.csv, range: 0-104217, partition values: [empty row]
[2021-05-14 11:43:48,278] {docker.py:276} INFO - 21/05/14 14:43:48 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/3/2021-05-14/from_1620983530_to_1620985330.csv, range: 0-104252, partition values: [empty row]
[2021-05-14 11:43:48,487] {docker.py:276} INFO - 21/05/14 14:43:48 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/2/2021-05-14/from_1620968675_to_1620970475.csv, range: 0-104296, partition values: [empty row]
[2021-05-14 11:43:48,602] {docker.py:276} INFO - 21/05/14 14:43:48 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/3/2021-05-14/from_1620939875_to_1620941675.csv, range: 0-111635, partition values: [empty row]
[2021-05-14 11:43:48,736] {docker.py:276} INFO - 21/05/14 14:43:48 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/2/2021-05-14/from_1620963730_to_1620965530.csv, range: 0-104216, partition values: [empty row]
[2021-05-14 11:43:48,788] {docker.py:276} INFO - 21/05/14 14:43:48 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/3/2021-05-14/from_1620970475_to_1620972275.csv, range: 0-104250, partition values: [empty row]
[2021-05-14 11:43:48,866] {docker.py:276} INFO - 21/05/14 14:43:48 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/3/2021-05-14/from_1620993875_to_1620995675.csv, range: 0-104296, partition values: [empty row]
[2021-05-14 11:43:48,991] {docker.py:276} INFO - 21/05/14 14:43:49 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/3/2021-05-14/from_1620936730_to_1620938530.csv, range: 0-111616, partition values: [empty row]
[2021-05-14 11:43:49,155] {docker.py:276} INFO - 21/05/14 14:43:49 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/2/2021-05-14/from_1620970930_to_1620972730.csv, range: 0-104215, partition values: [empty row]
[2021-05-14 11:43:49,172] {docker.py:276} INFO - 21/05/14 14:43:49 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/3/2021-05-14/from_1620983075_to_1620984875.csv, range: 0-104249, partition values: [empty row]
[2021-05-14 11:43:49,254] {docker.py:276} INFO - 21/05/14 14:43:49 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/3/2021-05-14/from_1620925930_to_1620927730.csv, range: 0-104295, partition values: [empty row]
[2021-05-14 11:43:49,354] {docker.py:276} INFO - 21/05/14 14:43:49 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/3/2021-05-14/from_1620938075_to_1620939875.csv, range: 0-111604, partition values: [empty row]
[2021-05-14 11:43:49,545] {docker.py:276} INFO - 21/05/14 14:43:49 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/3/2021-05-14/from_1620979930_to_1620981730.csv, range: 0-104215, partition values: [empty row]
[2021-05-14 11:43:49,560] {docker.py:276} INFO - 21/05/14 14:43:49 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/2/2021-05-14/from_1620970475_to_1620972275.csv, range: 0-104247, partition values: [empty row]
[2021-05-14 11:43:49,655] {docker.py:276} INFO - 21/05/14 14:43:49 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/2/2021-05-14/from_1620969130_to_1620970930.csv, range: 0-104294, partition values: [empty row]
[2021-05-14 11:43:49,737] {docker.py:276} INFO - 21/05/14 14:43:49 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/3/2021-05-14/from_1620940330_to_1620942130.csv, range: 0-111598, partition values: [empty row]
[2021-05-14 11:43:49,911] {docker.py:276} INFO - 21/05/14 14:43:49 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/2/2021-05-14/from_1620975875_to_1620977675.csv, range: 0-104212, partition values: [empty row]
[2021-05-14 11:43:49,983] {docker.py:276} INFO - 21/05/14 14:43:49 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/3/2021-05-14/from_1620952930_to_1620954730.csv, range: 0-104244, partition values: [empty row]
[2021-05-14 11:43:49,999] {docker.py:276} INFO - 21/05/14 14:43:50 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/2/2021-05-14/from_1620983075_to_1620984875.csv, range: 0-104288, partition values: [empty row]
[2021-05-14 11:43:50,081] {docker.py:276} INFO - 21/05/14 14:43:50 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/3/2021-05-14/from_1620943930_to_1620945730.csv, range: 0-111584, partition values: [empty row]
[2021-05-14 11:43:50,314] {docker.py:276} INFO - 21/05/14 14:43:50 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/3/2021-05-14/from_1620999275_to_1621001075.csv, range: 0-104212, partition values: [empty row]
[2021-05-14 11:43:50,363] {docker.py:276} INFO - 21/05/14 14:43:50 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/2/2021-05-14/from_1620992530_to_1620994330.csv, range: 0-104243, partition values: [empty row]
[2021-05-14 11:43:50,377] {docker.py:276} INFO - 21/05/14 14:43:50 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/2/2021-05-14/from_1620983530_to_1620985330.csv, range: 0-104287, partition values: [empty row]
[2021-05-14 11:43:50,457] {docker.py:276} INFO - 21/05/14 14:43:50 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/3/2021-05-14/from_1620943475_to_1620945275.csv, range: 0-111580, partition values: [empty row]
[2021-05-14 11:43:50,736] {docker.py:276} INFO - 21/05/14 14:43:50 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/3/2021-05-14/from_1620981730_to_1620983530.csv, range: 0-104287, partition values: [empty row]
[2021-05-14 11:43:50,769] {docker.py:276} INFO - 21/05/14 14:43:50 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/3/2021-05-14/from_1620981275_to_1620983075.csv, range: 0-104208, partition values: [empty row]
[2021-05-14 11:43:50,789] {docker.py:276} INFO - 21/05/14 14:43:50 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/2/2021-05-14/from_1620922330_to_1620924130.csv, range: 0-104239, partition values: [empty row]
[2021-05-14 11:43:50,850] {docker.py:276} INFO - 21/05/14 14:43:50 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/3/2021-05-14/from_1620936275_to_1620938075.csv, range: 0-111575, partition values: [empty row]
[2021-05-14 11:43:51,093] {docker.py:276} INFO - 21/05/14 14:43:51 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/2/2021-05-14/from_1620965075_to_1620966875.csv, range: 0-104283, partition values: [empty row]
[2021-05-14 11:43:51,158] {docker.py:276} INFO - 21/05/14 14:43:51 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/3/2021-05-14/from_1620960130_to_1620961930.csv, range: 0-104239, partition values: [empty row]
[2021-05-14 11:43:51,161] {docker.py:276} INFO - 21/05/14 14:43:51 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/3/2021-05-14/from_1620997475_to_1620999275.csv, range: 0-104208, partition values: [empty row]
[2021-05-14 11:43:51,224] {docker.py:276} INFO - 21/05/14 14:43:51 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/3/2021-05-14/from_1620945275_to_1620947075.csv, range: 0-110861, partition values: [empty row]
[2021-05-14 11:43:51,482] {docker.py:276} INFO - 21/05/14 14:43:51 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/1/2021-05-14/from_1620936730_to_1620938530.csv, range: 0-104282, partition values: [empty row]
[2021-05-14 11:43:51,540] {docker.py:276} INFO - 21/05/14 14:43:51 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/3/2021-05-14/from_1620999730_to_1621001530.csv, range: 0-104208, partition values: [empty row]
[2021-05-14 11:43:51,541] {docker.py:276} INFO - 21/05/14 14:43:51 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/2/2021-05-14/from_1620963275_to_1620965075.csv, range: 0-104238, partition values: [empty row]
[2021-05-14 11:43:51,609] {docker.py:276} INFO - 21/05/14 14:43:51 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/3/2021-05-14/from_1620945730_to_1620947530.csv, range: 0-108819, partition values: [empty row]
[2021-05-14 11:43:51,832] {docker.py:276} INFO - 21/05/14 14:43:51 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/2/2021-05-14/from_1620960130_to_1620961930.csv, range: 0-104279, partition values: [empty row]
[2021-05-14 11:43:51,904] {docker.py:276} INFO - 21/05/14 14:43:51 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/3/2021-05-14/from_1620916475_to_1620918275.csv, range: 0-104207, partition values: [empty row]
[2021-05-14 11:43:51,926] {docker.py:276} INFO - 21/05/14 14:43:51 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/2/2021-05-14/from_1620977675_to_1620979475.csv, range: 0-104238, partition values: [empty row]
[2021-05-14 11:43:51,954] {docker.py:276} INFO - 21/05/14 14:43:51 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/3/2021-05-14/from_1620934930_to_1620936730.csv, range: 0-107235, partition values: [empty row]
[2021-05-14 11:43:52,184] {docker.py:276} INFO - 21/05/14 14:43:52 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/2/2021-05-14/from_1620958330_to_1620960130.csv, range: 0-104278, partition values: [empty row]
[2021-05-14 11:43:52,296] {docker.py:276} INFO - 21/05/14 14:43:52 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/3/2021-05-14/from_1620934475_to_1620936275.csv, range: 0-105465, partition values: [empty row]
[2021-05-14 11:43:52,300] {docker.py:276} INFO - 21/05/14 14:43:52 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/3/2021-05-14/from_1620992075_to_1620993875.csv, range: 0-104238, partition values: [empty row]
[2021-05-14 11:43:52,311] {docker.py:276} INFO - 21/05/14 14:43:52 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/3/2021-05-14/from_1620987130_to_1620988930.csv, range: 0-104207, partition values: [empty row]
[2021-05-14 11:43:52,528] {docker.py:276} INFO - 21/05/14 14:43:52 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/3/2021-05-14/from_1620961930_to_1620963730.csv, range: 0-104274, partition values: [empty row]
[2021-05-14 11:43:52,669] {docker.py:276} INFO - 21/05/14 14:43:52 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/1/2021-05-14/from_1620939875_to_1620941675.csv, range: 0-104206, partition values: [empty row]
[2021-05-14 11:43:52,677] {docker.py:276} INFO - 21/05/14 14:43:52 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/2/2021-05-14/from_1620929075_to_1620930875.csv, range: 0-104233, partition values: [empty row]
[2021-05-14 11:43:52,752] {docker.py:276} INFO - 21/05/14 14:43:52 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/3/2021-05-14/from_1620984875_to_1620986675.csv, range: 0-104377, partition values: [empty row]
[2021-05-14 11:43:52,896] {docker.py:276} INFO - 21/05/14 14:43:52 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/3/2021-05-14/from_1620994330_to_1620996130.csv, range: 0-104274, partition values: [empty row]
[2021-05-14 11:43:53,052] {docker.py:276} INFO - 21/05/14 14:43:53 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/1/2021-05-14/from_1620945730_to_1620947530.csv, range: 0-104205, partition values: [empty row]
[2021-05-14 11:43:53,063] {docker.py:276} INFO - 21/05/14 14:43:53 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/3/2021-05-14/from_1620924130_to_1620925930.csv, range: 0-104232, partition values: [empty row]
[2021-05-14 11:43:53,126] {docker.py:276} INFO - 21/05/14 14:43:53 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/1/2021-05-14/from_1620940330_to_1620942130.csv, range: 0-104368, partition values: [empty row]
[2021-05-14 11:43:53,276] {docker.py:276} INFO - 21/05/14 14:43:53 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/3/2021-05-14/from_1620995675_to_1620997475.csv, range: 0-104274, partition values: [empty row]
[2021-05-14 11:43:53,410] {docker.py:276} INFO - 21/05/14 14:43:53 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/2/2021-05-14/from_1620981730_to_1620983530.csv, range: 0-104205, partition values: [empty row]
[2021-05-14 11:43:53,417] {docker.py:276} INFO - 21/05/14 14:43:53 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/2/2021-05-14/from_1620923675_to_1620925475.csv, range: 0-104230, partition values: [empty row]
[2021-05-14 11:43:53,498] {docker.py:276} INFO - 21/05/14 14:43:53 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/3/2021-05-14/from_1620933130_to_1620934930.csv, range: 0-104353, partition values: [empty row]
[2021-05-14 11:43:53,646] {docker.py:276} INFO - 21/05/14 14:43:53 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/2/2021-05-14/from_1620972275_to_1620974075.csv, range: 0-104271, partition values: [empty row]
[2021-05-14 11:43:53,764] {docker.py:276} INFO - 21/05/14 14:43:53 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/3/2021-05-14/from_1620988475_to_1620990275.csv, range: 0-104205, partition values: [empty row]
[2021-05-14 11:43:53,779] {docker.py:276} INFO - 21/05/14 14:43:53 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/2/2021-05-14/from_1620992075_to_1620993875.csv, range: 0-104229, partition values: [empty row]
[2021-05-14 11:43:53,848] {docker.py:276} INFO - 21/05/14 14:43:53 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/3/2021-05-14/from_1620956075_to_1620957875.csv, range: 0-104353, partition values: [empty row]
[2021-05-14 11:43:54,044] {docker.py:276} INFO - 21/05/14 14:43:54 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/2/2021-05-14/from_1620978130_to_1620979930.csv, range: 0-104271, partition values: [empty row]
[2021-05-14 11:43:54,168] {docker.py:276} INFO - 21/05/14 14:43:54 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/2/2021-05-14/from_1620995675_to_1620997475.csv, range: 0-104204, partition values: [empty row]
[2021-05-14 11:43:54,173] {docker.py:276} INFO - 21/05/14 14:43:54 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/3/2021-05-14/from_1620958330_to_1620960130.csv, range: 0-104228, partition values: [empty row]
[2021-05-14 11:43:54,257] {docker.py:276} INFO - 21/05/14 14:43:54 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/3/2021-05-14/from_1620985330_to_1620987130.csv, range: 0-104351, partition values: [empty row]
[2021-05-14 11:43:54,424] {docker.py:276} INFO - 21/05/14 14:43:54 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/3/2021-05-14/from_1620920530_to_1620922330.csv, range: 0-104271, partition values: [empty row]
[2021-05-14 11:43:54,554] {docker.py:276} INFO - 21/05/14 14:43:54 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/3/2021-05-14/from_1620988930_to_1620990730.csv, range: 0-104203, partition values: [empty row]
[2021-05-14 11:43:54,562] {docker.py:276} INFO - 21/05/14 14:43:54 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/3/2021-05-14/from_1620966875_to_1620968675.csv, range: 0-104227, partition values: [empty row]
[2021-05-14 11:43:54,622] {docker.py:276} INFO - 21/05/14 14:43:54 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/1/2021-05-14/from_1620941675_to_1620943475.csv, range: 0-104331, partition values: [empty row]
[2021-05-14 11:43:54,804] {docker.py:276} INFO - 21/05/14 14:43:54 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/3/2021-05-14/from_1620959675_to_1620961475.csv, range: 0-104268, partition values: [empty row]
[2021-05-14 11:43:54,943] {docker.py:276} INFO - 21/05/14 14:43:54 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/1/2021-05-14/from_1620948875_to_1620950675.csv, range: 0-104201, partition values: [empty row]
[2021-05-14 11:43:54,989] {docker.py:276} INFO - 21/05/14 14:43:55 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/3/2021-05-14/from_1620920075_to_1620921875.csv, range: 0-104226, partition values: [empty row]
[2021-05-14 11:43:54,993] {docker.py:276} INFO - 21/05/14 14:43:55 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/2/2021-05-14/from_1620961475_to_1620963275.csv, range: 0-104331, partition values: [empty row]
[2021-05-14 11:43:55,212] {docker.py:276} INFO - 21/05/14 14:43:55 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/2/2021-05-14/from_1620993875_to_1620995675.csv, range: 0-104267, partition values: [empty row]
[2021-05-14 11:43:55,350] {docker.py:276} INFO - 21/05/14 14:43:55 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/1/2021-05-14/from_1620943930_to_1620945730.csv, range: 0-104200, partition values: [empty row]
[2021-05-14 11:43:55,374] {docker.py:276} INFO - 21/05/14 14:43:55 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/3/2021-05-14/from_1620968675_to_1620970475.csv, range: 0-104326, partition values: [empty row]
[2021-05-14 11:43:55,477] {docker.py:276} INFO - 21/05/14 14:43:55 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/1/2021-05-14/from_1620942130_to_1620943930.csv, range: 0-104224, partition values: [empty row]
[2021-05-14 11:43:55,647] {docker.py:276} INFO - 21/05/14 14:43:55 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/2/2021-05-14/from_1620957875_to_1620959675.csv, range: 0-104263, partition values: [empty row]
[2021-05-14 11:43:55,733] {docker.py:276} INFO - 21/05/14 14:43:55 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/2/2021-05-14/from_1620985330_to_1620987130.csv, range: 0-104200, partition values: [empty row]
[2021-05-14 11:43:55,815] {docker.py:276} INFO - 21/05/14 14:43:55 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/3/2021-05-14/from_1620954275_to_1620956075.csv, range: 0-104325, partition values: [empty row]
[2021-05-14 11:43:55,912] {docker.py:276} INFO - 21/05/14 14:43:55 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/3/2021-05-14/from_1620986675_to_1620988475.csv, range: 0-104224, partition values: [empty row]
[2021-05-14 11:43:56,029] {docker.py:276} INFO - 21/05/14 14:43:56 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/2/2021-05-14/from_1620929530_to_1620931330.csv, range: 0-104262, partition values: [empty row]
[2021-05-14 11:43:56,119] {docker.py:276} INFO - 21/05/14 14:43:56 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/3/2021-05-14/from_1620974530_to_1620976330.csv, range: 0-104197, partition values: [empty row]
[2021-05-14 11:43:56,196] {docker.py:276} INFO - 21/05/14 14:43:56 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/3/2021-05-14/from_1620954730_to_1620956530.csv, range: 0-104325, partition values: [empty row]
[2021-05-14 11:43:56,297] {docker.py:276} INFO - 21/05/14 14:43:56 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/3/2021-05-14/from_1620996130_to_1620997930.csv, range: 0-104224, partition values: [empty row]
[2021-05-14 11:43:56,392] {docker.py:276} INFO - 21/05/14 14:43:56 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/3/2021-05-14/from_1620921875_to_1620923675.csv, range: 0-104262, partition values: [empty row]
[2021-05-14 11:43:56,483] {docker.py:276} INFO - 21/05/14 14:43:56 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/2/2021-05-14/from_1620974530_to_1620976330.csv, range: 0-104196, partition values: [empty row]
[2021-05-14 11:43:56,553] {docker.py:276} INFO - 21/05/14 14:43:56 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/1/2021-05-14/from_1620936275_to_1620938075.csv, range: 0-104321, partition values: [empty row]
[2021-05-14 11:43:56,670] {docker.py:276} INFO - 21/05/14 14:43:56 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/2/2021-05-14/from_1620952930_to_1620954730.csv, range: 0-104222, partition values: [empty row]
[2021-05-14 11:43:56,784] {docker.py:276} INFO - 21/05/14 14:43:56 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/3/2021-05-14/from_1620956530_to_1620958330.csv, range: 0-104262, partition values: [empty row]
[2021-05-14 11:43:56,840] {docker.py:276} INFO - 21/05/14 14:43:56 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/2/2021-05-14/from_1620956530_to_1620958330.csv, range: 0-104195, partition values: [empty row]
[2021-05-14 11:43:56,942] {docker.py:276} INFO - 21/05/14 14:43:56 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/2/2021-05-14/from_1620961930_to_1620963730.csv, range: 0-104321, partition values: [empty row]
[2021-05-14 11:43:57,080] {docker.py:276} INFO - 21/05/14 14:43:57 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/3/2021-05-14/from_1620997930_to_1620999730.csv, range: 0-104222, partition values: [empty row]
[2021-05-14 11:43:57,120] {docker.py:276} INFO - 21/05/14 14:43:57 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/3/2021-05-14/from_1620927730_to_1620929530.csv, range: 0-104261, partition values: [empty row]
[2021-05-14 11:43:57,189] {docker.py:276} INFO - 21/05/14 14:43:57 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/1/2021-05-14/from_1620945275_to_1620947075.csv, range: 0-104192, partition values: [empty row]
[2021-05-14 11:43:57,288] {docker.py:276} INFO - 21/05/14 14:43:57 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/1/2021-05-14/from_1620947075_to_1620948875.csv, range: 0-104318, partition values: [empty row]
[2021-05-14 11:43:57,439] {docker.py:276} INFO - 21/05/14 14:43:57 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/2/2021-05-14/from_1620927730_to_1620929530.csv, range: 0-104221, partition values: [empty row]
[2021-05-14 11:43:57,489] {docker.py:276} INFO - 21/05/14 14:43:57 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/3/2021-05-14/from_1620972275_to_1620974075.csv, range: 0-104261, partition values: [empty row]
[2021-05-14 11:43:57,573] {docker.py:276} INFO - 21/05/14 14:43:57 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/2/2021-05-14/from_1620921875_to_1620923675.csv, range: 0-104192, partition values: [empty row]
[2021-05-14 11:43:57,715] {docker.py:276} INFO - 21/05/14 14:43:57 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/3/2021-05-14/from_1620972730_to_1620974530.csv, range: 0-104313, partition values: [empty row]
[2021-05-14 11:43:57,799] {docker.py:276} INFO - 21/05/14 14:43:57 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/3/2021-05-14/from_1620925475_to_1620927275.csv, range: 0-104221, partition values: [empty row]
[2021-05-14 11:43:57,963] {docker.py:276} INFO - 21/05/14 14:43:57 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/3/2021-05-14/from_1620952475_to_1620954275.csv, range: 0-104191, partition values: [empty row]
[2021-05-14 11:43:58,103] {docker.py:276} INFO - 21/05/14 14:43:58 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/3/2021-05-14/from_1620992530_to_1620994330.csv, range: 0-104312, partition values: [empty row]
[2021-05-14 11:43:58,164] {docker.py:276} INFO - 21/05/14 14:43:58 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/3/2021-05-14/from_1620923675_to_1620925475.csv, range: 0-104220, partition values: [empty row]
[2021-05-14 11:43:58,376] {docker.py:276} INFO - 21/05/14 14:43:58 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/2/2021-05-14/from_1620997930_to_1620999730.csv, range: 0-104189, partition values: [empty row]
[2021-05-14 11:43:58,485] {docker.py:276} INFO - 21/05/14 14:43:58 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/3/2021-05-14/from_1620932675_to_1620934475.csv, range: 0-104311, partition values: [empty row]
[2021-05-14 11:43:58,538] {docker.py:276} INFO - 21/05/14 14:43:58 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/3/2021-05-14/from_1620961475_to_1620963275.csv, range: 0-104220, partition values: [empty row]
[2021-05-14 11:43:58,758] {docker.py:276} INFO - 21/05/14 14:43:58 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/3/2021-05-14/from_1620978130_to_1620979930.csv, range: 0-104189, partition values: [empty row]
[2021-05-14 11:43:58,809] {docker.py:276} INFO - 21/05/14 14:43:58 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/2/2021-05-14/from_1620972730_to_1620974530.csv, range: 0-104260, partition values: [empty row]
[2021-05-14 11:43:58,851] {docker.py:276} INFO - 21/05/14 14:43:58 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/3/2021-05-14/from_1620969130_to_1620970930.csv, range: 0-104305, partition values: [empty row]
[2021-05-14 11:43:58,919] {docker.py:276} INFO - 21/05/14 14:43:58 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/2/2021-05-14/from_1620988930_to_1620990730.csv, range: 0-104219, partition values: [empty row]
[2021-05-14 11:43:59,145] {docker.py:276} INFO - 21/05/14 14:43:59 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/2/2021-05-14/from_1620952475_to_1620954275.csv, range: 0-104187, partition values: [empty row]
[2021-05-14 11:43:59,234] {docker.py:276} INFO - 21/05/14 14:43:59 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/1/2021-05-14/from_1620947530_to_1620949330.csv, range: 0-104304, partition values: [empty row]
[2021-05-14 11:43:59,287] {docker.py:276} INFO - 21/05/14 14:43:59 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/2/2021-05-14/from_1620959675_to_1620961475.csv, range: 0-104259, partition values: [empty row]
[2021-05-14 11:43:59,295] {docker.py:276} INFO - 21/05/14 14:43:59 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/2/2021-05-14/from_1620984875_to_1620986675.csv, range: 0-104218, partition values: [empty row]
[2021-05-14 11:43:59,527] {docker.py:276} INFO - 21/05/14 14:43:59 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/3/2021-05-14/from_1620922330_to_1620924130.csv, range: 0-104187, partition values: [empty row]
[2021-05-14 11:43:59,645] {docker.py:276} INFO - 21/05/14 14:43:59 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/3/2021-05-14/from_1620967330_to_1620969130.csv, range: 0-104257, partition values: [empty row]
[2021-05-14 11:43:59,679] {docker.py:276} INFO - 21/05/14 14:43:59 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/2/2021-05-14/from_1620986675_to_1620988475.csv, range: 0-104218, partition values: [empty row]
[2021-05-14 11:43:59,880] {docker.py:276} INFO - 21/05/14 14:43:59 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/3/2021-05-14/from_1620990275_to_1620992075.csv, range: 0-104183, partition values: [empty row]
[2021-05-14 11:43:59,918] {docker.py:276} INFO - 21/05/14 14:43:59 INFO Executor: Finished task 0.0 in stage 3.0 (TID 563). 2722 bytes result sent to driver
[2021-05-14 11:43:59,919] {docker.py:276} INFO - 21/05/14 14:43:59 INFO TaskSetManager: Starting task 4.0 in stage 3.0 (TID 567) (f0b8ef7ba22f, executor driver, partition 4, PROCESS_LOCAL, 8016 bytes) taskResourceAssignments Map()
[2021-05-14 11:43:59,920] {docker.py:276} INFO - 21/05/14 14:43:59 INFO Executor: Running task 4.0 in stage 3.0 (TID 567)
[2021-05-14 11:43:59,922] {docker.py:276} INFO - 21/05/14 14:43:59 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 563) in 13446 ms on f0b8ef7ba22f (executor driver) (1/9)
[2021-05-14 11:43:59,939] {docker.py:276} INFO - 21/05/14 14:43:59 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/2/2021-05-14/from_1620979475_to_1620981275.csv, range: 0-104182, partition values: [empty row]
[2021-05-14 11:43:59,992] {docker.py:276} INFO - 21/05/14 14:44:00 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/2/2021-05-14/from_1620927275_to_1620929075.csv, range: 0-104255, partition values: [empty row]
[2021-05-14 11:44:00,080] {docker.py:276} INFO - 21/05/14 14:44:00 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/3/2021-05-14/from_1620918275_to_1620920075.csv, range: 0-104217, partition values: [empty row]
[2021-05-14 11:44:00,330] {docker.py:276} INFO - 21/05/14 14:44:00 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/2/2021-05-14/from_1620930875_to_1620932675.csv, range: 0-104179, partition values: [empty row]
[2021-05-14 11:44:00,367] {docker.py:276} INFO - 21/05/14 14:44:00 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/3/2021-05-14/from_1620974075_to_1620975875.csv, range: 0-104254, partition values: [empty row]
[2021-05-14 11:44:00,575] {docker.py:276} INFO - 21/05/14 14:44:00 INFO Executor: Finished task 3.0 in stage 3.0 (TID 566). 2679 bytes result sent to driver
[2021-05-14 11:44:00,576] {docker.py:276} INFO - 21/05/14 14:44:00 INFO TaskSetManager: Starting task 5.0 in stage 3.0 (TID 568) (f0b8ef7ba22f, executor driver, partition 5, PROCESS_LOCAL, 8016 bytes) taskResourceAssignments Map()
[2021-05-14 11:44:00,577] {docker.py:276} INFO - 21/05/14 14:44:00 INFO Executor: Running task 5.0 in stage 3.0 (TID 568)
[2021-05-14 11:44:00,577] {docker.py:276} INFO - 21/05/14 14:44:00 INFO TaskSetManager: Finished task 3.0 in stage 3.0 (TID 566) in 14095 ms on f0b8ef7ba22f (executor driver) (2/9)
[2021-05-14 11:44:00,593] {docker.py:276} INFO - 21/05/14 14:44:00 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/2/2021-05-14/from_1620956075_to_1620957875.csv, range: 0-104122, partition values: [empty row]
[2021-05-14 11:44:00,692] {docker.py:276} INFO - 21/05/14 14:44:00 INFO Executor: Finished task 2.0 in stage 3.0 (TID 565). 2679 bytes result sent to driver
[2021-05-14 11:44:00,694] {docker.py:276} INFO - 21/05/14 14:44:00 INFO TaskSetManager: Starting task 6.0 in stage 3.0 (TID 569) (f0b8ef7ba22f, executor driver, partition 6, PROCESS_LOCAL, 8016 bytes) taskResourceAssignments Map()
[2021-05-14 11:44:00,695] {docker.py:276} INFO - 21/05/14 14:44:00 INFO Executor: Running task 6.0 in stage 3.0 (TID 569)
[2021-05-14 11:44:00,696] {docker.py:276} INFO - 21/05/14 14:44:00 INFO TaskSetManager: Finished task 2.0 in stage 3.0 (TID 565) in 14218 ms on f0b8ef7ba22f (executor driver) (3/9)
[2021-05-14 11:44:00,709] {docker.py:276} INFO - 21/05/14 14:44:00 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/1/2021-05-14/from_1620966875_to_1620968675.csv, range: 0-104010, partition values: [empty row]
[2021-05-14 11:44:00,718] {docker.py:276} INFO - 21/05/14 14:44:00 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/3/2021-05-14/from_1620916930_to_1620918730.csv, range: 0-104179, partition values: [empty row]
[2021-05-14 11:44:00,916] {docker.py:276} INFO - 21/05/14 14:44:00 INFO Executor: Finished task 1.0 in stage 3.0 (TID 564). 2679 bytes result sent to driver
[2021-05-14 11:44:00,917] {docker.py:276} INFO - 21/05/14 14:44:00 INFO TaskSetManager: Starting task 7.0 in stage 3.0 (TID 570) (f0b8ef7ba22f, executor driver, partition 7, PROCESS_LOCAL, 8016 bytes) taskResourceAssignments Map()
[2021-05-14 11:44:00,918] {docker.py:276} INFO - 21/05/14 14:44:00 INFO TaskSetManager: Finished task 1.0 in stage 3.0 (TID 564) in 14440 ms on f0b8ef7ba22f (executor driver) (4/9)
21/05/14 14:44:00 INFO Executor: Running task 7.0 in stage 3.0 (TID 570)
[2021-05-14 11:44:00,930] {docker.py:276} INFO - 21/05/14 14:44:00 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/1/2021-05-14/from_1620921875_to_1620923675.csv, range: 0-103904, partition values: [empty row]
[2021-05-14 11:44:00,965] {docker.py:276} INFO - 21/05/14 14:44:00 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/3/2021-05-14/from_1620963730_to_1620965530.csv, range: 0-104119, partition values: [empty row]
[2021-05-14 11:44:01,080] {docker.py:276} INFO - 21/05/14 14:44:01 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/2/2021-05-14/from_1620976330_to_1620978130.csv, range: 0-104178, partition values: [empty row]
[2021-05-14 11:44:01,093] {docker.py:276} INFO - 21/05/14 14:44:01 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/1/2021-05-14/from_1620929530_to_1620931330.csv, range: 0-104006, partition values: [empty row]
[2021-05-14 11:44:01,301] {docker.py:276} INFO - 21/05/14 14:44:01 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/1/2021-05-14/from_1620958330_to_1620960130.csv, range: 0-103904, partition values: [empty row]
[2021-05-14 11:44:01,393] {docker.py:276} INFO - 21/05/14 14:44:01 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/2/2021-05-14/from_1620990730_to_1620992530.csv, range: 0-104117, partition values: [empty row]
[2021-05-14 11:44:01,431] {docker.py:276} INFO - 21/05/14 14:44:01 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/2/2021-05-14/from_1620954275_to_1620956075.csv, range: 0-104006, partition values: [empty row]
[2021-05-14 11:44:01,475] {docker.py:276} INFO - 21/05/14 14:44:01 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/2/2021-05-14/from_1620981275_to_1620983075.csv, range: 0-104178, partition values: [empty row]
[2021-05-14 11:44:01,677] {docker.py:276} INFO - 21/05/14 14:44:01 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/1/2021-05-14/from_1620961930_to_1620963730.csv, range: 0-103900, partition values: [empty row]
[2021-05-14 11:44:01,753] {docker.py:276} INFO - 21/05/14 14:44:01 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/1/2021-05-14/from_1620965530_to_1620967330.csv, range: 0-104112, partition values: [empty row]
[2021-05-14 11:44:01,806] {docker.py:276} INFO - 21/05/14 14:44:01 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/1/2021-05-14/from_1620929075_to_1620930875.csv, range: 0-104004, partition values: [empty row]
[2021-05-14 11:44:01,864] {docker.py:276} INFO - 21/05/14 14:44:01 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/3/2021-05-14/from_1620970930_to_1620972730.csv, range: 0-104176, partition values: [empty row]
[2021-05-14 11:44:02,046] {docker.py:276} INFO - 21/05/14 14:44:02 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/2/2021-05-14/from_1620954730_to_1620956530.csv, range: 0-103897, partition values: [empty row]
[2021-05-14 11:44:02,132] {docker.py:276} INFO - 21/05/14 14:44:02 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/1/2021-05-14/from_1620943475_to_1620945275.csv, range: 0-104099, partition values: [empty row]
[2021-05-14 11:44:02,190] {docker.py:276} INFO - 21/05/14 14:44:02 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/2/2021-05-14/from_1620920530_to_1620922330.csv, range: 0-104004, partition values: [empty row]
[2021-05-14 11:44:02,275] {docker.py:276} INFO - 21/05/14 14:44:02 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/2/2021-05-14/from_1620916930_to_1620918730.csv, range: 0-104174, partition values: [empty row]
[2021-05-14 11:44:02,396] {docker.py:276} INFO - 21/05/14 14:44:02 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/2/2021-05-14/from_1620934475_to_1620936275.csv, range: 0-103895, partition values: [empty row]
[2021-05-14 11:44:02,531] {docker.py:276} INFO - 21/05/14 14:44:02 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/3/2021-05-14/from_1620951130_to_1620952930.csv, range: 0-104099, partition values: [empty row]
[2021-05-14 11:44:02,552] {docker.py:276} INFO - 21/05/14 14:44:02 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/1/2021-05-14/from_1620994330_to_1620996130.csv, range: 0-104003, partition values: [empty row]
[2021-05-14 11:44:02,642] {docker.py:276} INFO - 21/05/14 14:44:02 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/3/2021-05-14/from_1620931330_to_1620933130.csv, range: 0-104172, partition values: [empty row]
[2021-05-14 11:44:02,779] {docker.py:276} INFO - 21/05/14 14:44:02 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/1/2021-05-14/from_1620923675_to_1620925475.csv, range: 0-103887, partition values: [empty row]
[2021-05-14 11:44:02,896] {docker.py:276} INFO - 21/05/14 14:44:02 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/2/2021-05-14/from_1620939875_to_1620941675.csv, range: 0-104092, partition values: [empty row]
[2021-05-14 11:44:02,952] {docker.py:276} INFO - 21/05/14 14:44:02 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/1/2021-05-14/from_1620925475_to_1620927275.csv, range: 0-103993, partition values: [empty row]
[2021-05-14 11:44:03,029] {docker.py:276} INFO - 21/05/14 14:44:03 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/3/2021-05-14/from_1620957875_to_1620959675.csv, range: 0-104172, partition values: [empty row]
[2021-05-14 11:44:03,193] {docker.py:276} INFO - 21/05/14 14:44:03 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/1/2021-05-14/from_1620922330_to_1620924130.csv, range: 0-103883, partition values: [empty row]
[2021-05-14 11:44:03,279] {docker.py:276} INFO - 21/05/14 14:44:03 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/2/2021-05-14/from_1620938075_to_1620939875.csv, range: 0-104088, partition values: [empty row]
[2021-05-14 11:44:03,345] {docker.py:276} INFO - 21/05/14 14:44:03 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/3/2021-05-14/from_1620948875_to_1620950675.csv, range: 0-103989, partition values: [empty row]
[2021-05-14 11:44:03,421] {docker.py:276} INFO - 21/05/14 14:44:03 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/3/2021-05-14/from_1620975875_to_1620977675.csv, range: 0-104170, partition values: [empty row]
[2021-05-14 11:44:03,559] {docker.py:276} INFO - 21/05/14 14:44:03 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/1/2021-05-14/from_1620974075_to_1620975875.csv, range: 0-103881, partition values: [empty row]
[2021-05-14 11:44:03,677] {docker.py:276} INFO - 21/05/14 14:44:03 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/3/2021-05-14/from_1620950675_to_1620952475.csv, range: 0-104088, partition values: [empty row]
[2021-05-14 11:44:03,723] {docker.py:276} INFO - 21/05/14 14:44:03 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/2/2021-05-14/from_1620936730_to_1620938530.csv, range: 0-103976, partition values: [empty row]
[2021-05-14 11:44:03,809] {docker.py:276} INFO - 21/05/14 14:44:03 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/2/2021-05-14/from_1620974075_to_1620975875.csv, range: 0-104165, partition values: [empty row]
[2021-05-14 11:44:03,945] {docker.py:276} INFO - 21/05/14 14:44:03 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/1/2021-05-14/from_1620952930_to_1620954730.csv, range: 0-103880, partition values: [empty row]
[2021-05-14 11:44:04,071] {docker.py:276} INFO - 21/05/14 14:44:04 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/1/2021-05-14/from_1620933130_to_1620934930.csv, range: 0-103973, partition values: [empty row]
[2021-05-14 11:44:04,082] {docker.py:276} INFO - 21/05/14 14:44:04 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/2/2021-05-14/from_1620931330_to_1620933130.csv, range: 0-104082, partition values: [empty row]
[2021-05-14 11:44:04,218] {docker.py:276} INFO - 21/05/14 14:44:04 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/2/2021-05-14/from_1620916475_to_1620918275.csv, range: 0-104164, partition values: [empty row]
[2021-05-14 11:44:04,294] {docker.py:276} INFO - 21/05/14 14:44:04 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/1/2021-05-14/from_1620960130_to_1620961930.csv, range: 0-103877, partition values: [empty row]
[2021-05-14 11:44:04,411] {docker.py:276} INFO - 21/05/14 14:44:04 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/1/2021-05-14/from_1620932675_to_1620934475.csv, range: 0-103971, partition values: [empty row]
[2021-05-14 11:44:04,475] {docker.py:276} INFO - 21/05/14 14:44:04 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/1/2021-05-14/from_1620981275_to_1620983075.csv, range: 0-104077, partition values: [empty row]
[2021-05-14 11:44:04,605] {docker.py:276} INFO - 21/05/14 14:44:04 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/2/2021-05-14/from_1620987130_to_1620988930.csv, range: 0-104164, partition values: [empty row]
[2021-05-14 11:44:04,663] {docker.py:276} INFO - 21/05/14 14:44:04 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/2/2021-05-14/from_1620947530_to_1620949330.csv, range: 0-103875, partition values: [empty row]
[2021-05-14 11:44:04,823] {docker.py:276} INFO - 21/05/14 14:44:04 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/3/2021-05-14/from_1620965530_to_1620967330.csv, range: 0-103966, partition values: [empty row]
[2021-05-14 11:44:04,862] {docker.py:276} INFO - 21/05/14 14:44:04 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/1/2021-05-14/from_1620979930_to_1620981730.csv, range: 0-104076, partition values: [empty row]
[2021-05-14 11:44:05,009] {docker.py:276} INFO - 21/05/14 14:44:05 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/3/2021-05-14/from_1620977675_to_1620979475.csv, range: 0-104162, partition values: [empty row]
[2021-05-14 11:44:05,015] {docker.py:276} INFO - 21/05/14 14:44:05 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/1/2021-05-14/from_1620956075_to_1620957875.csv, range: 0-103869, partition values: [empty row]
[2021-05-14 11:44:05,162] {docker.py:276} INFO - 21/05/14 14:44:05 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/1/2021-05-14/from_1620957875_to_1620959675.csv, range: 0-103960, partition values: [empty row]
[2021-05-14 11:44:05,245] {docker.py:276} INFO - 21/05/14 14:44:05 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/3/2021-05-14/from_1620949330_to_1620951130.csv, range: 0-104075, partition values: [empty row]
[2021-05-14 11:44:05,383] {docker.py:276} INFO - 21/05/14 14:44:05 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/2/2021-05-14/from_1620951130_to_1620952930.csv, range: 0-103869, partition values: [empty row]
[2021-05-14 11:44:05,388] {docker.py:276} INFO - 21/05/14 14:44:05 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/3/2021-05-14/from_1620930875_to_1620932675.csv, range: 0-104160, partition values: [empty row]
[2021-05-14 11:44:05,557] {docker.py:276} INFO - 21/05/14 14:44:05 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/1/2021-05-14/from_1620930875_to_1620932675.csv, range: 0-103958, partition values: [empty row]
[2021-05-14 11:44:05,598] {docker.py:276} INFO - 21/05/14 14:44:05 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/2/2021-05-14/from_1620967330_to_1620969130.csv, range: 0-104071, partition values: [empty row]
[2021-05-14 11:44:05,727] {docker.py:276} INFO - 21/05/14 14:44:05 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/1/2021-05-14/from_1620977675_to_1620979475.csv, range: 0-103865, partition values: [empty row]
[2021-05-14 11:44:05,769] {docker.py:276} INFO - 21/05/14 14:44:05 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/2/2021-05-14/from_1620979930_to_1620981730.csv, range: 0-104157, partition values: [empty row]
[2021-05-14 11:44:05,935] {docker.py:276} INFO - 21/05/14 14:44:05 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/1/2021-05-14/from_1620993875_to_1620995675.csv, range: 0-103956, partition values: [empty row]
[2021-05-14 11:44:05,958] {docker.py:276} INFO - 21/05/14 14:44:05 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/1/2021-05-14/from_1620927275_to_1620929075.csv, range: 0-104060, partition values: [empty row]
[2021-05-14 11:44:06,122] {docker.py:276} INFO - 21/05/14 14:44:06 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/2/2021-05-14/from_1620943930_to_1620945730.csv, range: 0-103858, partition values: [empty row]
[2021-05-14 11:44:06,126] {docker.py:276} INFO - 21/05/14 14:44:06 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/2/2021-05-14/from_1620999275_to_1621001075.csv, range: 0-104157, partition values: [empty row]
[2021-05-14 11:44:06,312] {docker.py:276} INFO - 21/05/14 14:44:06 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/1/2021-05-14/from_1620931330_to_1620933130.csv, range: 0-103954, partition values: [empty row]
[2021-05-14 11:44:06,332] {docker.py:276} INFO - 21/05/14 14:44:06 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/2/2021-05-14/from_1620925475_to_1620927275.csv, range: 0-104055, partition values: [empty row]
[2021-05-14 11:44:06,506] {docker.py:276} INFO - 21/05/14 14:44:06 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/3/2021-05-14/from_1620990730_to_1620992530.csv, range: 0-104155, partition values: [empty row]
[2021-05-14 11:44:06,540] {docker.py:276} INFO - 21/05/14 14:44:06 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/1/2021-05-14/from_1620952475_to_1620954275.csv, range: 0-103857, partition values: [empty row]
[2021-05-14 11:44:06,674] {docker.py:276} INFO - 21/05/14 14:44:06 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/1/2021-05-14/from_1620934475_to_1620936275.csv, range: 0-103947, partition values: [empty row]
[2021-05-14 11:44:06,710] {docker.py:276} INFO - 21/05/14 14:44:06 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/1/2021-05-14/from_1620965075_to_1620966875.csv, range: 0-104044, partition values: [empty row]
[2021-05-14 11:44:06,865] {docker.py:276} INFO - 21/05/14 14:44:06 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/3/2021-05-14/from_1620976330_to_1620978130.csv, range: 0-104154, partition values: [empty row]
[2021-05-14 11:44:06,903] {docker.py:276} INFO - 21/05/14 14:44:06 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/1/2021-05-14/from_1620959675_to_1620961475.csv, range: 0-103856, partition values: [empty row]
[2021-05-14 11:44:07,056] {docker.py:276} INFO - 21/05/14 14:44:07 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/1/2021-05-14/from_1620924130_to_1620925930.csv, range: 0-103946, partition values: [empty row]
[2021-05-14 11:44:07,106] {docker.py:276} INFO - 21/05/14 14:44:07 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/2/2021-05-14/from_1620938530_to_1620940330.csv, range: 0-104041, partition values: [empty row]
[2021-05-14 11:44:07,204] {docker.py:276} INFO - 21/05/14 14:44:07 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/3/2021-05-14/from_1620929530_to_1620931330.csv, range: 0-104153, partition values: [empty row]
[2021-05-14 11:44:07,410] {docker.py:276} INFO - 21/05/14 14:44:07 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/1/2021-05-14/from_1620988475_to_1620990275.csv, range: 0-103938, partition values: [empty row]
[2021-05-14 11:44:07,475] {docker.py:276} INFO - 21/05/14 14:44:07 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/2/2021-05-14/from_1620966875_to_1620968675.csv, range: 0-104041, partition values: [empty row]
[2021-05-14 11:44:07,548] {docker.py:276} INFO - 21/05/14 14:44:07 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/3/2021-05-14/from_1620963275_to_1620965075.csv, range: 0-104153, partition values: [empty row]
[2021-05-14 11:44:07,915] {docker.py:276} INFO - 21/05/14 14:44:07 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/2/2021-05-14/from_1620988475_to_1620990275.csv, range: 0-104151, partition values: [empty row]
[2021-05-14 11:44:08,250] {docker.py:276} INFO - 21/05/14 14:44:08 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/2/2021-05-14/from_1620936275_to_1620938075.csv, range: 0-103855, partition values: [empty row]
[2021-05-14 11:44:08,302] {docker.py:276} INFO - 21/05/14 14:44:08 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/2/2021-05-14/from_1620925930_to_1620927730.csv, range: 0-104146, partition values: [empty row]
[2021-05-14 11:44:08,645] {docker.py:276} INFO - 21/05/14 14:44:08 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/2/2021-05-14/from_1620999730_to_1621001530.csv, range: 0-104142, partition values: [empty row]
[2021-05-14 11:44:08,753] {docker.py:276} INFO - 21/05/14 14:44:08 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/2/2021-05-14/from_1620932675_to_1620934475.csv, range: 0-103932, partition values: [empty row]
[2021-05-14 11:44:08,791] {docker.py:276} INFO - 21/05/14 14:44:08 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/1/2021-05-14/from_1620986675_to_1620988475.csv, range: 0-103853, partition values: [empty row]
[2021-05-14 11:44:08,819] {docker.py:276} INFO - 21/05/14 14:44:08 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/1/2021-05-14/from_1620938075_to_1620939875.csv, range: 0-104040, partition values: [empty row]
[2021-05-14 11:44:08,990] {docker.py:276} INFO - 21/05/14 14:44:08 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/3/2021-05-14/from_1620929075_to_1620930875.csv, range: 0-104141, partition values: [empty row]
[2021-05-14 11:44:09,141] {docker.py:276} INFO - 21/05/14 14:44:09 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/3/2021-05-14/from_1620965075_to_1620966875.csv, range: 0-103931, partition values: [empty row]
[2021-05-14 11:44:09,159] {docker.py:276} INFO - 21/05/14 14:44:09 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/1/2021-05-14/from_1620983530_to_1620985330.csv, range: 0-103850, partition values: [empty row]
[2021-05-14 11:44:09,205] {docker.py:276} INFO - 21/05/14 14:44:09 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/1/2021-05-14/from_1620979475_to_1620981275.csv, range: 0-104037, partition values: [empty row]
[2021-05-14 11:44:09,346] {docker.py:276} INFO - 21/05/14 14:44:09 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/2/2021-05-14/from_1620924130_to_1620925930.csv, range: 0-104138, partition values: [empty row]
[2021-05-14 11:44:09,520] {docker.py:276} INFO - 21/05/14 14:44:09 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/1/2021-05-14/from_1620938530_to_1620940330.csv, range: 0-103930, partition values: [empty row]
[2021-05-14 11:44:09,530] {docker.py:276} INFO - 21/05/14 14:44:09 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/2/2021-05-14/from_1620934930_to_1620936730.csv, range: 0-103845, partition values: [empty row]
[2021-05-14 11:44:09,589] {docker.py:276} INFO - 21/05/14 14:44:09 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/1/2021-05-14/from_1620934930_to_1620936730.csv, range: 0-104036, partition values: [empty row]
[2021-05-14 11:44:09,692] {docker.py:276} INFO - 21/05/14 14:44:09 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/2/2021-05-14/from_1620918730_to_1620920530.csv, range: 0-104137, partition values: [empty row]
[2021-05-14 11:44:09,868] {docker.py:276} INFO - 21/05/14 14:44:09 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/2/2021-05-14/from_1620933130_to_1620934930.csv, range: 0-103929, partition values: [empty row]
[2021-05-14 11:44:09,900] {docker.py:276} INFO - 21/05/14 14:44:09 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/1/2021-05-14/from_1620920075_to_1620921875.csv, range: 0-103838, partition values: [empty row]
[2021-05-14 11:44:09,985] {docker.py:276} INFO - 21/05/14 14:44:09 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/1/2021-05-14/from_1620949330_to_1620951130.csv, range: 0-104034, partition values: [empty row]
[2021-05-14 11:44:10,077] {docker.py:276} INFO - 21/05/14 14:44:10 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/2/2021-05-14/from_1620990275_to_1620992075.csv, range: 0-104137, partition values: [empty row]
[2021-05-14 11:44:10,232] {docker.py:276} INFO - 21/05/14 14:44:10 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/1/2021-05-14/from_1620963275_to_1620965075.csv, range: 0-103924, partition values: [empty row]
[2021-05-14 11:44:10,280] {docker.py:276} INFO - 21/05/14 14:44:10 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/1/2021-05-14/from_1620969130_to_1620970930.csv, range: 0-103835, partition values: [empty row]
[2021-05-14 11:44:10,385] {docker.py:276} INFO - 21/05/14 14:44:10 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/1/2021-05-14/from_1620970475_to_1620972275.csv, range: 0-104033, partition values: [empty row]
[2021-05-14 11:44:10,466] {docker.py:276} INFO - 21/05/14 14:44:10 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/2/2021-05-14/from_1620918275_to_1620920075.csv, range: 0-104136, partition values: [empty row]
[2021-05-14 11:44:10,611] {docker.py:276} INFO - 21/05/14 14:44:10 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/1/2021-05-14/from_1620963730_to_1620965530.csv, range: 0-103921, partition values: [empty row]
[2021-05-14 11:44:10,625] {docker.py:276} INFO - 21/05/14 14:44:10 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/1/2021-05-14/from_1620920530_to_1620922330.csv, range: 0-103834, partition values: [empty row]
[2021-05-14 11:44:10,761] {docker.py:276} INFO - 21/05/14 14:44:10 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/2/2021-05-14/from_1620920075_to_1620921875.csv, range: 0-104025, partition values: [empty row]
[2021-05-14 11:44:10,861] {docker.py:276} INFO - 21/05/14 14:44:10 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/2/2021-05-14/from_1620997475_to_1620999275.csv, range: 0-104126, partition values: [empty row]
[2021-05-14 11:44:10,976] {docker.py:276} INFO - 21/05/14 14:44:10 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/1/2021-05-14/from_1620992530_to_1620994330.csv, range: 0-103834, partition values: [empty row]
[2021-05-14 11:44:10,993] {docker.py:276} INFO - 21/05/14 14:44:10 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/1/2021-05-14/from_1620956530_to_1620958330.csv, range: 0-103919, partition values: [empty row]
[2021-05-14 11:44:11,175] {docker.py:276} INFO - 21/05/14 14:44:11 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/1/2021-05-14/from_1620970930_to_1620972730.csv, range: 0-104023, partition values: [empty row]
[2021-05-14 11:44:11,245] {docker.py:276} INFO - 21/05/14 14:44:11 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/2/2021-05-14/from_1620940330_to_1620942130.csv, range: 0-104123, partition values: [empty row]
[2021-05-14 11:44:11,344] {docker.py:276} INFO - 21/05/14 14:44:11 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/1/2021-05-14/from_1620983075_to_1620984875.csv, range: 0-103918, partition values: [empty row]
[2021-05-14 11:44:11,353] {docker.py:276} INFO - 21/05/14 14:44:11 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/1/2021-05-14/from_1620990275_to_1620992075.csv, range: 0-103824, partition values: [empty row]
[2021-05-14 11:44:11,526] {docker.py:276} INFO - 21/05/14 14:44:11 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/1/2021-05-14/from_1620978130_to_1620979930.csv, range: 0-104022, partition values: [empty row]
[2021-05-14 11:44:11,661] {docker.py:276} INFO - 21/05/14 14:44:11 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/2/2021-05-14/from_1620996130_to_1620997930.csv, range: 0-104123, partition values: [empty row]
[2021-05-14 11:44:11,732] {docker.py:276} INFO - 21/05/14 14:44:11 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/1/2021-05-14/from_1620999730_to_1621001530.csv, range: 0-103824, partition values: [empty row]
[2021-05-14 11:44:11,735] {docker.py:276} INFO - 21/05/14 14:44:11 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/2/2021-05-14/from_1620941675_to_1620943475.csv, range: 0-103918, partition values: [empty row]
[2021-05-14 11:44:11,887] {docker.py:276} INFO - 21/05/14 14:44:11 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/1/2021-05-14/from_1620916930_to_1620918730.csv, range: 0-104021, partition values: [empty row]
[2021-05-14 11:44:12,113] {docker.py:276} INFO - 21/05/14 14:44:12 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/2/2021-05-14/from_1620943475_to_1620945275.csv, range: 0-103918, partition values: [empty row]
[2021-05-14 11:44:12,138] {docker.py:276} INFO - 21/05/14 14:44:12 INFO Executor: Finished task 4.0 in stage 3.0 (TID 567). 2679 bytes result sent to driver
[2021-05-14 11:44:12,139] {docker.py:276} INFO - 21/05/14 14:44:12 INFO TaskSetManager: Starting task 8.0 in stage 3.0 (TID 571) (f0b8ef7ba22f, executor driver, partition 8, PROCESS_LOCAL, 7309 bytes) taskResourceAssignments Map()
[2021-05-14 11:44:12,139] {docker.py:276} INFO - 21/05/14 14:44:12 INFO TaskSetManager: Finished task 4.0 in stage 3.0 (TID 567) in 12200 ms on f0b8ef7ba22f (executor driver) (5/9)
[2021-05-14 11:44:12,140] {docker.py:276} INFO - 21/05/14 14:44:12 INFO Executor: Running task 8.0 in stage 3.0 (TID 571)
[2021-05-14 11:44:12,151] {docker.py:276} INFO - 21/05/14 14:44:12 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/1/2021-05-14/from_1620992075_to_1620993875.csv, range: 0-103814, partition values: [empty row]
[2021-05-14 11:44:12,252] {docker.py:276} INFO - 21/05/14 14:44:12 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/1/2021-05-14/from_1620927730_to_1620929530.csv, range: 0-104017, partition values: [empty row]
[2021-05-14 11:44:12,290] {docker.py:276} INFO - 21/05/14 14:44:12 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/1/2021-05-14/from_1620987130_to_1620988930.csv, range: 0-103823, partition values: [empty row]
[2021-05-14 11:44:12,495] {docker.py:276} INFO - 21/05/14 14:44:12 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/1/2021-05-14/from_1620988930_to_1620990730.csv, range: 0-103912, partition values: [empty row]
[2021-05-14 11:44:12,545] {docker.py:276} INFO - 21/05/14 14:44:12 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/1/2021-05-14/from_1620961475_to_1620963275.csv, range: 0-103808, partition values: [empty row]
[2021-05-14 11:44:12,651] {docker.py:276} INFO - 21/05/14 14:44:12 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/1/2021-05-14/from_1620999275_to_1621001075.csv, range: 0-103823, partition values: [empty row]
[2021-05-14 11:44:12,652] {docker.py:276} INFO - 21/05/14 14:44:12 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/1/2021-05-14/from_1620925930_to_1620927730.csv, range: 0-104015, partition values: [empty row]
[2021-05-14 11:44:12,840] {docker.py:276} INFO - 21/05/14 14:44:12 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/1/2021-05-14/from_1620954275_to_1620956075.csv, range: 0-103910, partition values: [empty row]
[2021-05-14 11:44:12,922] {docker.py:276} INFO - 21/05/14 14:44:12 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/1/2021-05-14/from_1620975875_to_1620977675.csv, range: 0-103808, partition values: [empty row]
[2021-05-14 11:44:13,007] {docker.py:276} INFO - 21/05/14 14:44:13 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/1/2021-05-14/from_1620981730_to_1620983530.csv, range: 0-104013, partition values: [empty row]
[2021-05-14 11:44:13,050] {docker.py:276} INFO - 21/05/14 14:44:13 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/1/2021-05-14/from_1620968675_to_1620970475.csv, range: 0-103819, partition values: [empty row]
[2021-05-14 11:44:13,209] {docker.py:276} INFO - 21/05/14 14:44:13 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/1/2021-05-14/from_1620967330_to_1620969130.csv, range: 0-103908, partition values: [empty row]
[2021-05-14 11:44:13,301] {docker.py:276} INFO - 21/05/14 14:44:13 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/1/2021-05-14/from_1620985330_to_1620987130.csv, range: 0-103806, partition values: [empty row]
[2021-05-14 11:44:13,432] {docker.py:276} INFO - 21/05/14 14:44:13 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/1/2021-05-14/from_1620954730_to_1620956530.csv, range: 0-103818, partition values: [empty row]
[2021-05-14 11:44:13,438] {docker.py:276} INFO - 21/05/14 14:44:13 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/1/2021-05-14/from_1620916475_to_1620918275.csv, range: 0-104012, partition values: [empty row]
[2021-05-14 11:44:13,658] {docker.py:276} INFO - 21/05/14 14:44:13 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/1/2021-05-14/from_1620974530_to_1620976330.csv, range: 0-103805, partition values: [empty row]
[2021-05-14 11:44:13,668] {docker.py:276} INFO - 21/05/14 14:44:13 INFO Executor: Finished task 6.0 in stage 3.0 (TID 569). 2679 bytes result sent to driver
[2021-05-14 11:44:13,669] {docker.py:276} INFO - 21/05/14 14:44:13 INFO TaskSetManager: Finished task 6.0 in stage 3.0 (TID 569) in 12956 ms on f0b8ef7ba22f (executor driver) (6/9)
[2021-05-14 11:44:13,779] {docker.py:276} INFO - 21/05/14 14:44:13 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/1/2021-05-14/from_1620990730_to_1620992530.csv, range: 0-103816, partition values: [empty row]
[2021-05-14 11:44:13,991] {docker.py:276} INFO - 21/05/14 14:44:13 INFO Executor: Finished task 5.0 in stage 3.0 (TID 568). 2679 bytes result sent to driver
[2021-05-14 11:44:13,993] {docker.py:276} INFO - 21/05/14 14:44:13 INFO TaskSetManager: Finished task 5.0 in stage 3.0 (TID 568) in 13398 ms on f0b8ef7ba22f (executor driver) (7/9)
[2021-05-14 11:44:14,005] {docker.py:276} INFO - 21/05/14 14:44:14 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/1/2021-05-14/from_1620951130_to_1620952930.csv, range: 0-103801, partition values: [empty row]
[2021-05-14 11:44:14,261] {docker.py:276} INFO - 21/05/14 14:44:14 INFO Executor: Finished task 7.0 in stage 3.0 (TID 570). 2679 bytes result sent to driver
[2021-05-14 11:44:14,262] {docker.py:276} INFO - 21/05/14 14:44:14 INFO TaskSetManager: Finished task 7.0 in stage 3.0 (TID 570) in 13325 ms on f0b8ef7ba22f (executor driver) (8/9)
[2021-05-14 11:44:14,387] {docker.py:276} INFO - 21/05/14 14:44:14 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/2/2021-05-14/from_1620950675_to_1620952475.csv, range: 0-103799, partition values: [empty row]
[2021-05-14 11:44:14,765] {docker.py:276} INFO - 21/05/14 14:44:14 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/1/2021-05-14/from_1620972275_to_1620974075.csv, range: 0-103798, partition values: [empty row]
[2021-05-14 11:44:15,114] {docker.py:276} INFO - 21/05/14 14:44:15 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/1/2021-05-14/from_1620972730_to_1620974530.csv, range: 0-103791, partition values: [empty row]
[2021-05-14 11:44:15,495] {docker.py:276} INFO - 21/05/14 14:44:15 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/1/2021-05-14/from_1620997930_to_1620999730.csv, range: 0-103785, partition values: [empty row]
[2021-05-14 11:44:15,844] {docker.py:276} INFO - 21/05/14 14:44:15 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/2/2021-05-14/from_1620942130_to_1620943930.csv, range: 0-103785, partition values: [empty row]
[2021-05-14 11:44:16,209] {docker.py:276} INFO - 21/05/14 14:44:16 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/1/2021-05-14/from_1620976330_to_1620978130.csv, range: 0-103770, partition values: [empty row]
[2021-05-14 11:44:16,581] {docker.py:276} INFO - 21/05/14 14:44:16 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/1/2021-05-14/from_1620997475_to_1620999275.csv, range: 0-103767, partition values: [empty row]
[2021-05-14 11:44:16,967] {docker.py:276} INFO - 21/05/14 14:44:16 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/1/2021-05-14/from_1620950675_to_1620952475.csv, range: 0-103751, partition values: [empty row]
[2021-05-14 11:44:17,350] {docker.py:276} INFO - 21/05/14 14:44:17 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/1/2021-05-14/from_1620918275_to_1620920075.csv, range: 0-103745, partition values: [empty row]
[2021-05-14 11:44:17,743] {docker.py:276} INFO - 21/05/14 14:44:17 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/1/2021-05-14/from_1620918730_to_1620920530.csv, range: 0-103738, partition values: [empty row]
[2021-05-14 11:44:18,132] {docker.py:276} INFO - 21/05/14 14:44:18 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/1/2021-05-14/from_1620984875_to_1620986675.csv, range: 0-103695, partition values: [empty row]
[2021-05-14 11:44:18,513] {docker.py:276} INFO - 21/05/14 14:44:18 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/2/2021-05-14/from_1620945275_to_1620947075.csv, range: 0-103686, partition values: [empty row]
[2021-05-14 11:44:18,900] {docker.py:276} INFO - 21/05/14 14:44:18 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/3/2021-05-14/from_1620947530_to_1620949330.csv, range: 0-103682, partition values: [empty row]
[2021-05-14 11:44:19,280] {docker.py:276} INFO - 21/05/14 14:44:19 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/1/2021-05-14/from_1620996130_to_1620997930.csv, range: 0-103654, partition values: [empty row]
[2021-05-14 11:44:19,684] {docker.py:276} INFO - 21/05/14 14:44:19 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/2/2021-05-14/from_1620948875_to_1620950675.csv, range: 0-103647, partition values: [empty row]
[2021-05-14 11:44:20,057] {docker.py:276} INFO - 21/05/14 14:44:20 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/2/2021-05-14/from_1620949330_to_1620951130.csv, range: 0-103624, partition values: [empty row]
[2021-05-14 11:44:20,440] {docker.py:276} INFO - 21/05/14 14:44:20 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/3/2021-05-14/from_1620947075_to_1620948875.csv, range: 0-103599, partition values: [empty row]
[2021-05-14 11:44:20,875] {docker.py:276} INFO - 21/05/14 14:44:20 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/2/2021-05-14/from_1620947075_to_1620948875.csv, range: 0-103320, partition values: [empty row]
[2021-05-14 11:44:21,254] {docker.py:276} INFO - 21/05/14 14:44:21 INFO FileScanRDD: Reading File path: s3a://udac-forex-project/2/2021-05-14/from_1620945730_to_1620947530.csv, range: 0-103289, partition values: [empty row]
[2021-05-14 11:44:21,716] {docker.py:276} INFO - 21/05/14 14:44:21 INFO Executor: Finished task 8.0 in stage 3.0 (TID 571). 2679 bytes result sent to driver
[2021-05-14 11:44:21,718] {docker.py:276} INFO - 21/05/14 14:44:21 INFO TaskSetManager: Finished task 8.0 in stage 3.0 (TID 571) in 9590 ms on f0b8ef7ba22f (executor driver) (9/9)
21/05/14 14:44:21 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
21/05/14 14:44:21 INFO DAGScheduler: ShuffleMapStage 3 (csv at NativeMethodAccessorImpl.java:0) finished in 35.256 s
[2021-05-14 11:44:21,719] {docker.py:276} INFO - 21/05/14 14:44:21 INFO DAGScheduler: looking for newly runnable stages
[2021-05-14 11:44:21,720] {docker.py:276} INFO - 21/05/14 14:44:21 INFO DAGScheduler: running: Set()
[2021-05-14 11:44:21,720] {docker.py:276} INFO - 21/05/14 14:44:21 INFO DAGScheduler: waiting: Set(ResultStage 4)
[2021-05-14 11:44:21,721] {docker.py:276} INFO - 21/05/14 14:44:21 INFO DAGScheduler: failed: Set()
[2021-05-14 11:44:21,726] {docker.py:276} INFO - 21/05/14 14:44:21 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[23] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
[2021-05-14 11:44:21,780] {docker.py:276} INFO - 21/05/14 14:44:21 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 203.6 KiB, free 934.0 MiB)
[2021-05-14 11:44:21,782] {docker.py:276} INFO - 21/05/14 14:44:21 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 75.9 KiB, free 933.9 MiB)
[2021-05-14 11:44:21,782] {docker.py:276} INFO - 21/05/14 14:44:21 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on f0b8ef7ba22f:44207 (size: 75.9 KiB, free: 934.3 MiB)
[2021-05-14 11:44:21,783] {docker.py:276} INFO - 21/05/14 14:44:21 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1383
[2021-05-14 11:44:21,784] {docker.py:276} INFO - 21/05/14 14:44:21 INFO DAGScheduler: Submitting 200 missing tasks from ResultStage 4 (MapPartitionsRDD[23] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
[2021-05-14 11:44:21,785] {docker.py:276} INFO - 21/05/14 14:44:21 INFO TaskSchedulerImpl: Adding task set 4.0 with 200 tasks resource profile 0
[2021-05-14 11:44:21,792] {docker.py:276} INFO - 21/05/14 14:44:21 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 572) (f0b8ef7ba22f, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:44:21,792] {docker.py:276} INFO - 21/05/14 14:44:21 INFO TaskSetManager: Starting task 1.0 in stage 4.0 (TID 573) (f0b8ef7ba22f, executor driver, partition 1, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:44:21,792] {docker.py:276} INFO - 21/05/14 14:44:21 INFO TaskSetManager: Starting task 2.0 in stage 4.0 (TID 574) (f0b8ef7ba22f, executor driver, partition 2, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:44:21,793] {docker.py:276} INFO - 21/05/14 14:44:21 INFO TaskSetManager: Starting task 3.0 in stage 4.0 (TID 575) (f0b8ef7ba22f, executor driver, partition 3, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:44:21,793] {docker.py:276} INFO - 21/05/14 14:44:21 INFO Executor: Running task 2.0 in stage 4.0 (TID 574)
[2021-05-14 11:44:21,793] {docker.py:276} INFO - 21/05/14 14:44:21 INFO Executor: Running task 3.0 in stage 4.0 (TID 575)
[2021-05-14 11:44:21,794] {docker.py:276} INFO - 21/05/14 14:44:21 INFO Executor: Running task 1.0 in stage 4.0 (TID 573)
[2021-05-14 11:44:21,794] {docker.py:276} INFO - 21/05/14 14:44:21 INFO Executor: Running task 0.0 in stage 4.0 (TID 572)
[2021-05-14 11:44:21,925] {docker.py:276} INFO - 21/05/14 14:44:21 INFO ShuffleBlockFetcherIterator: Getting 9 (66.1 KiB) non-empty blocks including 9 (66.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
[2021-05-14 11:44:21,929] {docker.py:276} INFO - 21/05/14 14:44:21 INFO ShuffleBlockFetcherIterator: Getting 9 (63.8 KiB) non-empty blocks including 9 (63.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
[2021-05-14 11:44:21,930] {docker.py:276} INFO - 21/05/14 14:44:21 INFO ShuffleBlockFetcherIterator: Getting 9 (61.5 KiB) non-empty blocks including 9 (61.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
[2021-05-14 11:44:21,930] {docker.py:276} INFO - 21/05/14 14:44:21 INFO ShuffleBlockFetcherIterator: Getting 9 (66.7 KiB) non-empty blocks including 9 (66.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
[2021-05-14 11:44:21,931] {docker.py:276} INFO - 21/05/14 14:44:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 19 ms
[2021-05-14 11:44:21,932] {docker.py:276} INFO - 21/05/14 14:44:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 20 ms
[2021-05-14 11:44:21,932] {docker.py:276} INFO - 21/05/14 14:44:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 20 ms
[2021-05-14 11:44:21,932] {docker.py:276} INFO - 21/05/14 14:44:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 21 ms
[2021-05-14 11:44:21,964] {docker.py:276} INFO - 21/05/14 14:44:21 INFO CodeGenerator: Code generated in 18.1986 ms
[2021-05-14 11:44:21,991] {docker.py:276} INFO - 21/05/14 14:44:22 INFO CodeGenerator: Code generated in 17.3285 ms
[2021-05-14 11:44:22,021] {docker.py:276} INFO - 21/05/14 14:44:22 INFO CodeGenerator: Code generated in 16.7167 ms
[2021-05-14 11:44:22,127] {docker.py:276} INFO - 21/05/14 14:44:22 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2021-05-14 11:44:22,128] {docker.py:276} INFO - 21/05/14 14:44:22 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2021-05-14 11:44:22,129] {docker.py:276} INFO - 21/05/14 14:44:22 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:44:22 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2021-05-14 11:44:22,129] {docker.py:276} INFO - 21/05/14 14:44:22 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:44:22 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2021-05-14 11:44:22,129] {docker.py:276} INFO - 21/05/14 14:44:22 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2021-05-14 11:44:22,130] {docker.py:276} INFO - 21/05/14 14:44:22 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2021-05-14 11:44:22,131] {docker.py:276} INFO - 21/05/14 14:44:22 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
[2021-05-14 11:44:22,132] {docker.py:276} INFO - 21/05/14 14:44:22 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443461634226298497037682_0004_m_000001_573, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443461634226298497037682_0004_m_000001_573}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443461634226298497037682_0004}; taskId=attempt_202105141443461634226298497037682_0004_m_000001_573, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@2577945f}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
21/05/14 14:44:22 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
[2021-05-14 11:44:22,133] {docker.py:276} INFO - 21/05/14 14:44:22 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
[2021-05-14 11:44:22,133] {docker.py:276} INFO - 21/05/14 14:44:22 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443463017245660944353989_0004_m_000000_572, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443463017245660944353989_0004_m_000000_572}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443463017245660944353989_0004}; taskId=attempt_202105141443463017245660944353989_0004_m_000000_572, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@ccc9fcb}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
[2021-05-14 11:44:22,134] {docker.py:276} INFO - 21/05/14 14:44:22 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
[2021-05-14 11:44:22,138] {docker.py:276} INFO - 21/05/14 14:44:22 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
21/05/14 14:44:22 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443467657001254925019551_0004_m_000003_575, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443467657001254925019551_0004_m_000003_575}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443467657001254925019551_0004}; taskId=attempt_202105141443467657001254925019551_0004_m_000003_575, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@3877f054}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
[2021-05-14 11:44:22,138] {docker.py:276} INFO - 21/05/14 14:44:22 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
[2021-05-14 11:44:22,139] {docker.py:276} INFO - 21/05/14 14:44:22 INFO StagingCommitter: Starting: Task committer attempt_202105141443467657001254925019551_0004_m_000003_575: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443467657001254925019551_0004_m_000003_575
[2021-05-14 11:44:22,139] {docker.py:276} INFO - 21/05/14 14:44:22 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443466923305017909352240_0004_m_000002_574, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443466923305017909352240_0004_m_000002_574}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443466923305017909352240_0004}; taskId=attempt_202105141443466923305017909352240_0004_m_000002_574, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@6ad77d3f}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
[2021-05-14 11:44:22,140] {docker.py:276} INFO - 21/05/14 14:44:22 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
[2021-05-14 11:44:22,140] {docker.py:276} INFO - 21/05/14 14:44:22 INFO StagingCommitter: Starting: Task committer attempt_202105141443461634226298497037682_0004_m_000001_573: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443461634226298497037682_0004_m_000001_573
[2021-05-14 11:44:22,142] {docker.py:276} INFO - 21/05/14 14:44:22 INFO StagingCommitter: Starting: Task committer attempt_202105141443463017245660944353989_0004_m_000000_572: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443463017245660944353989_0004_m_000000_572
[2021-05-14 11:44:22,143] {docker.py:276} INFO - 21/05/14 14:44:22 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
[2021-05-14 11:44:22,144] {docker.py:276} INFO - 21/05/14 14:44:22 INFO StagingCommitter: Starting: Task committer attempt_202105141443466923305017909352240_0004_m_000002_574: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443466923305017909352240_0004_m_000002_574
[2021-05-14 11:44:22,165] {docker.py:276} INFO - 21/05/14 14:44:22 INFO StagingCommitter: Task committer attempt_202105141443466923305017909352240_0004_m_000002_574: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443466923305017909352240_0004_m_000002_574 : duration 0:00.022s
[2021-05-14 11:44:22,176] {docker.py:276} INFO - 21/05/14 14:44:22 INFO StagingCommitter: Task committer attempt_202105141443467657001254925019551_0004_m_000003_575: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443467657001254925019551_0004_m_000003_575 : duration 0:00.038s
[2021-05-14 11:44:22,181] {docker.py:276} INFO - 21/05/14 14:44:22 INFO StagingCommitter: Task committer attempt_202105141443461634226298497037682_0004_m_000001_573: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443461634226298497037682_0004_m_000001_573 : duration 0:00.047s
[2021-05-14 11:44:22,184] {docker.py:276} INFO - 21/05/14 14:44:22 INFO StagingCommitter: Task committer attempt_202105141443463017245660944353989_0004_m_000000_572: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443463017245660944353989_0004_m_000000_572 : duration 0:00.044s
[2021-05-14 11:44:22,189] {docker.py:276} INFO - 21/05/14 14:44:22 INFO CodeGenerator: Code generated in 18.1541 ms
[2021-05-14 11:44:22,206] {docker.py:276} INFO - 21/05/14 14:44:22 INFO CodeGenerator: Code generated in 12.3149 ms
[2021-05-14 11:44:22,252] {docker.py:276} INFO - 21/05/14 14:44:22 INFO CodeGenerator: Code generated in 20.2044 ms
[2021-05-14 11:44:28,573] {docker.py:276} INFO - 21/05/14 14:44:28 INFO StagingCommitter: Starting: Task committer attempt_202105141443467657001254925019551_0004_m_000003_575: needsTaskCommit() Task attempt_202105141443467657001254925019551_0004_m_000003_575
[2021-05-14 11:44:28,574] {docker.py:276} INFO - 21/05/14 14:44:28 INFO StagingCommitter: Task committer attempt_202105141443467657001254925019551_0004_m_000003_575: needsTaskCommit() Task attempt_202105141443467657001254925019551_0004_m_000003_575: duration 0:00.001s
[2021-05-14 11:44:28,576] {docker.py:276} INFO - 21/05/14 14:44:28 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443467657001254925019551_0004_m_000003_575
[2021-05-14 11:44:28,587] {docker.py:276} INFO - 21/05/14 14:44:28 INFO Executor: Finished task 3.0 in stage 4.0 (TID 575). 5192 bytes result sent to driver
[2021-05-14 11:44:28,589] {docker.py:276} INFO - 21/05/14 14:44:28 INFO TaskSetManager: Starting task 4.0 in stage 4.0 (TID 576) (f0b8ef7ba22f, executor driver, partition 4, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:44:28,589] {docker.py:276} INFO - 21/05/14 14:44:28 INFO Executor: Running task 4.0 in stage 4.0 (TID 576)
[2021-05-14 11:44:28,590] {docker.py:276} INFO - 21/05/14 14:44:28 INFO TaskSetManager: Finished task 3.0 in stage 4.0 (TID 575) in 6806 ms on f0b8ef7ba22f (executor driver) (1/200)
[2021-05-14 11:44:28,598] {docker.py:276} INFO - 21/05/14 14:44:28 INFO ShuffleBlockFetcherIterator: Getting 9 (64.9 KiB) non-empty blocks including 9 (64.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:44:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:44:28,617] {docker.py:276} INFO - 21/05/14 14:44:28 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:44:28 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/05/14 14:44:28 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
[2021-05-14 11:44:28,617] {docker.py:276} INFO - 21/05/14 14:44:28 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443466641724735573903185_0004_m_000004_576, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443466641724735573903185_0004_m_000004_576}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443466641724735573903185_0004}; taskId=attempt_202105141443466641724735573903185_0004_m_000004_576, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@50cf2f1c}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
21/05/14 14:44:28 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
21/05/14 14:44:28 INFO StagingCommitter: Starting: Task committer attempt_202105141443466641724735573903185_0004_m_000004_576: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443466641724735573903185_0004_m_000004_576
[2021-05-14 11:44:28,623] {docker.py:276} INFO - 21/05/14 14:44:28 INFO StagingCommitter: Task committer attempt_202105141443466641724735573903185_0004_m_000004_576: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443466641724735573903185_0004_m_000004_576 : duration 0:00.006s
[2021-05-14 11:44:29,503] {docker.py:276} INFO - 21/05/14 14:44:29 INFO StagingCommitter: Starting: Task committer attempt_202105141443461634226298497037682_0004_m_000001_573: needsTaskCommit() Task attempt_202105141443461634226298497037682_0004_m_000001_573
[2021-05-14 11:44:29,504] {docker.py:276} INFO - 21/05/14 14:44:29 INFO StagingCommitter: Task committer attempt_202105141443461634226298497037682_0004_m_000001_573: needsTaskCommit() Task attempt_202105141443461634226298497037682_0004_m_000001_573: duration 0:00.003s
[2021-05-14 11:44:29,507] {docker.py:276} INFO - 21/05/14 14:44:29 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443461634226298497037682_0004_m_000001_573
[2021-05-14 11:44:29,511] {docker.py:276} INFO - 21/05/14 14:44:29 INFO Executor: Finished task 1.0 in stage 4.0 (TID 573). 5192 bytes result sent to driver
[2021-05-14 11:44:29,513] {docker.py:276} INFO - 21/05/14 14:44:29 INFO TaskSetManager: Starting task 5.0 in stage 4.0 (TID 577) (f0b8ef7ba22f, executor driver, partition 5, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:44:29,514] {docker.py:276} INFO - 21/05/14 14:44:29 INFO TaskSetManager: Finished task 1.0 in stage 4.0 (TID 573) in 7731 ms on f0b8ef7ba22f (executor driver) (2/200)
[2021-05-14 11:44:29,517] {docker.py:276} INFO - 21/05/14 14:44:29 INFO Executor: Running task 5.0 in stage 4.0 (TID 577)
[2021-05-14 11:44:29,528] {docker.py:276} INFO - 21/05/14 14:44:29 INFO ShuffleBlockFetcherIterator: Getting 9 (63.8 KiB) non-empty blocks including 9 (63.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:44:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:44:29,546] {docker.py:276} INFO - 21/05/14 14:44:29 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:44:29 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/05/14 14:44:29 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
21/05/14 14:44:29 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443461928000865253780959_0004_m_000005_577, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443461928000865253780959_0004_m_000005_577}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443461928000865253780959_0004}; taskId=attempt_202105141443461928000865253780959_0004_m_000005_577, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@b73c774}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
[2021-05-14 11:44:29,546] {docker.py:276} INFO - 21/05/14 14:44:29 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
21/05/14 14:44:29 INFO StagingCommitter: Starting: Task committer attempt_202105141443461928000865253780959_0004_m_000005_577: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443461928000865253780959_0004_m_000005_577
[2021-05-14 11:44:29,550] {docker.py:276} INFO - 21/05/14 14:44:29 INFO StagingCommitter: Task committer attempt_202105141443461928000865253780959_0004_m_000005_577: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443461928000865253780959_0004_m_000005_577 : duration 0:00.003s
[2021-05-14 11:44:29,938] {docker.py:276} INFO - 21/05/14 14:44:29 INFO StagingCommitter: Starting: Task committer attempt_202105141443466923305017909352240_0004_m_000002_574: needsTaskCommit() Task attempt_202105141443466923305017909352240_0004_m_000002_574
21/05/14 14:44:29 INFO StagingCommitter: Task committer attempt_202105141443466923305017909352240_0004_m_000002_574: needsTaskCommit() Task attempt_202105141443466923305017909352240_0004_m_000002_574: duration 0:00.003s
21/05/14 14:44:29 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443466923305017909352240_0004_m_000002_574
[2021-05-14 11:44:29,941] {docker.py:276} INFO - 21/05/14 14:44:29 INFO Executor: Finished task 2.0 in stage 4.0 (TID 574). 5149 bytes result sent to driver
[2021-05-14 11:44:29,943] {docker.py:276} INFO - 21/05/14 14:44:29 INFO TaskSetManager: Starting task 6.0 in stage 4.0 (TID 578) (f0b8ef7ba22f, executor driver, partition 6, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:44:29,944] {docker.py:276} INFO - 21/05/14 14:44:29 INFO TaskSetManager: Finished task 2.0 in stage 4.0 (TID 574) in 8160 ms on f0b8ef7ba22f (executor driver) (3/200)
[2021-05-14 11:44:29,945] {docker.py:276} INFO - 21/05/14 14:44:29 INFO Executor: Running task 6.0 in stage 4.0 (TID 578)
[2021-05-14 11:44:29,956] {docker.py:276} INFO - 21/05/14 14:44:29 INFO ShuffleBlockFetcherIterator: Getting 9 (62.9 KiB) non-empty blocks including 9 (62.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:44:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:44:29,974] {docker.py:276} INFO - 21/05/14 14:44:29 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:44:29 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2021-05-14 11:44:29,975] {docker.py:276} INFO - 21/05/14 14:44:29 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
21/05/14 14:44:29 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443461504527203706339576_0004_m_000006_578, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443461504527203706339576_0004_m_000006_578}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443461504527203706339576_0004}; taskId=attempt_202105141443461504527203706339576_0004_m_000006_578, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@3f2122cb}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
[2021-05-14 11:44:29,975] {docker.py:276} INFO - 21/05/14 14:44:29 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
21/05/14 14:44:29 INFO StagingCommitter: Starting: Task committer attempt_202105141443461504527203706339576_0004_m_000006_578: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443461504527203706339576_0004_m_000006_578
[2021-05-14 11:44:29,979] {docker.py:276} INFO - 21/05/14 14:44:30 INFO StagingCommitter: Task committer attempt_202105141443461504527203706339576_0004_m_000006_578: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443461504527203706339576_0004_m_000006_578 : duration 0:00.004s
[2021-05-14 11:44:30,085] {docker.py:276} INFO - 21/05/14 14:44:30 INFO StagingCommitter: Starting: Task committer attempt_202105141443463017245660944353989_0004_m_000000_572: needsTaskCommit() Task attempt_202105141443463017245660944353989_0004_m_000000_572
[2021-05-14 11:44:30,085] {docker.py:276} INFO - 21/05/14 14:44:30 INFO StagingCommitter: Task committer attempt_202105141443463017245660944353989_0004_m_000000_572: needsTaskCommit() Task attempt_202105141443463017245660944353989_0004_m_000000_572: duration 0:00.002s
21/05/14 14:44:30 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443463017245660944353989_0004_m_000000_572
[2021-05-14 11:44:30,087] {docker.py:276} INFO - 21/05/14 14:44:30 INFO Executor: Finished task 0.0 in stage 4.0 (TID 572). 5149 bytes result sent to driver
[2021-05-14 11:44:30,088] {docker.py:276} INFO - 21/05/14 14:44:30 INFO TaskSetManager: Starting task 7.0 in stage 4.0 (TID 579) (f0b8ef7ba22f, executor driver, partition 7, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:44:30,089] {docker.py:276} INFO - 21/05/14 14:44:30 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 572) in 8309 ms on f0b8ef7ba22f (executor driver) (4/200)
21/05/14 14:44:30 INFO Executor: Running task 7.0 in stage 4.0 (TID 579)
[2021-05-14 11:44:30,100] {docker.py:276} INFO - 21/05/14 14:44:30 INFO ShuffleBlockFetcherIterator: Getting 9 (66.4 KiB) non-empty blocks including 9 (66.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:44:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:44:30,117] {docker.py:276} INFO - 21/05/14 14:44:30 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:44:30 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/05/14 14:44:30 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
[2021-05-14 11:44:30,118] {docker.py:276} INFO - 21/05/14 14:44:30 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_20210514144346546223842288496255_0004_m_000007_579, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_20210514144346546223842288496255_0004_m_000007_579}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_20210514144346546223842288496255_0004}; taskId=attempt_20210514144346546223842288496255_0004_m_000007_579, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@326e152e}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
21/05/14 14:44:30 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
21/05/14 14:44:30 INFO StagingCommitter: Starting: Task committer attempt_20210514144346546223842288496255_0004_m_000007_579: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_20210514144346546223842288496255_0004_m_000007_579
[2021-05-14 11:44:30,122] {docker.py:276} INFO - 21/05/14 14:44:30 INFO StagingCommitter: Task committer attempt_20210514144346546223842288496255_0004_m_000007_579: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_20210514144346546223842288496255_0004_m_000007_579 : duration 0:00.005s
[2021-05-14 11:44:36,090] {docker.py:276} INFO - 21/05/14 14:44:36 INFO StagingCommitter: Starting: Task committer attempt_202105141443461504527203706339576_0004_m_000006_578: needsTaskCommit() Task attempt_202105141443461504527203706339576_0004_m_000006_578
[2021-05-14 11:44:36,090] {docker.py:276} INFO - 21/05/14 14:44:36 INFO StagingCommitter: Task committer attempt_202105141443461504527203706339576_0004_m_000006_578: needsTaskCommit() Task attempt_202105141443461504527203706339576_0004_m_000006_578: duration 0:00.001s
21/05/14 14:44:36 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443461504527203706339576_0004_m_000006_578
[2021-05-14 11:44:36,092] {docker.py:276} INFO - 21/05/14 14:44:36 INFO Executor: Finished task 6.0 in stage 4.0 (TID 578). 5106 bytes result sent to driver
[2021-05-14 11:44:36,093] {docker.py:276} INFO - 21/05/14 14:44:36 INFO TaskSetManager: Starting task 8.0 in stage 4.0 (TID 580) (f0b8ef7ba22f, executor driver, partition 8, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:44:36,094] {docker.py:276} INFO - 21/05/14 14:44:36 INFO Executor: Running task 8.0 in stage 4.0 (TID 580)
[2021-05-14 11:44:36,095] {docker.py:276} INFO - 21/05/14 14:44:36 INFO TaskSetManager: Finished task 6.0 in stage 4.0 (TID 578) in 6159 ms on f0b8ef7ba22f (executor driver) (5/200)
[2021-05-14 11:44:36,104] {docker.py:276} INFO - 21/05/14 14:44:36 INFO ShuffleBlockFetcherIterator: Getting 9 (66.9 KiB) non-empty blocks including 9 (66.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
[2021-05-14 11:44:36,105] {docker.py:276} INFO - 21/05/14 14:44:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:44:36,125] {docker.py:276} INFO - 21/05/14 14:44:36 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:44:36 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2021-05-14 11:44:36,126] {docker.py:276} INFO - 21/05/14 14:44:36 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
21/05/14 14:44:36 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443465316589880112238106_0004_m_000008_580, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443465316589880112238106_0004_m_000008_580}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443465316589880112238106_0004}; taskId=attempt_202105141443465316589880112238106_0004_m_000008_580, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@39761132}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
21/05/14 14:44:36 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
21/05/14 14:44:36 INFO StagingCommitter: Starting: Task committer attempt_202105141443465316589880112238106_0004_m_000008_580: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443465316589880112238106_0004_m_000008_580
[2021-05-14 11:44:36,130] {docker.py:276} INFO - 21/05/14 14:44:36 INFO StagingCommitter: Task committer attempt_202105141443465316589880112238106_0004_m_000008_580: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443465316589880112238106_0004_m_000008_580 : duration 0:00.005s
[2021-05-14 11:44:36,206] {docker.py:276} INFO - 21/05/14 14:44:36 INFO StagingCommitter: Starting: Task committer attempt_202105141443466641724735573903185_0004_m_000004_576: needsTaskCommit() Task attempt_202105141443466641724735573903185_0004_m_000004_576
[2021-05-14 11:44:36,207] {docker.py:276} INFO - 21/05/14 14:44:36 INFO StagingCommitter: Task committer attempt_202105141443466641724735573903185_0004_m_000004_576: needsTaskCommit() Task attempt_202105141443466641724735573903185_0004_m_000004_576: duration 0:00.002s
[2021-05-14 11:44:36,207] {docker.py:276} INFO - 21/05/14 14:44:36 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443466641724735573903185_0004_m_000004_576
[2021-05-14 11:44:36,208] {docker.py:276} INFO - 21/05/14 14:44:36 INFO Executor: Finished task 4.0 in stage 4.0 (TID 576). 5106 bytes result sent to driver
[2021-05-14 11:44:36,210] {docker.py:276} INFO - 21/05/14 14:44:36 INFO TaskSetManager: Starting task 9.0 in stage 4.0 (TID 581) (f0b8ef7ba22f, executor driver, partition 9, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:44:36,211] {docker.py:276} INFO - 21/05/14 14:44:36 INFO Executor: Running task 9.0 in stage 4.0 (TID 581)
[2021-05-14 11:44:36,212] {docker.py:276} INFO - 21/05/14 14:44:36 INFO TaskSetManager: Finished task 4.0 in stage 4.0 (TID 576) in 7633 ms on f0b8ef7ba22f (executor driver) (6/200)
[2021-05-14 11:44:36,222] {docker.py:276} INFO - 21/05/14 14:44:36 INFO ShuffleBlockFetcherIterator: Getting 9 (66.7 KiB) non-empty blocks including 9 (66.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:44:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:44:36,239] {docker.py:276} INFO - 21/05/14 14:44:36 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:44:36 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2021-05-14 11:44:36,239] {docker.py:276} INFO - 21/05/14 14:44:36 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
21/05/14 14:44:36 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443461769529806964882363_0004_m_000009_581, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443461769529806964882363_0004_m_000009_581}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443461769529806964882363_0004}; taskId=attempt_202105141443461769529806964882363_0004_m_000009_581, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@6937561e}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
21/05/14 14:44:36 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
21/05/14 14:44:36 INFO StagingCommitter: Starting: Task committer attempt_202105141443461769529806964882363_0004_m_000009_581: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443461769529806964882363_0004_m_000009_581
[2021-05-14 11:44:36,244] {docker.py:276} INFO - 21/05/14 14:44:36 INFO StagingCommitter: Task committer attempt_202105141443461769529806964882363_0004_m_000009_581: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443461769529806964882363_0004_m_000009_581 : duration 0:00.005s
[2021-05-14 11:44:36,359] {docker.py:276} INFO - 21/05/14 14:44:36 INFO StagingCommitter: Starting: Task committer attempt_202105141443461928000865253780959_0004_m_000005_577: needsTaskCommit() Task attempt_202105141443461928000865253780959_0004_m_000005_577
[2021-05-14 11:44:36,360] {docker.py:276} INFO - 21/05/14 14:44:36 INFO StagingCommitter: Task committer attempt_202105141443461928000865253780959_0004_m_000005_577: needsTaskCommit() Task attempt_202105141443461928000865253780959_0004_m_000005_577: duration 0:00.001s
[2021-05-14 11:44:36,360] {docker.py:276} INFO - 21/05/14 14:44:36 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443461928000865253780959_0004_m_000005_577
[2021-05-14 11:44:36,361] {docker.py:276} INFO - 21/05/14 14:44:36 INFO Executor: Finished task 5.0 in stage 4.0 (TID 577). 5106 bytes result sent to driver
[2021-05-14 11:44:36,363] {docker.py:276} INFO - 21/05/14 14:44:36 INFO TaskSetManager: Starting task 10.0 in stage 4.0 (TID 582) (f0b8ef7ba22f, executor driver, partition 10, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:44:36,363] {docker.py:276} INFO - 21/05/14 14:44:36 INFO TaskSetManager: Finished task 5.0 in stage 4.0 (TID 577) in 6858 ms on f0b8ef7ba22f (executor driver) (7/200)
[2021-05-14 11:44:36,364] {docker.py:276} INFO - 21/05/14 14:44:36 INFO Executor: Running task 10.0 in stage 4.0 (TID 582)
[2021-05-14 11:44:36,372] {docker.py:276} INFO - 21/05/14 14:44:36 INFO ShuffleBlockFetcherIterator: Getting 9 (62.7 KiB) non-empty blocks including 9 (62.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:44:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:44:36,388] {docker.py:276} INFO - 21/05/14 14:44:36 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:44:36 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/05/14 14:44:36 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
[2021-05-14 11:44:36,388] {docker.py:276} INFO - 21/05/14 14:44:36 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443461051824457891851992_0004_m_000010_582, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443461051824457891851992_0004_m_000010_582}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443461051824457891851992_0004}; taskId=attempt_202105141443461051824457891851992_0004_m_000010_582, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@68dcc30a}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
21/05/14 14:44:36 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
[2021-05-14 11:44:36,388] {docker.py:276} INFO - 21/05/14 14:44:36 INFO StagingCommitter: Starting: Task committer attempt_202105141443461051824457891851992_0004_m_000010_582: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443461051824457891851992_0004_m_000010_582
[2021-05-14 11:44:36,392] {docker.py:276} INFO - 21/05/14 14:44:36 INFO StagingCommitter: Task committer attempt_202105141443461051824457891851992_0004_m_000010_582: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443461051824457891851992_0004_m_000010_582 : duration 0:00.004s
[2021-05-14 11:44:37,151] {docker.py:276} INFO - 21/05/14 14:44:37 INFO StagingCommitter: Starting: Task committer attempt_20210514144346546223842288496255_0004_m_000007_579: needsTaskCommit() Task attempt_20210514144346546223842288496255_0004_m_000007_579
[2021-05-14 11:44:37,151] {docker.py:276} INFO - 21/05/14 14:44:37 INFO StagingCommitter: Task committer attempt_20210514144346546223842288496255_0004_m_000007_579: needsTaskCommit() Task attempt_20210514144346546223842288496255_0004_m_000007_579: duration 0:00.002s
21/05/14 14:44:37 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_20210514144346546223842288496255_0004_m_000007_579
[2021-05-14 11:44:37,153] {docker.py:276} INFO - 21/05/14 14:44:37 INFO Executor: Finished task 7.0 in stage 4.0 (TID 579). 5106 bytes result sent to driver
[2021-05-14 11:44:37,154] {docker.py:276} INFO - 21/05/14 14:44:37 INFO TaskSetManager: Starting task 11.0 in stage 4.0 (TID 583) (f0b8ef7ba22f, executor driver, partition 11, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:44:37,156] {docker.py:276} INFO - 21/05/14 14:44:37 INFO TaskSetManager: Finished task 7.0 in stage 4.0 (TID 579) in 7076 ms on f0b8ef7ba22f (executor driver) (8/200)
[2021-05-14 11:44:37,157] {docker.py:276} INFO - 21/05/14 14:44:37 INFO Executor: Running task 11.0 in stage 4.0 (TID 583)
[2021-05-14 11:44:37,167] {docker.py:276} INFO - 21/05/14 14:44:37 INFO ShuffleBlockFetcherIterator: Getting 9 (64.3 KiB) non-empty blocks including 9 (64.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:44:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:44:37,182] {docker.py:276} INFO - 21/05/14 14:44:37 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:44:37 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/05/14 14:44:37 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
21/05/14 14:44:37 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443461718044583627523525_0004_m_000011_583, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443461718044583627523525_0004_m_000011_583}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443461718044583627523525_0004}; taskId=attempt_202105141443461718044583627523525_0004_m_000011_583, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@60855572}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
[2021-05-14 11:44:37,183] {docker.py:276} INFO - 21/05/14 14:44:37 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
21/05/14 14:44:37 INFO StagingCommitter: Starting: Task committer attempt_202105141443461718044583627523525_0004_m_000011_583: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443461718044583627523525_0004_m_000011_583
[2021-05-14 11:44:37,187] {docker.py:276} INFO - 21/05/14 14:44:37 INFO StagingCommitter: Task committer attempt_202105141443461718044583627523525_0004_m_000011_583: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443461718044583627523525_0004_m_000011_583 : duration 0:00.004s
[2021-05-14 11:44:42,707] {docker.py:276} INFO - 21/05/14 14:44:42 INFO StagingCommitter: Starting: Task committer attempt_202105141443465316589880112238106_0004_m_000008_580: needsTaskCommit() Task attempt_202105141443465316589880112238106_0004_m_000008_580
[2021-05-14 11:44:42,707] {docker.py:276} INFO - 21/05/14 14:44:42 INFO StagingCommitter: Task committer attempt_202105141443465316589880112238106_0004_m_000008_580: needsTaskCommit() Task attempt_202105141443465316589880112238106_0004_m_000008_580: duration 0:00.005s
[2021-05-14 11:44:42,708] {docker.py:276} INFO - 21/05/14 14:44:42 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443465316589880112238106_0004_m_000008_580
[2021-05-14 11:44:42,709] {docker.py:276} INFO - 21/05/14 14:44:42 INFO Executor: Finished task 8.0 in stage 4.0 (TID 580). 5106 bytes result sent to driver
[2021-05-14 11:44:42,711] {docker.py:276} INFO - 21/05/14 14:44:42 INFO TaskSetManager: Starting task 12.0 in stage 4.0 (TID 584) (f0b8ef7ba22f, executor driver, partition 12, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
21/05/14 14:44:42 INFO Executor: Running task 12.0 in stage 4.0 (TID 584)
21/05/14 14:44:42 INFO TaskSetManager: Finished task 8.0 in stage 4.0 (TID 580) in 6590 ms on f0b8ef7ba22f (executor driver) (9/200)
[2021-05-14 11:44:42,719] {docker.py:276} INFO - 21/05/14 14:44:42 INFO ShuffleBlockFetcherIterator: Getting 9 (67.6 KiB) non-empty blocks including 9 (67.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:44:42 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:44:42,738] {docker.py:276} INFO - 21/05/14 14:44:42 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:44:42 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/05/14 14:44:42 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
[2021-05-14 11:44:42,739] {docker.py:276} INFO - 21/05/14 14:44:42 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443464946780802470586933_0004_m_000012_584, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443464946780802470586933_0004_m_000012_584}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443464946780802470586933_0004}; taskId=attempt_202105141443464946780802470586933_0004_m_000012_584, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@251fc6c5}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
21/05/14 14:44:42 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
21/05/14 14:44:42 INFO StagingCommitter: Starting: Task committer attempt_202105141443464946780802470586933_0004_m_000012_584: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443464946780802470586933_0004_m_000012_584
[2021-05-14 11:44:42,742] {docker.py:276} INFO - 21/05/14 14:44:42 INFO StagingCommitter: Task committer attempt_202105141443464946780802470586933_0004_m_000012_584: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443464946780802470586933_0004_m_000012_584 : duration 0:00.003s
[2021-05-14 11:44:42,898] {docker.py:276} INFO - 21/05/14 14:44:42 INFO StagingCommitter: Starting: Task committer attempt_202105141443461051824457891851992_0004_m_000010_582: needsTaskCommit() Task attempt_202105141443461051824457891851992_0004_m_000010_582
[2021-05-14 11:44:42,899] {docker.py:276} INFO - 21/05/14 14:44:42 INFO StagingCommitter: Task committer attempt_202105141443461051824457891851992_0004_m_000010_582: needsTaskCommit() Task attempt_202105141443461051824457891851992_0004_m_000010_582: duration 0:00.002s
21/05/14 14:44:42 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443461051824457891851992_0004_m_000010_582
[2021-05-14 11:44:42,902] {docker.py:276} INFO - 21/05/14 14:44:42 INFO Executor: Finished task 10.0 in stage 4.0 (TID 582). 5106 bytes result sent to driver
[2021-05-14 11:44:42,903] {docker.py:276} INFO - 21/05/14 14:44:42 INFO TaskSetManager: Starting task 13.0 in stage 4.0 (TID 585) (f0b8ef7ba22f, executor driver, partition 13, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:44:42,904] {docker.py:276} INFO - 21/05/14 14:44:42 INFO TaskSetManager: Finished task 10.0 in stage 4.0 (TID 582) in 6514 ms on f0b8ef7ba22f (executor driver) (10/200)
21/05/14 14:44:42 INFO Executor: Running task 13.0 in stage 4.0 (TID 585)
[2021-05-14 11:44:42,914] {docker.py:276} INFO - 21/05/14 14:44:42 INFO ShuffleBlockFetcherIterator: Getting 9 (67.4 KiB) non-empty blocks including 9 (67.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:44:42 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:44:42,931] {docker.py:276} INFO - 21/05/14 14:44:42 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:44:42 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/05/14 14:44:42 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
21/05/14 14:44:42 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443463308335083026952048_0004_m_000013_585, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443463308335083026952048_0004_m_000013_585}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443463308335083026952048_0004}; taskId=attempt_202105141443463308335083026952048_0004_m_000013_585, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@34e05609}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
21/05/14 14:44:42 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
[2021-05-14 11:44:42,932] {docker.py:276} INFO - 21/05/14 14:44:42 INFO StagingCommitter: Starting: Task committer attempt_202105141443463308335083026952048_0004_m_000013_585: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443463308335083026952048_0004_m_000013_585
[2021-05-14 11:44:42,935] {docker.py:276} INFO - 21/05/14 14:44:42 INFO StagingCommitter: Task committer attempt_202105141443463308335083026952048_0004_m_000013_585: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443463308335083026952048_0004_m_000013_585 : duration 0:00.004s
[2021-05-14 11:44:43,357] {docker.py:276} INFO - 21/05/14 14:44:43 INFO StagingCommitter: Starting: Task committer attempt_202105141443461769529806964882363_0004_m_000009_581: needsTaskCommit() Task attempt_202105141443461769529806964882363_0004_m_000009_581
[2021-05-14 11:44:43,357] {docker.py:276} INFO - 21/05/14 14:44:43 INFO StagingCommitter: Task committer attempt_202105141443461769529806964882363_0004_m_000009_581: needsTaskCommit() Task attempt_202105141443461769529806964882363_0004_m_000009_581: duration 0:00.001s
21/05/14 14:44:43 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443461769529806964882363_0004_m_000009_581
[2021-05-14 11:44:43,359] {docker.py:276} INFO - 21/05/14 14:44:43 INFO Executor: Finished task 9.0 in stage 4.0 (TID 581). 5106 bytes result sent to driver
[2021-05-14 11:44:43,360] {docker.py:276} INFO - 21/05/14 14:44:43 INFO TaskSetManager: Starting task 14.0 in stage 4.0 (TID 586) (f0b8ef7ba22f, executor driver, partition 14, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:44:43,362] {docker.py:276} INFO - 21/05/14 14:44:43 INFO Executor: Running task 14.0 in stage 4.0 (TID 586)
[2021-05-14 11:44:43,363] {docker.py:276} INFO - 21/05/14 14:44:43 INFO TaskSetManager: Finished task 9.0 in stage 4.0 (TID 581) in 7127 ms on f0b8ef7ba22f (executor driver) (11/200)
[2021-05-14 11:44:43,371] {docker.py:276} INFO - 21/05/14 14:44:43 INFO ShuffleBlockFetcherIterator: Getting 9 (66.8 KiB) non-empty blocks including 9 (66.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:44:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:44:43,387] {docker.py:276} INFO - 21/05/14 14:44:43 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:44:43 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/05/14 14:44:43 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
21/05/14 14:44:43 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_20210514144346789339490640995026_0004_m_000014_586, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_20210514144346789339490640995026_0004_m_000014_586}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_20210514144346789339490640995026_0004}; taskId=attempt_20210514144346789339490640995026_0004_m_000014_586, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@75c5856}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
21/05/14 14:44:43 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
21/05/14 14:44:43 INFO StagingCommitter: Starting: Task committer attempt_20210514144346789339490640995026_0004_m_000014_586: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_20210514144346789339490640995026_0004_m_000014_586
[2021-05-14 11:44:43,392] {docker.py:276} INFO - 21/05/14 14:44:43 INFO StagingCommitter: Task committer attempt_20210514144346789339490640995026_0004_m_000014_586: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_20210514144346789339490640995026_0004_m_000014_586 : duration 0:00.004s
[2021-05-14 11:44:44,192] {docker.py:276} INFO - 21/05/14 14:44:44 INFO StagingCommitter: Starting: Task committer attempt_202105141443461718044583627523525_0004_m_000011_583: needsTaskCommit() Task attempt_202105141443461718044583627523525_0004_m_000011_583
[2021-05-14 11:44:44,193] {docker.py:276} INFO - 21/05/14 14:44:44 INFO StagingCommitter: Task committer attempt_202105141443461718044583627523525_0004_m_000011_583: needsTaskCommit() Task attempt_202105141443461718044583627523525_0004_m_000011_583: duration 0:00.002s
[2021-05-14 11:44:44,193] {docker.py:276} INFO - 21/05/14 14:44:44 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443461718044583627523525_0004_m_000011_583
[2021-05-14 11:44:44,195] {docker.py:276} INFO - 21/05/14 14:44:44 INFO Executor: Finished task 11.0 in stage 4.0 (TID 583). 5106 bytes result sent to driver
[2021-05-14 11:44:44,196] {docker.py:276} INFO - 21/05/14 14:44:44 INFO TaskSetManager: Starting task 15.0 in stage 4.0 (TID 587) (f0b8ef7ba22f, executor driver, partition 15, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:44:44,197] {docker.py:276} INFO - 21/05/14 14:44:44 INFO Executor: Running task 15.0 in stage 4.0 (TID 587)
[2021-05-14 11:44:44,198] {docker.py:276} INFO - 21/05/14 14:44:44 INFO TaskSetManager: Finished task 11.0 in stage 4.0 (TID 583) in 7017 ms on f0b8ef7ba22f (executor driver) (12/200)
[2021-05-14 11:44:44,223] {docker.py:276} INFO - 21/05/14 14:44:44 INFO ShuffleBlockFetcherIterator: Getting 9 (69.2 KiB) non-empty blocks including 9 (69.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:44:44 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:44:44,241] {docker.py:276} INFO - 21/05/14 14:44:44 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:44:44 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2021-05-14 11:44:44,241] {docker.py:276} INFO - 21/05/14 14:44:44 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
[2021-05-14 11:44:44,242] {docker.py:276} INFO - 21/05/14 14:44:44 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443466345971692833805871_0004_m_000015_587, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443466345971692833805871_0004_m_000015_587}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443466345971692833805871_0004}; taskId=attempt_202105141443466345971692833805871_0004_m_000015_587, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@d80e09e}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
21/05/14 14:44:44 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
[2021-05-14 11:44:44,242] {docker.py:276} INFO - 21/05/14 14:44:44 INFO StagingCommitter: Starting: Task committer attempt_202105141443466345971692833805871_0004_m_000015_587: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443466345971692833805871_0004_m_000015_587
[2021-05-14 11:44:44,248] {docker.py:276} INFO - 21/05/14 14:44:44 INFO StagingCommitter: Task committer attempt_202105141443466345971692833805871_0004_m_000015_587: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443466345971692833805871_0004_m_000015_587 : duration 0:00.006s
[2021-05-14 11:44:49,623] {docker.py:276} INFO - 21/05/14 14:44:49 INFO StagingCommitter: Starting: Task committer attempt_202105141443463308335083026952048_0004_m_000013_585: needsTaskCommit() Task attempt_202105141443463308335083026952048_0004_m_000013_585
[2021-05-14 11:44:49,624] {docker.py:276} INFO - 21/05/14 14:44:49 INFO StagingCommitter: Task committer attempt_202105141443463308335083026952048_0004_m_000013_585: needsTaskCommit() Task attempt_202105141443463308335083026952048_0004_m_000013_585: duration 0:00.002s
21/05/14 14:44:49 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443463308335083026952048_0004_m_000013_585
[2021-05-14 11:44:49,625] {docker.py:276} INFO - 21/05/14 14:44:49 INFO Executor: Finished task 13.0 in stage 4.0 (TID 585). 5149 bytes result sent to driver
[2021-05-14 11:44:49,626] {docker.py:276} INFO - 21/05/14 14:44:49 INFO TaskSetManager: Starting task 16.0 in stage 4.0 (TID 588) (f0b8ef7ba22f, executor driver, partition 16, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:44:49,627] {docker.py:276} INFO - 21/05/14 14:44:49 INFO Executor: Running task 16.0 in stage 4.0 (TID 588)
[2021-05-14 11:44:49,628] {docker.py:276} INFO - 21/05/14 14:44:49 INFO TaskSetManager: Finished task 13.0 in stage 4.0 (TID 585) in 6732 ms on f0b8ef7ba22f (executor driver) (13/200)
[2021-05-14 11:44:49,638] {docker.py:276} INFO - 21/05/14 14:44:49 INFO ShuffleBlockFetcherIterator: Getting 9 (67.8 KiB) non-empty blocks including 9 (67.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:44:49 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:44:49,654] {docker.py:276} INFO - 21/05/14 14:44:49 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:44:49 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/05/14 14:44:49 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
21/05/14 14:44:49 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443466818782230886037234_0004_m_000016_588, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443466818782230886037234_0004_m_000016_588}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443466818782230886037234_0004}; taskId=attempt_202105141443466818782230886037234_0004_m_000016_588, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@2303641d}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
[2021-05-14 11:44:49,654] {docker.py:276} INFO - 21/05/14 14:44:49 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
[2021-05-14 11:44:49,655] {docker.py:276} INFO - 21/05/14 14:44:49 INFO StagingCommitter: Starting: Task committer attempt_202105141443466818782230886037234_0004_m_000016_588: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443466818782230886037234_0004_m_000016_588
[2021-05-14 11:44:49,659] {docker.py:276} INFO - 21/05/14 14:44:49 INFO StagingCommitter: Task committer attempt_202105141443466818782230886037234_0004_m_000016_588: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443466818782230886037234_0004_m_000016_588 : duration 0:00.005s
[2021-05-14 11:44:49,681] {docker.py:276} INFO - 21/05/14 14:44:49 INFO StagingCommitter: Starting: Task committer attempt_202105141443464946780802470586933_0004_m_000012_584: needsTaskCommit() Task attempt_202105141443464946780802470586933_0004_m_000012_584
[2021-05-14 11:44:49,681] {docker.py:276} INFO - 21/05/14 14:44:49 INFO StagingCommitter: Task committer attempt_202105141443464946780802470586933_0004_m_000012_584: needsTaskCommit() Task attempt_202105141443464946780802470586933_0004_m_000012_584: duration 0:00.001s
[2021-05-14 11:44:49,682] {docker.py:276} INFO - 21/05/14 14:44:49 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443464946780802470586933_0004_m_000012_584
[2021-05-14 11:44:49,683] {docker.py:276} INFO - 21/05/14 14:44:49 INFO Executor: Finished task 12.0 in stage 4.0 (TID 584). 5149 bytes result sent to driver
[2021-05-14 11:44:49,684] {docker.py:276} INFO - 21/05/14 14:44:49 INFO TaskSetManager: Starting task 17.0 in stage 4.0 (TID 589) (f0b8ef7ba22f, executor driver, partition 17, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:44:49,684] {docker.py:276} INFO - 21/05/14 14:44:49 INFO Executor: Running task 17.0 in stage 4.0 (TID 589)
[2021-05-14 11:44:49,685] {docker.py:276} INFO - 21/05/14 14:44:49 INFO TaskSetManager: Finished task 12.0 in stage 4.0 (TID 584) in 6984 ms on f0b8ef7ba22f (executor driver) (14/200)
[2021-05-14 11:44:49,693] {docker.py:276} INFO - 21/05/14 14:44:49 INFO ShuffleBlockFetcherIterator: Getting 9 (71.0 KiB) non-empty blocks including 9 (71.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
[2021-05-14 11:44:49,693] {docker.py:276} INFO - 21/05/14 14:44:49 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:44:49,708] {docker.py:276} INFO - 21/05/14 14:44:49 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:44:49 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2021-05-14 11:44:49,709] {docker.py:276} INFO - 21/05/14 14:44:49 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
[2021-05-14 11:44:49,709] {docker.py:276} INFO - 21/05/14 14:44:49 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443468570666466307273452_0004_m_000017_589, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443468570666466307273452_0004_m_000017_589}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443468570666466307273452_0004}; taskId=attempt_202105141443468570666466307273452_0004_m_000017_589, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@5df103fd}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
21/05/14 14:44:49 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
[2021-05-14 11:44:49,710] {docker.py:276} INFO - 21/05/14 14:44:49 INFO StagingCommitter: Starting: Task committer attempt_202105141443468570666466307273452_0004_m_000017_589: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443468570666466307273452_0004_m_000017_589
[2021-05-14 11:44:49,714] {docker.py:276} INFO - 21/05/14 14:44:49 INFO StagingCommitter: Task committer attempt_202105141443468570666466307273452_0004_m_000017_589: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443468570666466307273452_0004_m_000017_589 : duration 0:00.004s
[2021-05-14 11:44:50,212] {docker.py:276} INFO - 21/05/14 14:44:50 INFO StagingCommitter: Starting: Task committer attempt_20210514144346789339490640995026_0004_m_000014_586: needsTaskCommit() Task attempt_20210514144346789339490640995026_0004_m_000014_586
[2021-05-14 11:44:50,213] {docker.py:276} INFO - 21/05/14 14:44:50 INFO StagingCommitter: Task committer attempt_20210514144346789339490640995026_0004_m_000014_586: needsTaskCommit() Task attempt_20210514144346789339490640995026_0004_m_000014_586: duration 0:00.002s
21/05/14 14:44:50 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_20210514144346789339490640995026_0004_m_000014_586
[2021-05-14 11:44:50,214] {docker.py:276} INFO - 21/05/14 14:44:50 INFO Executor: Finished task 14.0 in stage 4.0 (TID 586). 5149 bytes result sent to driver
[2021-05-14 11:44:50,216] {docker.py:276} INFO - 21/05/14 14:44:50 INFO TaskSetManager: Starting task 18.0 in stage 4.0 (TID 590) (f0b8ef7ba22f, executor driver, partition 18, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:44:50,218] {docker.py:276} INFO - 21/05/14 14:44:50 INFO Executor: Running task 18.0 in stage 4.0 (TID 590)
[2021-05-14 11:44:50,220] {docker.py:276} INFO - 21/05/14 14:44:50 INFO TaskSetManager: Finished task 14.0 in stage 4.0 (TID 586) in 6865 ms on f0b8ef7ba22f (executor driver) (15/200)
[2021-05-14 11:44:50,231] {docker.py:276} INFO - 21/05/14 14:44:50 INFO ShuffleBlockFetcherIterator: Getting 9 (66.3 KiB) non-empty blocks including 9 (66.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:44:50 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:44:50,253] {docker.py:276} INFO - 21/05/14 14:44:50 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:44:50 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/05/14 14:44:50 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
[2021-05-14 11:44:50,254] {docker.py:276} INFO - 21/05/14 14:44:50 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443463824117817888185363_0004_m_000018_590, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443463824117817888185363_0004_m_000018_590}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443463824117817888185363_0004}; taskId=attempt_202105141443463824117817888185363_0004_m_000018_590, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@180ce426}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
21/05/14 14:44:50 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
[2021-05-14 11:44:50,254] {docker.py:276} INFO - 21/05/14 14:44:50 INFO StagingCommitter: Starting: Task committer attempt_202105141443463824117817888185363_0004_m_000018_590: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443463824117817888185363_0004_m_000018_590
[2021-05-14 11:44:50,258] {docker.py:276} INFO - 21/05/14 14:44:50 INFO StagingCommitter: Task committer attempt_202105141443463824117817888185363_0004_m_000018_590: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443463824117817888185363_0004_m_000018_590 : duration 0:00.004s
[2021-05-14 11:44:51,618] {docker.py:276} INFO - 21/05/14 14:44:51 INFO StagingCommitter: Starting: Task committer attempt_202105141443466345971692833805871_0004_m_000015_587: needsTaskCommit() Task attempt_202105141443466345971692833805871_0004_m_000015_587
[2021-05-14 11:44:51,620] {docker.py:276} INFO - 21/05/14 14:44:51 INFO StagingCommitter: Task committer attempt_202105141443466345971692833805871_0004_m_000015_587: needsTaskCommit() Task attempt_202105141443466345971692833805871_0004_m_000015_587: duration 0:00.002s
21/05/14 14:44:51 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443466345971692833805871_0004_m_000015_587
[2021-05-14 11:44:51,620] {docker.py:276} INFO - 21/05/14 14:44:51 INFO Executor: Finished task 15.0 in stage 4.0 (TID 587). 5149 bytes result sent to driver
[2021-05-14 11:44:51,621] {docker.py:276} INFO - 21/05/14 14:44:51 INFO TaskSetManager: Starting task 19.0 in stage 4.0 (TID 591) (f0b8ef7ba22f, executor driver, partition 19, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:44:51,621] {docker.py:276} INFO - 21/05/14 14:44:51 INFO Executor: Running task 19.0 in stage 4.0 (TID 591)
[2021-05-14 11:44:51,623] {docker.py:276} INFO - 21/05/14 14:44:51 INFO TaskSetManager: Finished task 15.0 in stage 4.0 (TID 587) in 7436 ms on f0b8ef7ba22f (executor driver) (16/200)
[2021-05-14 11:44:51,634] {docker.py:276} INFO - 21/05/14 14:44:51 INFO ShuffleBlockFetcherIterator: Getting 9 (65.3 KiB) non-empty blocks including 9 (65.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:44:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:44:51,666] {docker.py:276} INFO - 21/05/14 14:44:51 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:44:51 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/05/14 14:44:51 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
21/05/14 14:44:51 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443463236217152555059416_0004_m_000019_591, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443463236217152555059416_0004_m_000019_591}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443463236217152555059416_0004}; taskId=attempt_202105141443463236217152555059416_0004_m_000019_591, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@41acc298}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
21/05/14 14:44:51 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
21/05/14 14:44:51 INFO StagingCommitter: Starting: Task committer attempt_202105141443463236217152555059416_0004_m_000019_591: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443463236217152555059416_0004_m_000019_591
[2021-05-14 11:44:51,674] {docker.py:276} INFO - 21/05/14 14:44:51 INFO StagingCommitter: Task committer attempt_202105141443463236217152555059416_0004_m_000019_591: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443463236217152555059416_0004_m_000019_591 : duration 0:00.009s
[2021-05-14 11:44:56,519] {docker.py:276} INFO - 21/05/14 14:44:56 INFO StagingCommitter: Starting: Task committer attempt_202105141443466818782230886037234_0004_m_000016_588: needsTaskCommit() Task attempt_202105141443466818782230886037234_0004_m_000016_588
[2021-05-14 11:44:56,520] {docker.py:276} INFO - 21/05/14 14:44:56 INFO StagingCommitter: Task committer attempt_202105141443466818782230886037234_0004_m_000016_588: needsTaskCommit() Task attempt_202105141443466818782230886037234_0004_m_000016_588: duration 0:00.002s
[2021-05-14 11:44:56,520] {docker.py:276} INFO - 21/05/14 14:44:56 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443466818782230886037234_0004_m_000016_588
[2021-05-14 11:44:56,522] {docker.py:276} INFO - 21/05/14 14:44:56 INFO Executor: Finished task 16.0 in stage 4.0 (TID 588). 5106 bytes result sent to driver
[2021-05-14 11:44:56,523] {docker.py:276} INFO - 21/05/14 14:44:56 INFO TaskSetManager: Starting task 20.0 in stage 4.0 (TID 592) (f0b8ef7ba22f, executor driver, partition 20, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:44:56,524] {docker.py:276} INFO - 21/05/14 14:44:56 INFO Executor: Running task 20.0 in stage 4.0 (TID 592)
21/05/14 14:44:56 INFO TaskSetManager: Finished task 16.0 in stage 4.0 (TID 588) in 6907 ms on f0b8ef7ba22f (executor driver) (17/200)
[2021-05-14 11:44:56,535] {docker.py:276} INFO - 21/05/14 14:44:56 INFO ShuffleBlockFetcherIterator: Getting 9 (62.2 KiB) non-empty blocks including 9 (62.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:44:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:44:56,553] {docker.py:276} INFO - 21/05/14 14:44:56 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:44:56 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/05/14 14:44:56 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
[2021-05-14 11:44:56,554] {docker.py:276} INFO - 21/05/14 14:44:56 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443463413573785123466617_0004_m_000020_592, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443463413573785123466617_0004_m_000020_592}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443463413573785123466617_0004}; taskId=attempt_202105141443463413573785123466617_0004_m_000020_592, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@53b2b4e6}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
21/05/14 14:44:56 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
21/05/14 14:44:56 INFO StagingCommitter: Starting: Task committer attempt_202105141443463413573785123466617_0004_m_000020_592: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443463413573785123466617_0004_m_000020_592
[2021-05-14 11:44:56,557] {docker.py:276} INFO - 21/05/14 14:44:56 INFO StagingCommitter: Task committer attempt_202105141443463413573785123466617_0004_m_000020_592: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443463413573785123466617_0004_m_000020_592 : duration 0:00.003s
[2021-05-14 11:44:56,951] {docker.py:276} INFO - 21/05/14 14:44:56 INFO StagingCommitter: Starting: Task committer attempt_202105141443463824117817888185363_0004_m_000018_590: needsTaskCommit() Task attempt_202105141443463824117817888185363_0004_m_000018_590
21/05/14 14:44:56 INFO StagingCommitter: Task committer attempt_202105141443463824117817888185363_0004_m_000018_590: needsTaskCommit() Task attempt_202105141443463824117817888185363_0004_m_000018_590: duration 0:00.003s
21/05/14 14:44:56 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443463824117817888185363_0004_m_000018_590
[2021-05-14 11:44:56,953] {docker.py:276} INFO - 21/05/14 14:44:56 INFO Executor: Finished task 18.0 in stage 4.0 (TID 590). 5106 bytes result sent to driver
[2021-05-14 11:44:56,954] {docker.py:276} INFO - 21/05/14 14:44:56 INFO TaskSetManager: Starting task 21.0 in stage 4.0 (TID 593) (f0b8ef7ba22f, executor driver, partition 21, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:44:56,956] {docker.py:276} INFO - 21/05/14 14:44:56 INFO Executor: Running task 21.0 in stage 4.0 (TID 593)
21/05/14 14:44:56 INFO TaskSetManager: Finished task 18.0 in stage 4.0 (TID 590) in 6749 ms on f0b8ef7ba22f (executor driver) (18/200)
[2021-05-14 11:44:56,966] {docker.py:276} INFO - 21/05/14 14:44:56 INFO ShuffleBlockFetcherIterator: Getting 9 (64.0 KiB) non-empty blocks including 9 (64.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:44:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:44:56,979] {docker.py:276} INFO - 21/05/14 14:44:56 INFO StagingCommitter: Starting: Task committer attempt_202105141443468570666466307273452_0004_m_000017_589: needsTaskCommit() Task attempt_202105141443468570666466307273452_0004_m_000017_589
[2021-05-14 11:44:56,979] {docker.py:276} INFO - 21/05/14 14:44:57 INFO StagingCommitter: Task committer attempt_202105141443468570666466307273452_0004_m_000017_589: needsTaskCommit() Task attempt_202105141443468570666466307273452_0004_m_000017_589: duration 0:00.001s
21/05/14 14:44:57 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443468570666466307273452_0004_m_000017_589
[2021-05-14 11:44:56,980] {docker.py:276} INFO - 21/05/14 14:44:57 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:44:57 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2021-05-14 11:44:56,980] {docker.py:276} INFO - 21/05/14 14:44:57 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
[2021-05-14 11:44:56,981] {docker.py:276} INFO - 21/05/14 14:44:57 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443465152871956447102218_0004_m_000021_593, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443465152871956447102218_0004_m_000021_593}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443465152871956447102218_0004}; taskId=attempt_202105141443465152871956447102218_0004_m_000021_593, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@6b7adcbb}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
21/05/14 14:44:57 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
[2021-05-14 11:44:56,981] {docker.py:276} INFO - 21/05/14 14:44:57 INFO StagingCommitter: Starting: Task committer attempt_202105141443465152871956447102218_0004_m_000021_593: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443465152871956447102218_0004_m_000021_593
[2021-05-14 11:44:56,982] {docker.py:276} INFO - 21/05/14 14:44:57 INFO Executor: Finished task 17.0 in stage 4.0 (TID 589). 5106 bytes result sent to driver
[2021-05-14 11:44:56,983] {docker.py:276} INFO - 21/05/14 14:44:57 INFO TaskSetManager: Starting task 22.0 in stage 4.0 (TID 594) (f0b8ef7ba22f, executor driver, partition 22, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:44:56,984] {docker.py:276} INFO - 21/05/14 14:44:57 INFO TaskSetManager: Finished task 17.0 in stage 4.0 (TID 589) in 7308 ms on f0b8ef7ba22f (executor driver) (19/200)
[2021-05-14 11:44:56,985] {docker.py:276} INFO - 21/05/14 14:44:57 INFO Executor: Running task 22.0 in stage 4.0 (TID 594)
[2021-05-14 11:44:56,988] {docker.py:276} INFO - 21/05/14 14:44:57 INFO StagingCommitter: Task committer attempt_202105141443465152871956447102218_0004_m_000021_593: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443465152871956447102218_0004_m_000021_593 : duration 0:00.007s
[2021-05-14 11:44:56,994] {docker.py:276} INFO - 21/05/14 14:44:57 INFO ShuffleBlockFetcherIterator: Getting 9 (63.6 KiB) non-empty blocks including 9 (63.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:44:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:44:57,007] {docker.py:276} INFO - 21/05/14 14:44:57 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:44:57 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/05/14 14:44:57 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
21/05/14 14:44:57 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443462555898216020784136_0004_m_000022_594, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443462555898216020784136_0004_m_000022_594}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443462555898216020784136_0004}; taskId=attempt_202105141443462555898216020784136_0004_m_000022_594, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@7ad16b5c}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
[2021-05-14 11:44:57,008] {docker.py:276} INFO - 21/05/14 14:44:57 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
21/05/14 14:44:57 INFO StagingCommitter: Starting: Task committer attempt_202105141443462555898216020784136_0004_m_000022_594: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443462555898216020784136_0004_m_000022_594
[2021-05-14 11:44:57,011] {docker.py:276} INFO - 21/05/14 14:44:57 INFO StagingCommitter: Task committer attempt_202105141443462555898216020784136_0004_m_000022_594: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443462555898216020784136_0004_m_000022_594 : duration 0:00.004s
[2021-05-14 11:44:58,937] {docker.py:276} INFO - 21/05/14 14:44:58 INFO StagingCommitter: Starting: Task committer attempt_202105141443463236217152555059416_0004_m_000019_591: needsTaskCommit() Task attempt_202105141443463236217152555059416_0004_m_000019_591
[2021-05-14 11:44:58,938] {docker.py:276} INFO - 21/05/14 14:44:58 INFO StagingCommitter: Task committer attempt_202105141443463236217152555059416_0004_m_000019_591: needsTaskCommit() Task attempt_202105141443463236217152555059416_0004_m_000019_591: duration 0:00.001s
21/05/14 14:44:58 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443463236217152555059416_0004_m_000019_591
[2021-05-14 11:44:58,939] {docker.py:276} INFO - 21/05/14 14:44:58 INFO Executor: Finished task 19.0 in stage 4.0 (TID 591). 5106 bytes result sent to driver
[2021-05-14 11:44:58,940] {docker.py:276} INFO - 21/05/14 14:44:58 INFO TaskSetManager: Starting task 23.0 in stage 4.0 (TID 595) (f0b8ef7ba22f, executor driver, partition 23, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:44:58,941] {docker.py:276} INFO - 21/05/14 14:44:58 INFO Executor: Running task 23.0 in stage 4.0 (TID 595)
[2021-05-14 11:44:58,941] {docker.py:276} INFO - 21/05/14 14:44:58 INFO TaskSetManager: Finished task 19.0 in stage 4.0 (TID 591) in 7329 ms on f0b8ef7ba22f (executor driver) (20/200)
[2021-05-14 11:44:58,952] {docker.py:276} INFO - 21/05/14 14:44:58 INFO ShuffleBlockFetcherIterator: Getting 9 (65.3 KiB) non-empty blocks including 9 (65.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:44:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:44:58,974] {docker.py:276} INFO - 21/05/14 14:44:58 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:44:58 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/05/14 14:44:58 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
21/05/14 14:44:58 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443461290635533571067765_0004_m_000023_595, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443461290635533571067765_0004_m_000023_595}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443461290635533571067765_0004}; taskId=attempt_202105141443461290635533571067765_0004_m_000023_595, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@51fadc88}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
21/05/14 14:44:58 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
[2021-05-14 11:44:58,974] {docker.py:276} INFO - 21/05/14 14:44:58 INFO StagingCommitter: Starting: Task committer attempt_202105141443461290635533571067765_0004_m_000023_595: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443461290635533571067765_0004_m_000023_595
[2021-05-14 11:44:58,979] {docker.py:276} INFO - 21/05/14 14:44:59 INFO StagingCommitter: Task committer attempt_202105141443461290635533571067765_0004_m_000023_595: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443461290635533571067765_0004_m_000023_595 : duration 0:00.005s
[2021-05-14 11:45:03,046] {docker.py:276} INFO - 21/05/14 14:45:03 INFO StagingCommitter: Starting: Task committer attempt_202105141443463413573785123466617_0004_m_000020_592: needsTaskCommit() Task attempt_202105141443463413573785123466617_0004_m_000020_592
[2021-05-14 11:45:03,048] {docker.py:276} INFO - 21/05/14 14:45:03 INFO StagingCommitter: Task committer attempt_202105141443463413573785123466617_0004_m_000020_592: needsTaskCommit() Task attempt_202105141443463413573785123466617_0004_m_000020_592: duration 0:00.004s
[2021-05-14 11:45:03,049] {docker.py:276} INFO - 21/05/14 14:45:03 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443463413573785123466617_0004_m_000020_592
[2021-05-14 11:45:03,051] {docker.py:276} INFO - 21/05/14 14:45:03 INFO Executor: Finished task 20.0 in stage 4.0 (TID 592). 5106 bytes result sent to driver
[2021-05-14 11:45:03,052] {docker.py:276} INFO - 21/05/14 14:45:03 INFO TaskSetManager: Starting task 24.0 in stage 4.0 (TID 596) (f0b8ef7ba22f, executor driver, partition 24, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:45:03,055] {docker.py:276} INFO - 21/05/14 14:45:03 INFO Executor: Running task 24.0 in stage 4.0 (TID 596)
21/05/14 14:45:03 INFO TaskSetManager: Finished task 20.0 in stage 4.0 (TID 592) in 6538 ms on f0b8ef7ba22f (executor driver) (21/200)
[2021-05-14 11:45:03,065] {docker.py:276} INFO - 21/05/14 14:45:03 INFO ShuffleBlockFetcherIterator: Getting 9 (64.6 KiB) non-empty blocks including 9 (64.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:45:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:45:03,078] {docker.py:276} INFO - 21/05/14 14:45:03 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:45:03 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2021-05-14 11:45:03,079] {docker.py:276} INFO - 21/05/14 14:45:03 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
21/05/14 14:45:03 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443468048959270363531891_0004_m_000024_596, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443468048959270363531891_0004_m_000024_596}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443468048959270363531891_0004}; taskId=attempt_202105141443468048959270363531891_0004_m_000024_596, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@64358846}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
21/05/14 14:45:03 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
[2021-05-14 11:45:03,079] {docker.py:276} INFO - 21/05/14 14:45:03 INFO StagingCommitter: Starting: Task committer attempt_202105141443468048959270363531891_0004_m_000024_596: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443468048959270363531891_0004_m_000024_596
[2021-05-14 11:45:03,082] {docker.py:276} INFO - 21/05/14 14:45:03 INFO StagingCommitter: Task committer attempt_202105141443468048959270363531891_0004_m_000024_596: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443468048959270363531891_0004_m_000024_596 : duration 0:00.004s
[2021-05-14 11:45:03,850] {docker.py:276} INFO - 21/05/14 14:45:03 INFO StagingCommitter: Starting: Task committer attempt_202105141443462555898216020784136_0004_m_000022_594: needsTaskCommit() Task attempt_202105141443462555898216020784136_0004_m_000022_594
[2021-05-14 11:45:03,851] {docker.py:276} INFO - 21/05/14 14:45:03 INFO StagingCommitter: Task committer attempt_202105141443462555898216020784136_0004_m_000022_594: needsTaskCommit() Task attempt_202105141443462555898216020784136_0004_m_000022_594: duration 0:00.003s
21/05/14 14:45:03 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443462555898216020784136_0004_m_000022_594
[2021-05-14 11:45:03,853] {docker.py:276} INFO - 21/05/14 14:45:03 INFO Executor: Finished task 22.0 in stage 4.0 (TID 594). 5106 bytes result sent to driver
[2021-05-14 11:45:03,853] {docker.py:276} INFO - 21/05/14 14:45:03 INFO TaskSetManager: Starting task 25.0 in stage 4.0 (TID 597) (f0b8ef7ba22f, executor driver, partition 25, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:45:03,854] {docker.py:276} INFO - 21/05/14 14:45:03 INFO Executor: Running task 25.0 in stage 4.0 (TID 597)
[2021-05-14 11:45:03,855] {docker.py:276} INFO - 21/05/14 14:45:03 INFO TaskSetManager: Finished task 22.0 in stage 4.0 (TID 594) in 6879 ms on f0b8ef7ba22f (executor driver) (22/200)
[2021-05-14 11:45:03,867] {docker.py:276} INFO - 21/05/14 14:45:03 INFO ShuffleBlockFetcherIterator: Getting 9 (65.3 KiB) non-empty blocks including 9 (65.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:45:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:45:03,881] {docker.py:276} INFO - 21/05/14 14:45:03 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:45:03 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/05/14 14:45:03 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
21/05/14 14:45:03 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443465296814008914204175_0004_m_000025_597, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443465296814008914204175_0004_m_000025_597}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443465296814008914204175_0004}; taskId=attempt_202105141443465296814008914204175_0004_m_000025_597, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@556d077b}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
21/05/14 14:45:03 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
[2021-05-14 11:45:03,882] {docker.py:276} INFO - 21/05/14 14:45:03 INFO StagingCommitter: Starting: Task committer attempt_202105141443465296814008914204175_0004_m_000025_597: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443465296814008914204175_0004_m_000025_597
[2021-05-14 11:45:03,886] {docker.py:276} INFO - 21/05/14 14:45:03 INFO StagingCommitter: Task committer attempt_202105141443465296814008914204175_0004_m_000025_597: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443465296814008914204175_0004_m_000025_597 : duration 0:00.004s
[2021-05-14 11:45:04,181] {docker.py:276} INFO - 21/05/14 14:45:04 INFO StagingCommitter: Starting: Task committer attempt_202105141443465152871956447102218_0004_m_000021_593: needsTaskCommit() Task attempt_202105141443465152871956447102218_0004_m_000021_593
[2021-05-14 11:45:04,182] {docker.py:276} INFO - 21/05/14 14:45:04 INFO StagingCommitter: Task committer attempt_202105141443465152871956447102218_0004_m_000021_593: needsTaskCommit() Task attempt_202105141443465152871956447102218_0004_m_000021_593: duration 0:00.002s
21/05/14 14:45:04 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443465152871956447102218_0004_m_000021_593
[2021-05-14 11:45:04,183] {docker.py:276} INFO - 21/05/14 14:45:04 INFO Executor: Finished task 21.0 in stage 4.0 (TID 593). 5106 bytes result sent to driver
[2021-05-14 11:45:04,184] {docker.py:276} INFO - 21/05/14 14:45:04 INFO TaskSetManager: Starting task 26.0 in stage 4.0 (TID 598) (f0b8ef7ba22f, executor driver, partition 26, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:45:04,185] {docker.py:276} INFO - 21/05/14 14:45:04 INFO TaskSetManager: Finished task 21.0 in stage 4.0 (TID 593) in 7240 ms on f0b8ef7ba22f (executor driver) (23/200)
[2021-05-14 11:45:04,186] {docker.py:276} INFO - 21/05/14 14:45:04 INFO Executor: Running task 26.0 in stage 4.0 (TID 598)
[2021-05-14 11:45:04,196] {docker.py:276} INFO - 21/05/14 14:45:04 INFO ShuffleBlockFetcherIterator: Getting 9 (68.6 KiB) non-empty blocks including 9 (68.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:45:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:45:04,210] {docker.py:276} INFO - 21/05/14 14:45:04 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2021-05-14 11:45:04,211] {docker.py:276} INFO - 21/05/14 14:45:04 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/05/14 14:45:04 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
21/05/14 14:45:04 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443465729928693513923001_0004_m_000026_598, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443465729928693513923001_0004_m_000026_598}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443465729928693513923001_0004}; taskId=attempt_202105141443465729928693513923001_0004_m_000026_598, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@7757ff3a}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
[2021-05-14 11:45:04,211] {docker.py:276} INFO - 21/05/14 14:45:04 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
[2021-05-14 11:45:04,212] {docker.py:276} INFO - 21/05/14 14:45:04 INFO StagingCommitter: Starting: Task committer attempt_202105141443465729928693513923001_0004_m_000026_598: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443465729928693513923001_0004_m_000026_598
[2021-05-14 11:45:04,215] {docker.py:276} INFO - 21/05/14 14:45:04 INFO StagingCommitter: Task committer attempt_202105141443465729928693513923001_0004_m_000026_598: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443465729928693513923001_0004_m_000026_598 : duration 0:00.004s
[2021-05-14 11:45:05,929] {docker.py:276} INFO - 21/05/14 14:45:05 INFO StagingCommitter: Starting: Task committer attempt_202105141443461290635533571067765_0004_m_000023_595: needsTaskCommit() Task attempt_202105141443461290635533571067765_0004_m_000023_595
[2021-05-14 11:45:05,930] {docker.py:276} INFO - 21/05/14 14:45:05 INFO StagingCommitter: Task committer attempt_202105141443461290635533571067765_0004_m_000023_595: needsTaskCommit() Task attempt_202105141443461290635533571067765_0004_m_000023_595: duration 0:00.003s
21/05/14 14:45:05 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443461290635533571067765_0004_m_000023_595
[2021-05-14 11:45:05,933] {docker.py:276} INFO - 21/05/14 14:45:05 INFO Executor: Finished task 23.0 in stage 4.0 (TID 595). 5106 bytes result sent to driver
[2021-05-14 11:45:05,934] {docker.py:276} INFO - 21/05/14 14:45:05 INFO TaskSetManager: Starting task 27.0 in stage 4.0 (TID 599) (f0b8ef7ba22f, executor driver, partition 27, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:45:05,936] {docker.py:276} INFO - 21/05/14 14:45:05 INFO TaskSetManager: Finished task 23.0 in stage 4.0 (TID 595) in 7004 ms on f0b8ef7ba22f (executor driver) (24/200)
21/05/14 14:45:05 INFO Executor: Running task 27.0 in stage 4.0 (TID 599)
[2021-05-14 11:45:05,946] {docker.py:276} INFO - 21/05/14 14:45:05 INFO ShuffleBlockFetcherIterator: Getting 9 (63.1 KiB) non-empty blocks including 9 (63.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:45:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:45:05,959] {docker.py:276} INFO - 21/05/14 14:45:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:45:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/05/14 14:45:05 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
21/05/14 14:45:05 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443463423688197542189896_0004_m_000027_599, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443463423688197542189896_0004_m_000027_599}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443463423688197542189896_0004}; taskId=attempt_202105141443463423688197542189896_0004_m_000027_599, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@2479c87b}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
21/05/14 14:45:05 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
[2021-05-14 11:45:05,960] {docker.py:276} INFO - 21/05/14 14:45:05 INFO StagingCommitter: Starting: Task committer attempt_202105141443463423688197542189896_0004_m_000027_599: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443463423688197542189896_0004_m_000027_599
[2021-05-14 11:45:05,963] {docker.py:276} INFO - 21/05/14 14:45:05 INFO StagingCommitter: Task committer attempt_202105141443463423688197542189896_0004_m_000027_599: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443463423688197542189896_0004_m_000027_599 : duration 0:00.004s
[2021-05-14 11:45:09,342] {docker.py:276} INFO - 21/05/14 14:45:09 INFO StagingCommitter: Starting: Task committer attempt_202105141443468048959270363531891_0004_m_000024_596: needsTaskCommit() Task attempt_202105141443468048959270363531891_0004_m_000024_596
21/05/14 14:45:09 INFO StagingCommitter: Task committer attempt_202105141443468048959270363531891_0004_m_000024_596: needsTaskCommit() Task attempt_202105141443468048959270363531891_0004_m_000024_596: duration 0:00.003s
[2021-05-14 11:45:09,343] {docker.py:276} INFO - 21/05/14 14:45:09 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443468048959270363531891_0004_m_000024_596
[2021-05-14 11:45:09,344] {docker.py:276} INFO - 21/05/14 14:45:09 INFO Executor: Finished task 24.0 in stage 4.0 (TID 596). 5149 bytes result sent to driver
[2021-05-14 11:45:09,345] {docker.py:276} INFO - 21/05/14 14:45:09 INFO TaskSetManager: Starting task 28.0 in stage 4.0 (TID 600) (f0b8ef7ba22f, executor driver, partition 28, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:45:09,347] {docker.py:276} INFO - 21/05/14 14:45:09 INFO TaskSetManager: Finished task 24.0 in stage 4.0 (TID 596) in 6267 ms on f0b8ef7ba22f (executor driver) (25/200)
[2021-05-14 11:45:09,347] {docker.py:276} INFO - 21/05/14 14:45:09 INFO Executor: Running task 28.0 in stage 4.0 (TID 600)
[2021-05-14 11:45:09,357] {docker.py:276} INFO - 21/05/14 14:45:09 INFO ShuffleBlockFetcherIterator: Getting 9 (62.7 KiB) non-empty blocks including 9 (62.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
[2021-05-14 11:45:09,358] {docker.py:276} INFO - 21/05/14 14:45:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:45:09,370] {docker.py:276} INFO - 21/05/14 14:45:09 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:45:09 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/05/14 14:45:09 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
[2021-05-14 11:45:09,371] {docker.py:276} INFO - 21/05/14 14:45:09 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443466139445615022014244_0004_m_000028_600, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443466139445615022014244_0004_m_000028_600}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443466139445615022014244_0004}; taskId=attempt_202105141443466139445615022014244_0004_m_000028_600, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@4aeacdac}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
21/05/14 14:45:09 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
[2021-05-14 11:45:09,371] {docker.py:276} INFO - 21/05/14 14:45:09 INFO StagingCommitter: Starting: Task committer attempt_202105141443466139445615022014244_0004_m_000028_600: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443466139445615022014244_0004_m_000028_600
[2021-05-14 11:45:09,375] {docker.py:276} INFO - 21/05/14 14:45:09 INFO StagingCommitter: Task committer attempt_202105141443466139445615022014244_0004_m_000028_600: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443466139445615022014244_0004_m_000028_600 : duration 0:00.005s
[2021-05-14 11:45:10,932] {docker.py:276} INFO - 21/05/14 14:45:10 INFO StagingCommitter: Starting: Task committer attempt_202105141443465296814008914204175_0004_m_000025_597: needsTaskCommit() Task attempt_202105141443465296814008914204175_0004_m_000025_597
[2021-05-14 11:45:10,933] {docker.py:276} INFO - 21/05/14 14:45:10 INFO StagingCommitter: Task committer attempt_202105141443465296814008914204175_0004_m_000025_597: needsTaskCommit() Task attempt_202105141443465296814008914204175_0004_m_000025_597: duration 0:00.001s
21/05/14 14:45:10 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443465296814008914204175_0004_m_000025_597
[2021-05-14 11:45:10,933] {docker.py:276} INFO - 21/05/14 14:45:10 INFO Executor: Finished task 25.0 in stage 4.0 (TID 597). 5149 bytes result sent to driver
[2021-05-14 11:45:10,934] {docker.py:276} INFO - 21/05/14 14:45:10 INFO TaskSetManager: Starting task 29.0 in stage 4.0 (TID 601) (f0b8ef7ba22f, executor driver, partition 29, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:45:10,935] {docker.py:276} INFO - 21/05/14 14:45:10 INFO TaskSetManager: Finished task 25.0 in stage 4.0 (TID 597) in 7056 ms on f0b8ef7ba22f (executor driver) (26/200)
[2021-05-14 11:45:10,936] {docker.py:276} INFO - 21/05/14 14:45:10 INFO Executor: Running task 29.0 in stage 4.0 (TID 601)
[2021-05-14 11:45:10,944] {docker.py:276} INFO - 21/05/14 14:45:10 INFO ShuffleBlockFetcherIterator: Getting 9 (69.4 KiB) non-empty blocks including 9 (69.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
[2021-05-14 11:45:10,944] {docker.py:276} INFO - 21/05/14 14:45:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:45:10,956] {docker.py:276} INFO - 21/05/14 14:45:10 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:45:10 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/05/14 14:45:10 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
[2021-05-14 11:45:10,957] {docker.py:276} INFO - 21/05/14 14:45:10 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443468603244092630634050_0004_m_000029_601, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443468603244092630634050_0004_m_000029_601}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443468603244092630634050_0004}; taskId=attempt_202105141443468603244092630634050_0004_m_000029_601, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@223eb0d0}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
21/05/14 14:45:10 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
[2021-05-14 11:45:10,957] {docker.py:276} INFO - 21/05/14 14:45:10 INFO StagingCommitter: Starting: Task committer attempt_202105141443468603244092630634050_0004_m_000029_601: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443468603244092630634050_0004_m_000029_601
[2021-05-14 11:45:10,961] {docker.py:276} INFO - 21/05/14 14:45:10 INFO StagingCommitter: Task committer attempt_202105141443468603244092630634050_0004_m_000029_601: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443468603244092630634050_0004_m_000029_601 : duration 0:00.004s
[2021-05-14 11:45:11,302] {docker.py:276} INFO - 21/05/14 14:45:11 INFO StagingCommitter: Starting: Task committer attempt_202105141443465729928693513923001_0004_m_000026_598: needsTaskCommit() Task attempt_202105141443465729928693513923001_0004_m_000026_598
21/05/14 14:45:11 INFO StagingCommitter: Task committer attempt_202105141443465729928693513923001_0004_m_000026_598: needsTaskCommit() Task attempt_202105141443465729928693513923001_0004_m_000026_598: duration 0:00.002s
21/05/14 14:45:11 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443465729928693513923001_0004_m_000026_598
[2021-05-14 11:45:11,303] {docker.py:276} INFO - 21/05/14 14:45:11 INFO Executor: Finished task 26.0 in stage 4.0 (TID 598). 5149 bytes result sent to driver
[2021-05-14 11:45:11,305] {docker.py:276} INFO - 21/05/14 14:45:11 INFO TaskSetManager: Starting task 30.0 in stage 4.0 (TID 602) (f0b8ef7ba22f, executor driver, partition 30, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:45:11,307] {docker.py:276} INFO - 21/05/14 14:45:11 INFO Executor: Running task 30.0 in stage 4.0 (TID 602)
21/05/14 14:45:11 INFO TaskSetManager: Finished task 26.0 in stage 4.0 (TID 598) in 7096 ms on f0b8ef7ba22f (executor driver) (27/200)
[2021-05-14 11:45:11,317] {docker.py:276} INFO - 21/05/14 14:45:11 INFO ShuffleBlockFetcherIterator: Getting 9 (65.6 KiB) non-empty blocks including 9 (65.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:45:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:45:11,327] {docker.py:276} INFO - 21/05/14 14:45:11 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:45:11 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/05/14 14:45:11 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
21/05/14 14:45:11 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443466666905729285289571_0004_m_000030_602, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443466666905729285289571_0004_m_000030_602}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443466666905729285289571_0004}; taskId=attempt_202105141443466666905729285289571_0004_m_000030_602, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@25c88ce3}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
21/05/14 14:45:11 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
[2021-05-14 11:45:11,328] {docker.py:276} INFO - 21/05/14 14:45:11 INFO StagingCommitter: Starting: Task committer attempt_202105141443466666905729285289571_0004_m_000030_602: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443466666905729285289571_0004_m_000030_602
[2021-05-14 11:45:11,332] {docker.py:276} INFO - 21/05/14 14:45:11 INFO StagingCommitter: Task committer attempt_202105141443466666905729285289571_0004_m_000030_602: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443466666905729285289571_0004_m_000030_602 : duration 0:00.005s
[2021-05-14 11:45:12,909] {docker.py:276} INFO - 21/05/14 14:45:12 INFO StagingCommitter: Starting: Task committer attempt_202105141443463423688197542189896_0004_m_000027_599: needsTaskCommit() Task attempt_202105141443463423688197542189896_0004_m_000027_599
21/05/14 14:45:12 INFO StagingCommitter: Task committer attempt_202105141443463423688197542189896_0004_m_000027_599: needsTaskCommit() Task attempt_202105141443463423688197542189896_0004_m_000027_599: duration 0:00.003s
[2021-05-14 11:45:12,910] {docker.py:276} INFO - 21/05/14 14:45:12 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443463423688197542189896_0004_m_000027_599
[2021-05-14 11:45:12,912] {docker.py:276} INFO - 21/05/14 14:45:12 INFO Executor: Finished task 27.0 in stage 4.0 (TID 599). 5149 bytes result sent to driver
[2021-05-14 11:45:12,914] {docker.py:276} INFO - 21/05/14 14:45:12 INFO TaskSetManager: Starting task 31.0 in stage 4.0 (TID 603) (f0b8ef7ba22f, executor driver, partition 31, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:45:12,914] {docker.py:276} INFO - 21/05/14 14:45:12 INFO Executor: Running task 31.0 in stage 4.0 (TID 603)
[2021-05-14 11:45:12,915] {docker.py:276} INFO - 21/05/14 14:45:12 INFO TaskSetManager: Finished task 27.0 in stage 4.0 (TID 599) in 6954 ms on f0b8ef7ba22f (executor driver) (28/200)
[2021-05-14 11:45:12,924] {docker.py:276} INFO - 21/05/14 14:45:12 INFO ShuffleBlockFetcherIterator: Getting 9 (65.4 KiB) non-empty blocks including 9 (65.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:45:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:45:12,936] {docker.py:276} INFO - 21/05/14 14:45:12 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2021-05-14 11:45:12,936] {docker.py:276} INFO - 21/05/14 14:45:12 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2021-05-14 11:45:12,937] {docker.py:276} INFO - 21/05/14 14:45:12 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
21/05/14 14:45:12 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443466025707383822116112_0004_m_000031_603, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443466025707383822116112_0004_m_000031_603}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443466025707383822116112_0004}; taskId=attempt_202105141443466025707383822116112_0004_m_000031_603, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@5119b509}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
[2021-05-14 11:45:12,937] {docker.py:276} INFO - 21/05/14 14:45:12 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
[2021-05-14 11:45:12,937] {docker.py:276} INFO - 21/05/14 14:45:12 INFO StagingCommitter: Starting: Task committer attempt_202105141443466025707383822116112_0004_m_000031_603: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443466025707383822116112_0004_m_000031_603
[2021-05-14 11:45:12,941] {docker.py:276} INFO - 21/05/14 14:45:12 INFO StagingCommitter: Task committer attempt_202105141443466025707383822116112_0004_m_000031_603: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443466025707383822116112_0004_m_000031_603 : duration 0:00.004s
[2021-05-14 11:45:16,031] {docker.py:276} INFO - 21/05/14 14:45:16 INFO StagingCommitter: Starting: Task committer attempt_202105141443466139445615022014244_0004_m_000028_600: needsTaskCommit() Task attempt_202105141443466139445615022014244_0004_m_000028_600
[2021-05-14 11:45:16,032] {docker.py:276} INFO - 21/05/14 14:45:16 INFO StagingCommitter: Task committer attempt_202105141443466139445615022014244_0004_m_000028_600: needsTaskCommit() Task attempt_202105141443466139445615022014244_0004_m_000028_600: duration 0:00.002s
21/05/14 14:45:16 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443466139445615022014244_0004_m_000028_600
[2021-05-14 11:45:16,034] {docker.py:276} INFO - 21/05/14 14:45:16 INFO Executor: Finished task 28.0 in stage 4.0 (TID 600). 5106 bytes result sent to driver
[2021-05-14 11:45:16,035] {docker.py:276} INFO - 21/05/14 14:45:16 INFO TaskSetManager: Starting task 32.0 in stage 4.0 (TID 604) (f0b8ef7ba22f, executor driver, partition 32, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:45:16,037] {docker.py:276} INFO - 21/05/14 14:45:16 INFO Executor: Running task 32.0 in stage 4.0 (TID 604)
[2021-05-14 11:45:16,038] {docker.py:276} INFO - 21/05/14 14:45:16 INFO TaskSetManager: Finished task 28.0 in stage 4.0 (TID 600) in 6701 ms on f0b8ef7ba22f (executor driver) (29/200)
[2021-05-14 11:45:16,048] {docker.py:276} INFO - 21/05/14 14:45:16 INFO ShuffleBlockFetcherIterator: Getting 9 (64.7 KiB) non-empty blocks including 9 (64.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:45:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:45:16,059] {docker.py:276} INFO - 21/05/14 14:45:16 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:45:16 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/05/14 14:45:16 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
[2021-05-14 11:45:16,060] {docker.py:276} INFO - 21/05/14 14:45:16 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443467027710939813995425_0004_m_000032_604, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443467027710939813995425_0004_m_000032_604}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443467027710939813995425_0004}; taskId=attempt_202105141443467027710939813995425_0004_m_000032_604, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@57e88449}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
21/05/14 14:45:16 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
21/05/14 14:45:16 INFO StagingCommitter: Starting: Task committer attempt_202105141443467027710939813995425_0004_m_000032_604: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443467027710939813995425_0004_m_000032_604
[2021-05-14 11:45:16,065] {docker.py:276} INFO - 21/05/14 14:45:16 INFO StagingCommitter: Task committer attempt_202105141443467027710939813995425_0004_m_000032_604: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443467027710939813995425_0004_m_000032_604 : duration 0:00.005s
[2021-05-14 11:45:17,845] {docker.py:276} INFO - 21/05/14 14:45:17 INFO StagingCommitter: Starting: Task committer attempt_202105141443468603244092630634050_0004_m_000029_601: needsTaskCommit() Task attempt_202105141443468603244092630634050_0004_m_000029_601
[2021-05-14 11:45:17,846] {docker.py:276} INFO - 21/05/14 14:45:17 INFO StagingCommitter: Task committer attempt_202105141443468603244092630634050_0004_m_000029_601: needsTaskCommit() Task attempt_202105141443468603244092630634050_0004_m_000029_601: duration 0:00.003s
[2021-05-14 11:45:17,846] {docker.py:276} INFO - 21/05/14 14:45:17 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443468603244092630634050_0004_m_000029_601
[2021-05-14 11:45:17,848] {docker.py:276} INFO - 21/05/14 14:45:17 INFO Executor: Finished task 29.0 in stage 4.0 (TID 601). 5106 bytes result sent to driver
[2021-05-14 11:45:17,849] {docker.py:276} INFO - 21/05/14 14:45:17 INFO TaskSetManager: Starting task 33.0 in stage 4.0 (TID 605) (f0b8ef7ba22f, executor driver, partition 33, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:45:17,850] {docker.py:276} INFO - 21/05/14 14:45:17 INFO TaskSetManager: Finished task 29.0 in stage 4.0 (TID 601) in 6924 ms on f0b8ef7ba22f (executor driver) (30/200)
[2021-05-14 11:45:17,852] {docker.py:276} INFO - 21/05/14 14:45:17 INFO Executor: Running task 33.0 in stage 4.0 (TID 605)
[2021-05-14 11:45:17,861] {docker.py:276} INFO - 21/05/14 14:45:17 INFO ShuffleBlockFetcherIterator: Getting 9 (64.2 KiB) non-empty blocks including 9 (64.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:45:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:45:17,871] {docker.py:276} INFO - 21/05/14 14:45:17 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2021-05-14 11:45:17,872] {docker.py:276} INFO - 21/05/14 14:45:17 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2021-05-14 11:45:17,873] {docker.py:276} INFO - 21/05/14 14:45:17 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
[2021-05-14 11:45:17,873] {docker.py:276} INFO - 21/05/14 14:45:17 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_20210514144346863704130321345624_0004_m_000033_605, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_20210514144346863704130321345624_0004_m_000033_605}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_20210514144346863704130321345624_0004}; taskId=attempt_20210514144346863704130321345624_0004_m_000033_605, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@716b6008}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
[2021-05-14 11:45:17,873] {docker.py:276} INFO - 21/05/14 14:45:17 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
21/05/14 14:45:17 INFO StagingCommitter: Starting: Task committer attempt_20210514144346863704130321345624_0004_m_000033_605: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_20210514144346863704130321345624_0004_m_000033_605
[2021-05-14 11:45:17,879] {docker.py:276} INFO - 21/05/14 14:45:17 INFO StagingCommitter: Task committer attempt_20210514144346863704130321345624_0004_m_000033_605: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_20210514144346863704130321345624_0004_m_000033_605 : duration 0:00.005s
[2021-05-14 11:45:18,214] {docker.py:276} INFO - 21/05/14 14:45:18 INFO StagingCommitter: Starting: Task committer attempt_202105141443466666905729285289571_0004_m_000030_602: needsTaskCommit() Task attempt_202105141443466666905729285289571_0004_m_000030_602
[2021-05-14 11:45:18,214] {docker.py:276} INFO - 21/05/14 14:45:18 INFO StagingCommitter: Task committer attempt_202105141443466666905729285289571_0004_m_000030_602: needsTaskCommit() Task attempt_202105141443466666905729285289571_0004_m_000030_602: duration 0:00.003s
21/05/14 14:45:18 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443466666905729285289571_0004_m_000030_602
[2021-05-14 11:45:18,217] {docker.py:276} INFO - 21/05/14 14:45:18 INFO Executor: Finished task 30.0 in stage 4.0 (TID 602). 5106 bytes result sent to driver
[2021-05-14 11:45:18,219] {docker.py:276} INFO - 21/05/14 14:45:18 INFO TaskSetManager: Starting task 34.0 in stage 4.0 (TID 606) (f0b8ef7ba22f, executor driver, partition 34, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:45:18,221] {docker.py:276} INFO - 21/05/14 14:45:18 INFO Executor: Running task 34.0 in stage 4.0 (TID 606)
[2021-05-14 11:45:18,221] {docker.py:276} INFO - 21/05/14 14:45:18 INFO TaskSetManager: Finished task 30.0 in stage 4.0 (TID 602) in 6923 ms on f0b8ef7ba22f (executor driver) (31/200)
[2021-05-14 11:45:18,231] {docker.py:276} INFO - 21/05/14 14:45:18 INFO ShuffleBlockFetcherIterator: Getting 9 (68.3 KiB) non-empty blocks including 9 (68.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:45:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:45:18,240] {docker.py:276} INFO - 21/05/14 14:45:18 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:45:18 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/05/14 14:45:18 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
[2021-05-14 11:45:18,241] {docker.py:276} INFO - 21/05/14 14:45:18 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443465203222104036797590_0004_m_000034_606, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443465203222104036797590_0004_m_000034_606}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443465203222104036797590_0004}; taskId=attempt_202105141443465203222104036797590_0004_m_000034_606, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@69d5213d}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
21/05/14 14:45:18 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
21/05/14 14:45:18 INFO StagingCommitter: Starting: Task committer attempt_202105141443465203222104036797590_0004_m_000034_606: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443465203222104036797590_0004_m_000034_606
[2021-05-14 11:45:18,246] {docker.py:276} INFO - 21/05/14 14:45:18 INFO StagingCommitter: Task committer attempt_202105141443465203222104036797590_0004_m_000034_606: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443465203222104036797590_0004_m_000034_606 : duration 0:00.005s
[2021-05-14 11:45:19,992] {docker.py:276} INFO - 21/05/14 14:45:20 INFO StagingCommitter: Starting: Task committer attempt_202105141443466025707383822116112_0004_m_000031_603: needsTaskCommit() Task attempt_202105141443466025707383822116112_0004_m_000031_603
[2021-05-14 11:45:19,993] {docker.py:276} INFO - 21/05/14 14:45:20 INFO StagingCommitter: Task committer attempt_202105141443466025707383822116112_0004_m_000031_603: needsTaskCommit() Task attempt_202105141443466025707383822116112_0004_m_000031_603: duration 0:00.003s
[2021-05-14 11:45:19,994] {docker.py:276} INFO - 21/05/14 14:45:20 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443466025707383822116112_0004_m_000031_603
[2021-05-14 11:45:19,996] {docker.py:276} INFO - 21/05/14 14:45:20 INFO Executor: Finished task 31.0 in stage 4.0 (TID 603). 5106 bytes result sent to driver
[2021-05-14 11:45:19,999] {docker.py:276} INFO - 21/05/14 14:45:20 INFO TaskSetManager: Starting task 35.0 in stage 4.0 (TID 607) (f0b8ef7ba22f, executor driver, partition 35, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:45:20,000] {docker.py:276} INFO - 21/05/14 14:45:20 INFO Executor: Running task 35.0 in stage 4.0 (TID 607)
[2021-05-14 11:45:20,000] {docker.py:276} INFO - 21/05/14 14:45:20 INFO TaskSetManager: Finished task 31.0 in stage 4.0 (TID 603) in 7094 ms on f0b8ef7ba22f (executor driver) (32/200)
[2021-05-14 11:45:20,008] {docker.py:276} INFO - 21/05/14 14:45:20 INFO ShuffleBlockFetcherIterator: Getting 9 (65.7 KiB) non-empty blocks including 9 (65.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:45:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:45:20,021] {docker.py:276} INFO - 21/05/14 14:45:20 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:45:20 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/05/14 14:45:20 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
21/05/14 14:45:20 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443461015692802905086987_0004_m_000035_607, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443461015692802905086987_0004_m_000035_607}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443461015692802905086987_0004}; taskId=attempt_202105141443461015692802905086987_0004_m_000035_607, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@773e3fb5}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
21/05/14 14:45:20 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
[2021-05-14 11:45:20,021] {docker.py:276} INFO - 21/05/14 14:45:20 INFO StagingCommitter: Starting: Task committer attempt_202105141443461015692802905086987_0004_m_000035_607: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443461015692802905086987_0004_m_000035_607
[2021-05-14 11:45:20,025] {docker.py:276} INFO - 21/05/14 14:45:20 INFO StagingCommitter: Task committer attempt_202105141443461015692802905086987_0004_m_000035_607: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443461015692802905086987_0004_m_000035_607 : duration 0:00.005s
[2021-05-14 11:45:23,058] {docker.py:276} INFO - 21/05/14 14:45:23 INFO StagingCommitter: Starting: Task committer attempt_202105141443467027710939813995425_0004_m_000032_604: needsTaskCommit() Task attempt_202105141443467027710939813995425_0004_m_000032_604
[2021-05-14 11:45:23,059] {docker.py:276} INFO - 21/05/14 14:45:23 INFO StagingCommitter: Task committer attempt_202105141443467027710939813995425_0004_m_000032_604: needsTaskCommit() Task attempt_202105141443467027710939813995425_0004_m_000032_604: duration 0:00.003s
[2021-05-14 11:45:23,060] {docker.py:276} INFO - 21/05/14 14:45:23 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443467027710939813995425_0004_m_000032_604
[2021-05-14 11:45:23,062] {docker.py:276} INFO - 21/05/14 14:45:23 INFO Executor: Finished task 32.0 in stage 4.0 (TID 604). 5106 bytes result sent to driver
[2021-05-14 11:45:23,064] {docker.py:276} INFO - 21/05/14 14:45:23 INFO TaskSetManager: Starting task 36.0 in stage 4.0 (TID 608) (f0b8ef7ba22f, executor driver, partition 36, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:45:23,064] {docker.py:276} INFO - 21/05/14 14:45:23 INFO Executor: Running task 36.0 in stage 4.0 (TID 608)
[2021-05-14 11:45:23,065] {docker.py:276} INFO - 21/05/14 14:45:23 INFO TaskSetManager: Finished task 32.0 in stage 4.0 (TID 604) in 7037 ms on f0b8ef7ba22f (executor driver) (33/200)
[2021-05-14 11:45:23,075] {docker.py:276} INFO - 21/05/14 14:45:23 INFO ShuffleBlockFetcherIterator: Getting 9 (66.2 KiB) non-empty blocks including 9 (66.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
[2021-05-14 11:45:23,075] {docker.py:276} INFO - 21/05/14 14:45:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:45:23,086] {docker.py:276} INFO - 21/05/14 14:45:23 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:45:23 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2021-05-14 11:45:23,086] {docker.py:276} INFO - 21/05/14 14:45:23 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
[2021-05-14 11:45:23,087] {docker.py:276} INFO - 21/05/14 14:45:23 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443466984511059887249441_0004_m_000036_608, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443466984511059887249441_0004_m_000036_608}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443466984511059887249441_0004}; taskId=attempt_202105141443466984511059887249441_0004_m_000036_608, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@6ddafcab}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
[2021-05-14 11:45:23,087] {docker.py:276} INFO - 21/05/14 14:45:23 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
21/05/14 14:45:23 INFO StagingCommitter: Starting: Task committer attempt_202105141443466984511059887249441_0004_m_000036_608: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443466984511059887249441_0004_m_000036_608
[2021-05-14 11:45:23,090] {docker.py:276} INFO - 21/05/14 14:45:23 INFO StagingCommitter: Task committer attempt_202105141443466984511059887249441_0004_m_000036_608: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443466984511059887249441_0004_m_000036_608 : duration 0:00.003s
[2021-05-14 11:45:24,886] {docker.py:276} INFO - 21/05/14 14:45:24 INFO StagingCommitter: Starting: Task committer attempt_20210514144346863704130321345624_0004_m_000033_605: needsTaskCommit() Task attempt_20210514144346863704130321345624_0004_m_000033_605
[2021-05-14 11:45:24,887] {docker.py:276} INFO - 21/05/14 14:45:24 INFO StagingCommitter: Task committer attempt_20210514144346863704130321345624_0004_m_000033_605: needsTaskCommit() Task attempt_20210514144346863704130321345624_0004_m_000033_605: duration 0:00.002s
21/05/14 14:45:24 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_20210514144346863704130321345624_0004_m_000033_605
[2021-05-14 11:45:24,890] {docker.py:276} INFO - 21/05/14 14:45:24 INFO Executor: Finished task 33.0 in stage 4.0 (TID 605). 5106 bytes result sent to driver
[2021-05-14 11:45:24,891] {docker.py:276} INFO - 21/05/14 14:45:24 INFO TaskSetManager: Starting task 37.0 in stage 4.0 (TID 609) (f0b8ef7ba22f, executor driver, partition 37, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:45:24,892] {docker.py:276} INFO - 21/05/14 14:45:24 INFO Executor: Running task 37.0 in stage 4.0 (TID 609)
[2021-05-14 11:45:24,893] {docker.py:276} INFO - 21/05/14 14:45:24 INFO TaskSetManager: Finished task 33.0 in stage 4.0 (TID 605) in 7052 ms on f0b8ef7ba22f (executor driver) (34/200)
[2021-05-14 11:45:24,904] {docker.py:276} INFO - 21/05/14 14:45:24 INFO ShuffleBlockFetcherIterator: Getting 9 (66.9 KiB) non-empty blocks including 9 (66.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:45:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:45:24,914] {docker.py:276} INFO - 21/05/14 14:45:24 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:45:24 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2021-05-14 11:45:24,914] {docker.py:276} INFO - 21/05/14 14:45:24 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
[2021-05-14 11:45:24,915] {docker.py:276} INFO - 21/05/14 14:45:24 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_20210514144346932896058849018712_0004_m_000037_609, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_20210514144346932896058849018712_0004_m_000037_609}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_20210514144346932896058849018712_0004}; taskId=attempt_20210514144346932896058849018712_0004_m_000037_609, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@37171290}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
21/05/14 14:45:24 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
[2021-05-14 11:45:24,915] {docker.py:276} INFO - 21/05/14 14:45:24 INFO StagingCommitter: Starting: Task committer attempt_20210514144346932896058849018712_0004_m_000037_609: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_20210514144346932896058849018712_0004_m_000037_609
[2021-05-14 11:45:24,921] {docker.py:276} INFO - 21/05/14 14:45:24 INFO StagingCommitter: Task committer attempt_20210514144346932896058849018712_0004_m_000037_609: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_20210514144346932896058849018712_0004_m_000037_609 : duration 0:00.006s
[2021-05-14 11:45:25,387] {docker.py:276} INFO - 21/05/14 14:45:25 INFO StagingCommitter: Starting: Task committer attempt_202105141443465203222104036797590_0004_m_000034_606: needsTaskCommit() Task attempt_202105141443465203222104036797590_0004_m_000034_606
[2021-05-14 11:45:25,388] {docker.py:276} INFO - 21/05/14 14:45:25 INFO StagingCommitter: Task committer attempt_202105141443465203222104036797590_0004_m_000034_606: needsTaskCommit() Task attempt_202105141443465203222104036797590_0004_m_000034_606: duration 0:00.002s
[2021-05-14 11:45:25,389] {docker.py:276} INFO - 21/05/14 14:45:25 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443465203222104036797590_0004_m_000034_606
[2021-05-14 11:45:25,390] {docker.py:276} INFO - 21/05/14 14:45:25 INFO Executor: Finished task 34.0 in stage 4.0 (TID 606). 5106 bytes result sent to driver
[2021-05-14 11:45:25,391] {docker.py:276} INFO - 21/05/14 14:45:25 INFO TaskSetManager: Starting task 38.0 in stage 4.0 (TID 610) (f0b8ef7ba22f, executor driver, partition 38, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:45:25,392] {docker.py:276} INFO - 21/05/14 14:45:25 INFO Executor: Running task 38.0 in stage 4.0 (TID 610)
[2021-05-14 11:45:25,396] {docker.py:276} INFO - 21/05/14 14:45:25 INFO TaskSetManager: Finished task 34.0 in stage 4.0 (TID 606) in 7186 ms on f0b8ef7ba22f (executor driver) (35/200)
[2021-05-14 11:45:25,402] {docker.py:276} INFO - 21/05/14 14:45:25 INFO ShuffleBlockFetcherIterator: Getting 9 (66.0 KiB) non-empty blocks including 9 (66.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:45:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:45:25,411] {docker.py:276} INFO - 21/05/14 14:45:25 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:45:25 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/05/14 14:45:25 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
21/05/14 14:45:25 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443462742514052387908456_0004_m_000038_610, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443462742514052387908456_0004_m_000038_610}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443462742514052387908456_0004}; taskId=attempt_202105141443462742514052387908456_0004_m_000038_610, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@d71dd9d}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
[2021-05-14 11:45:25,412] {docker.py:276} INFO - 21/05/14 14:45:25 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
21/05/14 14:45:25 INFO StagingCommitter: Starting: Task committer attempt_202105141443462742514052387908456_0004_m_000038_610: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443462742514052387908456_0004_m_000038_610
[2021-05-14 11:45:25,415] {docker.py:276} INFO - 21/05/14 14:45:25 INFO StagingCommitter: Task committer attempt_202105141443462742514052387908456_0004_m_000038_610: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443462742514052387908456_0004_m_000038_610 : duration 0:00.004s
[2021-05-14 11:45:26,371] {docker.py:276} INFO - 21/05/14 14:45:26 INFO StagingCommitter: Starting: Task committer attempt_202105141443461015692802905086987_0004_m_000035_607: needsTaskCommit() Task attempt_202105141443461015692802905086987_0004_m_000035_607
21/05/14 14:45:26 INFO StagingCommitter: Task committer attempt_202105141443461015692802905086987_0004_m_000035_607: needsTaskCommit() Task attempt_202105141443461015692802905086987_0004_m_000035_607: duration 0:00.002s
21/05/14 14:45:26 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443461015692802905086987_0004_m_000035_607
[2021-05-14 11:45:26,375] {docker.py:276} INFO - 21/05/14 14:45:26 INFO Executor: Finished task 35.0 in stage 4.0 (TID 607). 5106 bytes result sent to driver
[2021-05-14 11:45:26,376] {docker.py:276} INFO - 21/05/14 14:45:26 INFO TaskSetManager: Starting task 39.0 in stage 4.0 (TID 611) (f0b8ef7ba22f, executor driver, partition 39, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:45:26,377] {docker.py:276} INFO - 21/05/14 14:45:26 INFO Executor: Running task 39.0 in stage 4.0 (TID 611)
21/05/14 14:45:26 INFO TaskSetManager: Finished task 35.0 in stage 4.0 (TID 607) in 6388 ms on f0b8ef7ba22f (executor driver) (36/200)
[2021-05-14 11:45:26,388] {docker.py:276} INFO - 21/05/14 14:45:26 INFO ShuffleBlockFetcherIterator: Getting 9 (61.4 KiB) non-empty blocks including 9 (61.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:45:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:45:26,397] {docker.py:276} INFO - 21/05/14 14:45:26 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:45:26 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/05/14 14:45:26 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
21/05/14 14:45:26 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443467575475413781798654_0004_m_000039_611, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443467575475413781798654_0004_m_000039_611}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443467575475413781798654_0004}; taskId=attempt_202105141443467575475413781798654_0004_m_000039_611, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@4e038982}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
21/05/14 14:45:26 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
[2021-05-14 11:45:26,397] {docker.py:276} INFO - 21/05/14 14:45:26 INFO StagingCommitter: Starting: Task committer attempt_202105141443467575475413781798654_0004_m_000039_611: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443467575475413781798654_0004_m_000039_611
[2021-05-14 11:45:26,402] {docker.py:276} INFO - 21/05/14 14:45:26 INFO StagingCommitter: Task committer attempt_202105141443467575475413781798654_0004_m_000039_611: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443467575475413781798654_0004_m_000039_611 : duration 0:00.005s
[2021-05-14 11:45:29,876] {docker.py:276} INFO - 21/05/14 14:45:29 INFO StagingCommitter: Starting: Task committer attempt_202105141443466984511059887249441_0004_m_000036_608: needsTaskCommit() Task attempt_202105141443466984511059887249441_0004_m_000036_608
[2021-05-14 11:45:29,877] {docker.py:276} INFO - 21/05/14 14:45:29 INFO StagingCommitter: Task committer attempt_202105141443466984511059887249441_0004_m_000036_608: needsTaskCommit() Task attempt_202105141443466984511059887249441_0004_m_000036_608: duration 0:00.003s
[2021-05-14 11:45:29,878] {docker.py:276} INFO - 21/05/14 14:45:29 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443466984511059887249441_0004_m_000036_608
[2021-05-14 11:45:29,879] {docker.py:276} INFO - 21/05/14 14:45:29 INFO Executor: Finished task 36.0 in stage 4.0 (TID 608). 5106 bytes result sent to driver
[2021-05-14 11:45:29,880] {docker.py:276} INFO - 21/05/14 14:45:29 INFO TaskSetManager: Starting task 40.0 in stage 4.0 (TID 612) (f0b8ef7ba22f, executor driver, partition 40, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:45:29,881] {docker.py:276} INFO - 21/05/14 14:45:29 INFO TaskSetManager: Finished task 36.0 in stage 4.0 (TID 608) in 6826 ms on f0b8ef7ba22f (executor driver) (37/200)
21/05/14 14:45:29 INFO Executor: Running task 40.0 in stage 4.0 (TID 612)
[2021-05-14 11:45:29,892] {docker.py:276} INFO - 21/05/14 14:45:29 INFO ShuffleBlockFetcherIterator: Getting 9 (68.5 KiB) non-empty blocks including 9 (68.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:45:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:45:29,929] {docker.py:276} INFO - 21/05/14 14:45:29 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:45:29 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/05/14 14:45:29 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
21/05/14 14:45:29 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443468656977232632690033_0004_m_000040_612, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443468656977232632690033_0004_m_000040_612}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443468656977232632690033_0004}; taskId=attempt_202105141443468656977232632690033_0004_m_000040_612, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@159bedfa}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
21/05/14 14:45:29 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
[2021-05-14 11:45:29,929] {docker.py:276} INFO - 21/05/14 14:45:29 INFO StagingCommitter: Starting: Task committer attempt_202105141443468656977232632690033_0004_m_000040_612: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443468656977232632690033_0004_m_000040_612
[2021-05-14 11:45:29,934] {docker.py:276} INFO - 21/05/14 14:45:29 INFO StagingCommitter: Task committer attempt_202105141443468656977232632690033_0004_m_000040_612: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443468656977232632690033_0004_m_000040_612 : duration 0:00.004s
[2021-05-14 11:45:31,620] {docker.py:276} INFO - 21/05/14 14:45:31 INFO StagingCommitter: Starting: Task committer attempt_20210514144346932896058849018712_0004_m_000037_609: needsTaskCommit() Task attempt_20210514144346932896058849018712_0004_m_000037_609
21/05/14 14:45:31 INFO StagingCommitter: Task committer attempt_20210514144346932896058849018712_0004_m_000037_609: needsTaskCommit() Task attempt_20210514144346932896058849018712_0004_m_000037_609: duration 0:00.006s
[2021-05-14 11:45:31,621] {docker.py:276} INFO - 21/05/14 14:45:31 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_20210514144346932896058849018712_0004_m_000037_609
[2021-05-14 11:45:31,622] {docker.py:276} INFO - 21/05/14 14:45:31 INFO Executor: Finished task 37.0 in stage 4.0 (TID 609). 5149 bytes result sent to driver
[2021-05-14 11:45:31,623] {docker.py:276} INFO - 21/05/14 14:45:31 INFO TaskSetManager: Starting task 41.0 in stage 4.0 (TID 613) (f0b8ef7ba22f, executor driver, partition 41, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:45:31,625] {docker.py:276} INFO - 21/05/14 14:45:31 INFO Executor: Running task 41.0 in stage 4.0 (TID 613)
[2021-05-14 11:45:31,625] {docker.py:276} INFO - 21/05/14 14:45:31 INFO TaskSetManager: Finished task 37.0 in stage 4.0 (TID 609) in 6742 ms on f0b8ef7ba22f (executor driver) (38/200)
[2021-05-14 11:45:31,634] {docker.py:276} INFO - 21/05/14 14:45:31 INFO ShuffleBlockFetcherIterator: Getting 9 (65.5 KiB) non-empty blocks including 9 (65.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:45:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:45:31,645] {docker.py:276} INFO - 21/05/14 14:45:31 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:45:31 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2021-05-14 11:45:31,645] {docker.py:276} INFO - 21/05/14 14:45:31 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
[2021-05-14 11:45:31,646] {docker.py:276} INFO - 21/05/14 14:45:31 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443465952588006291863696_0004_m_000041_613, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443465952588006291863696_0004_m_000041_613}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443465952588006291863696_0004}; taskId=attempt_202105141443465952588006291863696_0004_m_000041_613, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@5ac771a4}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
[2021-05-14 11:45:31,646] {docker.py:276} INFO - 21/05/14 14:45:31 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
[2021-05-14 11:45:31,646] {docker.py:276} INFO - 21/05/14 14:45:31 INFO StagingCommitter: Starting: Task committer attempt_202105141443465952588006291863696_0004_m_000041_613: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443465952588006291863696_0004_m_000041_613
[2021-05-14 11:45:31,650] {docker.py:276} INFO - 21/05/14 14:45:31 INFO StagingCommitter: Task committer attempt_202105141443465952588006291863696_0004_m_000041_613: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443465952588006291863696_0004_m_000041_613 : duration 0:00.004s
[2021-05-14 11:45:31,783] {docker.py:276} INFO - 21/05/14 14:45:31 INFO StagingCommitter: Starting: Task committer attempt_202105141443462742514052387908456_0004_m_000038_610: needsTaskCommit() Task attempt_202105141443462742514052387908456_0004_m_000038_610
[2021-05-14 11:45:31,784] {docker.py:276} INFO - 21/05/14 14:45:31 INFO StagingCommitter: Task committer attempt_202105141443462742514052387908456_0004_m_000038_610: needsTaskCommit() Task attempt_202105141443462742514052387908456_0004_m_000038_610: duration 0:00.001s
21/05/14 14:45:31 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443462742514052387908456_0004_m_000038_610
[2021-05-14 11:45:31,785] {docker.py:276} INFO - 21/05/14 14:45:31 INFO Executor: Finished task 38.0 in stage 4.0 (TID 610). 5149 bytes result sent to driver
[2021-05-14 11:45:31,786] {docker.py:276} INFO - 21/05/14 14:45:31 INFO TaskSetManager: Starting task 42.0 in stage 4.0 (TID 614) (f0b8ef7ba22f, executor driver, partition 42, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:45:31,787] {docker.py:276} INFO - 21/05/14 14:45:31 INFO Executor: Running task 42.0 in stage 4.0 (TID 614)
[2021-05-14 11:45:31,787] {docker.py:276} INFO - 21/05/14 14:45:31 INFO TaskSetManager: Finished task 38.0 in stage 4.0 (TID 610) in 6403 ms on f0b8ef7ba22f (executor driver) (39/200)
[2021-05-14 11:45:31,798] {docker.py:276} INFO - 21/05/14 14:45:31 INFO ShuffleBlockFetcherIterator: Getting 9 (63.2 KiB) non-empty blocks including 9 (63.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
[2021-05-14 11:45:31,799] {docker.py:276} INFO - 21/05/14 14:45:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:45:31,808] {docker.py:276} INFO - 21/05/14 14:45:31 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:45:31 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/05/14 14:45:31 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
[2021-05-14 11:45:31,809] {docker.py:276} INFO - 21/05/14 14:45:31 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443464843790816844193508_0004_m_000042_614, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443464843790816844193508_0004_m_000042_614}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443464843790816844193508_0004}; taskId=attempt_202105141443464843790816844193508_0004_m_000042_614, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@5ababb7}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
21/05/14 14:45:31 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
21/05/14 14:45:31 INFO StagingCommitter: Starting: Task committer attempt_202105141443464843790816844193508_0004_m_000042_614: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443464843790816844193508_0004_m_000042_614
[2021-05-14 11:45:31,814] {docker.py:276} INFO - 21/05/14 14:45:31 INFO StagingCommitter: Task committer attempt_202105141443464843790816844193508_0004_m_000042_614: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443464843790816844193508_0004_m_000042_614 : duration 0:00.005s
[2021-05-14 11:45:33,405] {docker.py:276} INFO - 21/05/14 14:45:33 INFO StagingCommitter: Starting: Task committer attempt_202105141443467575475413781798654_0004_m_000039_611: needsTaskCommit() Task attempt_202105141443467575475413781798654_0004_m_000039_611
[2021-05-14 11:45:33,406] {docker.py:276} INFO - 21/05/14 14:45:33 INFO StagingCommitter: Task committer attempt_202105141443467575475413781798654_0004_m_000039_611: needsTaskCommit() Task attempt_202105141443467575475413781798654_0004_m_000039_611: duration 0:00.004s
21/05/14 14:45:33 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443467575475413781798654_0004_m_000039_611
[2021-05-14 11:45:33,410] {docker.py:276} INFO - 21/05/14 14:45:33 INFO Executor: Finished task 39.0 in stage 4.0 (TID 611). 5149 bytes result sent to driver
[2021-05-14 11:45:33,411] {docker.py:276} INFO - 21/05/14 14:45:33 INFO TaskSetManager: Starting task 43.0 in stage 4.0 (TID 615) (f0b8ef7ba22f, executor driver, partition 43, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:45:33,412] {docker.py:276} INFO - 21/05/14 14:45:33 INFO Executor: Running task 43.0 in stage 4.0 (TID 615)
[2021-05-14 11:45:33,413] {docker.py:276} INFO - 21/05/14 14:45:33 INFO TaskSetManager: Finished task 39.0 in stage 4.0 (TID 611) in 7046 ms on f0b8ef7ba22f (executor driver) (40/200)
[2021-05-14 11:45:33,424] {docker.py:276} INFO - 21/05/14 14:45:33 INFO ShuffleBlockFetcherIterator: Getting 9 (65.7 KiB) non-empty blocks including 9 (65.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:45:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2021-05-14 11:45:33,436] {docker.py:276} INFO - 21/05/14 14:45:33 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:45:33 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2021-05-14 11:45:33,437] {docker.py:276} INFO - 21/05/14 14:45:33 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
21/05/14 14:45:33 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443467441200394271758307_0004_m_000043_615, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443467441200394271758307_0004_m_000043_615}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443467441200394271758307_0004}; taskId=attempt_202105141443467441200394271758307_0004_m_000043_615, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@d473e36}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
21/05/14 14:45:33 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
21/05/14 14:45:33 INFO StagingCommitter: Starting: Task committer attempt_202105141443467441200394271758307_0004_m_000043_615: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443467441200394271758307_0004_m_000043_615
[2021-05-14 11:45:33,440] {docker.py:276} INFO - 21/05/14 14:45:33 INFO StagingCommitter: Task committer attempt_202105141443467441200394271758307_0004_m_000043_615: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443467441200394271758307_0004_m_000043_615 : duration 0:00.004s
[2021-05-14 11:45:36,759] {docker.py:276} INFO - 21/05/14 14:45:36 INFO StagingCommitter: Starting: Task committer attempt_202105141443468656977232632690033_0004_m_000040_612: needsTaskCommit() Task attempt_202105141443468656977232632690033_0004_m_000040_612
[2021-05-14 11:45:36,760] {docker.py:276} INFO - 21/05/14 14:45:36 INFO StagingCommitter: Task committer attempt_202105141443468656977232632690033_0004_m_000040_612: needsTaskCommit() Task attempt_202105141443468656977232632690033_0004_m_000040_612: duration 0:00.003s
21/05/14 14:45:36 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443468656977232632690033_0004_m_000040_612
[2021-05-14 11:45:36,762] {docker.py:276} INFO - 21/05/14 14:45:36 INFO Executor: Finished task 40.0 in stage 4.0 (TID 612). 5149 bytes result sent to driver
[2021-05-14 11:45:36,763] {docker.py:276} INFO - 21/05/14 14:45:36 INFO TaskSetManager: Starting task 44.0 in stage 4.0 (TID 616) (f0b8ef7ba22f, executor driver, partition 44, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:45:36,764] {docker.py:276} INFO - 21/05/14 14:45:36 INFO Executor: Running task 44.0 in stage 4.0 (TID 616)
[2021-05-14 11:45:36,765] {docker.py:276} INFO - 21/05/14 14:45:36 INFO TaskSetManager: Finished task 40.0 in stage 4.0 (TID 612) in 6893 ms on f0b8ef7ba22f (executor driver) (41/200)
[2021-05-14 11:45:36,775] {docker.py:276} INFO - 21/05/14 14:45:36 INFO ShuffleBlockFetcherIterator: Getting 9 (67.2 KiB) non-empty blocks including 9 (67.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:45:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:45:36,790] {docker.py:276} INFO - 21/05/14 14:45:36 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:45:36 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2021-05-14 11:45:36,790] {docker.py:276} INFO - 21/05/14 14:45:36 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
21/05/14 14:45:36 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443466275032610842477162_0004_m_000044_616, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443466275032610842477162_0004_m_000044_616}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443466275032610842477162_0004}; taskId=attempt_202105141443466275032610842477162_0004_m_000044_616, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@590634a0}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
21/05/14 14:45:36 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
[2021-05-14 11:45:36,791] {docker.py:276} INFO - 21/05/14 14:45:36 INFO StagingCommitter: Starting: Task committer attempt_202105141443466275032610842477162_0004_m_000044_616: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443466275032610842477162_0004_m_000044_616
[2021-05-14 11:45:36,794] {docker.py:276} INFO - 21/05/14 14:45:36 INFO StagingCommitter: Task committer attempt_202105141443466275032610842477162_0004_m_000044_616: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443466275032610842477162_0004_m_000044_616 : duration 0:00.004s
[2021-05-14 11:45:38,633] {docker.py:276} INFO - 21/05/14 14:45:38 INFO StagingCommitter: Starting: Task committer attempt_202105141443465952588006291863696_0004_m_000041_613: needsTaskCommit() Task attempt_202105141443465952588006291863696_0004_m_000041_613
[2021-05-14 11:45:38,634] {docker.py:276} INFO - 21/05/14 14:45:38 INFO StagingCommitter: Task committer attempt_202105141443465952588006291863696_0004_m_000041_613: needsTaskCommit() Task attempt_202105141443465952588006291863696_0004_m_000041_613: duration 0:00.002s
21/05/14 14:45:38 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443465952588006291863696_0004_m_000041_613
[2021-05-14 11:45:38,635] {docker.py:276} INFO - 21/05/14 14:45:38 INFO Executor: Finished task 41.0 in stage 4.0 (TID 613). 5106 bytes result sent to driver
[2021-05-14 11:45:38,636] {docker.py:276} INFO - 21/05/14 14:45:38 INFO TaskSetManager: Starting task 45.0 in stage 4.0 (TID 617) (f0b8ef7ba22f, executor driver, partition 45, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:45:38,637] {docker.py:276} INFO - 21/05/14 14:45:38 INFO Executor: Running task 45.0 in stage 4.0 (TID 617)
21/05/14 14:45:38 INFO TaskSetManager: Finished task 41.0 in stage 4.0 (TID 613) in 7023 ms on f0b8ef7ba22f (executor driver) (42/200)
[2021-05-14 11:45:38,646] {docker.py:276} INFO - 21/05/14 14:45:38 INFO ShuffleBlockFetcherIterator: Getting 9 (68.8 KiB) non-empty blocks including 9 (68.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:45:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:45:38,655] {docker.py:276} INFO - 21/05/14 14:45:38 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:45:38 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/05/14 14:45:38 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
21/05/14 14:45:38 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_20210514144346683017322319083506_0004_m_000045_617, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_20210514144346683017322319083506_0004_m_000045_617}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_20210514144346683017322319083506_0004}; taskId=attempt_20210514144346683017322319083506_0004_m_000045_617, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@47dec1e2}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
21/05/14 14:45:38 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
21/05/14 14:45:38 INFO StagingCommitter: Starting: Task committer attempt_20210514144346683017322319083506_0004_m_000045_617: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_20210514144346683017322319083506_0004_m_000045_617
[2021-05-14 11:45:38,659] {docker.py:276} INFO - 21/05/14 14:45:38 INFO StagingCommitter: Task committer attempt_20210514144346683017322319083506_0004_m_000045_617: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_20210514144346683017322319083506_0004_m_000045_617 : duration 0:00.004s
[2021-05-14 11:45:38,823] {docker.py:276} INFO - 21/05/14 14:45:38 INFO StagingCommitter: Starting: Task committer attempt_202105141443464843790816844193508_0004_m_000042_614: needsTaskCommit() Task attempt_202105141443464843790816844193508_0004_m_000042_614
[2021-05-14 11:45:38,824] {docker.py:276} INFO - 21/05/14 14:45:38 INFO StagingCommitter: Task committer attempt_202105141443464843790816844193508_0004_m_000042_614: needsTaskCommit() Task attempt_202105141443464843790816844193508_0004_m_000042_614: duration 0:00.003s
21/05/14 14:45:38 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443464843790816844193508_0004_m_000042_614
[2021-05-14 11:45:38,826] {docker.py:276} INFO - 21/05/14 14:45:38 INFO Executor: Finished task 42.0 in stage 4.0 (TID 614). 5106 bytes result sent to driver
[2021-05-14 11:45:38,827] {docker.py:276} INFO - 21/05/14 14:45:38 INFO TaskSetManager: Starting task 46.0 in stage 4.0 (TID 618) (f0b8ef7ba22f, executor driver, partition 46, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:45:38,828] {docker.py:276} INFO - 21/05/14 14:45:38 INFO TaskSetManager: Finished task 42.0 in stage 4.0 (TID 614) in 7014 ms on f0b8ef7ba22f (executor driver) (43/200)
21/05/14 14:45:38 INFO Executor: Running task 46.0 in stage 4.0 (TID 618)
[2021-05-14 11:45:38,838] {docker.py:276} INFO - 21/05/14 14:45:38 INFO ShuffleBlockFetcherIterator: Getting 9 (67.2 KiB) non-empty blocks including 9 (67.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:45:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:45:38,848] {docker.py:276} INFO - 21/05/14 14:45:38 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:45:38 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/05/14 14:45:38 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
21/05/14 14:45:38 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443462160423338674685025_0004_m_000046_618, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443462160423338674685025_0004_m_000046_618}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443462160423338674685025_0004}; taskId=attempt_202105141443462160423338674685025_0004_m_000046_618, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@77297b27}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
[2021-05-14 11:45:38,848] {docker.py:276} INFO - 21/05/14 14:45:38 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
21/05/14 14:45:38 INFO StagingCommitter: Starting: Task committer attempt_202105141443462160423338674685025_0004_m_000046_618: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443462160423338674685025_0004_m_000046_618
[2021-05-14 11:45:38,852] {docker.py:276} INFO - 21/05/14 14:45:38 INFO StagingCommitter: Task committer attempt_202105141443462160423338674685025_0004_m_000046_618: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443462160423338674685025_0004_m_000046_618 : duration 0:00.005s
[2021-05-14 11:45:41,055] {docker.py:276} INFO - 21/05/14 14:45:41 INFO StagingCommitter: Starting: Task committer attempt_202105141443467441200394271758307_0004_m_000043_615: needsTaskCommit() Task attempt_202105141443467441200394271758307_0004_m_000043_615
[2021-05-14 11:45:41,056] {docker.py:276} INFO - 21/05/14 14:45:41 INFO StagingCommitter: Task committer attempt_202105141443467441200394271758307_0004_m_000043_615: needsTaskCommit() Task attempt_202105141443467441200394271758307_0004_m_000043_615: duration 0:00.002s
21/05/14 14:45:41 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443467441200394271758307_0004_m_000043_615
[2021-05-14 11:45:41,057] {docker.py:276} INFO - 21/05/14 14:45:41 INFO Executor: Finished task 43.0 in stage 4.0 (TID 615). 5106 bytes result sent to driver
[2021-05-14 11:45:41,058] {docker.py:276} INFO - 21/05/14 14:45:41 INFO TaskSetManager: Starting task 47.0 in stage 4.0 (TID 619) (f0b8ef7ba22f, executor driver, partition 47, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:45:41,059] {docker.py:276} INFO - 21/05/14 14:45:41 INFO Executor: Running task 47.0 in stage 4.0 (TID 619)
[2021-05-14 11:45:41,060] {docker.py:276} INFO - 21/05/14 14:45:41 INFO TaskSetManager: Finished task 43.0 in stage 4.0 (TID 615) in 7624 ms on f0b8ef7ba22f (executor driver) (44/200)
[2021-05-14 11:45:41,070] {docker.py:276} INFO - 21/05/14 14:45:41 INFO ShuffleBlockFetcherIterator: Getting 9 (63.5 KiB) non-empty blocks including 9 (63.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:45:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:45:41,079] {docker.py:276} INFO - 21/05/14 14:45:41 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:45:41 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/05/14 14:45:41 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
21/05/14 14:45:41 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443467034722121605666751_0004_m_000047_619, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443467034722121605666751_0004_m_000047_619}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443467034722121605666751_0004}; taskId=attempt_202105141443467034722121605666751_0004_m_000047_619, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@73f712e0}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
[2021-05-14 11:45:41,080] {docker.py:276} INFO - 21/05/14 14:45:41 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
21/05/14 14:45:41 INFO StagingCommitter: Starting: Task committer attempt_202105141443467034722121605666751_0004_m_000047_619: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443467034722121605666751_0004_m_000047_619
[2021-05-14 11:45:41,084] {docker.py:276} INFO - 21/05/14 14:45:41 INFO StagingCommitter: Task committer attempt_202105141443467034722121605666751_0004_m_000047_619: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443467034722121605666751_0004_m_000047_619 : duration 0:00.004s
[2021-05-14 11:45:43,382] {docker.py:276} INFO - 21/05/14 14:45:43 INFO StagingCommitter: Starting: Task committer attempt_202105141443466275032610842477162_0004_m_000044_616: needsTaskCommit() Task attempt_202105141443466275032610842477162_0004_m_000044_616
[2021-05-14 11:45:43,383] {docker.py:276} INFO - 21/05/14 14:45:43 INFO StagingCommitter: Task committer attempt_202105141443466275032610842477162_0004_m_000044_616: needsTaskCommit() Task attempt_202105141443466275032610842477162_0004_m_000044_616: duration 0:00.002s
21/05/14 14:45:43 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443466275032610842477162_0004_m_000044_616
[2021-05-14 11:45:43,385] {docker.py:276} INFO - 21/05/14 14:45:43 INFO Executor: Finished task 44.0 in stage 4.0 (TID 616). 5106 bytes result sent to driver
[2021-05-14 11:45:43,387] {docker.py:276} INFO - 21/05/14 14:45:43 INFO TaskSetManager: Starting task 48.0 in stage 4.0 (TID 620) (f0b8ef7ba22f, executor driver, partition 48, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:45:43,388] {docker.py:276} INFO - 21/05/14 14:45:43 INFO TaskSetManager: Finished task 44.0 in stage 4.0 (TID 616) in 6597 ms on f0b8ef7ba22f (executor driver) (45/200)
[2021-05-14 11:45:43,388] {docker.py:276} INFO - 21/05/14 14:45:43 INFO Executor: Running task 48.0 in stage 4.0 (TID 620)
[2021-05-14 11:45:43,398] {docker.py:276} INFO - 21/05/14 14:45:43 INFO ShuffleBlockFetcherIterator: Getting 9 (65.3 KiB) non-empty blocks including 9 (65.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
[2021-05-14 11:45:43,398] {docker.py:276} INFO - 21/05/14 14:45:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:45:43,408] {docker.py:276} INFO - 21/05/14 14:45:43 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2021-05-14 11:45:43,409] {docker.py:276} INFO - 21/05/14 14:45:43 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2021-05-14 11:45:43,409] {docker.py:276} INFO - 21/05/14 14:45:43 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
[2021-05-14 11:45:43,410] {docker.py:276} INFO - 21/05/14 14:45:43 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443462006578146877513371_0004_m_000048_620, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443462006578146877513371_0004_m_000048_620}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443462006578146877513371_0004}; taskId=attempt_202105141443462006578146877513371_0004_m_000048_620, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@3dfe4a3d}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
[2021-05-14 11:45:43,410] {docker.py:276} INFO - 21/05/14 14:45:43 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
[2021-05-14 11:45:43,410] {docker.py:276} INFO - 21/05/14 14:45:43 INFO StagingCommitter: Starting: Task committer attempt_202105141443462006578146877513371_0004_m_000048_620: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443462006578146877513371_0004_m_000048_620
[2021-05-14 11:45:43,413] {docker.py:276} INFO - 21/05/14 14:45:43 INFO StagingCommitter: Task committer attempt_202105141443462006578146877513371_0004_m_000048_620: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443462006578146877513371_0004_m_000048_620 : duration 0:00.004s
[2021-05-14 11:45:45,772] {docker.py:276} INFO - 21/05/14 14:45:45 INFO StagingCommitter: Starting: Task committer attempt_20210514144346683017322319083506_0004_m_000045_617: needsTaskCommit() Task attempt_20210514144346683017322319083506_0004_m_000045_617
21/05/14 14:45:45 INFO StagingCommitter: Task committer attempt_20210514144346683017322319083506_0004_m_000045_617: needsTaskCommit() Task attempt_20210514144346683017322319083506_0004_m_000045_617: duration 0:00.003s
21/05/14 14:45:45 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_20210514144346683017322319083506_0004_m_000045_617
[2021-05-14 11:45:45,775] {docker.py:276} INFO - 21/05/14 14:45:45 INFO Executor: Finished task 45.0 in stage 4.0 (TID 617). 5106 bytes result sent to driver
[2021-05-14 11:45:45,776] {docker.py:276} INFO - 21/05/14 14:45:45 INFO TaskSetManager: Starting task 49.0 in stage 4.0 (TID 621) (f0b8ef7ba22f, executor driver, partition 49, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:45:45,777] {docker.py:276} INFO - 21/05/14 14:45:45 INFO Executor: Running task 49.0 in stage 4.0 (TID 621)
[2021-05-14 11:45:45,778] {docker.py:276} INFO - 21/05/14 14:45:45 INFO TaskSetManager: Finished task 45.0 in stage 4.0 (TID 617) in 7114 ms on f0b8ef7ba22f (executor driver) (46/200)
[2021-05-14 11:45:45,787] {docker.py:276} INFO - 21/05/14 14:45:45 INFO ShuffleBlockFetcherIterator: Getting 9 (65.8 KiB) non-empty blocks including 9 (65.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
[2021-05-14 11:45:45,788] {docker.py:276} INFO - 21/05/14 14:45:45 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:45:45,797] {docker.py:276} INFO - 21/05/14 14:45:45 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2021-05-14 11:45:45,798] {docker.py:276} INFO - 21/05/14 14:45:45 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2021-05-14 11:45:45,798] {docker.py:276} INFO - 21/05/14 14:45:45 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
[2021-05-14 11:45:45,798] {docker.py:276} INFO - 21/05/14 14:45:45 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443467729886833019635127_0004_m_000049_621, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443467729886833019635127_0004_m_000049_621}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443467729886833019635127_0004}; taskId=attempt_202105141443467729886833019635127_0004_m_000049_621, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@76886dcf}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
[2021-05-14 11:45:45,799] {docker.py:276} INFO - 21/05/14 14:45:45 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
[2021-05-14 11:45:45,799] {docker.py:276} INFO - 21/05/14 14:45:45 INFO StagingCommitter: Starting: Task committer attempt_202105141443467729886833019635127_0004_m_000049_621: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443467729886833019635127_0004_m_000049_621
[2021-05-14 11:45:45,803] {docker.py:276} INFO - 21/05/14 14:45:45 INFO StagingCommitter: Task committer attempt_202105141443467729886833019635127_0004_m_000049_621: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443467729886833019635127_0004_m_000049_621 : duration 0:00.004s
[2021-05-14 11:45:45,824] {docker.py:276} INFO - 21/05/14 14:45:45 INFO StagingCommitter: Starting: Task committer attempt_202105141443462160423338674685025_0004_m_000046_618: needsTaskCommit() Task attempt_202105141443462160423338674685025_0004_m_000046_618
[2021-05-14 11:45:45,825] {docker.py:276} INFO - 21/05/14 14:45:45 INFO StagingCommitter: Task committer attempt_202105141443462160423338674685025_0004_m_000046_618: needsTaskCommit() Task attempt_202105141443462160423338674685025_0004_m_000046_618: duration 0:00.000s
21/05/14 14:45:45 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443462160423338674685025_0004_m_000046_618
[2021-05-14 11:45:45,826] {docker.py:276} INFO - 21/05/14 14:45:45 INFO Executor: Finished task 46.0 in stage 4.0 (TID 618). 5106 bytes result sent to driver
[2021-05-14 11:45:45,826] {docker.py:276} INFO - 21/05/14 14:45:45 INFO TaskSetManager: Starting task 50.0 in stage 4.0 (TID 622) (f0b8ef7ba22f, executor driver, partition 50, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:45:45,827] {docker.py:276} INFO - 21/05/14 14:45:45 INFO Executor: Running task 50.0 in stage 4.0 (TID 622)
[2021-05-14 11:45:45,828] {docker.py:276} INFO - 21/05/14 14:45:45 INFO TaskSetManager: Finished task 46.0 in stage 4.0 (TID 618) in 7010 ms on f0b8ef7ba22f (executor driver) (47/200)
[2021-05-14 11:45:45,834] {docker.py:276} INFO - 21/05/14 14:45:45 INFO ShuffleBlockFetcherIterator: Getting 9 (63.3 KiB) non-empty blocks including 9 (63.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:45:45 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:45:45,845] {docker.py:276} INFO - 21/05/14 14:45:45 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:45:45 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/05/14 14:45:45 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
[2021-05-14 11:45:45,846] {docker.py:276} INFO - 21/05/14 14:45:45 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443468872932758637024292_0004_m_000050_622, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443468872932758637024292_0004_m_000050_622}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443468872932758637024292_0004}; taskId=attempt_202105141443468872932758637024292_0004_m_000050_622, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@499cb8b2}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
21/05/14 14:45:45 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
21/05/14 14:45:45 INFO StagingCommitter: Starting: Task committer attempt_202105141443468872932758637024292_0004_m_000050_622: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443468872932758637024292_0004_m_000050_622
[2021-05-14 11:45:45,851] {docker.py:276} INFO - 21/05/14 14:45:45 INFO StagingCommitter: Task committer attempt_202105141443468872932758637024292_0004_m_000050_622: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443468872932758637024292_0004_m_000050_622 : duration 0:00.005s
[2021-05-14 11:45:48,092] {docker.py:276} INFO - 21/05/14 14:45:48 INFO StagingCommitter: Starting: Task committer attempt_202105141443467034722121605666751_0004_m_000047_619: needsTaskCommit() Task attempt_202105141443467034722121605666751_0004_m_000047_619
[2021-05-14 11:45:48,093] {docker.py:276} INFO - 21/05/14 14:45:48 INFO StagingCommitter: Task committer attempt_202105141443467034722121605666751_0004_m_000047_619: needsTaskCommit() Task attempt_202105141443467034722121605666751_0004_m_000047_619: duration 0:00.004s
[2021-05-14 11:45:48,093] {docker.py:276} INFO - 21/05/14 14:45:48 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443467034722121605666751_0004_m_000047_619
[2021-05-14 11:45:48,096] {docker.py:276} INFO - 21/05/14 14:45:48 INFO Executor: Finished task 47.0 in stage 4.0 (TID 619). 5106 bytes result sent to driver
[2021-05-14 11:45:48,098] {docker.py:276} INFO - 21/05/14 14:45:48 INFO TaskSetManager: Starting task 51.0 in stage 4.0 (TID 623) (f0b8ef7ba22f, executor driver, partition 51, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:45:48,099] {docker.py:276} INFO - 21/05/14 14:45:48 INFO Executor: Running task 51.0 in stage 4.0 (TID 623)
[2021-05-14 11:45:48,100] {docker.py:276} INFO - 21/05/14 14:45:48 INFO TaskSetManager: Finished task 47.0 in stage 4.0 (TID 619) in 7051 ms on f0b8ef7ba22f (executor driver) (48/200)
[2021-05-14 11:45:48,109] {docker.py:276} INFO - 21/05/14 14:45:48 INFO ShuffleBlockFetcherIterator: Getting 9 (66.4 KiB) non-empty blocks including 9 (66.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:45:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:45:48,122] {docker.py:276} INFO - 21/05/14 14:45:48 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:45:48 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/05/14 14:45:48 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
21/05/14 14:45:48 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443461939846379015451182_0004_m_000051_623, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443461939846379015451182_0004_m_000051_623}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443461939846379015451182_0004}; taskId=attempt_202105141443461939846379015451182_0004_m_000051_623, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@1b05d635}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
21/05/14 14:45:48 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
21/05/14 14:45:48 INFO StagingCommitter: Starting: Task committer attempt_202105141443461939846379015451182_0004_m_000051_623: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443461939846379015451182_0004_m_000051_623
[2021-05-14 11:45:48,126] {docker.py:276} INFO - 21/05/14 14:45:48 INFO StagingCommitter: Task committer attempt_202105141443461939846379015451182_0004_m_000051_623: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443461939846379015451182_0004_m_000051_623 : duration 0:00.004s
[2021-05-14 11:45:50,410] {docker.py:276} INFO - 21/05/14 14:45:50 INFO StagingCommitter: Starting: Task committer attempt_202105141443462006578146877513371_0004_m_000048_620: needsTaskCommit() Task attempt_202105141443462006578146877513371_0004_m_000048_620
[2021-05-14 11:45:50,411] {docker.py:276} INFO - 21/05/14 14:45:50 INFO StagingCommitter: Task committer attempt_202105141443462006578146877513371_0004_m_000048_620: needsTaskCommit() Task attempt_202105141443462006578146877513371_0004_m_000048_620: duration 0:00.002s
21/05/14 14:45:50 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443462006578146877513371_0004_m_000048_620
[2021-05-14 11:45:50,412] {docker.py:276} INFO - 21/05/14 14:45:50 INFO Executor: Finished task 48.0 in stage 4.0 (TID 620). 5106 bytes result sent to driver
[2021-05-14 11:45:50,413] {docker.py:276} INFO - 21/05/14 14:45:50 INFO TaskSetManager: Starting task 52.0 in stage 4.0 (TID 624) (f0b8ef7ba22f, executor driver, partition 52, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:45:50,414] {docker.py:276} INFO - 21/05/14 14:45:50 INFO Executor: Running task 52.0 in stage 4.0 (TID 624)
[2021-05-14 11:45:50,415] {docker.py:276} INFO - 21/05/14 14:45:50 INFO TaskSetManager: Finished task 48.0 in stage 4.0 (TID 620) in 7037 ms on f0b8ef7ba22f (executor driver) (49/200)
[2021-05-14 11:45:50,423] {docker.py:276} INFO - 21/05/14 14:45:50 INFO ShuffleBlockFetcherIterator: Getting 9 (61.5 KiB) non-empty blocks including 9 (61.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:45:50 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:45:50,433] {docker.py:276} INFO - 21/05/14 14:45:50 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:45:50 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/05/14 14:45:50 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
[2021-05-14 11:45:50,433] {docker.py:276} INFO - 21/05/14 14:45:50 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443462907262087074688786_0004_m_000052_624, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443462907262087074688786_0004_m_000052_624}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443462907262087074688786_0004}; taskId=attempt_202105141443462907262087074688786_0004_m_000052_624, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@240e3244}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
21/05/14 14:45:50 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
21/05/14 14:45:50 INFO StagingCommitter: Starting: Task committer attempt_202105141443462907262087074688786_0004_m_000052_624: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443462907262087074688786_0004_m_000052_624
[2021-05-14 11:45:50,439] {docker.py:276} INFO - 21/05/14 14:45:50 INFO StagingCommitter: Task committer attempt_202105141443462907262087074688786_0004_m_000052_624: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443462907262087074688786_0004_m_000052_624 : duration 0:00.005s
[2021-05-14 11:45:52,623] {docker.py:276} INFO - 21/05/14 14:45:52 INFO StagingCommitter: Starting: Task committer attempt_202105141443467729886833019635127_0004_m_000049_621: needsTaskCommit() Task attempt_202105141443467729886833019635127_0004_m_000049_621
21/05/14 14:45:52 INFO StagingCommitter: Task committer attempt_202105141443467729886833019635127_0004_m_000049_621: needsTaskCommit() Task attempt_202105141443467729886833019635127_0004_m_000049_621: duration 0:00.002s
21/05/14 14:45:52 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443467729886833019635127_0004_m_000049_621
[2021-05-14 11:45:52,625] {docker.py:276} INFO - 21/05/14 14:45:52 INFO Executor: Finished task 49.0 in stage 4.0 (TID 621). 5106 bytes result sent to driver
[2021-05-14 11:45:52,627] {docker.py:276} INFO - 21/05/14 14:45:52 INFO TaskSetManager: Starting task 53.0 in stage 4.0 (TID 625) (f0b8ef7ba22f, executor driver, partition 53, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:45:52,628] {docker.py:276} INFO - 21/05/14 14:45:52 INFO Executor: Running task 53.0 in stage 4.0 (TID 625)
21/05/14 14:45:52 INFO TaskSetManager: Finished task 49.0 in stage 4.0 (TID 621) in 6861 ms on f0b8ef7ba22f (executor driver) (50/200)
[2021-05-14 11:45:52,638] {docker.py:276} INFO - 21/05/14 14:45:52 INFO ShuffleBlockFetcherIterator: Getting 9 (65.9 KiB) non-empty blocks including 9 (65.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:45:52 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:45:52,648] {docker.py:276} INFO - 21/05/14 14:45:52 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:45:52 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/05/14 14:45:52 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
[2021-05-14 11:45:52,648] {docker.py:276} INFO - 21/05/14 14:45:52 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443468828345223131791741_0004_m_000053_625, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443468828345223131791741_0004_m_000053_625}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443468828345223131791741_0004}; taskId=attempt_202105141443468828345223131791741_0004_m_000053_625, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@7153759f}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
21/05/14 14:45:52 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
21/05/14 14:45:52 INFO StagingCommitter: Starting: Task committer attempt_202105141443468828345223131791741_0004_m_000053_625: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443468828345223131791741_0004_m_000053_625
[2021-05-14 11:45:52,652] {docker.py:276} INFO - 21/05/14 14:45:52 INFO StagingCommitter: Task committer attempt_202105141443468828345223131791741_0004_m_000053_625: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443468828345223131791741_0004_m_000053_625 : duration 0:00.004s
[2021-05-14 11:45:53,303] {docker.py:276} INFO - 21/05/14 14:45:53 INFO StagingCommitter: Starting: Task committer attempt_202105141443468872932758637024292_0004_m_000050_622: needsTaskCommit() Task attempt_202105141443468872932758637024292_0004_m_000050_622
[2021-05-14 11:45:53,304] {docker.py:276} INFO - 21/05/14 14:45:53 INFO StagingCommitter: Task committer attempt_202105141443468872932758637024292_0004_m_000050_622: needsTaskCommit() Task attempt_202105141443468872932758637024292_0004_m_000050_622: duration 0:00.003s
[2021-05-14 11:45:53,304] {docker.py:276} INFO - 21/05/14 14:45:53 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443468872932758637024292_0004_m_000050_622
[2021-05-14 11:45:53,306] {docker.py:276} INFO - 21/05/14 14:45:53 INFO Executor: Finished task 50.0 in stage 4.0 (TID 622). 5149 bytes result sent to driver
[2021-05-14 11:45:53,308] {docker.py:276} INFO - 21/05/14 14:45:53 INFO TaskSetManager: Starting task 54.0 in stage 4.0 (TID 626) (f0b8ef7ba22f, executor driver, partition 54, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:45:53,309] {docker.py:276} INFO - 21/05/14 14:45:53 INFO Executor: Running task 54.0 in stage 4.0 (TID 626)
[2021-05-14 11:45:53,310] {docker.py:276} INFO - 21/05/14 14:45:53 INFO TaskSetManager: Finished task 50.0 in stage 4.0 (TID 622) in 7492 ms on f0b8ef7ba22f (executor driver) (51/200)
[2021-05-14 11:45:53,320] {docker.py:276} INFO - 21/05/14 14:45:53 INFO ShuffleBlockFetcherIterator: Getting 9 (64.9 KiB) non-empty blocks including 9 (64.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:45:53 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:45:53,329] {docker.py:276} INFO - 21/05/14 14:45:53 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:45:53 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/05/14 14:45:53 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
21/05/14 14:45:53 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443464583302181838745006_0004_m_000054_626, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443464583302181838745006_0004_m_000054_626}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443464583302181838745006_0004}; taskId=attempt_202105141443464583302181838745006_0004_m_000054_626, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@790420a2}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
21/05/14 14:45:53 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
21/05/14 14:45:53 INFO StagingCommitter: Starting: Task committer attempt_202105141443464583302181838745006_0004_m_000054_626: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443464583302181838745006_0004_m_000054_626
[2021-05-14 11:45:53,334] {docker.py:276} INFO - 21/05/14 14:45:53 INFO StagingCommitter: Task committer attempt_202105141443464583302181838745006_0004_m_000054_626: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443464583302181838745006_0004_m_000054_626 : duration 0:00.004s
[2021-05-14 11:45:55,047] {docker.py:276} INFO - 21/05/14 14:45:55 INFO StagingCommitter: Starting: Task committer attempt_202105141443461939846379015451182_0004_m_000051_623: needsTaskCommit() Task attempt_202105141443461939846379015451182_0004_m_000051_623
[2021-05-14 11:45:55,047] {docker.py:276} INFO - 21/05/14 14:45:55 INFO StagingCommitter: Task committer attempt_202105141443461939846379015451182_0004_m_000051_623: needsTaskCommit() Task attempt_202105141443461939846379015451182_0004_m_000051_623: duration 0:00.002s
21/05/14 14:45:55 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443461939846379015451182_0004_m_000051_623
[2021-05-14 11:45:55,049] {docker.py:276} INFO - 21/05/14 14:45:55 INFO Executor: Finished task 51.0 in stage 4.0 (TID 623). 5149 bytes result sent to driver
[2021-05-14 11:45:55,050] {docker.py:276} INFO - 21/05/14 14:45:55 INFO TaskSetManager: Starting task 55.0 in stage 4.0 (TID 627) (f0b8ef7ba22f, executor driver, partition 55, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:45:55,051] {docker.py:276} INFO - 21/05/14 14:45:55 INFO TaskSetManager: Finished task 51.0 in stage 4.0 (TID 623) in 6962 ms on f0b8ef7ba22f (executor driver) (52/200)
[2021-05-14 11:45:55,052] {docker.py:276} INFO - 21/05/14 14:45:55 INFO Executor: Running task 55.0 in stage 4.0 (TID 627)
[2021-05-14 11:45:55,061] {docker.py:276} INFO - 21/05/14 14:45:55 INFO ShuffleBlockFetcherIterator: Getting 9 (65.7 KiB) non-empty blocks including 9 (65.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:45:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:45:55,070] {docker.py:276} INFO - 21/05/14 14:45:55 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:45:55 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/05/14 14:45:55 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
[2021-05-14 11:45:55,071] {docker.py:276} INFO - 21/05/14 14:45:55 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443468252987342699284241_0004_m_000055_627, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443468252987342699284241_0004_m_000055_627}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443468252987342699284241_0004}; taskId=attempt_202105141443468252987342699284241_0004_m_000055_627, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@3aea949f}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
21/05/14 14:45:55 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
21/05/14 14:45:55 INFO StagingCommitter: Starting: Task committer attempt_202105141443468252987342699284241_0004_m_000055_627: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443468252987342699284241_0004_m_000055_627
[2021-05-14 11:45:55,075] {docker.py:276} INFO - 21/05/14 14:45:55 INFO StagingCommitter: Task committer attempt_202105141443468252987342699284241_0004_m_000055_627: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443468252987342699284241_0004_m_000055_627 : duration 0:00.004s
[2021-05-14 11:45:56,545] {docker.py:276} INFO - 21/05/14 14:45:56 INFO StagingCommitter: Starting: Task committer attempt_202105141443462907262087074688786_0004_m_000052_624: needsTaskCommit() Task attempt_202105141443462907262087074688786_0004_m_000052_624
[2021-05-14 11:45:56,546] {docker.py:276} INFO - 21/05/14 14:45:56 INFO StagingCommitter: Task committer attempt_202105141443462907262087074688786_0004_m_000052_624: needsTaskCommit() Task attempt_202105141443462907262087074688786_0004_m_000052_624: duration 0:00.003s
21/05/14 14:45:56 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443462907262087074688786_0004_m_000052_624
[2021-05-14 11:45:56,548] {docker.py:276} INFO - 21/05/14 14:45:56 INFO Executor: Finished task 52.0 in stage 4.0 (TID 624). 5149 bytes result sent to driver
[2021-05-14 11:45:56,550] {docker.py:276} INFO - 21/05/14 14:45:56 INFO TaskSetManager: Starting task 56.0 in stage 4.0 (TID 628) (f0b8ef7ba22f, executor driver, partition 56, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:45:56,551] {docker.py:276} INFO - 21/05/14 14:45:56 INFO TaskSetManager: Finished task 52.0 in stage 4.0 (TID 624) in 6146 ms on f0b8ef7ba22f (executor driver) (53/200)
[2021-05-14 11:45:56,552] {docker.py:276} INFO - 21/05/14 14:45:56 INFO Executor: Running task 56.0 in stage 4.0 (TID 628)
[2021-05-14 11:45:56,563] {docker.py:276} INFO - 21/05/14 14:45:56 INFO ShuffleBlockFetcherIterator: Getting 9 (64.2 KiB) non-empty blocks including 9 (64.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:45:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:45:56,573] {docker.py:276} INFO - 21/05/14 14:45:56 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:45:56 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/05/14 14:45:56 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
21/05/14 14:45:56 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443464862212373443192426_0004_m_000056_628, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443464862212373443192426_0004_m_000056_628}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443464862212373443192426_0004}; taskId=attempt_202105141443464862212373443192426_0004_m_000056_628, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@5521e901}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
21/05/14 14:45:56 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
21/05/14 14:45:56 INFO StagingCommitter: Starting: Task committer attempt_202105141443464862212373443192426_0004_m_000056_628: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443464862212373443192426_0004_m_000056_628
[2021-05-14 11:45:56,577] {docker.py:276} INFO - 21/05/14 14:45:56 INFO StagingCommitter: Task committer attempt_202105141443464862212373443192426_0004_m_000056_628: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443464862212373443192426_0004_m_000056_628 : duration 0:00.004s
[2021-05-14 11:45:59,338] {docker.py:276} INFO - 21/05/14 14:45:59 INFO StagingCommitter: Starting: Task committer attempt_202105141443468828345223131791741_0004_m_000053_625: needsTaskCommit() Task attempt_202105141443468828345223131791741_0004_m_000053_625
21/05/14 14:45:59 INFO StagingCommitter: Task committer attempt_202105141443468828345223131791741_0004_m_000053_625: needsTaskCommit() Task attempt_202105141443468828345223131791741_0004_m_000053_625: duration 0:00.002s
21/05/14 14:45:59 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443468828345223131791741_0004_m_000053_625
[2021-05-14 11:45:59,340] {docker.py:276} INFO - 21/05/14 14:45:59 INFO Executor: Finished task 53.0 in stage 4.0 (TID 625). 5149 bytes result sent to driver
[2021-05-14 11:45:59,342] {docker.py:276} INFO - 21/05/14 14:45:59 INFO TaskSetManager: Starting task 57.0 in stage 4.0 (TID 629) (f0b8ef7ba22f, executor driver, partition 57, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:45:59,343] {docker.py:276} INFO - 21/05/14 14:45:59 INFO Executor: Running task 57.0 in stage 4.0 (TID 629)
[2021-05-14 11:45:59,343] {docker.py:276} INFO - 21/05/14 14:45:59 INFO TaskSetManager: Finished task 53.0 in stage 4.0 (TID 625) in 6725 ms on f0b8ef7ba22f (executor driver) (54/200)
[2021-05-14 11:45:59,354] {docker.py:276} INFO - 21/05/14 14:45:59 INFO ShuffleBlockFetcherIterator: Getting 9 (68.7 KiB) non-empty blocks including 9 (68.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:45:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:45:59,366] {docker.py:276} INFO - 21/05/14 14:45:59 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:45:59 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/05/14 14:45:59 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
[2021-05-14 11:45:59,367] {docker.py:276} INFO - 21/05/14 14:45:59 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443468483120772839843249_0004_m_000057_629, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443468483120772839843249_0004_m_000057_629}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443468483120772839843249_0004}; taskId=attempt_202105141443468483120772839843249_0004_m_000057_629, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@7735497a}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
21/05/14 14:45:59 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
[2021-05-14 11:45:59,367] {docker.py:276} INFO - 21/05/14 14:45:59 INFO StagingCommitter: Starting: Task committer attempt_202105141443468483120772839843249_0004_m_000057_629: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443468483120772839843249_0004_m_000057_629
[2021-05-14 11:45:59,372] {docker.py:276} INFO - 21/05/14 14:45:59 INFO StagingCommitter: Task committer attempt_202105141443468483120772839843249_0004_m_000057_629: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443468483120772839843249_0004_m_000057_629 : duration 0:00.005s
[2021-05-14 11:46:00,239] {docker.py:276} INFO - 21/05/14 14:46:00 INFO StagingCommitter: Starting: Task committer attempt_202105141443464583302181838745006_0004_m_000054_626: needsTaskCommit() Task attempt_202105141443464583302181838745006_0004_m_000054_626
[2021-05-14 11:46:00,240] {docker.py:276} INFO - 21/05/14 14:46:00 INFO StagingCommitter: Task committer attempt_202105141443464583302181838745006_0004_m_000054_626: needsTaskCommit() Task attempt_202105141443464583302181838745006_0004_m_000054_626: duration 0:00.002s
21/05/14 14:46:00 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443464583302181838745006_0004_m_000054_626
[2021-05-14 11:46:00,241] {docker.py:276} INFO - 21/05/14 14:46:00 INFO Executor: Finished task 54.0 in stage 4.0 (TID 626). 5106 bytes result sent to driver
[2021-05-14 11:46:00,242] {docker.py:276} INFO - 21/05/14 14:46:00 INFO TaskSetManager: Starting task 58.0 in stage 4.0 (TID 630) (f0b8ef7ba22f, executor driver, partition 58, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:46:00,243] {docker.py:276} INFO - 21/05/14 14:46:00 INFO Executor: Running task 58.0 in stage 4.0 (TID 630)
[2021-05-14 11:46:00,244] {docker.py:276} INFO - 21/05/14 14:46:00 INFO TaskSetManager: Finished task 54.0 in stage 4.0 (TID 626) in 6944 ms on f0b8ef7ba22f (executor driver) (55/200)
[2021-05-14 11:46:00,254] {docker.py:276} INFO - 21/05/14 14:46:00 INFO ShuffleBlockFetcherIterator: Getting 9 (68.3 KiB) non-empty blocks including 9 (68.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:46:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:46:00,264] {docker.py:276} INFO - 21/05/14 14:46:00 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:46:00 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2021-05-14 11:46:00,264] {docker.py:276} INFO - 21/05/14 14:46:00 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
[2021-05-14 11:46:00,264] {docker.py:276} INFO - 21/05/14 14:46:00 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443465487245764815979833_0004_m_000058_630, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443465487245764815979833_0004_m_000058_630}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443465487245764815979833_0004}; taskId=attempt_202105141443465487245764815979833_0004_m_000058_630, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@25a4de7e}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
[2021-05-14 11:46:00,265] {docker.py:276} INFO - 21/05/14 14:46:00 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
21/05/14 14:46:00 INFO StagingCommitter: Starting: Task committer attempt_202105141443465487245764815979833_0004_m_000058_630: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443465487245764815979833_0004_m_000058_630
[2021-05-14 11:46:00,267] {docker.py:276} INFO - 21/05/14 14:46:00 INFO StagingCommitter: Task committer attempt_202105141443465487245764815979833_0004_m_000058_630: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443465487245764815979833_0004_m_000058_630 : duration 0:00.004s
[2021-05-14 11:46:01,717] {docker.py:276} INFO - 21/05/14 14:46:01 INFO StagingCommitter: Starting: Task committer attempt_202105141443468252987342699284241_0004_m_000055_627: needsTaskCommit() Task attempt_202105141443468252987342699284241_0004_m_000055_627
21/05/14 14:46:01 INFO StagingCommitter: Task committer attempt_202105141443468252987342699284241_0004_m_000055_627: needsTaskCommit() Task attempt_202105141443468252987342699284241_0004_m_000055_627: duration 0:00.001s
21/05/14 14:46:01 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443468252987342699284241_0004_m_000055_627
[2021-05-14 11:46:01,717] {docker.py:276} INFO - 21/05/14 14:46:01 INFO Executor: Finished task 55.0 in stage 4.0 (TID 627). 5106 bytes result sent to driver
[2021-05-14 11:46:01,718] {docker.py:276} INFO - 21/05/14 14:46:01 INFO TaskSetManager: Starting task 59.0 in stage 4.0 (TID 631) (f0b8ef7ba22f, executor driver, partition 59, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:46:01,719] {docker.py:276} INFO - 21/05/14 14:46:01 INFO TaskSetManager: Finished task 55.0 in stage 4.0 (TID 627) in 6677 ms on f0b8ef7ba22f (executor driver) (56/200)
[2021-05-14 11:46:01,720] {docker.py:276} INFO - 21/05/14 14:46:01 INFO Executor: Running task 59.0 in stage 4.0 (TID 631)
[2021-05-14 11:46:01,728] {docker.py:276} INFO - 21/05/14 14:46:01 INFO ShuffleBlockFetcherIterator: Getting 9 (68.0 KiB) non-empty blocks including 9 (68.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:46:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:46:01,738] {docker.py:276} INFO - 21/05/14 14:46:01 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:46:01 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/05/14 14:46:01 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
21/05/14 14:46:01 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443465444495853592068329_0004_m_000059_631, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443465444495853592068329_0004_m_000059_631}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443465444495853592068329_0004}; taskId=attempt_202105141443465444495853592068329_0004_m_000059_631, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@440acc70}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
[2021-05-14 11:46:01,739] {docker.py:276} INFO - 21/05/14 14:46:01 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
21/05/14 14:46:01 INFO StagingCommitter: Starting: Task committer attempt_202105141443465444495853592068329_0004_m_000059_631: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443465444495853592068329_0004_m_000059_631
[2021-05-14 11:46:01,743] {docker.py:276} INFO - 21/05/14 14:46:01 INFO StagingCommitter: Task committer attempt_202105141443465444495853592068329_0004_m_000059_631: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443465444495853592068329_0004_m_000059_631 : duration 0:00.004s
[2021-05-14 11:46:03,903] {docker.py:276} INFO - 21/05/14 14:46:03 INFO StagingCommitter: Starting: Task committer attempt_202105141443464862212373443192426_0004_m_000056_628: needsTaskCommit() Task attempt_202105141443464862212373443192426_0004_m_000056_628
[2021-05-14 11:46:03,904] {docker.py:276} INFO - 21/05/14 14:46:03 INFO StagingCommitter: Task committer attempt_202105141443464862212373443192426_0004_m_000056_628: needsTaskCommit() Task attempt_202105141443464862212373443192426_0004_m_000056_628: duration 0:00.001s
[2021-05-14 11:46:03,904] {docker.py:276} INFO - 21/05/14 14:46:03 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443464862212373443192426_0004_m_000056_628
[2021-05-14 11:46:03,905] {docker.py:276} INFO - 21/05/14 14:46:03 INFO Executor: Finished task 56.0 in stage 4.0 (TID 628). 5106 bytes result sent to driver
[2021-05-14 11:46:03,907] {docker.py:276} INFO - 21/05/14 14:46:03 INFO TaskSetManager: Starting task 60.0 in stage 4.0 (TID 632) (f0b8ef7ba22f, executor driver, partition 60, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
21/05/14 14:46:03 INFO Executor: Running task 60.0 in stage 4.0 (TID 632)
[2021-05-14 11:46:03,909] {docker.py:276} INFO - 21/05/14 14:46:03 INFO TaskSetManager: Finished task 56.0 in stage 4.0 (TID 628) in 7368 ms on f0b8ef7ba22f (executor driver) (57/200)
[2021-05-14 11:46:03,916] {docker.py:276} INFO - 21/05/14 14:46:03 INFO ShuffleBlockFetcherIterator: Getting 9 (64.2 KiB) non-empty blocks including 9 (64.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:46:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:46:03,926] {docker.py:276} INFO - 21/05/14 14:46:03 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:46:03 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2021-05-14 11:46:03,926] {docker.py:276} INFO - 21/05/14 14:46:03 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
21/05/14 14:46:03 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443461722366081045782482_0004_m_000060_632, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443461722366081045782482_0004_m_000060_632}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443461722366081045782482_0004}; taskId=attempt_202105141443461722366081045782482_0004_m_000060_632, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@1f08cdae}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
21/05/14 14:46:03 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
[2021-05-14 11:46:03,927] {docker.py:276} INFO - 21/05/14 14:46:03 INFO StagingCommitter: Starting: Task committer attempt_202105141443461722366081045782482_0004_m_000060_632: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443461722366081045782482_0004_m_000060_632
[2021-05-14 11:46:03,930] {docker.py:276} INFO - 21/05/14 14:46:03 INFO StagingCommitter: Task committer attempt_202105141443461722366081045782482_0004_m_000060_632: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443461722366081045782482_0004_m_000060_632 : duration 0:00.004s
[2021-05-14 11:46:06,690] {docker.py:276} INFO - 21/05/14 14:46:06 INFO StagingCommitter: Starting: Task committer attempt_202105141443468483120772839843249_0004_m_000057_629: needsTaskCommit() Task attempt_202105141443468483120772839843249_0004_m_000057_629
21/05/14 14:46:06 INFO StagingCommitter: Task committer attempt_202105141443468483120772839843249_0004_m_000057_629: needsTaskCommit() Task attempt_202105141443468483120772839843249_0004_m_000057_629: duration 0:00.003s
21/05/14 14:46:06 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443468483120772839843249_0004_m_000057_629
[2021-05-14 11:46:06,692] {docker.py:276} INFO - 21/05/14 14:46:06 INFO Executor: Finished task 57.0 in stage 4.0 (TID 629). 5106 bytes result sent to driver
[2021-05-14 11:46:06,694] {docker.py:276} INFO - 21/05/14 14:46:06 INFO TaskSetManager: Starting task 61.0 in stage 4.0 (TID 633) (f0b8ef7ba22f, executor driver, partition 61, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:46:06,695] {docker.py:276} INFO - 21/05/14 14:46:06 INFO Executor: Running task 61.0 in stage 4.0 (TID 633)
[2021-05-14 11:46:06,696] {docker.py:276} INFO - 21/05/14 14:46:06 INFO TaskSetManager: Finished task 57.0 in stage 4.0 (TID 629) in 7363 ms on f0b8ef7ba22f (executor driver) (58/200)
[2021-05-14 11:46:06,706] {docker.py:276} INFO - 21/05/14 14:46:06 INFO ShuffleBlockFetcherIterator: Getting 9 (65.9 KiB) non-empty blocks including 9 (65.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:46:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:46:06,716] {docker.py:276} INFO - 21/05/14 14:46:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:46:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/05/14 14:46:06 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
21/05/14 14:46:06 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443461434878926719331238_0004_m_000061_633, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443461434878926719331238_0004_m_000061_633}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443461434878926719331238_0004}; taskId=attempt_202105141443461434878926719331238_0004_m_000061_633, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@3af72eb0}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
21/05/14 14:46:06 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
21/05/14 14:46:06 INFO StagingCommitter: Starting: Task committer attempt_202105141443461434878926719331238_0004_m_000061_633: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443461434878926719331238_0004_m_000061_633
[2021-05-14 11:46:06,720] {docker.py:276} INFO - 21/05/14 14:46:06 INFO StagingCommitter: Task committer attempt_202105141443461434878926719331238_0004_m_000061_633: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443461434878926719331238_0004_m_000061_633 : duration 0:00.004s
[2021-05-14 11:46:06,744] {docker.py:276} INFO - 21/05/14 14:46:06 INFO StagingCommitter: Starting: Task committer attempt_202105141443465487245764815979833_0004_m_000058_630: needsTaskCommit() Task attempt_202105141443465487245764815979833_0004_m_000058_630
[2021-05-14 11:46:06,745] {docker.py:276} INFO - 21/05/14 14:46:06 INFO StagingCommitter: Task committer attempt_202105141443465487245764815979833_0004_m_000058_630: needsTaskCommit() Task attempt_202105141443465487245764815979833_0004_m_000058_630: duration 0:00.002s
21/05/14 14:46:06 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443465487245764815979833_0004_m_000058_630
[2021-05-14 11:46:06,748] {docker.py:276} INFO - 21/05/14 14:46:06 INFO Executor: Finished task 58.0 in stage 4.0 (TID 630). 5106 bytes result sent to driver
[2021-05-14 11:46:06,749] {docker.py:276} INFO - 21/05/14 14:46:06 INFO TaskSetManager: Starting task 62.0 in stage 4.0 (TID 634) (f0b8ef7ba22f, executor driver, partition 62, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:46:06,750] {docker.py:276} INFO - 21/05/14 14:46:06 INFO Executor: Running task 62.0 in stage 4.0 (TID 634)
[2021-05-14 11:46:06,751] {docker.py:276} INFO - 21/05/14 14:46:06 INFO TaskSetManager: Finished task 58.0 in stage 4.0 (TID 630) in 6516 ms on f0b8ef7ba22f (executor driver) (59/200)
[2021-05-14 11:46:06,760] {docker.py:276} INFO - 21/05/14 14:46:06 INFO ShuffleBlockFetcherIterator: Getting 9 (63.8 KiB) non-empty blocks including 9 (63.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:46:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:46:06,769] {docker.py:276} INFO - 21/05/14 14:46:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:46:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/05/14 14:46:06 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
[2021-05-14 11:46:06,770] {docker.py:276} INFO - 21/05/14 14:46:06 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443468001697642873501187_0004_m_000062_634, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443468001697642873501187_0004_m_000062_634}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443468001697642873501187_0004}; taskId=attempt_202105141443468001697642873501187_0004_m_000062_634, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@67a5b434}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
21/05/14 14:46:06 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
21/05/14 14:46:06 INFO StagingCommitter: Starting: Task committer attempt_202105141443468001697642873501187_0004_m_000062_634: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443468001697642873501187_0004_m_000062_634
[2021-05-14 11:46:06,774] {docker.py:276} INFO - 21/05/14 14:46:06 INFO StagingCommitter: Task committer attempt_202105141443468001697642873501187_0004_m_000062_634: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443468001697642873501187_0004_m_000062_634 : duration 0:00.003s
[2021-05-14 11:46:08,120] {docker.py:276} INFO - 21/05/14 14:46:08 INFO StagingCommitter: Starting: Task committer attempt_202105141443465444495853592068329_0004_m_000059_631: needsTaskCommit() Task attempt_202105141443465444495853592068329_0004_m_000059_631
[2021-05-14 11:46:08,121] {docker.py:276} INFO - 21/05/14 14:46:08 INFO StagingCommitter: Task committer attempt_202105141443465444495853592068329_0004_m_000059_631: needsTaskCommit() Task attempt_202105141443465444495853592068329_0004_m_000059_631: duration 0:00.003s
[2021-05-14 11:46:08,121] {docker.py:276} INFO - 21/05/14 14:46:08 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443465444495853592068329_0004_m_000059_631
[2021-05-14 11:46:08,122] {docker.py:276} INFO - 21/05/14 14:46:08 INFO Executor: Finished task 59.0 in stage 4.0 (TID 631). 5106 bytes result sent to driver
[2021-05-14 11:46:08,125] {docker.py:276} INFO - 21/05/14 14:46:08 INFO TaskSetManager: Starting task 63.0 in stage 4.0 (TID 635) (f0b8ef7ba22f, executor driver, partition 63, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:46:08,126] {docker.py:276} INFO - 21/05/14 14:46:08 INFO Executor: Running task 63.0 in stage 4.0 (TID 635)
[2021-05-14 11:46:08,126] {docker.py:276} INFO - 21/05/14 14:46:08 INFO TaskSetManager: Finished task 59.0 in stage 4.0 (TID 631) in 6415 ms on f0b8ef7ba22f (executor driver) (60/200)
[2021-05-14 11:46:08,135] {docker.py:276} INFO - 21/05/14 14:46:08 INFO ShuffleBlockFetcherIterator: Getting 9 (70.6 KiB) non-empty blocks including 9 (70.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:46:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:46:08,145] {docker.py:276} INFO - 21/05/14 14:46:08 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:46:08 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/05/14 14:46:08 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
21/05/14 14:46:08 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443466901785362957392748_0004_m_000063_635, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443466901785362957392748_0004_m_000063_635}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443466901785362957392748_0004}; taskId=attempt_202105141443466901785362957392748_0004_m_000063_635, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@696b0bcb}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
21/05/14 14:46:08 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
[2021-05-14 11:46:08,145] {docker.py:276} INFO - 21/05/14 14:46:08 INFO StagingCommitter: Starting: Task committer attempt_202105141443466901785362957392748_0004_m_000063_635: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443466901785362957392748_0004_m_000063_635
[2021-05-14 11:46:08,149] {docker.py:276} INFO - 21/05/14 14:46:08 INFO StagingCommitter: Task committer attempt_202105141443466901785362957392748_0004_m_000063_635: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443466901785362957392748_0004_m_000063_635 : duration 0:00.005s
[2021-05-14 11:46:11,428] {docker.py:276} INFO - 21/05/14 14:46:11 INFO StagingCommitter: Starting: Task committer attempt_202105141443461722366081045782482_0004_m_000060_632: needsTaskCommit() Task attempt_202105141443461722366081045782482_0004_m_000060_632
[2021-05-14 11:46:11,430] {docker.py:276} INFO - 21/05/14 14:46:11 INFO StagingCommitter: Task committer attempt_202105141443461722366081045782482_0004_m_000060_632: needsTaskCommit() Task attempt_202105141443461722366081045782482_0004_m_000060_632: duration 0:00.003s
[2021-05-14 11:46:11,431] {docker.py:276} INFO - 21/05/14 14:46:11 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443461722366081045782482_0004_m_000060_632
[2021-05-14 11:46:11,432] {docker.py:276} INFO - 21/05/14 14:46:11 INFO Executor: Finished task 60.0 in stage 4.0 (TID 632). 5106 bytes result sent to driver
[2021-05-14 11:46:11,434] {docker.py:276} INFO - 21/05/14 14:46:11 INFO TaskSetManager: Starting task 64.0 in stage 4.0 (TID 636) (f0b8ef7ba22f, executor driver, partition 64, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:46:11,435] {docker.py:276} INFO - 21/05/14 14:46:11 INFO TaskSetManager: Finished task 60.0 in stage 4.0 (TID 632) in 7502 ms on f0b8ef7ba22f (executor driver) (61/200)
[2021-05-14 11:46:11,435] {docker.py:276} INFO - 21/05/14 14:46:11 INFO Executor: Running task 64.0 in stage 4.0 (TID 636)
[2021-05-14 11:46:11,444] {docker.py:276} INFO - 21/05/14 14:46:11 INFO ShuffleBlockFetcherIterator: Getting 9 (65.0 KiB) non-empty blocks including 9 (65.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:46:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:46:11,454] {docker.py:276} INFO - 21/05/14 14:46:11 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:46:11 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2021-05-14 11:46:11,454] {docker.py:276} INFO - 21/05/14 14:46:11 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
21/05/14 14:46:11 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443463257226363229852518_0004_m_000064_636, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443463257226363229852518_0004_m_000064_636}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443463257226363229852518_0004}; taskId=attempt_202105141443463257226363229852518_0004_m_000064_636, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@7d68b919}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
[2021-05-14 11:46:11,455] {docker.py:276} INFO - 21/05/14 14:46:11 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
[2021-05-14 11:46:11,455] {docker.py:276} INFO - 21/05/14 14:46:11 INFO StagingCommitter: Starting: Task committer attempt_202105141443463257226363229852518_0004_m_000064_636: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443463257226363229852518_0004_m_000064_636
[2021-05-14 11:46:11,458] {docker.py:276} INFO - 21/05/14 14:46:11 INFO StagingCommitter: Task committer attempt_202105141443463257226363229852518_0004_m_000064_636: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443463257226363229852518_0004_m_000064_636 : duration 0:00.004s
[2021-05-14 11:46:12,713] {docker.py:276} INFO - 21/05/14 14:46:12 INFO StagingCommitter: Starting: Task committer attempt_202105141443461434878926719331238_0004_m_000061_633: needsTaskCommit() Task attempt_202105141443461434878926719331238_0004_m_000061_633
[2021-05-14 11:46:12,714] {docker.py:276} INFO - 21/05/14 14:46:12 INFO StagingCommitter: Task committer attempt_202105141443461434878926719331238_0004_m_000061_633: needsTaskCommit() Task attempt_202105141443461434878926719331238_0004_m_000061_633: duration 0:00.002s
[2021-05-14 11:46:12,715] {docker.py:276} INFO - 21/05/14 14:46:12 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443461434878926719331238_0004_m_000061_633
[2021-05-14 11:46:12,716] {docker.py:276} INFO - 21/05/14 14:46:12 INFO Executor: Finished task 61.0 in stage 4.0 (TID 633). 5106 bytes result sent to driver
[2021-05-14 11:46:12,717] {docker.py:276} INFO - 21/05/14 14:46:12 INFO TaskSetManager: Starting task 65.0 in stage 4.0 (TID 637) (f0b8ef7ba22f, executor driver, partition 65, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:46:12,718] {docker.py:276} INFO - 21/05/14 14:46:12 INFO Executor: Running task 65.0 in stage 4.0 (TID 637)
[2021-05-14 11:46:12,719] {docker.py:276} INFO - 21/05/14 14:46:12 INFO TaskSetManager: Finished task 61.0 in stage 4.0 (TID 633) in 5998 ms on f0b8ef7ba22f (executor driver) (62/200)
[2021-05-14 11:46:12,728] {docker.py:276} INFO - 21/05/14 14:46:12 INFO ShuffleBlockFetcherIterator: Getting 9 (67.9 KiB) non-empty blocks including 9 (67.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:46:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:46:12,738] {docker.py:276} INFO - 21/05/14 14:46:12 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:46:12 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2021-05-14 11:46:12,738] {docker.py:276} INFO - 21/05/14 14:46:12 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
[2021-05-14 11:46:12,739] {docker.py:276} INFO - 21/05/14 14:46:12 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443463552774655430343736_0004_m_000065_637, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443463552774655430343736_0004_m_000065_637}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443463552774655430343736_0004}; taskId=attempt_202105141443463552774655430343736_0004_m_000065_637, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@6355f589}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
21/05/14 14:46:12 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
21/05/14 14:46:12 INFO StagingCommitter: Starting: Task committer attempt_202105141443463552774655430343736_0004_m_000065_637: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443463552774655430343736_0004_m_000065_637
[2021-05-14 11:46:12,744] {docker.py:276} INFO - 21/05/14 14:46:12 INFO StagingCommitter: Task committer attempt_202105141443463552774655430343736_0004_m_000065_637: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443463552774655430343736_0004_m_000065_637 : duration 0:00.004s
[2021-05-14 11:46:13,595] {docker.py:276} INFO - 21/05/14 14:46:13 INFO StagingCommitter: Starting: Task committer attempt_202105141443468001697642873501187_0004_m_000062_634: needsTaskCommit() Task attempt_202105141443468001697642873501187_0004_m_000062_634
[2021-05-14 11:46:13,596] {docker.py:276} INFO - 21/05/14 14:46:13 INFO StagingCommitter: Task committer attempt_202105141443468001697642873501187_0004_m_000062_634: needsTaskCommit() Task attempt_202105141443468001697642873501187_0004_m_000062_634: duration 0:00.001s
[2021-05-14 11:46:13,597] {docker.py:276} INFO - 21/05/14 14:46:13 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443468001697642873501187_0004_m_000062_634
[2021-05-14 11:46:13,601] {docker.py:276} INFO - 21/05/14 14:46:13 INFO Executor: Finished task 62.0 in stage 4.0 (TID 634). 5106 bytes result sent to driver
[2021-05-14 11:46:13,602] {docker.py:276} INFO - 21/05/14 14:46:13 INFO TaskSetManager: Starting task 66.0 in stage 4.0 (TID 638) (f0b8ef7ba22f, executor driver, partition 66, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
21/05/14 14:46:13 INFO Executor: Running task 66.0 in stage 4.0 (TID 638)
21/05/14 14:46:13 INFO TaskSetManager: Finished task 62.0 in stage 4.0 (TID 634) in 6824 ms on f0b8ef7ba22f (executor driver) (63/200)
[2021-05-14 11:46:13,613] {docker.py:276} INFO - 21/05/14 14:46:13 INFO ShuffleBlockFetcherIterator: Getting 9 (63.8 KiB) non-empty blocks including 9 (63.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
[2021-05-14 11:46:13,614] {docker.py:276} INFO - 21/05/14 14:46:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:46:13,630] {docker.py:276} INFO - 21/05/14 14:46:13 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:46:13 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/05/14 14:46:13 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
21/05/14 14:46:13 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_20210514144346432018119543652959_0004_m_000066_638, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_20210514144346432018119543652959_0004_m_000066_638}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_20210514144346432018119543652959_0004}; taskId=attempt_20210514144346432018119543652959_0004_m_000066_638, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@1ba17444}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
[2021-05-14 11:46:13,631] {docker.py:276} INFO - 21/05/14 14:46:13 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
[2021-05-14 11:46:13,633] {docker.py:276} INFO - 21/05/14 14:46:13 INFO StagingCommitter: Starting: Task committer attempt_20210514144346432018119543652959_0004_m_000066_638: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_20210514144346432018119543652959_0004_m_000066_638
[2021-05-14 11:46:13,644] {docker.py:276} INFO - 21/05/14 14:46:13 INFO StagingCommitter: Task committer attempt_20210514144346432018119543652959_0004_m_000066_638: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_20210514144346432018119543652959_0004_m_000066_638 : duration 0:00.012s
[2021-05-14 11:46:14,454] {docker.py:276} INFO - 21/05/14 14:46:14 INFO StagingCommitter: Starting: Task committer attempt_202105141443466901785362957392748_0004_m_000063_635: needsTaskCommit() Task attempt_202105141443466901785362957392748_0004_m_000063_635
21/05/14 14:46:14 INFO StagingCommitter: Task committer attempt_202105141443466901785362957392748_0004_m_000063_635: needsTaskCommit() Task attempt_202105141443466901785362957392748_0004_m_000063_635: duration 0:00.002s
21/05/14 14:46:14 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443466901785362957392748_0004_m_000063_635
[2021-05-14 11:46:14,459] {docker.py:276} INFO - 21/05/14 14:46:14 INFO Executor: Finished task 63.0 in stage 4.0 (TID 635). 5106 bytes result sent to driver
21/05/14 14:46:14 INFO TaskSetManager: Starting task 67.0 in stage 4.0 (TID 639) (f0b8ef7ba22f, executor driver, partition 67, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
21/05/14 14:46:14 INFO TaskSetManager: Finished task 63.0 in stage 4.0 (TID 635) in 6308 ms on f0b8ef7ba22f (executor driver) (64/200)
[2021-05-14 11:46:14,460] {docker.py:276} INFO - 21/05/14 14:46:14 INFO Executor: Running task 67.0 in stage 4.0 (TID 639)
[2021-05-14 11:46:14,471] {docker.py:276} INFO - 21/05/14 14:46:14 INFO ShuffleBlockFetcherIterator: Getting 9 (67.5 KiB) non-empty blocks including 9 (67.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:46:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:46:14,480] {docker.py:276} INFO - 21/05/14 14:46:14 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:46:14 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2021-05-14 11:46:14,480] {docker.py:276} INFO - 21/05/14 14:46:14 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
21/05/14 14:46:14 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443461296917024732922060_0004_m_000067_639, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443461296917024732922060_0004_m_000067_639}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443461296917024732922060_0004}; taskId=attempt_202105141443461296917024732922060_0004_m_000067_639, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@ac7cc3f}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
[2021-05-14 11:46:14,481] {docker.py:276} INFO - 21/05/14 14:46:14 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
[2021-05-14 11:46:14,481] {docker.py:276} INFO - 21/05/14 14:46:14 INFO StagingCommitter: Starting: Task committer attempt_202105141443461296917024732922060_0004_m_000067_639: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443461296917024732922060_0004_m_000067_639
[2021-05-14 11:46:14,484] {docker.py:276} INFO - 21/05/14 14:46:14 INFO StagingCommitter: Task committer attempt_202105141443461296917024732922060_0004_m_000067_639: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443461296917024732922060_0004_m_000067_639 : duration 0:00.005s
[2021-05-14 11:46:18,177] {docker.py:276} INFO - 21/05/14 14:46:18 INFO StagingCommitter: Starting: Task committer attempt_202105141443463257226363229852518_0004_m_000064_636: needsTaskCommit() Task attempt_202105141443463257226363229852518_0004_m_000064_636
21/05/14 14:46:18 INFO StagingCommitter: Task committer attempt_202105141443463257226363229852518_0004_m_000064_636: needsTaskCommit() Task attempt_202105141443463257226363229852518_0004_m_000064_636: duration 0:00.003s
21/05/14 14:46:18 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443463257226363229852518_0004_m_000064_636
[2021-05-14 11:46:18,180] {docker.py:276} INFO - 21/05/14 14:46:18 INFO Executor: Finished task 64.0 in stage 4.0 (TID 636). 5149 bytes result sent to driver
[2021-05-14 11:46:18,182] {docker.py:276} INFO - 21/05/14 14:46:18 INFO TaskSetManager: Starting task 68.0 in stage 4.0 (TID 640) (f0b8ef7ba22f, executor driver, partition 68, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:46:18,183] {docker.py:276} INFO - 21/05/14 14:46:18 INFO Executor: Running task 68.0 in stage 4.0 (TID 640)
[2021-05-14 11:46:18,184] {docker.py:276} INFO - 21/05/14 14:46:18 INFO TaskSetManager: Finished task 64.0 in stage 4.0 (TID 636) in 6758 ms on f0b8ef7ba22f (executor driver) (65/200)
[2021-05-14 11:46:18,194] {docker.py:276} INFO - 21/05/14 14:46:18 INFO ShuffleBlockFetcherIterator: Getting 9 (67.1 KiB) non-empty blocks including 9 (67.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:46:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:46:18,203] {docker.py:276} INFO - 21/05/14 14:46:18 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:46:18 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2021-05-14 11:46:18,203] {docker.py:276} INFO - 21/05/14 14:46:18 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
21/05/14 14:46:18 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443463356930078687661014_0004_m_000068_640, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443463356930078687661014_0004_m_000068_640}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443463356930078687661014_0004}; taskId=attempt_202105141443463356930078687661014_0004_m_000068_640, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@3f411ad0}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
21/05/14 14:46:18 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
[2021-05-14 11:46:18,204] {docker.py:276} INFO - 21/05/14 14:46:18 INFO StagingCommitter: Starting: Task committer attempt_202105141443463356930078687661014_0004_m_000068_640: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443463356930078687661014_0004_m_000068_640
[2021-05-14 11:46:18,208] {docker.py:276} INFO - 21/05/14 14:46:18 INFO StagingCommitter: Task committer attempt_202105141443463356930078687661014_0004_m_000068_640: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443463356930078687661014_0004_m_000068_640 : duration 0:00.004s
[2021-05-14 11:46:19,626] {docker.py:276} INFO - 21/05/14 14:46:19 INFO StagingCommitter: Starting: Task committer attempt_20210514144346432018119543652959_0004_m_000066_638: needsTaskCommit() Task attempt_20210514144346432018119543652959_0004_m_000066_638
21/05/14 14:46:19 INFO StagingCommitter: Task committer attempt_20210514144346432018119543652959_0004_m_000066_638: needsTaskCommit() Task attempt_20210514144346432018119543652959_0004_m_000066_638: duration 0:00.002s
21/05/14 14:46:19 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_20210514144346432018119543652959_0004_m_000066_638
[2021-05-14 11:46:19,629] {docker.py:276} INFO - 21/05/14 14:46:19 INFO Executor: Finished task 66.0 in stage 4.0 (TID 638). 5149 bytes result sent to driver
[2021-05-14 11:46:19,630] {docker.py:276} INFO - 21/05/14 14:46:19 INFO TaskSetManager: Starting task 69.0 in stage 4.0 (TID 641) (f0b8ef7ba22f, executor driver, partition 69, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:46:19,631] {docker.py:276} INFO - 21/05/14 14:46:19 INFO Executor: Running task 69.0 in stage 4.0 (TID 641)
[2021-05-14 11:46:19,632] {docker.py:276} INFO - 21/05/14 14:46:19 INFO TaskSetManager: Finished task 66.0 in stage 4.0 (TID 638) in 6040 ms on f0b8ef7ba22f (executor driver) (66/200)
[2021-05-14 11:46:19,641] {docker.py:276} INFO - 21/05/14 14:46:19 INFO ShuffleBlockFetcherIterator: Getting 9 (64.4 KiB) non-empty blocks including 9 (64.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:46:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:46:19,651] {docker.py:276} INFO - 21/05/14 14:46:19 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:46:19 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/05/14 14:46:19 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
21/05/14 14:46:19 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443466086712585068803106_0004_m_000069_641, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443466086712585068803106_0004_m_000069_641}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443466086712585068803106_0004}; taskId=attempt_202105141443466086712585068803106_0004_m_000069_641, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@1f08e5be}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
21/05/14 14:46:19 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
[2021-05-14 11:46:19,652] {docker.py:276} INFO - 21/05/14 14:46:19 INFO StagingCommitter: Starting: Task committer attempt_202105141443466086712585068803106_0004_m_000069_641: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443466086712585068803106_0004_m_000069_641
[2021-05-14 11:46:19,656] {docker.py:276} INFO - 21/05/14 14:46:19 INFO StagingCommitter: Task committer attempt_202105141443466086712585068803106_0004_m_000069_641: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443466086712585068803106_0004_m_000069_641 : duration 0:00.005s
[2021-05-14 11:46:19,750] {docker.py:276} INFO - 21/05/14 14:46:19 INFO StagingCommitter: Starting: Task committer attempt_202105141443463552774655430343736_0004_m_000065_637: needsTaskCommit() Task attempt_202105141443463552774655430343736_0004_m_000065_637
[2021-05-14 11:46:19,751] {docker.py:276} INFO - 21/05/14 14:46:19 INFO StagingCommitter: Task committer attempt_202105141443463552774655430343736_0004_m_000065_637: needsTaskCommit() Task attempt_202105141443463552774655430343736_0004_m_000065_637: duration 0:00.003s
21/05/14 14:46:19 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443463552774655430343736_0004_m_000065_637
[2021-05-14 11:46:19,752] {docker.py:276} INFO - 21/05/14 14:46:19 INFO Executor: Finished task 65.0 in stage 4.0 (TID 637). 5149 bytes result sent to driver
[2021-05-14 11:46:19,753] {docker.py:276} INFO - 21/05/14 14:46:19 INFO TaskSetManager: Starting task 70.0 in stage 4.0 (TID 642) (f0b8ef7ba22f, executor driver, partition 70, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:46:19,754] {docker.py:276} INFO - 21/05/14 14:46:19 INFO Executor: Running task 70.0 in stage 4.0 (TID 642)
[2021-05-14 11:46:19,756] {docker.py:276} INFO - 21/05/14 14:46:19 INFO TaskSetManager: Finished task 65.0 in stage 4.0 (TID 637) in 7046 ms on f0b8ef7ba22f (executor driver) (67/200)
[2021-05-14 11:46:19,765] {docker.py:276} INFO - 21/05/14 14:46:19 INFO ShuffleBlockFetcherIterator: Getting 9 (62.5 KiB) non-empty blocks including 9 (62.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:46:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:46:19,775] {docker.py:276} INFO - 21/05/14 14:46:19 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:46:19 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2021-05-14 11:46:19,776] {docker.py:276} INFO - 21/05/14 14:46:19 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
21/05/14 14:46:19 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_20210514144346941274497104605188_0004_m_000070_642, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_20210514144346941274497104605188_0004_m_000070_642}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_20210514144346941274497104605188_0004}; taskId=attempt_20210514144346941274497104605188_0004_m_000070_642, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@2d7a9f3a}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
[2021-05-14 11:46:19,776] {docker.py:276} INFO - 21/05/14 14:46:19 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
21/05/14 14:46:19 INFO StagingCommitter: Starting: Task committer attempt_20210514144346941274497104605188_0004_m_000070_642: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_20210514144346941274497104605188_0004_m_000070_642
[2021-05-14 11:46:19,779] {docker.py:276} INFO - 21/05/14 14:46:19 INFO StagingCommitter: Task committer attempt_20210514144346941274497104605188_0004_m_000070_642: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_20210514144346941274497104605188_0004_m_000070_642 : duration 0:00.003s
[2021-05-14 11:46:20,518] {docker.py:276} INFO - 21/05/14 14:46:20 INFO StagingCommitter: Starting: Task committer attempt_202105141443461296917024732922060_0004_m_000067_639: needsTaskCommit() Task attempt_202105141443461296917024732922060_0004_m_000067_639
[2021-05-14 11:46:20,519] {docker.py:276} INFO - 21/05/14 14:46:20 INFO StagingCommitter: Task committer attempt_202105141443461296917024732922060_0004_m_000067_639: needsTaskCommit() Task attempt_202105141443461296917024732922060_0004_m_000067_639: duration 0:00.002s
21/05/14 14:46:20 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443461296917024732922060_0004_m_000067_639
[2021-05-14 11:46:20,521] {docker.py:276} INFO - 21/05/14 14:46:20 INFO Executor: Finished task 67.0 in stage 4.0 (TID 639). 5149 bytes result sent to driver
[2021-05-14 11:46:20,524] {docker.py:276} INFO - 21/05/14 14:46:20 INFO TaskSetManager: Starting task 71.0 in stage 4.0 (TID 643) (f0b8ef7ba22f, executor driver, partition 71, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:46:20,525] {docker.py:276} INFO - 21/05/14 14:46:20 INFO Executor: Running task 71.0 in stage 4.0 (TID 643)
[2021-05-14 11:46:20,525] {docker.py:276} INFO - 21/05/14 14:46:20 INFO TaskSetManager: Finished task 67.0 in stage 4.0 (TID 639) in 6072 ms on f0b8ef7ba22f (executor driver) (68/200)
[2021-05-14 11:46:20,532] {docker.py:276} INFO - 21/05/14 14:46:20 INFO ShuffleBlockFetcherIterator: Getting 9 (67.2 KiB) non-empty blocks including 9 (67.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:46:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:46:20,543] {docker.py:276} INFO - 21/05/14 14:46:20 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:46:20 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/05/14 14:46:20 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
21/05/14 14:46:20 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443465712193297068789159_0004_m_000071_643, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443465712193297068789159_0004_m_000071_643}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443465712193297068789159_0004}; taskId=attempt_202105141443465712193297068789159_0004_m_000071_643, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@15546fc1}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
21/05/14 14:46:20 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
21/05/14 14:46:20 INFO StagingCommitter: Starting: Task committer attempt_202105141443465712193297068789159_0004_m_000071_643: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443465712193297068789159_0004_m_000071_643
[2021-05-14 11:46:20,547] {docker.py:276} INFO - 21/05/14 14:46:20 INFO StagingCommitter: Task committer attempt_202105141443465712193297068789159_0004_m_000071_643: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443465712193297068789159_0004_m_000071_643 : duration 0:00.004s
[2021-05-14 11:46:25,113] {docker.py:276} INFO - 21/05/14 14:46:25 INFO StagingCommitter: Starting: Task committer attempt_202105141443463356930078687661014_0004_m_000068_640: needsTaskCommit() Task attempt_202105141443463356930078687661014_0004_m_000068_640
21/05/14 14:46:25 INFO StagingCommitter: Task committer attempt_202105141443463356930078687661014_0004_m_000068_640: needsTaskCommit() Task attempt_202105141443463356930078687661014_0004_m_000068_640: duration 0:00.003s
21/05/14 14:46:25 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443463356930078687661014_0004_m_000068_640
[2021-05-14 11:46:25,117] {docker.py:276} INFO - 21/05/14 14:46:25 INFO Executor: Finished task 68.0 in stage 4.0 (TID 640). 5106 bytes result sent to driver
[2021-05-14 11:46:25,118] {docker.py:276} INFO - 21/05/14 14:46:25 INFO TaskSetManager: Starting task 72.0 in stage 4.0 (TID 644) (f0b8ef7ba22f, executor driver, partition 72, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:46:25,118] {docker.py:276} INFO - 21/05/14 14:46:25 INFO Executor: Running task 72.0 in stage 4.0 (TID 644)
[2021-05-14 11:46:25,119] {docker.py:276} INFO - 21/05/14 14:46:25 INFO TaskSetManager: Finished task 68.0 in stage 4.0 (TID 640) in 6945 ms on f0b8ef7ba22f (executor driver) (69/200)
[2021-05-14 11:46:25,129] {docker.py:276} INFO - 21/05/14 14:46:25 INFO ShuffleBlockFetcherIterator: Getting 9 (63.7 KiB) non-empty blocks including 9 (63.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:46:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:46:25,137] {docker.py:276} INFO - 21/05/14 14:46:25 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2021-05-14 11:46:25,138] {docker.py:276} INFO - 21/05/14 14:46:25 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2021-05-14 11:46:25,138] {docker.py:276} INFO - 21/05/14 14:46:25 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
[2021-05-14 11:46:25,138] {docker.py:276} INFO - 21/05/14 14:46:25 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443465920916793064216988_0004_m_000072_644, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443465920916793064216988_0004_m_000072_644}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443465920916793064216988_0004}; taskId=attempt_202105141443465920916793064216988_0004_m_000072_644, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@600340cd}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
21/05/14 14:46:25 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
21/05/14 14:46:25 INFO StagingCommitter: Starting: Task committer attempt_202105141443465920916793064216988_0004_m_000072_644: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443465920916793064216988_0004_m_000072_644
[2021-05-14 11:46:25,144] {docker.py:276} INFO - 21/05/14 14:46:25 INFO StagingCommitter: Task committer attempt_202105141443465920916793064216988_0004_m_000072_644: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443465920916793064216988_0004_m_000072_644 : duration 0:00.006s
[2021-05-14 11:46:26,615] {docker.py:276} INFO - 21/05/14 14:46:26 INFO StagingCommitter: Starting: Task committer attempt_20210514144346941274497104605188_0004_m_000070_642: needsTaskCommit() Task attempt_20210514144346941274497104605188_0004_m_000070_642
[2021-05-14 11:46:26,617] {docker.py:276} INFO - 21/05/14 14:46:26 INFO StagingCommitter: Task committer attempt_20210514144346941274497104605188_0004_m_000070_642: needsTaskCommit() Task attempt_20210514144346941274497104605188_0004_m_000070_642: duration 0:00.002s
21/05/14 14:46:26 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_20210514144346941274497104605188_0004_m_000070_642
[2021-05-14 11:46:26,619] {docker.py:276} INFO - 21/05/14 14:46:26 INFO Executor: Finished task 70.0 in stage 4.0 (TID 642). 5106 bytes result sent to driver
[2021-05-14 11:46:26,620] {docker.py:276} INFO - 21/05/14 14:46:26 INFO TaskSetManager: Starting task 73.0 in stage 4.0 (TID 645) (f0b8ef7ba22f, executor driver, partition 73, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:46:26,621] {docker.py:276} INFO - 21/05/14 14:46:26 INFO TaskSetManager: Finished task 70.0 in stage 4.0 (TID 642) in 6877 ms on f0b8ef7ba22f (executor driver) (70/200)
[2021-05-14 11:46:26,623] {docker.py:276} INFO - 21/05/14 14:46:26 INFO Executor: Running task 73.0 in stage 4.0 (TID 645)
[2021-05-14 11:46:26,632] {docker.py:276} INFO - 21/05/14 14:46:26 INFO ShuffleBlockFetcherIterator: Getting 9 (64.2 KiB) non-empty blocks including 9 (64.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:46:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:46:26,641] {docker.py:276} INFO - 21/05/14 14:46:26 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:46:26 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/05/14 14:46:26 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
[2021-05-14 11:46:26,641] {docker.py:276} INFO - 21/05/14 14:46:26 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443463328835193201642964_0004_m_000073_645, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443463328835193201642964_0004_m_000073_645}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443463328835193201642964_0004}; taskId=attempt_202105141443463328835193201642964_0004_m_000073_645, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@17555945}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
[2021-05-14 11:46:26,642] {docker.py:276} INFO - 21/05/14 14:46:26 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
[2021-05-14 11:46:26,642] {docker.py:276} INFO - 21/05/14 14:46:26 INFO StagingCommitter: Starting: Task committer attempt_202105141443463328835193201642964_0004_m_000073_645: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443463328835193201642964_0004_m_000073_645
[2021-05-14 11:46:26,647] {docker.py:276} INFO - 21/05/14 14:46:26 INFO StagingCommitter: Task committer attempt_202105141443463328835193201642964_0004_m_000073_645: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443463328835193201642964_0004_m_000073_645 : duration 0:00.005s
[2021-05-14 11:46:27,150] {docker.py:276} INFO - 21/05/14 14:46:27 INFO StagingCommitter: Starting: Task committer attempt_202105141443466086712585068803106_0004_m_000069_641: needsTaskCommit() Task attempt_202105141443466086712585068803106_0004_m_000069_641
21/05/14 14:46:27 INFO StagingCommitter: Task committer attempt_202105141443466086712585068803106_0004_m_000069_641: needsTaskCommit() Task attempt_202105141443466086712585068803106_0004_m_000069_641: duration 0:00.002s
21/05/14 14:46:27 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443466086712585068803106_0004_m_000069_641
[2021-05-14 11:46:27,152] {docker.py:276} INFO - 21/05/14 14:46:27 INFO Executor: Finished task 69.0 in stage 4.0 (TID 641). 5106 bytes result sent to driver
[2021-05-14 11:46:27,153] {docker.py:276} INFO - 21/05/14 14:46:27 INFO TaskSetManager: Starting task 74.0 in stage 4.0 (TID 646) (f0b8ef7ba22f, executor driver, partition 74, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:46:27,154] {docker.py:276} INFO - 21/05/14 14:46:27 INFO Executor: Running task 74.0 in stage 4.0 (TID 646)
21/05/14 14:46:27 INFO TaskSetManager: Finished task 69.0 in stage 4.0 (TID 641) in 7534 ms on f0b8ef7ba22f (executor driver) (71/200)
[2021-05-14 11:46:27,163] {docker.py:276} INFO - 21/05/14 14:46:27 INFO ShuffleBlockFetcherIterator: Getting 9 (65.2 KiB) non-empty blocks including 9 (65.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
[2021-05-14 11:46:27,164] {docker.py:276} INFO - 21/05/14 14:46:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:46:27,174] {docker.py:276} INFO - 21/05/14 14:46:27 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:46:27 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/05/14 14:46:27 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
21/05/14 14:46:27 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443468600071111274635396_0004_m_000074_646, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443468600071111274635396_0004_m_000074_646}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443468600071111274635396_0004}; taskId=attempt_202105141443468600071111274635396_0004_m_000074_646, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@5f8d82da}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
[2021-05-14 11:46:27,175] {docker.py:276} INFO - 21/05/14 14:46:27 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
21/05/14 14:46:27 INFO StagingCommitter: Starting: Task committer attempt_202105141443468600071111274635396_0004_m_000074_646: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443468600071111274635396_0004_m_000074_646
[2021-05-14 11:46:27,179] {docker.py:276} INFO - 21/05/14 14:46:27 INFO StagingCommitter: Task committer attempt_202105141443468600071111274635396_0004_m_000074_646: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443468600071111274635396_0004_m_000074_646 : duration 0:00.004s
[2021-05-14 11:46:27,249] {docker.py:276} INFO - 21/05/14 14:46:27 INFO StagingCommitter: Starting: Task committer attempt_202105141443465712193297068789159_0004_m_000071_643: needsTaskCommit() Task attempt_202105141443465712193297068789159_0004_m_000071_643
[2021-05-14 11:46:27,250] {docker.py:276} INFO - 21/05/14 14:46:27 INFO StagingCommitter: Task committer attempt_202105141443465712193297068789159_0004_m_000071_643: needsTaskCommit() Task attempt_202105141443465712193297068789159_0004_m_000071_643: duration 0:00.003s
21/05/14 14:46:27 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443465712193297068789159_0004_m_000071_643
[2021-05-14 11:46:27,252] {docker.py:276} INFO - 21/05/14 14:46:27 INFO Executor: Finished task 71.0 in stage 4.0 (TID 643). 5106 bytes result sent to driver
[2021-05-14 11:46:27,253] {docker.py:276} INFO - 21/05/14 14:46:27 INFO TaskSetManager: Starting task 75.0 in stage 4.0 (TID 647) (f0b8ef7ba22f, executor driver, partition 75, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:46:27,254] {docker.py:276} INFO - 21/05/14 14:46:27 INFO Executor: Running task 75.0 in stage 4.0 (TID 647)
[2021-05-14 11:46:27,255] {docker.py:276} INFO - 21/05/14 14:46:27 INFO TaskSetManager: Finished task 71.0 in stage 4.0 (TID 643) in 6740 ms on f0b8ef7ba22f (executor driver) (72/200)
[2021-05-14 11:46:27,264] {docker.py:276} INFO - 21/05/14 14:46:27 INFO ShuffleBlockFetcherIterator: Getting 9 (67.4 KiB) non-empty blocks including 9 (67.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:46:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2021-05-14 11:46:27,274] {docker.py:276} INFO - 21/05/14 14:46:27 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:46:27 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/05/14 14:46:27 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
[2021-05-14 11:46:27,275] {docker.py:276} INFO - 21/05/14 14:46:27 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443463852208304445391850_0004_m_000075_647, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443463852208304445391850_0004_m_000075_647}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443463852208304445391850_0004}; taskId=attempt_202105141443463852208304445391850_0004_m_000075_647, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@69a1ada3}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
21/05/14 14:46:27 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
21/05/14 14:46:27 INFO StagingCommitter: Starting: Task committer attempt_202105141443463852208304445391850_0004_m_000075_647: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443463852208304445391850_0004_m_000075_647
[2021-05-14 11:46:27,279] {docker.py:276} INFO - 21/05/14 14:46:27 INFO StagingCommitter: Task committer attempt_202105141443463852208304445391850_0004_m_000075_647: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443463852208304445391850_0004_m_000075_647 : duration 0:00.003s
[2021-05-14 11:46:31,126] {docker.py:276} INFO - 21/05/14 14:46:31 INFO StagingCommitter: Starting: Task committer attempt_202105141443465920916793064216988_0004_m_000072_644: needsTaskCommit() Task attempt_202105141443465920916793064216988_0004_m_000072_644
[2021-05-14 11:46:31,127] {docker.py:276} INFO - 21/05/14 14:46:31 INFO StagingCommitter: Task committer attempt_202105141443465920916793064216988_0004_m_000072_644: needsTaskCommit() Task attempt_202105141443465920916793064216988_0004_m_000072_644: duration 0:00.001s
[2021-05-14 11:46:31,127] {docker.py:276} INFO - 21/05/14 14:46:31 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443465920916793064216988_0004_m_000072_644
[2021-05-14 11:46:31,128] {docker.py:276} INFO - 21/05/14 14:46:31 INFO Executor: Finished task 72.0 in stage 4.0 (TID 644). 5106 bytes result sent to driver
[2021-05-14 11:46:31,129] {docker.py:276} INFO - 21/05/14 14:46:31 INFO TaskSetManager: Starting task 76.0 in stage 4.0 (TID 648) (f0b8ef7ba22f, executor driver, partition 76, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:46:31,131] {docker.py:276} INFO - 21/05/14 14:46:31 INFO Executor: Running task 76.0 in stage 4.0 (TID 648)
[2021-05-14 11:46:31,131] {docker.py:276} INFO - 21/05/14 14:46:31 INFO TaskSetManager: Finished task 72.0 in stage 4.0 (TID 644) in 6021 ms on f0b8ef7ba22f (executor driver) (73/200)
[2021-05-14 11:46:31,139] {docker.py:276} INFO - 21/05/14 14:46:31 INFO ShuffleBlockFetcherIterator: Getting 9 (67.0 KiB) non-empty blocks including 9 (67.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
[2021-05-14 11:46:31,140] {docker.py:276} INFO - 21/05/14 14:46:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:46:31,149] {docker.py:276} INFO - 21/05/14 14:46:31 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:46:31 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/05/14 14:46:31 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
21/05/14 14:46:31 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443464843694931965584416_0004_m_000076_648, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443464843694931965584416_0004_m_000076_648}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443464843694931965584416_0004}; taskId=attempt_202105141443464843694931965584416_0004_m_000076_648, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@2fe553b4}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
[2021-05-14 11:46:31,149] {docker.py:276} INFO - 21/05/14 14:46:31 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
[2021-05-14 11:46:31,150] {docker.py:276} INFO - 21/05/14 14:46:31 INFO StagingCommitter: Starting: Task committer attempt_202105141443464843694931965584416_0004_m_000076_648: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443464843694931965584416_0004_m_000076_648
[2021-05-14 11:46:31,154] {docker.py:276} INFO - 21/05/14 14:46:31 INFO StagingCommitter: Task committer attempt_202105141443464843694931965584416_0004_m_000076_648: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443464843694931965584416_0004_m_000076_648 : duration 0:00.004s
[2021-05-14 11:46:33,910] {docker.py:276} INFO - 21/05/14 14:46:33 INFO StagingCommitter: Starting: Task committer attempt_202105141443468600071111274635396_0004_m_000074_646: needsTaskCommit() Task attempt_202105141443468600071111274635396_0004_m_000074_646
[2021-05-14 11:46:33,911] {docker.py:276} INFO - 21/05/14 14:46:33 INFO StagingCommitter: Task committer attempt_202105141443468600071111274635396_0004_m_000074_646: needsTaskCommit() Task attempt_202105141443468600071111274635396_0004_m_000074_646: duration 0:00.003s
21/05/14 14:46:33 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443468600071111274635396_0004_m_000074_646
[2021-05-14 11:46:33,913] {docker.py:276} INFO - 21/05/14 14:46:33 INFO Executor: Finished task 74.0 in stage 4.0 (TID 646). 5106 bytes result sent to driver
[2021-05-14 11:46:33,914] {docker.py:276} INFO - 21/05/14 14:46:33 INFO TaskSetManager: Starting task 77.0 in stage 4.0 (TID 649) (f0b8ef7ba22f, executor driver, partition 77, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:46:33,915] {docker.py:276} INFO - 21/05/14 14:46:33 INFO TaskSetManager: Finished task 74.0 in stage 4.0 (TID 646) in 6770 ms on f0b8ef7ba22f (executor driver) (74/200)
[2021-05-14 11:46:33,916] {docker.py:276} INFO - 21/05/14 14:46:33 INFO Executor: Running task 77.0 in stage 4.0 (TID 649)
[2021-05-14 11:46:33,925] {docker.py:276} INFO - 21/05/14 14:46:33 INFO ShuffleBlockFetcherIterator: Getting 9 (64.8 KiB) non-empty blocks including 9 (64.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:46:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:46:33,934] {docker.py:276} INFO - 21/05/14 14:46:33 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2021-05-14 11:46:33,935] {docker.py:276} INFO - 21/05/14 14:46:33 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2021-05-14 11:46:33,936] {docker.py:276} INFO - 21/05/14 14:46:33 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
21/05/14 14:46:33 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_20210514144346430057629342109358_0004_m_000077_649, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_20210514144346430057629342109358_0004_m_000077_649}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_20210514144346430057629342109358_0004}; taskId=attempt_20210514144346430057629342109358_0004_m_000077_649, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@50232194}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
[2021-05-14 11:46:33,936] {docker.py:276} INFO - 21/05/14 14:46:33 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
[2021-05-14 11:46:33,936] {docker.py:276} INFO - 21/05/14 14:46:33 INFO StagingCommitter: Starting: Task committer attempt_20210514144346430057629342109358_0004_m_000077_649: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_20210514144346430057629342109358_0004_m_000077_649
[2021-05-14 11:46:33,941] {docker.py:276} INFO - 21/05/14 14:46:33 INFO StagingCommitter: Task committer attempt_20210514144346430057629342109358_0004_m_000077_649: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_20210514144346430057629342109358_0004_m_000077_649 : duration 0:00.005s
[2021-05-14 11:46:33,990] {docker.py:276} INFO - 21/05/14 14:46:34 INFO StagingCommitter: Starting: Task committer attempt_202105141443463328835193201642964_0004_m_000073_645: needsTaskCommit() Task attempt_202105141443463328835193201642964_0004_m_000073_645
[2021-05-14 11:46:33,991] {docker.py:276} INFO - 21/05/14 14:46:34 INFO StagingCommitter: Task committer attempt_202105141443463328835193201642964_0004_m_000073_645: needsTaskCommit() Task attempt_202105141443463328835193201642964_0004_m_000073_645: duration 0:00.001s
[2021-05-14 11:46:33,992] {docker.py:276} INFO - 21/05/14 14:46:34 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443463328835193201642964_0004_m_000073_645
[2021-05-14 11:46:33,993] {docker.py:276} INFO - 21/05/14 14:46:34 INFO Executor: Finished task 73.0 in stage 4.0 (TID 645). 5106 bytes result sent to driver
[2021-05-14 11:46:33,994] {docker.py:276} INFO - 21/05/14 14:46:34 INFO TaskSetManager: Starting task 78.0 in stage 4.0 (TID 650) (f0b8ef7ba22f, executor driver, partition 78, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:46:33,995] {docker.py:276} INFO - 21/05/14 14:46:34 INFO Executor: Running task 78.0 in stage 4.0 (TID 650)
[2021-05-14 11:46:33,996] {docker.py:276} INFO - 21/05/14 14:46:34 INFO TaskSetManager: Finished task 73.0 in stage 4.0 (TID 645) in 7384 ms on f0b8ef7ba22f (executor driver) (75/200)
[2021-05-14 11:46:34,007] {docker.py:276} INFO - 21/05/14 14:46:34 INFO ShuffleBlockFetcherIterator: Getting 9 (65.1 KiB) non-empty blocks including 9 (65.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:46:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:46:34,020] {docker.py:276} INFO - 21/05/14 14:46:34 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:46:34 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2021-05-14 11:46:34,020] {docker.py:276} INFO - 21/05/14 14:46:34 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
[2021-05-14 11:46:34,021] {docker.py:276} INFO - 21/05/14 14:46:34 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443466564087298766893187_0004_m_000078_650, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443466564087298766893187_0004_m_000078_650}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443466564087298766893187_0004}; taskId=attempt_202105141443466564087298766893187_0004_m_000078_650, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@1cb1a8c}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
[2021-05-14 11:46:34,021] {docker.py:276} INFO - 21/05/14 14:46:34 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
[2021-05-14 11:46:34,022] {docker.py:276} INFO - 21/05/14 14:46:34 INFO StagingCommitter: Starting: Task committer attempt_202105141443466564087298766893187_0004_m_000078_650: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443466564087298766893187_0004_m_000078_650
[2021-05-14 11:46:34,027] {docker.py:276} INFO - 21/05/14 14:46:34 INFO StagingCommitter: Task committer attempt_202105141443466564087298766893187_0004_m_000078_650: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443466564087298766893187_0004_m_000078_650 : duration 0:00.006s
[2021-05-14 11:46:34,362] {docker.py:276} INFO - 21/05/14 14:46:34 INFO StagingCommitter: Starting: Task committer attempt_202105141443463852208304445391850_0004_m_000075_647: needsTaskCommit() Task attempt_202105141443463852208304445391850_0004_m_000075_647
[2021-05-14 11:46:34,363] {docker.py:276} INFO - 21/05/14 14:46:34 INFO StagingCommitter: Task committer attempt_202105141443463852208304445391850_0004_m_000075_647: needsTaskCommit() Task attempt_202105141443463852208304445391850_0004_m_000075_647: duration 0:00.002s
21/05/14 14:46:34 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443463852208304445391850_0004_m_000075_647
[2021-05-14 11:46:34,365] {docker.py:276} INFO - 21/05/14 14:46:34 INFO Executor: Finished task 75.0 in stage 4.0 (TID 647). 5106 bytes result sent to driver
[2021-05-14 11:46:34,367] {docker.py:276} INFO - 21/05/14 14:46:34 INFO TaskSetManager: Starting task 79.0 in stage 4.0 (TID 651) (f0b8ef7ba22f, executor driver, partition 79, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:46:34,368] {docker.py:276} INFO - 21/05/14 14:46:34 INFO TaskSetManager: Finished task 75.0 in stage 4.0 (TID 647) in 7123 ms on f0b8ef7ba22f (executor driver) (76/200)
[2021-05-14 11:46:34,368] {docker.py:276} INFO - 21/05/14 14:46:34 INFO Executor: Running task 79.0 in stage 4.0 (TID 651)
[2021-05-14 11:46:34,378] {docker.py:276} INFO - 21/05/14 14:46:34 INFO ShuffleBlockFetcherIterator: Getting 9 (66.0 KiB) non-empty blocks including 9 (66.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:46:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2021-05-14 11:46:34,388] {docker.py:276} INFO - 21/05/14 14:46:34 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:46:34 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/05/14 14:46:34 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
[2021-05-14 11:46:34,389] {docker.py:276} INFO - 21/05/14 14:46:34 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443467788140768456553832_0004_m_000079_651, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443467788140768456553832_0004_m_000079_651}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443467788140768456553832_0004}; taskId=attempt_202105141443467788140768456553832_0004_m_000079_651, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@f765b36}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
21/05/14 14:46:34 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
[2021-05-14 11:46:34,389] {docker.py:276} INFO - 21/05/14 14:46:34 INFO StagingCommitter: Starting: Task committer attempt_202105141443467788140768456553832_0004_m_000079_651: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443467788140768456553832_0004_m_000079_651
[2021-05-14 11:46:34,394] {docker.py:276} INFO - 21/05/14 14:46:34 INFO StagingCommitter: Task committer attempt_202105141443467788140768456553832_0004_m_000079_651: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443467788140768456553832_0004_m_000079_651 : duration 0:00.005s
[2021-05-14 11:46:38,236] {docker.py:276} INFO - 21/05/14 14:46:38 INFO StagingCommitter: Starting: Task committer attempt_202105141443464843694931965584416_0004_m_000076_648: needsTaskCommit() Task attempt_202105141443464843694931965584416_0004_m_000076_648
[2021-05-14 11:46:38,237] {docker.py:276} INFO - 21/05/14 14:46:38 INFO StagingCommitter: Task committer attempt_202105141443464843694931965584416_0004_m_000076_648: needsTaskCommit() Task attempt_202105141443464843694931965584416_0004_m_000076_648: duration 0:00.002s
21/05/14 14:46:38 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443464843694931965584416_0004_m_000076_648
[2021-05-14 11:46:38,241] {docker.py:276} INFO - 21/05/14 14:46:38 INFO Executor: Finished task 76.0 in stage 4.0 (TID 648). 5106 bytes result sent to driver
[2021-05-14 11:46:38,241] {docker.py:276} INFO - 21/05/14 14:46:38 INFO TaskSetManager: Starting task 80.0 in stage 4.0 (TID 652) (f0b8ef7ba22f, executor driver, partition 80, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:46:38,243] {docker.py:276} INFO - 21/05/14 14:46:38 INFO Executor: Running task 80.0 in stage 4.0 (TID 652)
[2021-05-14 11:46:38,243] {docker.py:276} INFO - 21/05/14 14:46:38 INFO TaskSetManager: Finished task 76.0 in stage 4.0 (TID 648) in 7121 ms on f0b8ef7ba22f (executor driver) (77/200)
[2021-05-14 11:46:38,255] {docker.py:276} INFO - 21/05/14 14:46:38 INFO ShuffleBlockFetcherIterator: Getting 9 (65.9 KiB) non-empty blocks including 9 (65.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
[2021-05-14 11:46:38,256] {docker.py:276} INFO - 21/05/14 14:46:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2021-05-14 11:46:38,265] {docker.py:276} INFO - 21/05/14 14:46:38 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:46:38 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/05/14 14:46:38 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
21/05/14 14:46:38 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443466985642091275415980_0004_m_000080_652, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443466985642091275415980_0004_m_000080_652}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443466985642091275415980_0004}; taskId=attempt_202105141443466985642091275415980_0004_m_000080_652, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@4ffcd5de}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
[2021-05-14 11:46:38,266] {docker.py:276} INFO - 21/05/14 14:46:38 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
21/05/14 14:46:38 INFO StagingCommitter: Starting: Task committer attempt_202105141443466985642091275415980_0004_m_000080_652: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443466985642091275415980_0004_m_000080_652
[2021-05-14 11:46:38,270] {docker.py:276} INFO - 21/05/14 14:46:38 INFO StagingCommitter: Task committer attempt_202105141443466985642091275415980_0004_m_000080_652: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443466985642091275415980_0004_m_000080_652 : duration 0:00.004s
[2021-05-14 11:46:40,573] {docker.py:276} INFO - 21/05/14 14:46:40 INFO StagingCommitter: Starting: Task committer attempt_20210514144346430057629342109358_0004_m_000077_649: needsTaskCommit() Task attempt_20210514144346430057629342109358_0004_m_000077_649
[2021-05-14 11:46:40,574] {docker.py:276} INFO - 21/05/14 14:46:40 INFO StagingCommitter: Task committer attempt_20210514144346430057629342109358_0004_m_000077_649: needsTaskCommit() Task attempt_20210514144346430057629342109358_0004_m_000077_649: duration 0:00.002s
21/05/14 14:46:40 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_20210514144346430057629342109358_0004_m_000077_649
[2021-05-14 11:46:40,575] {docker.py:276} INFO - 21/05/14 14:46:40 INFO Executor: Finished task 77.0 in stage 4.0 (TID 649). 5149 bytes result sent to driver
[2021-05-14 11:46:40,576] {docker.py:276} INFO - 21/05/14 14:46:40 INFO TaskSetManager: Starting task 81.0 in stage 4.0 (TID 653) (f0b8ef7ba22f, executor driver, partition 81, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:46:40,577] {docker.py:276} INFO - 21/05/14 14:46:40 INFO Executor: Running task 81.0 in stage 4.0 (TID 653)
21/05/14 14:46:40 INFO TaskSetManager: Finished task 77.0 in stage 4.0 (TID 649) in 6636 ms on f0b8ef7ba22f (executor driver) (78/200)
[2021-05-14 11:46:40,586] {docker.py:276} INFO - 21/05/14 14:46:40 INFO ShuffleBlockFetcherIterator: Getting 9 (65.7 KiB) non-empty blocks including 9 (65.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:46:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:46:40,594] {docker.py:276} INFO - 21/05/14 14:46:40 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:46:40 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/05/14 14:46:40 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
21/05/14 14:46:40 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443462662384704860099172_0004_m_000081_653, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443462662384704860099172_0004_m_000081_653}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443462662384704860099172_0004}; taskId=attempt_202105141443462662384704860099172_0004_m_000081_653, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@b57ea75}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
21/05/14 14:46:40 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
21/05/14 14:46:40 INFO StagingCommitter: Starting: Task committer attempt_202105141443462662384704860099172_0004_m_000081_653: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443462662384704860099172_0004_m_000081_653
[2021-05-14 11:46:40,598] {docker.py:276} INFO - 21/05/14 14:46:40 INFO StagingCommitter: Task committer attempt_202105141443462662384704860099172_0004_m_000081_653: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443462662384704860099172_0004_m_000081_653 : duration 0:00.004s
[2021-05-14 11:46:40,948] {docker.py:276} INFO - 21/05/14 14:46:40 INFO StagingCommitter: Starting: Task committer attempt_202105141443466564087298766893187_0004_m_000078_650: needsTaskCommit() Task attempt_202105141443466564087298766893187_0004_m_000078_650
21/05/14 14:46:40 INFO StagingCommitter: Task committer attempt_202105141443466564087298766893187_0004_m_000078_650: needsTaskCommit() Task attempt_202105141443466564087298766893187_0004_m_000078_650: duration 0:00.002s
21/05/14 14:46:40 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443466564087298766893187_0004_m_000078_650
[2021-05-14 11:46:40,949] {docker.py:276} INFO - 21/05/14 14:46:40 INFO Executor: Finished task 78.0 in stage 4.0 (TID 650). 5149 bytes result sent to driver
[2021-05-14 11:46:40,951] {docker.py:276} INFO - 21/05/14 14:46:40 INFO TaskSetManager: Starting task 82.0 in stage 4.0 (TID 654) (f0b8ef7ba22f, executor driver, partition 82, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:46:40,952] {docker.py:276} INFO - 21/05/14 14:46:40 INFO TaskSetManager: Finished task 78.0 in stage 4.0 (TID 650) in 6931 ms on f0b8ef7ba22f (executor driver) (79/200)
[2021-05-14 11:46:40,952] {docker.py:276} INFO - 21/05/14 14:46:40 INFO Executor: Running task 82.0 in stage 4.0 (TID 654)
[2021-05-14 11:46:40,961] {docker.py:276} INFO - 21/05/14 14:46:40 INFO ShuffleBlockFetcherIterator: Getting 9 (67.1 KiB) non-empty blocks including 9 (67.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:46:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:46:40,971] {docker.py:276} INFO - 21/05/14 14:46:40 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:46:40 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/05/14 14:46:40 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
21/05/14 14:46:40 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443461577587443927442191_0004_m_000082_654, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443461577587443927442191_0004_m_000082_654}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443461577587443927442191_0004}; taskId=attempt_202105141443461577587443927442191_0004_m_000082_654, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@3fe0dfa3}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
21/05/14 14:46:40 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
21/05/14 14:46:40 INFO StagingCommitter: Starting: Task committer attempt_202105141443461577587443927442191_0004_m_000082_654: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443461577587443927442191_0004_m_000082_654
[2021-05-14 11:46:40,975] {docker.py:276} INFO - 21/05/14 14:46:40 INFO StagingCommitter: Task committer attempt_202105141443461577587443927442191_0004_m_000082_654: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443461577587443927442191_0004_m_000082_654 : duration 0:00.004s
[2021-05-14 11:46:41,244] {docker.py:276} INFO - 21/05/14 14:46:41 INFO StagingCommitter: Starting: Task committer attempt_202105141443467788140768456553832_0004_m_000079_651: needsTaskCommit() Task attempt_202105141443467788140768456553832_0004_m_000079_651
[2021-05-14 11:46:41,246] {docker.py:276} INFO - 21/05/14 14:46:41 INFO StagingCommitter: Task committer attempt_202105141443467788140768456553832_0004_m_000079_651: needsTaskCommit() Task attempt_202105141443467788140768456553832_0004_m_000079_651: duration 0:00.003s
21/05/14 14:46:41 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443467788140768456553832_0004_m_000079_651
[2021-05-14 11:46:41,247] {docker.py:276} INFO - 21/05/14 14:46:41 INFO Executor: Finished task 79.0 in stage 4.0 (TID 651). 5149 bytes result sent to driver
[2021-05-14 11:46:41,248] {docker.py:276} INFO - 21/05/14 14:46:41 INFO TaskSetManager: Starting task 83.0 in stage 4.0 (TID 655) (f0b8ef7ba22f, executor driver, partition 83, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:46:41,249] {docker.py:276} INFO - 21/05/14 14:46:41 INFO Executor: Running task 83.0 in stage 4.0 (TID 655)
21/05/14 14:46:41 INFO TaskSetManager: Finished task 79.0 in stage 4.0 (TID 651) in 6856 ms on f0b8ef7ba22f (executor driver) (80/200)
[2021-05-14 11:46:41,259] {docker.py:276} INFO - 21/05/14 14:46:41 INFO ShuffleBlockFetcherIterator: Getting 9 (67.3 KiB) non-empty blocks including 9 (67.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:46:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:46:41,268] {docker.py:276} INFO - 21/05/14 14:46:41 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:46:41 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2021-05-14 11:46:41,269] {docker.py:276} INFO - 21/05/14 14:46:41 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
21/05/14 14:46:41 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443461466970491194160442_0004_m_000083_655, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443461466970491194160442_0004_m_000083_655}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443461466970491194160442_0004}; taskId=attempt_202105141443461466970491194160442_0004_m_000083_655, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@35985232}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
21/05/14 14:46:41 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
21/05/14 14:46:41 INFO StagingCommitter: Starting: Task committer attempt_202105141443461466970491194160442_0004_m_000083_655: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443461466970491194160442_0004_m_000083_655
[2021-05-14 11:46:41,273] {docker.py:276} INFO - 21/05/14 14:46:41 INFO StagingCommitter: Task committer attempt_202105141443461466970491194160442_0004_m_000083_655: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443461466970491194160442_0004_m_000083_655 : duration 0:00.004s
[2021-05-14 11:46:45,310] {docker.py:276} INFO - 21/05/14 14:46:45 INFO StagingCommitter: Starting: Task committer attempt_202105141443466985642091275415980_0004_m_000080_652: needsTaskCommit() Task attempt_202105141443466985642091275415980_0004_m_000080_652
[2021-05-14 11:46:45,310] {docker.py:276} INFO - 21/05/14 14:46:45 INFO StagingCommitter: Task committer attempt_202105141443466985642091275415980_0004_m_000080_652: needsTaskCommit() Task attempt_202105141443466985642091275415980_0004_m_000080_652: duration 0:00.002s
21/05/14 14:46:45 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443466985642091275415980_0004_m_000080_652
[2021-05-14 11:46:45,312] {docker.py:276} INFO - 21/05/14 14:46:45 INFO Executor: Finished task 80.0 in stage 4.0 (TID 652). 5149 bytes result sent to driver
[2021-05-14 11:46:45,313] {docker.py:276} INFO - 21/05/14 14:46:45 INFO TaskSetManager: Starting task 84.0 in stage 4.0 (TID 656) (f0b8ef7ba22f, executor driver, partition 84, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:46:45,314] {docker.py:276} INFO - 21/05/14 14:46:45 INFO TaskSetManager: Finished task 80.0 in stage 4.0 (TID 652) in 7046 ms on f0b8ef7ba22f (executor driver) (81/200)
[2021-05-14 11:46:45,315] {docker.py:276} INFO - 21/05/14 14:46:45 INFO Executor: Running task 84.0 in stage 4.0 (TID 656)
[2021-05-14 11:46:45,323] {docker.py:276} INFO - 21/05/14 14:46:45 INFO ShuffleBlockFetcherIterator: Getting 9 (68.6 KiB) non-empty blocks including 9 (68.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:46:45 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:46:45,331] {docker.py:276} INFO - 21/05/14 14:46:45 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:46:45 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/05/14 14:46:45 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
21/05/14 14:46:45 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443468609778310057336292_0004_m_000084_656, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443468609778310057336292_0004_m_000084_656}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443468609778310057336292_0004}; taskId=attempt_202105141443468609778310057336292_0004_m_000084_656, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@69130fc6}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
[2021-05-14 11:46:45,331] {docker.py:276} INFO - 21/05/14 14:46:45 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
21/05/14 14:46:45 INFO StagingCommitter: Starting: Task committer attempt_202105141443468609778310057336292_0004_m_000084_656: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443468609778310057336292_0004_m_000084_656
[2021-05-14 11:46:45,336] {docker.py:276} INFO - 21/05/14 14:46:45 INFO StagingCommitter: Task committer attempt_202105141443468609778310057336292_0004_m_000084_656: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443468609778310057336292_0004_m_000084_656 : duration 0:00.004s
[2021-05-14 11:46:47,909] {docker.py:276} INFO - 21/05/14 14:46:47 INFO StagingCommitter: Starting: Task committer attempt_202105141443462662384704860099172_0004_m_000081_653: needsTaskCommit() Task attempt_202105141443462662384704860099172_0004_m_000081_653
[2021-05-14 11:46:47,910] {docker.py:276} INFO - 21/05/14 14:46:47 INFO StagingCommitter: Task committer attempt_202105141443462662384704860099172_0004_m_000081_653: needsTaskCommit() Task attempt_202105141443462662384704860099172_0004_m_000081_653: duration 0:00.002s
21/05/14 14:46:47 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443462662384704860099172_0004_m_000081_653
[2021-05-14 11:46:47,911] {docker.py:276} INFO - 21/05/14 14:46:47 INFO Executor: Finished task 81.0 in stage 4.0 (TID 653). 5106 bytes result sent to driver
[2021-05-14 11:46:47,913] {docker.py:276} INFO - 21/05/14 14:46:47 INFO TaskSetManager: Starting task 85.0 in stage 4.0 (TID 657) (f0b8ef7ba22f, executor driver, partition 85, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:46:47,914] {docker.py:276} INFO - 21/05/14 14:46:47 INFO Executor: Running task 85.0 in stage 4.0 (TID 657)
[2021-05-14 11:46:47,915] {docker.py:276} INFO - 21/05/14 14:46:47 INFO TaskSetManager: Finished task 81.0 in stage 4.0 (TID 653) in 7347 ms on f0b8ef7ba22f (executor driver) (82/200)
[2021-05-14 11:46:47,922] {docker.py:276} INFO - 21/05/14 14:46:47 INFO ShuffleBlockFetcherIterator: Getting 9 (64.2 KiB) non-empty blocks including 9 (64.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:46:47 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:46:47,931] {docker.py:276} INFO - 21/05/14 14:46:47 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:46:47 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/05/14 14:46:47 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
[2021-05-14 11:46:47,931] {docker.py:276} INFO - 21/05/14 14:46:47 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443462525227241350310670_0004_m_000085_657, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443462525227241350310670_0004_m_000085_657}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443462525227241350310670_0004}; taskId=attempt_202105141443462525227241350310670_0004_m_000085_657, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@5c103a31}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
21/05/14 14:46:47 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
21/05/14 14:46:47 INFO StagingCommitter: Starting: Task committer attempt_202105141443462525227241350310670_0004_m_000085_657: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443462525227241350310670_0004_m_000085_657
[2021-05-14 11:46:47,935] {docker.py:276} INFO - 21/05/14 14:46:47 INFO StagingCommitter: Task committer attempt_202105141443462525227241350310670_0004_m_000085_657: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443462525227241350310670_0004_m_000085_657 : duration 0:00.004s
[2021-05-14 11:46:48,102] {docker.py:276} INFO - 21/05/14 14:46:48 INFO StagingCommitter: Starting: Task committer attempt_202105141443461466970491194160442_0004_m_000083_655: needsTaskCommit() Task attempt_202105141443461466970491194160442_0004_m_000083_655
[2021-05-14 11:46:48,102] {docker.py:276} INFO - 21/05/14 14:46:48 INFO StagingCommitter: Task committer attempt_202105141443461466970491194160442_0004_m_000083_655: needsTaskCommit() Task attempt_202105141443461466970491194160442_0004_m_000083_655: duration 0:00.001s
21/05/14 14:46:48 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443461466970491194160442_0004_m_000083_655
[2021-05-14 11:46:48,104] {docker.py:276} INFO - 21/05/14 14:46:48 INFO Executor: Finished task 83.0 in stage 4.0 (TID 655). 5106 bytes result sent to driver
[2021-05-14 11:46:48,105] {docker.py:276} INFO - 21/05/14 14:46:48 INFO TaskSetManager: Starting task 86.0 in stage 4.0 (TID 658) (f0b8ef7ba22f, executor driver, partition 86, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:46:48,106] {docker.py:276} INFO - 21/05/14 14:46:48 INFO Executor: Running task 86.0 in stage 4.0 (TID 658)
[2021-05-14 11:46:48,107] {docker.py:276} INFO - 21/05/14 14:46:48 INFO TaskSetManager: Finished task 83.0 in stage 4.0 (TID 655) in 6867 ms on f0b8ef7ba22f (executor driver) (83/200)
[2021-05-14 11:46:48,114] {docker.py:276} INFO - 21/05/14 14:46:48 INFO ShuffleBlockFetcherIterator: Getting 9 (66.7 KiB) non-empty blocks including 9 (66.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
[2021-05-14 11:46:48,115] {docker.py:276} INFO - 21/05/14 14:46:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:46:48,123] {docker.py:276} INFO - 21/05/14 14:46:48 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:46:48 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2021-05-14 11:46:48,124] {docker.py:276} INFO - 21/05/14 14:46:48 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
21/05/14 14:46:48 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443462628367438129903712_0004_m_000086_658, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443462628367438129903712_0004_m_000086_658}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443462628367438129903712_0004}; taskId=attempt_202105141443462628367438129903712_0004_m_000086_658, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@7dc754bb}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
[2021-05-14 11:46:48,124] {docker.py:276} INFO - 21/05/14 14:46:48 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
[2021-05-14 11:46:48,125] {docker.py:276} INFO - 21/05/14 14:46:48 INFO StagingCommitter: Starting: Task committer attempt_202105141443462628367438129903712_0004_m_000086_658: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443462628367438129903712_0004_m_000086_658
[2021-05-14 11:46:48,128] {docker.py:276} INFO - 21/05/14 14:46:48 INFO StagingCommitter: Task committer attempt_202105141443462628367438129903712_0004_m_000086_658: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443462628367438129903712_0004_m_000086_658 : duration 0:00.004s
[2021-05-14 11:46:48,618] {docker.py:276} INFO - 21/05/14 14:46:48 INFO StagingCommitter: Starting: Task committer attempt_202105141443461577587443927442191_0004_m_000082_654: needsTaskCommit() Task attempt_202105141443461577587443927442191_0004_m_000082_654
[2021-05-14 11:46:48,618] {docker.py:276} INFO - 21/05/14 14:46:48 INFO StagingCommitter: Task committer attempt_202105141443461577587443927442191_0004_m_000082_654: needsTaskCommit() Task attempt_202105141443461577587443927442191_0004_m_000082_654: duration 0:00.002s
[2021-05-14 11:46:48,619] {docker.py:276} INFO - 21/05/14 14:46:48 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443461577587443927442191_0004_m_000082_654
[2021-05-14 11:46:48,623] {docker.py:276} INFO - 21/05/14 14:46:48 INFO Executor: Finished task 82.0 in stage 4.0 (TID 654). 5106 bytes result sent to driver
[2021-05-14 11:46:48,624] {docker.py:276} INFO - 21/05/14 14:46:48 INFO TaskSetManager: Starting task 87.0 in stage 4.0 (TID 659) (f0b8ef7ba22f, executor driver, partition 87, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:46:48,625] {docker.py:276} INFO - 21/05/14 14:46:48 INFO Executor: Running task 87.0 in stage 4.0 (TID 659)
[2021-05-14 11:46:48,625] {docker.py:276} INFO - 21/05/14 14:46:48 INFO TaskSetManager: Finished task 82.0 in stage 4.0 (TID 654) in 7684 ms on f0b8ef7ba22f (executor driver) (84/200)
[2021-05-14 11:46:48,635] {docker.py:276} INFO - 21/05/14 14:46:48 INFO ShuffleBlockFetcherIterator: Getting 9 (66.4 KiB) non-empty blocks including 9 (66.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:46:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:46:48,645] {docker.py:276} INFO - 21/05/14 14:46:48 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:46:48 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2021-05-14 11:46:48,645] {docker.py:276} INFO - 21/05/14 14:46:48 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
21/05/14 14:46:48 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443466661713836072719543_0004_m_000087_659, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443466661713836072719543_0004_m_000087_659}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443466661713836072719543_0004}; taskId=attempt_202105141443466661713836072719543_0004_m_000087_659, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@647265c2}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
[2021-05-14 11:46:48,645] {docker.py:276} INFO - 21/05/14 14:46:48 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
[2021-05-14 11:46:48,645] {docker.py:276} INFO - 21/05/14 14:46:48 INFO StagingCommitter: Starting: Task committer attempt_202105141443466661713836072719543_0004_m_000087_659: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443466661713836072719543_0004_m_000087_659
[2021-05-14 11:46:48,648] {docker.py:276} INFO - 21/05/14 14:46:48 INFO StagingCommitter: Task committer attempt_202105141443466661713836072719543_0004_m_000087_659: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443466661713836072719543_0004_m_000087_659 : duration 0:00.003s
[2021-05-14 11:46:52,957] {docker.py:276} INFO - 21/05/14 14:46:52 INFO StagingCommitter: Starting: Task committer attempt_202105141443468609778310057336292_0004_m_000084_656: needsTaskCommit() Task attempt_202105141443468609778310057336292_0004_m_000084_656
[2021-05-14 11:46:52,958] {docker.py:276} INFO - 21/05/14 14:46:52 INFO StagingCommitter: Task committer attempt_202105141443468609778310057336292_0004_m_000084_656: needsTaskCommit() Task attempt_202105141443468609778310057336292_0004_m_000084_656: duration 0:00.001s
21/05/14 14:46:52 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443468609778310057336292_0004_m_000084_656
[2021-05-14 11:46:52,960] {docker.py:276} INFO - 21/05/14 14:46:52 INFO Executor: Finished task 84.0 in stage 4.0 (TID 656). 5106 bytes result sent to driver
[2021-05-14 11:46:52,961] {docker.py:276} INFO - 21/05/14 14:46:52 INFO TaskSetManager: Starting task 88.0 in stage 4.0 (TID 660) (f0b8ef7ba22f, executor driver, partition 88, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:46:52,962] {docker.py:276} INFO - 21/05/14 14:46:52 INFO Executor: Running task 88.0 in stage 4.0 (TID 660)
[2021-05-14 11:46:52,963] {docker.py:276} INFO - 21/05/14 14:46:52 INFO TaskSetManager: Finished task 84.0 in stage 4.0 (TID 656) in 7659 ms on f0b8ef7ba22f (executor driver) (85/200)
[2021-05-14 11:46:52,971] {docker.py:276} INFO - 21/05/14 14:46:52 INFO ShuffleBlockFetcherIterator: Getting 9 (66.8 KiB) non-empty blocks including 9 (66.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:46:52 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:46:52,982] {docker.py:276} INFO - 21/05/14 14:46:52 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:46:52 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/05/14 14:46:52 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
21/05/14 14:46:52 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443462612608889568373703_0004_m_000088_660, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443462612608889568373703_0004_m_000088_660}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443462612608889568373703_0004}; taskId=attempt_202105141443462612608889568373703_0004_m_000088_660, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@6da309be}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
[2021-05-14 11:46:52,982] {docker.py:276} INFO - 21/05/14 14:46:52 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
21/05/14 14:46:52 INFO StagingCommitter: Starting: Task committer attempt_202105141443462612608889568373703_0004_m_000088_660: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443462612608889568373703_0004_m_000088_660
[2021-05-14 11:46:52,986] {docker.py:276} INFO - 21/05/14 14:46:53 INFO StagingCommitter: Task committer attempt_202105141443462612608889568373703_0004_m_000088_660: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443462612608889568373703_0004_m_000088_660 : duration 0:00.005s
[2021-05-14 11:46:53,838] {docker.py:276} INFO - 21/05/14 14:46:53 INFO StagingCommitter: Starting: Task committer attempt_202105141443462628367438129903712_0004_m_000086_658: needsTaskCommit() Task attempt_202105141443462628367438129903712_0004_m_000086_658
21/05/14 14:46:53 INFO StagingCommitter: Task committer attempt_202105141443462628367438129903712_0004_m_000086_658: needsTaskCommit() Task attempt_202105141443462628367438129903712_0004_m_000086_658: duration 0:00.002s
21/05/14 14:46:53 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443462628367438129903712_0004_m_000086_658
[2021-05-14 11:46:53,842] {docker.py:276} INFO - 21/05/14 14:46:53 INFO Executor: Finished task 86.0 in stage 4.0 (TID 658). 5106 bytes result sent to driver
[2021-05-14 11:46:53,842] {docker.py:276} INFO - 21/05/14 14:46:53 INFO TaskSetManager: Starting task 89.0 in stage 4.0 (TID 661) (f0b8ef7ba22f, executor driver, partition 89, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:46:53,843] {docker.py:276} INFO - 21/05/14 14:46:53 INFO Executor: Running task 89.0 in stage 4.0 (TID 661)
[2021-05-14 11:46:53,844] {docker.py:276} INFO - 21/05/14 14:46:53 INFO TaskSetManager: Finished task 86.0 in stage 4.0 (TID 658) in 5745 ms on f0b8ef7ba22f (executor driver) (86/200)
[2021-05-14 11:46:53,853] {docker.py:276} INFO - 21/05/14 14:46:53 INFO ShuffleBlockFetcherIterator: Getting 9 (69.1 KiB) non-empty blocks including 9 (69.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:46:53 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:46:53,863] {docker.py:276} INFO - 21/05/14 14:46:53 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:46:53 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/05/14 14:46:53 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
21/05/14 14:46:53 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443468734607203643225688_0004_m_000089_661, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443468734607203643225688_0004_m_000089_661}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443468734607203643225688_0004}; taskId=attempt_202105141443468734607203643225688_0004_m_000089_661, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@590127e9}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
21/05/14 14:46:53 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
21/05/14 14:46:53 INFO StagingCommitter: Starting: Task committer attempt_202105141443468734607203643225688_0004_m_000089_661: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443468734607203643225688_0004_m_000089_661
[2021-05-14 11:46:53,867] {docker.py:276} INFO - 21/05/14 14:46:53 INFO StagingCommitter: Task committer attempt_202105141443468734607203643225688_0004_m_000089_661: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443468734607203643225688_0004_m_000089_661 : duration 0:00.004s
[2021-05-14 11:46:55,425] {docker.py:276} INFO - 21/05/14 14:46:55 INFO StagingCommitter: Starting: Task committer attempt_202105141443466661713836072719543_0004_m_000087_659: needsTaskCommit() Task attempt_202105141443466661713836072719543_0004_m_000087_659
[2021-05-14 11:46:55,427] {docker.py:276} INFO - 21/05/14 14:46:55 INFO StagingCommitter: Task committer attempt_202105141443466661713836072719543_0004_m_000087_659: needsTaskCommit() Task attempt_202105141443466661713836072719543_0004_m_000087_659: duration 0:00.004s
21/05/14 14:46:55 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443466661713836072719543_0004_m_000087_659
[2021-05-14 11:46:55,430] {docker.py:276} INFO - 21/05/14 14:46:55 INFO Executor: Finished task 87.0 in stage 4.0 (TID 659). 5106 bytes result sent to driver
[2021-05-14 11:46:55,431] {docker.py:276} INFO - 21/05/14 14:46:55 INFO TaskSetManager: Starting task 90.0 in stage 4.0 (TID 662) (f0b8ef7ba22f, executor driver, partition 90, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:46:55,432] {docker.py:276} INFO - 21/05/14 14:46:55 INFO Executor: Running task 90.0 in stage 4.0 (TID 662)
[2021-05-14 11:46:55,432] {docker.py:276} INFO - 21/05/14 14:46:55 INFO TaskSetManager: Finished task 87.0 in stage 4.0 (TID 659) in 6817 ms on f0b8ef7ba22f (executor driver) (87/200)
[2021-05-14 11:46:55,442] {docker.py:276} INFO - 21/05/14 14:46:55 INFO ShuffleBlockFetcherIterator: Getting 9 (61.8 KiB) non-empty blocks including 9 (61.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:46:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:46:55,451] {docker.py:276} INFO - 21/05/14 14:46:55 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:46:55 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/05/14 14:46:55 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
21/05/14 14:46:55 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443464586610549727723546_0004_m_000090_662, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443464586610549727723546_0004_m_000090_662}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443464586610549727723546_0004}; taskId=attempt_202105141443464586610549727723546_0004_m_000090_662, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@7e4937b7}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
21/05/14 14:46:55 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
21/05/14 14:46:55 INFO StagingCommitter: Starting: Task committer attempt_202105141443464586610549727723546_0004_m_000090_662: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443464586610549727723546_0004_m_000090_662
[2021-05-14 11:46:55,455] {docker.py:276} INFO - 21/05/14 14:46:55 INFO StagingCommitter: Task committer attempt_202105141443464586610549727723546_0004_m_000090_662: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443464586610549727723546_0004_m_000090_662 : duration 0:00.004s
[2021-05-14 11:46:56,024] {docker.py:276} INFO - 21/05/14 14:46:56 INFO StagingCommitter: Starting: Task committer attempt_202105141443462525227241350310670_0004_m_000085_657: needsTaskCommit() Task attempt_202105141443462525227241350310670_0004_m_000085_657
21/05/14 14:46:56 INFO StagingCommitter: Task committer attempt_202105141443462525227241350310670_0004_m_000085_657: needsTaskCommit() Task attempt_202105141443462525227241350310670_0004_m_000085_657: duration 0:00.001s
21/05/14 14:46:56 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443462525227241350310670_0004_m_000085_657
[2021-05-14 11:46:56,025] {docker.py:276} INFO - 21/05/14 14:46:56 INFO Executor: Finished task 85.0 in stage 4.0 (TID 657). 5106 bytes result sent to driver
[2021-05-14 11:46:56,026] {docker.py:276} INFO - 21/05/14 14:46:56 INFO TaskSetManager: Starting task 91.0 in stage 4.0 (TID 663) (f0b8ef7ba22f, executor driver, partition 91, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:46:56,027] {docker.py:276} INFO - 21/05/14 14:46:56 INFO TaskSetManager: Finished task 85.0 in stage 4.0 (TID 657) in 8125 ms on f0b8ef7ba22f (executor driver) (88/200)
[2021-05-14 11:46:56,028] {docker.py:276} INFO - 21/05/14 14:46:56 INFO Executor: Running task 91.0 in stage 4.0 (TID 663)
[2021-05-14 11:46:56,035] {docker.py:276} INFO - 21/05/14 14:46:56 INFO ShuffleBlockFetcherIterator: Getting 9 (61.0 KiB) non-empty blocks including 9 (61.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:46:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:46:56,043] {docker.py:276} INFO - 21/05/14 14:46:56 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:46:56 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/05/14 14:46:56 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
21/05/14 14:46:56 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443463076459905013449372_0004_m_000091_663, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443463076459905013449372_0004_m_000091_663}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443463076459905013449372_0004}; taskId=attempt_202105141443463076459905013449372_0004_m_000091_663, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@27ab8672}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
21/05/14 14:46:56 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
21/05/14 14:46:56 INFO StagingCommitter: Starting: Task committer attempt_202105141443463076459905013449372_0004_m_000091_663: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443463076459905013449372_0004_m_000091_663
[2021-05-14 11:46:56,048] {docker.py:276} INFO - 21/05/14 14:46:56 INFO StagingCommitter: Task committer attempt_202105141443463076459905013449372_0004_m_000091_663: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443463076459905013449372_0004_m_000091_663 : duration 0:00.005s
[2021-05-14 11:47:00,216] {docker.py:276} INFO - 21/05/14 14:47:00 INFO StagingCommitter: Starting: Task committer attempt_202105141443462612608889568373703_0004_m_000088_660: needsTaskCommit() Task attempt_202105141443462612608889568373703_0004_m_000088_660
21/05/14 14:47:00 INFO StagingCommitter: Task committer attempt_202105141443462612608889568373703_0004_m_000088_660: needsTaskCommit() Task attempt_202105141443462612608889568373703_0004_m_000088_660: duration 0:00.004s
21/05/14 14:47:00 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443462612608889568373703_0004_m_000088_660
[2021-05-14 11:47:00,218] {docker.py:276} INFO - 21/05/14 14:47:00 INFO Executor: Finished task 88.0 in stage 4.0 (TID 660). 5106 bytes result sent to driver
[2021-05-14 11:47:00,220] {docker.py:276} INFO - 21/05/14 14:47:00 INFO TaskSetManager: Starting task 92.0 in stage 4.0 (TID 664) (f0b8ef7ba22f, executor driver, partition 92, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:47:00,221] {docker.py:276} INFO - 21/05/14 14:47:00 INFO Executor: Running task 92.0 in stage 4.0 (TID 664)
[2021-05-14 11:47:00,222] {docker.py:276} INFO - 21/05/14 14:47:00 INFO TaskSetManager: Finished task 88.0 in stage 4.0 (TID 660) in 7270 ms on f0b8ef7ba22f (executor driver) (89/200)
[2021-05-14 11:47:00,227] {docker.py:276} INFO - 21/05/14 14:47:00 INFO StagingCommitter: Starting: Task committer attempt_202105141443468734607203643225688_0004_m_000089_661: needsTaskCommit() Task attempt_202105141443468734607203643225688_0004_m_000089_661
[2021-05-14 11:47:00,227] {docker.py:276} INFO - 21/05/14 14:47:00 INFO StagingCommitter: Task committer attempt_202105141443468734607203643225688_0004_m_000089_661: needsTaskCommit() Task attempt_202105141443468734607203643225688_0004_m_000089_661: duration 0:00.000s
21/05/14 14:47:00 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443468734607203643225688_0004_m_000089_661
[2021-05-14 11:47:00,228] {docker.py:276} INFO - 21/05/14 14:47:00 INFO Executor: Finished task 89.0 in stage 4.0 (TID 661). 5106 bytes result sent to driver
[2021-05-14 11:47:00,228] {docker.py:276} INFO - 21/05/14 14:47:00 INFO TaskSetManager: Finished task 89.0 in stage 4.0 (TID 661) in 6395 ms on f0b8ef7ba22f (executor driver) (90/200)
[2021-05-14 11:47:00,229] {docker.py:276} INFO - 21/05/14 14:47:00 INFO TaskSetManager: Starting task 93.0 in stage 4.0 (TID 665) (f0b8ef7ba22f, executor driver, partition 93, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:47:00,230] {docker.py:276} INFO - 21/05/14 14:47:00 INFO Executor: Running task 93.0 in stage 4.0 (TID 665)
[2021-05-14 11:47:00,234] {docker.py:276} INFO - 21/05/14 14:47:00 INFO ShuffleBlockFetcherIterator: Getting 9 (68.9 KiB) non-empty blocks including 9 (68.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:47:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:47:00,238] {docker.py:276} INFO - 21/05/14 14:47:00 INFO ShuffleBlockFetcherIterator: Getting 9 (63.4 KiB) non-empty blocks including 9 (63.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:47:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:47:00,242] {docker.py:276} INFO - 21/05/14 14:47:00 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:47:00 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/05/14 14:47:00 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
21/05/14 14:47:00 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443463090971663526556472_0004_m_000092_664, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443463090971663526556472_0004_m_000092_664}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443463090971663526556472_0004}; taskId=attempt_202105141443463090971663526556472_0004_m_000092_664, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@187c37f4}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
21/05/14 14:47:00 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
[2021-05-14 11:47:00,243] {docker.py:276} INFO - 21/05/14 14:47:00 INFO StagingCommitter: Starting: Task committer attempt_202105141443463090971663526556472_0004_m_000092_664: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443463090971663526556472_0004_m_000092_664
[2021-05-14 11:47:00,247] {docker.py:276} INFO - 21/05/14 14:47:00 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:47:00 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/05/14 14:47:00 INFO StagingCommitter: Task committer attempt_202105141443463090971663526556472_0004_m_000092_664: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443463090971663526556472_0004_m_000092_664 : duration 0:00.004s
21/05/14 14:47:00 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
[2021-05-14 11:47:00,248] {docker.py:276} INFO - 21/05/14 14:47:00 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_20210514144346366452078137788781_0004_m_000093_665, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_20210514144346366452078137788781_0004_m_000093_665}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_20210514144346366452078137788781_0004}; taskId=attempt_20210514144346366452078137788781_0004_m_000093_665, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@3c5ec645}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
21/05/14 14:47:00 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
21/05/14 14:47:00 INFO StagingCommitter: Starting: Task committer attempt_20210514144346366452078137788781_0004_m_000093_665: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_20210514144346366452078137788781_0004_m_000093_665
[2021-05-14 11:47:00,253] {docker.py:276} INFO - 21/05/14 14:47:00 INFO StagingCommitter: Task committer attempt_20210514144346366452078137788781_0004_m_000093_665: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_20210514144346366452078137788781_0004_m_000093_665 : duration 0:00.005s
[2021-05-14 11:47:02,933] {docker.py:276} INFO - 21/05/14 14:47:02 INFO StagingCommitter: Starting: Task committer attempt_202105141443463076459905013449372_0004_m_000091_663: needsTaskCommit() Task attempt_202105141443463076459905013449372_0004_m_000091_663
[2021-05-14 11:47:02,935] {docker.py:276} INFO - 21/05/14 14:47:02 INFO StagingCommitter: Task committer attempt_202105141443463076459905013449372_0004_m_000091_663: needsTaskCommit() Task attempt_202105141443463076459905013449372_0004_m_000091_663: duration 0:00.003s
21/05/14 14:47:02 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443463076459905013449372_0004_m_000091_663
[2021-05-14 11:47:02,937] {docker.py:276} INFO - 21/05/14 14:47:02 INFO Executor: Finished task 91.0 in stage 4.0 (TID 663). 5149 bytes result sent to driver
[2021-05-14 11:47:02,939] {docker.py:276} INFO - 21/05/14 14:47:02 INFO TaskSetManager: Starting task 94.0 in stage 4.0 (TID 666) (f0b8ef7ba22f, executor driver, partition 94, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:47:02,940] {docker.py:276} INFO - 21/05/14 14:47:02 INFO Executor: Running task 94.0 in stage 4.0 (TID 666)
21/05/14 14:47:02 INFO TaskSetManager: Finished task 91.0 in stage 4.0 (TID 663) in 6921 ms on f0b8ef7ba22f (executor driver) (91/200)
[2021-05-14 11:47:02,949] {docker.py:276} INFO - 21/05/14 14:47:02 INFO ShuffleBlockFetcherIterator: Getting 9 (68.4 KiB) non-empty blocks including 9 (68.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:47:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:47:02,957] {docker.py:276} INFO - 21/05/14 14:47:02 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:47:02 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/05/14 14:47:02 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
21/05/14 14:47:02 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443461104542666669331736_0004_m_000094_666, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443461104542666669331736_0004_m_000094_666}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443461104542666669331736_0004}; taskId=attempt_202105141443461104542666669331736_0004_m_000094_666, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@68dea82d}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
21/05/14 14:47:02 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
[2021-05-14 11:47:02,958] {docker.py:276} INFO - 21/05/14 14:47:02 INFO StagingCommitter: Starting: Task committer attempt_202105141443461104542666669331736_0004_m_000094_666: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443461104542666669331736_0004_m_000094_666
[2021-05-14 11:47:02,961] {docker.py:276} INFO - 21/05/14 14:47:02 INFO StagingCommitter: Task committer attempt_202105141443461104542666669331736_0004_m_000094_666: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443461104542666669331736_0004_m_000094_666 : duration 0:00.004s
[2021-05-14 11:47:03,101] {docker.py:276} INFO - 21/05/14 14:47:03 INFO StagingCommitter: Starting: Task committer attempt_202105141443464586610549727723546_0004_m_000090_662: needsTaskCommit() Task attempt_202105141443464586610549727723546_0004_m_000090_662
[2021-05-14 11:47:03,101] {docker.py:276} INFO - 21/05/14 14:47:03 INFO StagingCommitter: Task committer attempt_202105141443464586610549727723546_0004_m_000090_662: needsTaskCommit() Task attempt_202105141443464586610549727723546_0004_m_000090_662: duration 0:00.001s
21/05/14 14:47:03 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443464586610549727723546_0004_m_000090_662
[2021-05-14 11:47:03,102] {docker.py:276} INFO - 21/05/14 14:47:03 INFO Executor: Finished task 90.0 in stage 4.0 (TID 662). 5149 bytes result sent to driver
[2021-05-14 11:47:03,103] {docker.py:276} INFO - 21/05/14 14:47:03 INFO TaskSetManager: Starting task 95.0 in stage 4.0 (TID 667) (f0b8ef7ba22f, executor driver, partition 95, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:47:03,104] {docker.py:276} INFO - 21/05/14 14:47:03 INFO Executor: Running task 95.0 in stage 4.0 (TID 667)
[2021-05-14 11:47:03,105] {docker.py:276} INFO - 21/05/14 14:47:03 INFO TaskSetManager: Finished task 90.0 in stage 4.0 (TID 662) in 7683 ms on f0b8ef7ba22f (executor driver) (92/200)
[2021-05-14 11:47:03,112] {docker.py:276} INFO - 21/05/14 14:47:03 INFO ShuffleBlockFetcherIterator: Getting 9 (64.9 KiB) non-empty blocks including 9 (64.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:47:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:47:03,123] {docker.py:276} INFO - 21/05/14 14:47:03 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:47:03 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/05/14 14:47:03 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
21/05/14 14:47:03 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443466215773743763626546_0004_m_000095_667, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443466215773743763626546_0004_m_000095_667}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443466215773743763626546_0004}; taskId=attempt_202105141443466215773743763626546_0004_m_000095_667, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@1fcb3394}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
21/05/14 14:47:03 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
21/05/14 14:47:03 INFO StagingCommitter: Starting: Task committer attempt_202105141443466215773743763626546_0004_m_000095_667: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443466215773743763626546_0004_m_000095_667
[2021-05-14 11:47:03,128] {docker.py:276} INFO - 21/05/14 14:47:03 INFO StagingCommitter: Task committer attempt_202105141443466215773743763626546_0004_m_000095_667: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443466215773743763626546_0004_m_000095_667 : duration 0:00.005s
[2021-05-14 11:47:06,818] {docker.py:276} INFO - 21/05/14 14:47:06 INFO StagingCommitter: Starting: Task committer attempt_20210514144346366452078137788781_0004_m_000093_665: needsTaskCommit() Task attempt_20210514144346366452078137788781_0004_m_000093_665
[2021-05-14 11:47:06,819] {docker.py:276} INFO - 21/05/14 14:47:06 INFO StagingCommitter: Task committer attempt_20210514144346366452078137788781_0004_m_000093_665: needsTaskCommit() Task attempt_20210514144346366452078137788781_0004_m_000093_665: duration 0:00.003s
21/05/14 14:47:06 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_20210514144346366452078137788781_0004_m_000093_665
[2021-05-14 11:47:06,821] {docker.py:276} INFO - 21/05/14 14:47:06 INFO Executor: Finished task 93.0 in stage 4.0 (TID 665). 5149 bytes result sent to driver
[2021-05-14 11:47:06,822] {docker.py:276} INFO - 21/05/14 14:47:06 INFO TaskSetManager: Starting task 96.0 in stage 4.0 (TID 668) (f0b8ef7ba22f, executor driver, partition 96, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:47:06,824] {docker.py:276} INFO - 21/05/14 14:47:06 INFO TaskSetManager: Finished task 93.0 in stage 4.0 (TID 665) in 6601 ms on f0b8ef7ba22f (executor driver) (93/200)
21/05/14 14:47:06 INFO Executor: Running task 96.0 in stage 4.0 (TID 668)
[2021-05-14 11:47:06,833] {docker.py:276} INFO - 21/05/14 14:47:06 INFO ShuffleBlockFetcherIterator: Getting 9 (66.0 KiB) non-empty blocks including 9 (66.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:47:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:47:06,842] {docker.py:276} INFO - 21/05/14 14:47:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:47:06 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/05/14 14:47:06 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
[2021-05-14 11:47:06,843] {docker.py:276} INFO - 21/05/14 14:47:06 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443462254031529512272002_0004_m_000096_668, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443462254031529512272002_0004_m_000096_668}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443462254031529512272002_0004}; taskId=attempt_202105141443462254031529512272002_0004_m_000096_668, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@504ed9b7}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
21/05/14 14:47:06 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
21/05/14 14:47:06 INFO StagingCommitter: Starting: Task committer attempt_202105141443462254031529512272002_0004_m_000096_668: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443462254031529512272002_0004_m_000096_668
[2021-05-14 11:47:06,847] {docker.py:276} INFO - 21/05/14 14:47:06 INFO StagingCommitter: Task committer attempt_202105141443462254031529512272002_0004_m_000096_668: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443462254031529512272002_0004_m_000096_668 : duration 0:00.004s
[2021-05-14 11:47:07,321] {docker.py:276} INFO - 21/05/14 14:47:07 INFO StagingCommitter: Starting: Task committer attempt_202105141443463090971663526556472_0004_m_000092_664: needsTaskCommit() Task attempt_202105141443463090971663526556472_0004_m_000092_664
[2021-05-14 11:47:07,322] {docker.py:276} INFO - 21/05/14 14:47:07 INFO StagingCommitter: Task committer attempt_202105141443463090971663526556472_0004_m_000092_664: needsTaskCommit() Task attempt_202105141443463090971663526556472_0004_m_000092_664: duration 0:00.003s
21/05/14 14:47:07 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443463090971663526556472_0004_m_000092_664
[2021-05-14 11:47:07,325] {docker.py:276} INFO - 21/05/14 14:47:07 INFO Executor: Finished task 92.0 in stage 4.0 (TID 664). 5149 bytes result sent to driver
[2021-05-14 11:47:07,326] {docker.py:276} INFO - 21/05/14 14:47:07 INFO TaskSetManager: Starting task 97.0 in stage 4.0 (TID 669) (f0b8ef7ba22f, executor driver, partition 97, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:47:07,327] {docker.py:276} INFO - 21/05/14 14:47:07 INFO Executor: Running task 97.0 in stage 4.0 (TID 669)
[2021-05-14 11:47:07,328] {docker.py:276} INFO - 21/05/14 14:47:07 INFO TaskSetManager: Finished task 92.0 in stage 4.0 (TID 664) in 7116 ms on f0b8ef7ba22f (executor driver) (94/200)
[2021-05-14 11:47:07,340] {docker.py:276} INFO - 21/05/14 14:47:07 INFO ShuffleBlockFetcherIterator: Getting 9 (63.8 KiB) non-empty blocks including 9 (63.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:47:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:47:07,350] {docker.py:276} INFO - 21/05/14 14:47:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:47:07 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2021-05-14 11:47:07,350] {docker.py:276} INFO - 21/05/14 14:47:07 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
[2021-05-14 11:47:07,350] {docker.py:276} INFO - 21/05/14 14:47:07 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443462778004417144691218_0004_m_000097_669, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443462778004417144691218_0004_m_000097_669}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443462778004417144691218_0004}; taskId=attempt_202105141443462778004417144691218_0004_m_000097_669, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@1efafb7c}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
[2021-05-14 11:47:07,351] {docker.py:276} INFO - 21/05/14 14:47:07 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
[2021-05-14 11:47:07,351] {docker.py:276} INFO - 21/05/14 14:47:07 INFO StagingCommitter: Starting: Task committer attempt_202105141443462778004417144691218_0004_m_000097_669: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443462778004417144691218_0004_m_000097_669
[2021-05-14 11:47:07,355] {docker.py:276} INFO - 21/05/14 14:47:07 INFO StagingCommitter: Task committer attempt_202105141443462778004417144691218_0004_m_000097_669: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443462778004417144691218_0004_m_000097_669 : duration 0:00.004s
[2021-05-14 11:47:09,695] {docker.py:276} INFO - 21/05/14 14:47:09 INFO StagingCommitter: Starting: Task committer attempt_202105141443466215773743763626546_0004_m_000095_667: needsTaskCommit() Task attempt_202105141443466215773743763626546_0004_m_000095_667
[2021-05-14 11:47:09,696] {docker.py:276} INFO - 21/05/14 14:47:09 INFO StagingCommitter: Task committer attempt_202105141443466215773743763626546_0004_m_000095_667: needsTaskCommit() Task attempt_202105141443466215773743763626546_0004_m_000095_667: duration 0:00.003s
21/05/14 14:47:09 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443466215773743763626546_0004_m_000095_667
[2021-05-14 11:47:09,696] {docker.py:276} INFO - 21/05/14 14:47:09 INFO Executor: Finished task 95.0 in stage 4.0 (TID 667). 5106 bytes result sent to driver
[2021-05-14 11:47:09,697] {docker.py:276} INFO - 21/05/14 14:47:09 INFO TaskSetManager: Starting task 98.0 in stage 4.0 (TID 670) (f0b8ef7ba22f, executor driver, partition 98, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:47:09,698] {docker.py:276} INFO - 21/05/14 14:47:09 INFO Executor: Running task 98.0 in stage 4.0 (TID 670)
[2021-05-14 11:47:09,698] {docker.py:276} INFO - 21/05/14 14:47:09 INFO TaskSetManager: Finished task 95.0 in stage 4.0 (TID 667) in 6567 ms on f0b8ef7ba22f (executor driver) (95/200)
[2021-05-14 11:47:09,706] {docker.py:276} INFO - 21/05/14 14:47:09 INFO ShuffleBlockFetcherIterator: Getting 9 (67.0 KiB) non-empty blocks including 9 (67.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:47:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:47:09,715] {docker.py:276} INFO - 21/05/14 14:47:09 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:47:09 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/05/14 14:47:09 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
21/05/14 14:47:09 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443463612640145413020164_0004_m_000098_670, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443463612640145413020164_0004_m_000098_670}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443463612640145413020164_0004}; taskId=attempt_202105141443463612640145413020164_0004_m_000098_670, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@4a7d4c8a}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
[2021-05-14 11:47:09,716] {docker.py:276} INFO - 21/05/14 14:47:09 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
21/05/14 14:47:09 INFO StagingCommitter: Starting: Task committer attempt_202105141443463612640145413020164_0004_m_000098_670: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443463612640145413020164_0004_m_000098_670
[2021-05-14 11:47:09,720] {docker.py:276} INFO - 21/05/14 14:47:09 INFO StagingCommitter: Task committer attempt_202105141443463612640145413020164_0004_m_000098_670: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443463612640145413020164_0004_m_000098_670 : duration 0:00.004s
[2021-05-14 11:47:10,138] {docker.py:276} INFO - 21/05/14 14:47:10 INFO StagingCommitter: Starting: Task committer attempt_202105141443461104542666669331736_0004_m_000094_666: needsTaskCommit() Task attempt_202105141443461104542666669331736_0004_m_000094_666
[2021-05-14 11:47:10,139] {docker.py:276} INFO - 21/05/14 14:47:10 INFO StagingCommitter: Task committer attempt_202105141443461104542666669331736_0004_m_000094_666: needsTaskCommit() Task attempt_202105141443461104542666669331736_0004_m_000094_666: duration 0:00.001s
[2021-05-14 11:47:10,140] {docker.py:276} INFO - 21/05/14 14:47:10 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443461104542666669331736_0004_m_000094_666
[2021-05-14 11:47:10,141] {docker.py:276} INFO - 21/05/14 14:47:10 INFO Executor: Finished task 94.0 in stage 4.0 (TID 666). 5106 bytes result sent to driver
[2021-05-14 11:47:10,142] {docker.py:276} INFO - 21/05/14 14:47:10 INFO TaskSetManager: Starting task 99.0 in stage 4.0 (TID 671) (f0b8ef7ba22f, executor driver, partition 99, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:47:10,143] {docker.py:276} INFO - 21/05/14 14:47:10 INFO TaskSetManager: Finished task 94.0 in stage 4.0 (TID 666) in 7178 ms on f0b8ef7ba22f (executor driver) (96/200)
21/05/14 14:47:10 INFO Executor: Running task 99.0 in stage 4.0 (TID 671)
[2021-05-14 11:47:10,153] {docker.py:276} INFO - 21/05/14 14:47:10 INFO ShuffleBlockFetcherIterator: Getting 9 (66.3 KiB) non-empty blocks including 9 (66.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:47:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:47:10,161] {docker.py:276} INFO - 21/05/14 14:47:10 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:47:10 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/05/14 14:47:10 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
21/05/14 14:47:10 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443461969701067695744789_0004_m_000099_671, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443461969701067695744789_0004_m_000099_671}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443461969701067695744789_0004}; taskId=attempt_202105141443461969701067695744789_0004_m_000099_671, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@60fc94f7}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
[2021-05-14 11:47:10,162] {docker.py:276} INFO - 21/05/14 14:47:10 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
21/05/14 14:47:10 INFO StagingCommitter: Starting: Task committer attempt_202105141443461969701067695744789_0004_m_000099_671: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443461969701067695744789_0004_m_000099_671
[2021-05-14 11:47:10,166] {docker.py:276} INFO - 21/05/14 14:47:10 INFO StagingCommitter: Task committer attempt_202105141443461969701067695744789_0004_m_000099_671: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443461969701067695744789_0004_m_000099_671 : duration 0:00.005s
[2021-05-14 11:47:13,130] {docker.py:276} INFO - 21/05/14 14:47:13 INFO StagingCommitter: Starting: Task committer attempt_202105141443462254031529512272002_0004_m_000096_668: needsTaskCommit() Task attempt_202105141443462254031529512272002_0004_m_000096_668
[2021-05-14 11:47:13,131] {docker.py:276} INFO - 21/05/14 14:47:13 INFO StagingCommitter: Task committer attempt_202105141443462254031529512272002_0004_m_000096_668: needsTaskCommit() Task attempt_202105141443462254031529512272002_0004_m_000096_668: duration 0:00.002s
21/05/14 14:47:13 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443462254031529512272002_0004_m_000096_668
[2021-05-14 11:47:13,133] {docker.py:276} INFO - 21/05/14 14:47:13 INFO Executor: Finished task 96.0 in stage 4.0 (TID 668). 5106 bytes result sent to driver
[2021-05-14 11:47:13,134] {docker.py:276} INFO - 21/05/14 14:47:13 INFO TaskSetManager: Starting task 100.0 in stage 4.0 (TID 672) (f0b8ef7ba22f, executor driver, partition 100, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:47:13,135] {docker.py:276} INFO - 21/05/14 14:47:13 INFO TaskSetManager: Finished task 96.0 in stage 4.0 (TID 668) in 6286 ms on f0b8ef7ba22f (executor driver) (97/200)
[2021-05-14 11:47:13,136] {docker.py:276} INFO - 21/05/14 14:47:13 INFO Executor: Running task 100.0 in stage 4.0 (TID 672)
[2021-05-14 11:47:13,145] {docker.py:276} INFO - 21/05/14 14:47:13 INFO ShuffleBlockFetcherIterator: Getting 9 (63.4 KiB) non-empty blocks including 9 (63.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:47:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:47:13,154] {docker.py:276} INFO - 21/05/14 14:47:13 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:47:13 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/05/14 14:47:13 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
21/05/14 14:47:13 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_20210514144346689433342522687732_0004_m_000100_672, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_20210514144346689433342522687732_0004_m_000100_672}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_20210514144346689433342522687732_0004}; taskId=attempt_20210514144346689433342522687732_0004_m_000100_672, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@262df88c}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
21/05/14 14:47:13 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
21/05/14 14:47:13 INFO StagingCommitter: Starting: Task committer attempt_20210514144346689433342522687732_0004_m_000100_672: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_20210514144346689433342522687732_0004_m_000100_672
[2021-05-14 11:47:13,158] {docker.py:276} INFO - 21/05/14 14:47:13 INFO StagingCommitter: Task committer attempt_20210514144346689433342522687732_0004_m_000100_672: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_20210514144346689433342522687732_0004_m_000100_672 : duration 0:00.004s
[2021-05-14 11:47:14,126] {docker.py:276} INFO - 21/05/14 14:47:14 INFO StagingCommitter: Starting: Task committer attempt_202105141443462778004417144691218_0004_m_000097_669: needsTaskCommit() Task attempt_202105141443462778004417144691218_0004_m_000097_669
[2021-05-14 11:47:14,127] {docker.py:276} INFO - 21/05/14 14:47:14 INFO StagingCommitter: Task committer attempt_202105141443462778004417144691218_0004_m_000097_669: needsTaskCommit() Task attempt_202105141443462778004417144691218_0004_m_000097_669: duration 0:00.002s
21/05/14 14:47:14 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443462778004417144691218_0004_m_000097_669
[2021-05-14 11:47:14,129] {docker.py:276} INFO - 21/05/14 14:47:14 INFO Executor: Finished task 97.0 in stage 4.0 (TID 669). 5106 bytes result sent to driver
[2021-05-14 11:47:14,130] {docker.py:276} INFO - 21/05/14 14:47:14 INFO TaskSetManager: Starting task 101.0 in stage 4.0 (TID 673) (f0b8ef7ba22f, executor driver, partition 101, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:47:14,131] {docker.py:276} INFO - 21/05/14 14:47:14 INFO Executor: Running task 101.0 in stage 4.0 (TID 673)
[2021-05-14 11:47:14,132] {docker.py:276} INFO - 21/05/14 14:47:14 INFO TaskSetManager: Finished task 97.0 in stage 4.0 (TID 669) in 6779 ms on f0b8ef7ba22f (executor driver) (98/200)
[2021-05-14 11:47:14,141] {docker.py:276} INFO - 21/05/14 14:47:14 INFO ShuffleBlockFetcherIterator: Getting 9 (65.8 KiB) non-empty blocks including 9 (65.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:47:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:47:14,149] {docker.py:276} INFO - 21/05/14 14:47:14 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:47:14 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/05/14 14:47:14 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
21/05/14 14:47:14 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443464890906220151772366_0004_m_000101_673, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443464890906220151772366_0004_m_000101_673}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443464890906220151772366_0004}; taskId=attempt_202105141443464890906220151772366_0004_m_000101_673, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@1ac0a38f}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
21/05/14 14:47:14 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
[2021-05-14 11:47:14,150] {docker.py:276} INFO - 21/05/14 14:47:14 INFO StagingCommitter: Starting: Task committer attempt_202105141443464890906220151772366_0004_m_000101_673: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443464890906220151772366_0004_m_000101_673
[2021-05-14 11:47:14,154] {docker.py:276} INFO - 21/05/14 14:47:14 INFO StagingCommitter: Task committer attempt_202105141443464890906220151772366_0004_m_000101_673: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443464890906220151772366_0004_m_000101_673 : duration 0:00.004s
[2021-05-14 11:47:16,504] {docker.py:276} INFO - 21/05/14 14:47:16 INFO StagingCommitter: Starting: Task committer attempt_202105141443463612640145413020164_0004_m_000098_670: needsTaskCommit() Task attempt_202105141443463612640145413020164_0004_m_000098_670
[2021-05-14 11:47:16,505] {docker.py:276} INFO - 21/05/14 14:47:16 INFO StagingCommitter: Task committer attempt_202105141443463612640145413020164_0004_m_000098_670: needsTaskCommit() Task attempt_202105141443463612640145413020164_0004_m_000098_670: duration 0:00.002s
21/05/14 14:47:16 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443463612640145413020164_0004_m_000098_670
[2021-05-14 11:47:16,507] {docker.py:276} INFO - 21/05/14 14:47:16 INFO Executor: Finished task 98.0 in stage 4.0 (TID 670). 5106 bytes result sent to driver
[2021-05-14 11:47:16,508] {docker.py:276} INFO - 21/05/14 14:47:16 INFO TaskSetManager: Starting task 102.0 in stage 4.0 (TID 674) (f0b8ef7ba22f, executor driver, partition 102, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:47:16,509] {docker.py:276} INFO - 21/05/14 14:47:16 INFO Executor: Running task 102.0 in stage 4.0 (TID 674)
[2021-05-14 11:47:16,509] {docker.py:276} INFO - 21/05/14 14:47:16 INFO TaskSetManager: Finished task 98.0 in stage 4.0 (TID 670) in 6820 ms on f0b8ef7ba22f (executor driver) (99/200)
[2021-05-14 11:47:16,518] {docker.py:276} INFO - 21/05/14 14:47:16 INFO ShuffleBlockFetcherIterator: Getting 9 (69.4 KiB) non-empty blocks including 9 (69.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
[2021-05-14 11:47:16,518] {docker.py:276} INFO - 21/05/14 14:47:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:47:16,528] {docker.py:276} INFO - 21/05/14 14:47:16 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:47:16 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/05/14 14:47:16 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
21/05/14 14:47:16 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443464539195468914108300_0004_m_000102_674, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443464539195468914108300_0004_m_000102_674}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443464539195468914108300_0004}; taskId=attempt_202105141443464539195468914108300_0004_m_000102_674, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@508a5ce8}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
21/05/14 14:47:16 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
21/05/14 14:47:16 INFO StagingCommitter: Starting: Task committer attempt_202105141443464539195468914108300_0004_m_000102_674: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443464539195468914108300_0004_m_000102_674
[2021-05-14 11:47:16,531] {docker.py:276} INFO - 21/05/14 14:47:16 INFO StagingCommitter: Task committer attempt_202105141443464539195468914108300_0004_m_000102_674: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443464539195468914108300_0004_m_000102_674 : duration 0:00.003s
[2021-05-14 11:47:16,794] {docker.py:276} INFO - 21/05/14 14:47:16 INFO StagingCommitter: Starting: Task committer attempt_202105141443461969701067695744789_0004_m_000099_671: needsTaskCommit() Task attempt_202105141443461969701067695744789_0004_m_000099_671
[2021-05-14 11:47:16,794] {docker.py:276} INFO - 21/05/14 14:47:16 INFO StagingCommitter: Task committer attempt_202105141443461969701067695744789_0004_m_000099_671: needsTaskCommit() Task attempt_202105141443461969701067695744789_0004_m_000099_671: duration 0:00.001s
21/05/14 14:47:16 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443461969701067695744789_0004_m_000099_671
[2021-05-14 11:47:16,794] {docker.py:276} INFO - 21/05/14 14:47:16 INFO Executor: Finished task 99.0 in stage 4.0 (TID 671). 5106 bytes result sent to driver
[2021-05-14 11:47:16,795] {docker.py:276} INFO - 21/05/14 14:47:16 INFO TaskSetManager: Starting task 103.0 in stage 4.0 (TID 675) (f0b8ef7ba22f, executor driver, partition 103, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:47:16,796] {docker.py:276} INFO - 21/05/14 14:47:16 INFO Executor: Running task 103.0 in stage 4.0 (TID 675)
[2021-05-14 11:47:16,797] {docker.py:276} INFO - 21/05/14 14:47:16 INFO TaskSetManager: Finished task 99.0 in stage 4.0 (TID 671) in 6663 ms on f0b8ef7ba22f (executor driver) (100/200)
[2021-05-14 11:47:16,805] {docker.py:276} INFO - 21/05/14 14:47:16 INFO ShuffleBlockFetcherIterator: Getting 9 (68.2 KiB) non-empty blocks including 9 (68.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:47:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:47:16,817] {docker.py:276} INFO - 21/05/14 14:47:16 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:47:16 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/05/14 14:47:16 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
21/05/14 14:47:16 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443468517075231820683834_0004_m_000103_675, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443468517075231820683834_0004_m_000103_675}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443468517075231820683834_0004}; taskId=attempt_202105141443468517075231820683834_0004_m_000103_675, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@419bfe89}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
[2021-05-14 11:47:16,817] {docker.py:276} INFO - 21/05/14 14:47:16 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
21/05/14 14:47:16 INFO StagingCommitter: Starting: Task committer attempt_202105141443468517075231820683834_0004_m_000103_675: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443468517075231820683834_0004_m_000103_675
[2021-05-14 11:47:16,820] {docker.py:276} INFO - 21/05/14 14:47:16 INFO StagingCommitter: Task committer attempt_202105141443468517075231820683834_0004_m_000103_675: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443468517075231820683834_0004_m_000103_675 : duration 0:00.004s
[2021-05-14 11:47:19,348] {docker.py:276} INFO - 21/05/14 14:47:19 INFO StagingCommitter: Starting: Task committer attempt_20210514144346689433342522687732_0004_m_000100_672: needsTaskCommit() Task attempt_20210514144346689433342522687732_0004_m_000100_672
[2021-05-14 11:47:19,350] {docker.py:276} INFO - 21/05/14 14:47:19 INFO StagingCommitter: Task committer attempt_20210514144346689433342522687732_0004_m_000100_672: needsTaskCommit() Task attempt_20210514144346689433342522687732_0004_m_000100_672: duration 0:00.003s
21/05/14 14:47:19 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_20210514144346689433342522687732_0004_m_000100_672
[2021-05-14 11:47:19,351] {docker.py:276} INFO - 21/05/14 14:47:19 INFO Executor: Finished task 100.0 in stage 4.0 (TID 672). 5106 bytes result sent to driver
[2021-05-14 11:47:19,353] {docker.py:276} INFO - 21/05/14 14:47:19 INFO TaskSetManager: Starting task 104.0 in stage 4.0 (TID 676) (f0b8ef7ba22f, executor driver, partition 104, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:47:19,354] {docker.py:276} INFO - 21/05/14 14:47:19 INFO TaskSetManager: Finished task 100.0 in stage 4.0 (TID 672) in 6227 ms on f0b8ef7ba22f (executor driver) (101/200)
[2021-05-14 11:47:19,355] {docker.py:276} INFO - 21/05/14 14:47:19 INFO Executor: Running task 104.0 in stage 4.0 (TID 676)
[2021-05-14 11:47:19,364] {docker.py:276} INFO - 21/05/14 14:47:19 INFO ShuffleBlockFetcherIterator: Getting 9 (66.0 KiB) non-empty blocks including 9 (66.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:47:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:47:19,373] {docker.py:276} INFO - 21/05/14 14:47:19 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:47:19 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2021-05-14 11:47:19,373] {docker.py:276} INFO - 21/05/14 14:47:19 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
21/05/14 14:47:19 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443461637092537354410970_0004_m_000104_676, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443461637092537354410970_0004_m_000104_676}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443461637092537354410970_0004}; taskId=attempt_202105141443461637092537354410970_0004_m_000104_676, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@1d1b4376}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
21/05/14 14:47:19 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
[2021-05-14 11:47:19,374] {docker.py:276} INFO - 21/05/14 14:47:19 INFO StagingCommitter: Starting: Task committer attempt_202105141443461637092537354410970_0004_m_000104_676: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443461637092537354410970_0004_m_000104_676
[2021-05-14 11:47:19,378] {docker.py:276} INFO - 21/05/14 14:47:19 INFO StagingCommitter: Task committer attempt_202105141443461637092537354410970_0004_m_000104_676: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443461637092537354410970_0004_m_000104_676 : duration 0:00.004s
[2021-05-14 11:47:21,023] {docker.py:276} INFO - 21/05/14 14:47:21 INFO StagingCommitter: Starting: Task committer attempt_202105141443464890906220151772366_0004_m_000101_673: needsTaskCommit() Task attempt_202105141443464890906220151772366_0004_m_000101_673
[2021-05-14 11:47:21,024] {docker.py:276} INFO - 21/05/14 14:47:21 INFO StagingCommitter: Task committer attempt_202105141443464890906220151772366_0004_m_000101_673: needsTaskCommit() Task attempt_202105141443464890906220151772366_0004_m_000101_673: duration 0:00.002s
21/05/14 14:47:21 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443464890906220151772366_0004_m_000101_673
[2021-05-14 11:47:21,025] {docker.py:276} INFO - 21/05/14 14:47:21 INFO Executor: Finished task 101.0 in stage 4.0 (TID 673). 5106 bytes result sent to driver
[2021-05-14 11:47:21,027] {docker.py:276} INFO - 21/05/14 14:47:21 INFO TaskSetManager: Starting task 105.0 in stage 4.0 (TID 677) (f0b8ef7ba22f, executor driver, partition 105, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:47:21,027] {docker.py:276} INFO - 21/05/14 14:47:21 INFO Executor: Running task 105.0 in stage 4.0 (TID 677)
21/05/14 14:47:21 INFO TaskSetManager: Finished task 101.0 in stage 4.0 (TID 673) in 6905 ms on f0b8ef7ba22f (executor driver) (102/200)
[2021-05-14 11:47:21,037] {docker.py:276} INFO - 21/05/14 14:47:21 INFO ShuffleBlockFetcherIterator: Getting 9 (64.5 KiB) non-empty blocks including 9 (64.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
[2021-05-14 11:47:21,038] {docker.py:276} INFO - 21/05/14 14:47:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:47:21,047] {docker.py:276} INFO - 21/05/14 14:47:21 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:47:21 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2021-05-14 11:47:21,048] {docker.py:276} INFO - 21/05/14 14:47:21 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
21/05/14 14:47:21 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443465237149167940315219_0004_m_000105_677, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443465237149167940315219_0004_m_000105_677}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443465237149167940315219_0004}; taskId=attempt_202105141443465237149167940315219_0004_m_000105_677, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@29f9ae60}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
[2021-05-14 11:47:21,048] {docker.py:276} INFO - 21/05/14 14:47:21 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
[2021-05-14 11:47:21,049] {docker.py:276} INFO - 21/05/14 14:47:21 INFO StagingCommitter: Starting: Task committer attempt_202105141443465237149167940315219_0004_m_000105_677: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443465237149167940315219_0004_m_000105_677
[2021-05-14 11:47:21,053] {docker.py:276} INFO - 21/05/14 14:47:21 INFO StagingCommitter: Task committer attempt_202105141443465237149167940315219_0004_m_000105_677: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443465237149167940315219_0004_m_000105_677 : duration 0:00.005s
[2021-05-14 11:47:23,614] {docker.py:276} INFO - 21/05/14 14:47:23 INFO StagingCommitter: Starting: Task committer attempt_202105141443464539195468914108300_0004_m_000102_674: needsTaskCommit() Task attempt_202105141443464539195468914108300_0004_m_000102_674
[2021-05-14 11:47:23,615] {docker.py:276} INFO - 21/05/14 14:47:23 INFO StagingCommitter: Task committer attempt_202105141443464539195468914108300_0004_m_000102_674: needsTaskCommit() Task attempt_202105141443464539195468914108300_0004_m_000102_674: duration 0:00.002s
21/05/14 14:47:23 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443464539195468914108300_0004_m_000102_674
[2021-05-14 11:47:23,616] {docker.py:276} INFO - 21/05/14 14:47:23 INFO Executor: Finished task 102.0 in stage 4.0 (TID 674). 5106 bytes result sent to driver
[2021-05-14 11:47:23,618] {docker.py:276} INFO - 21/05/14 14:47:23 INFO TaskSetManager: Starting task 106.0 in stage 4.0 (TID 678) (f0b8ef7ba22f, executor driver, partition 106, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
21/05/14 14:47:23 INFO Executor: Running task 106.0 in stage 4.0 (TID 678)
[2021-05-14 11:47:23,619] {docker.py:276} INFO - 21/05/14 14:47:23 INFO TaskSetManager: Finished task 102.0 in stage 4.0 (TID 674) in 7119 ms on f0b8ef7ba22f (executor driver) (103/200)
[2021-05-14 11:47:23,628] {docker.py:276} INFO - 21/05/14 14:47:23 INFO ShuffleBlockFetcherIterator: Getting 9 (66.9 KiB) non-empty blocks including 9 (66.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:47:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:47:23,636] {docker.py:276} INFO - 21/05/14 14:47:23 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:47:23 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2021-05-14 11:47:23,637] {docker.py:276} INFO - 21/05/14 14:47:23 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
21/05/14 14:47:23 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443466883092758430168240_0004_m_000106_678, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443466883092758430168240_0004_m_000106_678}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443466883092758430168240_0004}; taskId=attempt_202105141443466883092758430168240_0004_m_000106_678, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@5c874f3d}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
[2021-05-14 11:47:23,637] {docker.py:276} INFO - 21/05/14 14:47:23 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
[2021-05-14 11:47:23,637] {docker.py:276} INFO - 21/05/14 14:47:23 INFO StagingCommitter: Starting: Task committer attempt_202105141443466883092758430168240_0004_m_000106_678: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443466883092758430168240_0004_m_000106_678
[2021-05-14 11:47:23,641] {docker.py:276} INFO - 21/05/14 14:47:23 INFO StagingCommitter: Task committer attempt_202105141443466883092758430168240_0004_m_000106_678: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443466883092758430168240_0004_m_000106_678 : duration 0:00.004s
[2021-05-14 11:47:24,237] {docker.py:276} INFO - 21/05/14 14:47:24 INFO StagingCommitter: Starting: Task committer attempt_202105141443468517075231820683834_0004_m_000103_675: needsTaskCommit() Task attempt_202105141443468517075231820683834_0004_m_000103_675
[2021-05-14 11:47:24,238] {docker.py:276} INFO - 21/05/14 14:47:24 INFO StagingCommitter: Task committer attempt_202105141443468517075231820683834_0004_m_000103_675: needsTaskCommit() Task attempt_202105141443468517075231820683834_0004_m_000103_675: duration 0:00.002s
21/05/14 14:47:24 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443468517075231820683834_0004_m_000103_675
[2021-05-14 11:47:24,242] {docker.py:276} INFO - 21/05/14 14:47:24 INFO Executor: Finished task 103.0 in stage 4.0 (TID 675). 5106 bytes result sent to driver
[2021-05-14 11:47:24,243] {docker.py:276} INFO - 21/05/14 14:47:24 INFO TaskSetManager: Starting task 107.0 in stage 4.0 (TID 679) (f0b8ef7ba22f, executor driver, partition 107, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:47:24,244] {docker.py:276} INFO - 21/05/14 14:47:24 INFO Executor: Running task 107.0 in stage 4.0 (TID 679)
[2021-05-14 11:47:24,245] {docker.py:276} INFO - 21/05/14 14:47:24 INFO TaskSetManager: Finished task 103.0 in stage 4.0 (TID 675) in 7458 ms on f0b8ef7ba22f (executor driver) (104/200)
[2021-05-14 11:47:24,255] {docker.py:276} INFO - 21/05/14 14:47:24 INFO ShuffleBlockFetcherIterator: Getting 9 (66.8 KiB) non-empty blocks including 9 (66.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:47:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:47:24,264] {docker.py:276} INFO - 21/05/14 14:47:24 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:47:24 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/05/14 14:47:24 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
[2021-05-14 11:47:24,264] {docker.py:276} INFO - 21/05/14 14:47:24 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_20210514144346310487856113752434_0004_m_000107_679, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_20210514144346310487856113752434_0004_m_000107_679}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_20210514144346310487856113752434_0004}; taskId=attempt_20210514144346310487856113752434_0004_m_000107_679, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@6cb37f9b}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
21/05/14 14:47:24 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
[2021-05-14 11:47:24,265] {docker.py:276} INFO - 21/05/14 14:47:24 INFO StagingCommitter: Starting: Task committer attempt_20210514144346310487856113752434_0004_m_000107_679: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_20210514144346310487856113752434_0004_m_000107_679
[2021-05-14 11:47:24,270] {docker.py:276} INFO - 21/05/14 14:47:24 INFO StagingCommitter: Task committer attempt_20210514144346310487856113752434_0004_m_000107_679: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_20210514144346310487856113752434_0004_m_000107_679 : duration 0:00.005s
[2021-05-14 11:47:26,377] {docker.py:276} INFO - 21/05/14 14:47:26 INFO StagingCommitter: Starting: Task committer attempt_202105141443461637092537354410970_0004_m_000104_676: needsTaskCommit() Task attempt_202105141443461637092537354410970_0004_m_000104_676
[2021-05-14 11:47:26,378] {docker.py:276} INFO - 21/05/14 14:47:26 INFO StagingCommitter: Task committer attempt_202105141443461637092537354410970_0004_m_000104_676: needsTaskCommit() Task attempt_202105141443461637092537354410970_0004_m_000104_676: duration 0:00.003s
21/05/14 14:47:26 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443461637092537354410970_0004_m_000104_676
[2021-05-14 11:47:26,382] {docker.py:276} INFO - 21/05/14 14:47:26 INFO Executor: Finished task 104.0 in stage 4.0 (TID 676). 5149 bytes result sent to driver
[2021-05-14 11:47:26,383] {docker.py:276} INFO - 21/05/14 14:47:26 INFO TaskSetManager: Starting task 108.0 in stage 4.0 (TID 680) (f0b8ef7ba22f, executor driver, partition 108, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:47:26,384] {docker.py:276} INFO - 21/05/14 14:47:26 INFO Executor: Running task 108.0 in stage 4.0 (TID 680)
21/05/14 14:47:26 INFO TaskSetManager: Finished task 104.0 in stage 4.0 (TID 676) in 7039 ms on f0b8ef7ba22f (executor driver) (105/200)
[2021-05-14 11:47:26,394] {docker.py:276} INFO - 21/05/14 14:47:26 INFO ShuffleBlockFetcherIterator: Getting 9 (64.2 KiB) non-empty blocks including 9 (64.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:47:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:47:26,403] {docker.py:276} INFO - 21/05/14 14:47:26 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:47:26 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/05/14 14:47:26 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
21/05/14 14:47:26 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443467363976428786655250_0004_m_000108_680, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443467363976428786655250_0004_m_000108_680}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443467363976428786655250_0004}; taskId=attempt_202105141443467363976428786655250_0004_m_000108_680, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@e815a6a}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
21/05/14 14:47:26 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
21/05/14 14:47:26 INFO StagingCommitter: Starting: Task committer attempt_202105141443467363976428786655250_0004_m_000108_680: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443467363976428786655250_0004_m_000108_680
[2021-05-14 11:47:26,407] {docker.py:276} INFO - 21/05/14 14:47:26 INFO StagingCommitter: Task committer attempt_202105141443467363976428786655250_0004_m_000108_680: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443467363976428786655250_0004_m_000108_680 : duration 0:00.004s
[2021-05-14 11:47:28,255] {docker.py:276} INFO - 21/05/14 14:47:28 INFO StagingCommitter: Starting: Task committer attempt_202105141443465237149167940315219_0004_m_000105_677: needsTaskCommit() Task attempt_202105141443465237149167940315219_0004_m_000105_677
21/05/14 14:47:28 INFO StagingCommitter: Task committer attempt_202105141443465237149167940315219_0004_m_000105_677: needsTaskCommit() Task attempt_202105141443465237149167940315219_0004_m_000105_677: duration 0:00.003s
21/05/14 14:47:28 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443465237149167940315219_0004_m_000105_677
[2021-05-14 11:47:28,258] {docker.py:276} INFO - 21/05/14 14:47:28 INFO Executor: Finished task 105.0 in stage 4.0 (TID 677). 5149 bytes result sent to driver
21/05/14 14:47:28 INFO TaskSetManager: Starting task 109.0 in stage 4.0 (TID 681) (f0b8ef7ba22f, executor driver, partition 109, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:47:28,259] {docker.py:276} INFO - 21/05/14 14:47:28 INFO TaskSetManager: Finished task 105.0 in stage 4.0 (TID 677) in 7241 ms on f0b8ef7ba22f (executor driver) (106/200)
[2021-05-14 11:47:28,261] {docker.py:276} INFO - 21/05/14 14:47:28 INFO Executor: Running task 109.0 in stage 4.0 (TID 681)
[2021-05-14 11:47:28,274] {docker.py:276} INFO - 21/05/14 14:47:28 INFO ShuffleBlockFetcherIterator: Getting 9 (65.4 KiB) non-empty blocks including 9 (65.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:47:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:47:28,284] {docker.py:276} INFO - 21/05/14 14:47:28 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:47:28 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/05/14 14:47:28 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
21/05/14 14:47:28 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443463218290550478819439_0004_m_000109_681, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443463218290550478819439_0004_m_000109_681}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443463218290550478819439_0004}; taskId=attempt_202105141443463218290550478819439_0004_m_000109_681, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@655fe434}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
21/05/14 14:47:28 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
21/05/14 14:47:28 INFO StagingCommitter: Starting: Task committer attempt_202105141443463218290550478819439_0004_m_000109_681: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443463218290550478819439_0004_m_000109_681
[2021-05-14 11:47:28,288] {docker.py:276} INFO - 21/05/14 14:47:28 INFO StagingCommitter: Task committer attempt_202105141443463218290550478819439_0004_m_000109_681: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443463218290550478819439_0004_m_000109_681 : duration 0:00.005s
[2021-05-14 11:47:30,402] {docker.py:276} INFO - 21/05/14 14:47:30 INFO StagingCommitter: Starting: Task committer attempt_202105141443466883092758430168240_0004_m_000106_678: needsTaskCommit() Task attempt_202105141443466883092758430168240_0004_m_000106_678
[2021-05-14 11:47:30,403] {docker.py:276} INFO - 21/05/14 14:47:30 INFO StagingCommitter: Task committer attempt_202105141443466883092758430168240_0004_m_000106_678: needsTaskCommit() Task attempt_202105141443466883092758430168240_0004_m_000106_678: duration 0:00.002s
21/05/14 14:47:30 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443466883092758430168240_0004_m_000106_678
[2021-05-14 11:47:30,404] {docker.py:276} INFO - 21/05/14 14:47:30 INFO Executor: Finished task 106.0 in stage 4.0 (TID 678). 5149 bytes result sent to driver
[2021-05-14 11:47:30,406] {docker.py:276} INFO - 21/05/14 14:47:30 INFO TaskSetManager: Starting task 110.0 in stage 4.0 (TID 682) (f0b8ef7ba22f, executor driver, partition 110, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:47:30,407] {docker.py:276} INFO - 21/05/14 14:47:30 INFO TaskSetManager: Finished task 106.0 in stage 4.0 (TID 678) in 6797 ms on f0b8ef7ba22f (executor driver) (107/200)
[2021-05-14 11:47:30,407] {docker.py:276} INFO - 21/05/14 14:47:30 INFO Executor: Running task 110.0 in stage 4.0 (TID 682)
[2021-05-14 11:47:30,416] {docker.py:276} INFO - 21/05/14 14:47:30 INFO ShuffleBlockFetcherIterator: Getting 9 (62.7 KiB) non-empty blocks including 9 (62.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:47:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:47:30,426] {docker.py:276} INFO - 21/05/14 14:47:30 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:47:30 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2021-05-14 11:47:30,427] {docker.py:276} INFO - 21/05/14 14:47:30 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
[2021-05-14 11:47:30,427] {docker.py:276} INFO - 21/05/14 14:47:30 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443462011301384793391354_0004_m_000110_682, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443462011301384793391354_0004_m_000110_682}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443462011301384793391354_0004}; taskId=attempt_202105141443462011301384793391354_0004_m_000110_682, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@8d29e26}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
[2021-05-14 11:47:30,428] {docker.py:276} INFO - 21/05/14 14:47:30 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
21/05/14 14:47:30 INFO StagingCommitter: Starting: Task committer attempt_202105141443462011301384793391354_0004_m_000110_682: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443462011301384793391354_0004_m_000110_682
[2021-05-14 11:47:30,432] {docker.py:276} INFO - 21/05/14 14:47:30 INFO StagingCommitter: Task committer attempt_202105141443462011301384793391354_0004_m_000110_682: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443462011301384793391354_0004_m_000110_682 : duration 0:00.004s
[2021-05-14 11:47:31,264] {docker.py:276} INFO - 21/05/14 14:47:31 INFO StagingCommitter: Starting: Task committer attempt_20210514144346310487856113752434_0004_m_000107_679: needsTaskCommit() Task attempt_20210514144346310487856113752434_0004_m_000107_679
[2021-05-14 11:47:31,265] {docker.py:276} INFO - 21/05/14 14:47:31 INFO StagingCommitter: Task committer attempt_20210514144346310487856113752434_0004_m_000107_679: needsTaskCommit() Task attempt_20210514144346310487856113752434_0004_m_000107_679: duration 0:00.004s
[2021-05-14 11:47:31,266] {docker.py:276} INFO - 21/05/14 14:47:31 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_20210514144346310487856113752434_0004_m_000107_679
[2021-05-14 11:47:31,270] {docker.py:276} INFO - 21/05/14 14:47:31 INFO Executor: Finished task 107.0 in stage 4.0 (TID 679). 5149 bytes result sent to driver
[2021-05-14 11:47:31,271] {docker.py:276} INFO - 21/05/14 14:47:31 INFO TaskSetManager: Starting task 111.0 in stage 4.0 (TID 683) (f0b8ef7ba22f, executor driver, partition 111, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:47:31,272] {docker.py:276} INFO - 21/05/14 14:47:31 INFO Executor: Running task 111.0 in stage 4.0 (TID 683)
21/05/14 14:47:31 INFO TaskSetManager: Finished task 107.0 in stage 4.0 (TID 679) in 7038 ms on f0b8ef7ba22f (executor driver) (108/200)
[2021-05-14 11:47:31,286] {docker.py:276} INFO - 21/05/14 14:47:31 INFO ShuffleBlockFetcherIterator: Getting 9 (69.5 KiB) non-empty blocks including 9 (69.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:47:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:47:31,295] {docker.py:276} INFO - 21/05/14 14:47:31 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:47:31 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/05/14 14:47:31 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
21/05/14 14:47:31 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443465656541808808050965_0004_m_000111_683, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443465656541808808050965_0004_m_000111_683}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443465656541808808050965_0004}; taskId=attempt_202105141443465656541808808050965_0004_m_000111_683, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@27677bbf}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
[2021-05-14 11:47:31,295] {docker.py:276} INFO - 21/05/14 14:47:31 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
21/05/14 14:47:31 INFO StagingCommitter: Starting: Task committer attempt_202105141443465656541808808050965_0004_m_000111_683: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443465656541808808050965_0004_m_000111_683
[2021-05-14 11:47:31,299] {docker.py:276} INFO - 21/05/14 14:47:31 INFO StagingCommitter: Task committer attempt_202105141443465656541808808050965_0004_m_000111_683: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443465656541808808050965_0004_m_000111_683 : duration 0:00.005s
[2021-05-14 11:47:33,216] {docker.py:276} INFO - 21/05/14 14:47:33 INFO StagingCommitter: Starting: Task committer attempt_202105141443467363976428786655250_0004_m_000108_680: needsTaskCommit() Task attempt_202105141443467363976428786655250_0004_m_000108_680
[2021-05-14 11:47:33,218] {docker.py:276} INFO - 21/05/14 14:47:33 INFO StagingCommitter: Task committer attempt_202105141443467363976428786655250_0004_m_000108_680: needsTaskCommit() Task attempt_202105141443467363976428786655250_0004_m_000108_680: duration 0:00.003s
[2021-05-14 11:47:33,220] {docker.py:276} INFO - 21/05/14 14:47:33 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443467363976428786655250_0004_m_000108_680
[2021-05-14 11:47:33,222] {docker.py:276} INFO - 21/05/14 14:47:33 INFO Executor: Finished task 108.0 in stage 4.0 (TID 680). 5106 bytes result sent to driver
[2021-05-14 11:47:33,223] {docker.py:276} INFO - 21/05/14 14:47:33 INFO TaskSetManager: Starting task 112.0 in stage 4.0 (TID 684) (f0b8ef7ba22f, executor driver, partition 112, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:47:33,224] {docker.py:276} INFO - 21/05/14 14:47:33 INFO Executor: Running task 112.0 in stage 4.0 (TID 684)
[2021-05-14 11:47:33,225] {docker.py:276} INFO - 21/05/14 14:47:33 INFO TaskSetManager: Finished task 108.0 in stage 4.0 (TID 680) in 6850 ms on f0b8ef7ba22f (executor driver) (109/200)
[2021-05-14 11:47:33,233] {docker.py:276} INFO - 21/05/14 14:47:33 INFO ShuffleBlockFetcherIterator: Getting 9 (64.3 KiB) non-empty blocks including 9 (64.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:47:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:47:33,242] {docker.py:276} INFO - 21/05/14 14:47:33 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:47:33 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2021-05-14 11:47:33,242] {docker.py:276} INFO - 21/05/14 14:47:33 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
[2021-05-14 11:47:33,243] {docker.py:276} INFO - 21/05/14 14:47:33 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443461899101677685376035_0004_m_000112_684, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443461899101677685376035_0004_m_000112_684}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443461899101677685376035_0004}; taskId=attempt_202105141443461899101677685376035_0004_m_000112_684, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@1d42add1}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
21/05/14 14:47:33 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
[2021-05-14 11:47:33,243] {docker.py:276} INFO - 21/05/14 14:47:33 INFO StagingCommitter: Starting: Task committer attempt_202105141443461899101677685376035_0004_m_000112_684: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443461899101677685376035_0004_m_000112_684
[2021-05-14 11:47:33,247] {docker.py:276} INFO - 21/05/14 14:47:33 INFO StagingCommitter: Task committer attempt_202105141443461899101677685376035_0004_m_000112_684: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443461899101677685376035_0004_m_000112_684 : duration 0:00.004s
[2021-05-14 11:47:34,965] {docker.py:276} INFO - 21/05/14 14:47:34 INFO StagingCommitter: Starting: Task committer attempt_202105141443463218290550478819439_0004_m_000109_681: needsTaskCommit() Task attempt_202105141443463218290550478819439_0004_m_000109_681
[2021-05-14 11:47:34,966] {docker.py:276} INFO - 21/05/14 14:47:34 INFO StagingCommitter: Task committer attempt_202105141443463218290550478819439_0004_m_000109_681: needsTaskCommit() Task attempt_202105141443463218290550478819439_0004_m_000109_681: duration 0:00.002s
[2021-05-14 11:47:34,967] {docker.py:276} INFO - 21/05/14 14:47:34 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443463218290550478819439_0004_m_000109_681
[2021-05-14 11:47:34,969] {docker.py:276} INFO - 21/05/14 14:47:34 INFO Executor: Finished task 109.0 in stage 4.0 (TID 681). 5106 bytes result sent to driver
21/05/14 14:47:34 INFO TaskSetManager: Starting task 113.0 in stage 4.0 (TID 685) (f0b8ef7ba22f, executor driver, partition 113, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:47:34,970] {docker.py:276} INFO - 21/05/14 14:47:34 INFO Executor: Running task 113.0 in stage 4.0 (TID 685)
21/05/14 14:47:34 INFO TaskSetManager: Finished task 109.0 in stage 4.0 (TID 681) in 6720 ms on f0b8ef7ba22f (executor driver) (110/200)
[2021-05-14 11:47:34,979] {docker.py:276} INFO - 21/05/14 14:47:35 INFO ShuffleBlockFetcherIterator: Getting 9 (65.2 KiB) non-empty blocks including 9 (65.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:47:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:47:34,988] {docker.py:276} INFO - 21/05/14 14:47:35 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:47:35 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/05/14 14:47:35 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
21/05/14 14:47:35 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443461579521552657295195_0004_m_000113_685, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443461579521552657295195_0004_m_000113_685}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443461579521552657295195_0004}; taskId=attempt_202105141443461579521552657295195_0004_m_000113_685, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@e3f961b}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
[2021-05-14 11:47:34,989] {docker.py:276} INFO - 21/05/14 14:47:35 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
21/05/14 14:47:35 INFO StagingCommitter: Starting: Task committer attempt_202105141443461579521552657295195_0004_m_000113_685: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443461579521552657295195_0004_m_000113_685
[2021-05-14 11:47:34,993] {docker.py:276} INFO - 21/05/14 14:47:35 INFO StagingCommitter: Task committer attempt_202105141443461579521552657295195_0004_m_000113_685: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443461579521552657295195_0004_m_000113_685 : duration 0:00.004s
[2021-05-14 11:47:37,261] {docker.py:276} INFO - 21/05/14 14:47:37 INFO StagingCommitter: Starting: Task committer attempt_202105141443462011301384793391354_0004_m_000110_682: needsTaskCommit() Task attempt_202105141443462011301384793391354_0004_m_000110_682
[2021-05-14 11:47:37,262] {docker.py:276} INFO - 21/05/14 14:47:37 INFO StagingCommitter: Task committer attempt_202105141443462011301384793391354_0004_m_000110_682: needsTaskCommit() Task attempt_202105141443462011301384793391354_0004_m_000110_682: duration 0:00.002s
[2021-05-14 11:47:37,262] {docker.py:276} INFO - 21/05/14 14:47:37 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443462011301384793391354_0004_m_000110_682
[2021-05-14 11:47:37,264] {docker.py:276} INFO - 21/05/14 14:47:37 INFO Executor: Finished task 110.0 in stage 4.0 (TID 682). 5106 bytes result sent to driver
[2021-05-14 11:47:37,266] {docker.py:276} INFO - 21/05/14 14:47:37 INFO TaskSetManager: Finished task 110.0 in stage 4.0 (TID 682) in 6868 ms on f0b8ef7ba22f (executor driver) (111/200)
[2021-05-14 11:47:37,267] {docker.py:276} INFO - 21/05/14 14:47:37 INFO TaskSetManager: Starting task 114.0 in stage 4.0 (TID 686) (f0b8ef7ba22f, executor driver, partition 114, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:47:37,268] {docker.py:276} INFO - 21/05/14 14:47:37 INFO Executor: Running task 114.0 in stage 4.0 (TID 686)
[2021-05-14 11:47:37,277] {docker.py:276} INFO - 21/05/14 14:47:37 INFO ShuffleBlockFetcherIterator: Getting 9 (63.5 KiB) non-empty blocks including 9 (63.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:47:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:47:37,286] {docker.py:276} INFO - 21/05/14 14:47:37 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:47:37 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2021-05-14 11:47:37,287] {docker.py:276} INFO - 21/05/14 14:47:37 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
[2021-05-14 11:47:37,287] {docker.py:276} INFO - 21/05/14 14:47:37 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443465113959011680403183_0004_m_000114_686, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443465113959011680403183_0004_m_000114_686}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443465113959011680403183_0004}; taskId=attempt_202105141443465113959011680403183_0004_m_000114_686, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@461523dd}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
[2021-05-14 11:47:37,288] {docker.py:276} INFO - 21/05/14 14:47:37 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
[2021-05-14 11:47:37,288] {docker.py:276} INFO - 21/05/14 14:47:37 INFO StagingCommitter: Starting: Task committer attempt_202105141443465113959011680403183_0004_m_000114_686: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443465113959011680403183_0004_m_000114_686
[2021-05-14 11:47:37,291] {docker.py:276} INFO - 21/05/14 14:47:37 INFO StagingCommitter: Task committer attempt_202105141443465113959011680403183_0004_m_000114_686: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443465113959011680403183_0004_m_000114_686 : duration 0:00.005s
[2021-05-14 11:47:38,484] {docker.py:276} INFO - 21/05/14 14:47:38 INFO StagingCommitter: Starting: Task committer attempt_202105141443465656541808808050965_0004_m_000111_683: needsTaskCommit() Task attempt_202105141443465656541808808050965_0004_m_000111_683
[2021-05-14 11:47:38,486] {docker.py:276} INFO - 21/05/14 14:47:38 INFO StagingCommitter: Task committer attempt_202105141443465656541808808050965_0004_m_000111_683: needsTaskCommit() Task attempt_202105141443465656541808808050965_0004_m_000111_683: duration 0:00.003s
21/05/14 14:47:38 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443465656541808808050965_0004_m_000111_683
[2021-05-14 11:47:38,488] {docker.py:276} INFO - 21/05/14 14:47:38 INFO Executor: Finished task 111.0 in stage 4.0 (TID 683). 5106 bytes result sent to driver
[2021-05-14 11:47:38,490] {docker.py:276} INFO - 21/05/14 14:47:38 INFO TaskSetManager: Starting task 115.0 in stage 4.0 (TID 687) (f0b8ef7ba22f, executor driver, partition 115, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:47:38,491] {docker.py:276} INFO - 21/05/14 14:47:38 INFO Executor: Running task 115.0 in stage 4.0 (TID 687)
[2021-05-14 11:47:38,492] {docker.py:276} INFO - 21/05/14 14:47:38 INFO TaskSetManager: Finished task 111.0 in stage 4.0 (TID 683) in 7230 ms on f0b8ef7ba22f (executor driver) (112/200)
[2021-05-14 11:47:38,500] {docker.py:276} INFO - 21/05/14 14:47:38 INFO ShuffleBlockFetcherIterator: Getting 9 (66.1 KiB) non-empty blocks including 9 (66.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:47:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:47:38,509] {docker.py:276} INFO - 21/05/14 14:47:38 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:47:38 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/05/14 14:47:38 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
21/05/14 14:47:38 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443467269054685054929072_0004_m_000115_687, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443467269054685054929072_0004_m_000115_687}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443467269054685054929072_0004}; taskId=attempt_202105141443467269054685054929072_0004_m_000115_687, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@62799ebc}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
21/05/14 14:47:38 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
[2021-05-14 11:47:38,510] {docker.py:276} INFO - 21/05/14 14:47:38 INFO StagingCommitter: Starting: Task committer attempt_202105141443467269054685054929072_0004_m_000115_687: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443467269054685054929072_0004_m_000115_687
[2021-05-14 11:47:38,513] {docker.py:276} INFO - 21/05/14 14:47:38 INFO StagingCommitter: Task committer attempt_202105141443467269054685054929072_0004_m_000115_687: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443467269054685054929072_0004_m_000115_687 : duration 0:00.004s
[2021-05-14 11:47:40,252] {docker.py:276} INFO - 21/05/14 14:47:40 INFO StagingCommitter: Starting: Task committer attempt_202105141443461899101677685376035_0004_m_000112_684: needsTaskCommit() Task attempt_202105141443461899101677685376035_0004_m_000112_684
[2021-05-14 11:47:40,253] {docker.py:276} INFO - 21/05/14 14:47:40 INFO StagingCommitter: Task committer attempt_202105141443461899101677685376035_0004_m_000112_684: needsTaskCommit() Task attempt_202105141443461899101677685376035_0004_m_000112_684: duration 0:00.002s
21/05/14 14:47:40 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443461899101677685376035_0004_m_000112_684
[2021-05-14 11:47:40,254] {docker.py:276} INFO - 21/05/14 14:47:40 INFO Executor: Finished task 112.0 in stage 4.0 (TID 684). 5106 bytes result sent to driver
[2021-05-14 11:47:40,255] {docker.py:276} INFO - 21/05/14 14:47:40 INFO TaskSetManager: Starting task 116.0 in stage 4.0 (TID 688) (f0b8ef7ba22f, executor driver, partition 116, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:47:40,256] {docker.py:276} INFO - 21/05/14 14:47:40 INFO TaskSetManager: Finished task 112.0 in stage 4.0 (TID 684) in 7006 ms on f0b8ef7ba22f (executor driver) (113/200)
21/05/14 14:47:40 INFO Executor: Running task 116.0 in stage 4.0 (TID 688)
[2021-05-14 11:47:40,266] {docker.py:276} INFO - 21/05/14 14:47:40 INFO ShuffleBlockFetcherIterator: Getting 9 (66.3 KiB) non-empty blocks including 9 (66.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:47:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:47:40,275] {docker.py:276} INFO - 21/05/14 14:47:40 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:47:40 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/05/14 14:47:40 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
21/05/14 14:47:40 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443468901133370939241282_0004_m_000116_688, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443468901133370939241282_0004_m_000116_688}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443468901133370939241282_0004}; taskId=attempt_202105141443468901133370939241282_0004_m_000116_688, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@647ff85a}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
21/05/14 14:47:40 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
21/05/14 14:47:40 INFO StagingCommitter: Starting: Task committer attempt_202105141443468901133370939241282_0004_m_000116_688: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443468901133370939241282_0004_m_000116_688
[2021-05-14 11:47:40,280] {docker.py:276} INFO - 21/05/14 14:47:40 INFO StagingCommitter: Task committer attempt_202105141443468901133370939241282_0004_m_000116_688: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443468901133370939241282_0004_m_000116_688 : duration 0:00.005s
[2021-05-14 11:47:41,836] {docker.py:276} INFO - 21/05/14 14:47:41 INFO StagingCommitter: Starting: Task committer attempt_202105141443461579521552657295195_0004_m_000113_685: needsTaskCommit() Task attempt_202105141443461579521552657295195_0004_m_000113_685
[2021-05-14 11:47:41,836] {docker.py:276} INFO - 21/05/14 14:47:41 INFO StagingCommitter: Task committer attempt_202105141443461579521552657295195_0004_m_000113_685: needsTaskCommit() Task attempt_202105141443461579521552657295195_0004_m_000113_685: duration 0:00.001s
21/05/14 14:47:41 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443461579521552657295195_0004_m_000113_685
[2021-05-14 11:47:41,837] {docker.py:276} INFO - 21/05/14 14:47:41 INFO Executor: Finished task 113.0 in stage 4.0 (TID 685). 5106 bytes result sent to driver
[2021-05-14 11:47:41,837] {docker.py:276} INFO - 21/05/14 14:47:41 INFO TaskSetManager: Starting task 117.0 in stage 4.0 (TID 689) (f0b8ef7ba22f, executor driver, partition 117, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:47:41,838] {docker.py:276} INFO - 21/05/14 14:47:41 INFO Executor: Running task 117.0 in stage 4.0 (TID 689)
[2021-05-14 11:47:41,839] {docker.py:276} INFO - 21/05/14 14:47:41 INFO TaskSetManager: Finished task 113.0 in stage 4.0 (TID 685) in 6843 ms on f0b8ef7ba22f (executor driver) (114/200)
[2021-05-14 11:47:41,850] {docker.py:276} INFO - 21/05/14 14:47:41 INFO ShuffleBlockFetcherIterator: Getting 9 (65.0 KiB) non-empty blocks including 9 (65.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:47:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:47:41,859] {docker.py:276} INFO - 21/05/14 14:47:41 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:47:41 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/05/14 14:47:41 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
21/05/14 14:47:41 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443466300556771503241493_0004_m_000117_689, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443466300556771503241493_0004_m_000117_689}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443466300556771503241493_0004}; taskId=attempt_202105141443466300556771503241493_0004_m_000117_689, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@3a930720}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
[2021-05-14 11:47:41,860] {docker.py:276} INFO - 21/05/14 14:47:41 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
21/05/14 14:47:41 INFO StagingCommitter: Starting: Task committer attempt_202105141443466300556771503241493_0004_m_000117_689: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443466300556771503241493_0004_m_000117_689
[2021-05-14 11:47:41,864] {docker.py:276} INFO - 21/05/14 14:47:41 INFO StagingCommitter: Task committer attempt_202105141443466300556771503241493_0004_m_000117_689: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443466300556771503241493_0004_m_000117_689 : duration 0:00.004s
[2021-05-14 11:47:44,368] {docker.py:276} INFO - 21/05/14 14:47:44 INFO StagingCommitter: Starting: Task committer attempt_202105141443465113959011680403183_0004_m_000114_686: needsTaskCommit() Task attempt_202105141443465113959011680403183_0004_m_000114_686
[2021-05-14 11:47:44,369] {docker.py:276} INFO - 21/05/14 14:47:44 INFO StagingCommitter: Task committer attempt_202105141443465113959011680403183_0004_m_000114_686: needsTaskCommit() Task attempt_202105141443465113959011680403183_0004_m_000114_686: duration 0:00.002s
21/05/14 14:47:44 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443465113959011680403183_0004_m_000114_686
[2021-05-14 11:47:44,370] {docker.py:276} INFO - 21/05/14 14:47:44 INFO Executor: Finished task 114.0 in stage 4.0 (TID 686). 5106 bytes result sent to driver
[2021-05-14 11:47:44,371] {docker.py:276} INFO - 21/05/14 14:47:44 INFO TaskSetManager: Starting task 118.0 in stage 4.0 (TID 690) (f0b8ef7ba22f, executor driver, partition 118, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:47:44,373] {docker.py:276} INFO - 21/05/14 14:47:44 INFO TaskSetManager: Finished task 114.0 in stage 4.0 (TID 686) in 7079 ms on f0b8ef7ba22f (executor driver) (115/200)
21/05/14 14:47:44 INFO Executor: Running task 118.0 in stage 4.0 (TID 690)
[2021-05-14 11:47:44,383] {docker.py:276} INFO - 21/05/14 14:47:44 INFO ShuffleBlockFetcherIterator: Getting 9 (69.4 KiB) non-empty blocks including 9 (69.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:47:44 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:47:44,393] {docker.py:276} INFO - 21/05/14 14:47:44 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:47:44 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/05/14 14:47:44 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
21/05/14 14:47:44 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443461592461160496276047_0004_m_000118_690, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443461592461160496276047_0004_m_000118_690}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443461592461160496276047_0004}; taskId=attempt_202105141443461592461160496276047_0004_m_000118_690, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@52056051}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
21/05/14 14:47:44 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
21/05/14 14:47:44 INFO StagingCommitter: Starting: Task committer attempt_202105141443461592461160496276047_0004_m_000118_690: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443461592461160496276047_0004_m_000118_690
[2021-05-14 11:47:44,398] {docker.py:276} INFO - 21/05/14 14:47:44 INFO StagingCommitter: Task committer attempt_202105141443461592461160496276047_0004_m_000118_690: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443461592461160496276047_0004_m_000118_690 : duration 0:00.004s
[2021-05-14 11:47:45,119] {docker.py:276} INFO - 21/05/14 14:47:45 INFO StagingCommitter: Starting: Task committer attempt_202105141443467269054685054929072_0004_m_000115_687: needsTaskCommit() Task attempt_202105141443467269054685054929072_0004_m_000115_687
21/05/14 14:47:45 INFO StagingCommitter: Task committer attempt_202105141443467269054685054929072_0004_m_000115_687: needsTaskCommit() Task attempt_202105141443467269054685054929072_0004_m_000115_687: duration 0:00.004s
21/05/14 14:47:45 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443467269054685054929072_0004_m_000115_687
[2021-05-14 11:47:45,121] {docker.py:276} INFO - 21/05/14 14:47:45 INFO Executor: Finished task 115.0 in stage 4.0 (TID 687). 5106 bytes result sent to driver
[2021-05-14 11:47:45,123] {docker.py:276} INFO - 21/05/14 14:47:45 INFO TaskSetManager: Starting task 119.0 in stage 4.0 (TID 691) (f0b8ef7ba22f, executor driver, partition 119, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:47:45,124] {docker.py:276} INFO - 21/05/14 14:47:45 INFO TaskSetManager: Finished task 115.0 in stage 4.0 (TID 687) in 6608 ms on f0b8ef7ba22f (executor driver) (116/200)
[2021-05-14 11:47:45,125] {docker.py:276} INFO - 21/05/14 14:47:45 INFO Executor: Running task 119.0 in stage 4.0 (TID 691)
[2021-05-14 11:47:45,134] {docker.py:276} INFO - 21/05/14 14:47:45 INFO ShuffleBlockFetcherIterator: Getting 9 (66.1 KiB) non-empty blocks including 9 (66.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:47:45 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:47:45,143] {docker.py:276} INFO - 21/05/14 14:47:45 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:47:45 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/05/14 14:47:45 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
21/05/14 14:47:45 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443469062619545074677798_0004_m_000119_691, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443469062619545074677798_0004_m_000119_691}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443469062619545074677798_0004}; taskId=attempt_202105141443469062619545074677798_0004_m_000119_691, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@404bb713}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
21/05/14 14:47:45 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
21/05/14 14:47:45 INFO StagingCommitter: Starting: Task committer attempt_202105141443469062619545074677798_0004_m_000119_691: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443469062619545074677798_0004_m_000119_691
[2021-05-14 11:47:45,147] {docker.py:276} INFO - 21/05/14 14:47:45 INFO StagingCommitter: Task committer attempt_202105141443469062619545074677798_0004_m_000119_691: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443469062619545074677798_0004_m_000119_691 : duration 0:00.004s
[2021-05-14 11:47:46,995] {docker.py:276} INFO - 21/05/14 14:47:47 INFO StagingCommitter: Starting: Task committer attempt_202105141443468901133370939241282_0004_m_000116_688: needsTaskCommit() Task attempt_202105141443468901133370939241282_0004_m_000116_688
21/05/14 14:47:47 INFO StagingCommitter: Task committer attempt_202105141443468901133370939241282_0004_m_000116_688: needsTaskCommit() Task attempt_202105141443468901133370939241282_0004_m_000116_688: duration 0:00.002s
21/05/14 14:47:47 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443468901133370939241282_0004_m_000116_688
[2021-05-14 11:47:46,999] {docker.py:276} INFO - 21/05/14 14:47:47 INFO Executor: Finished task 116.0 in stage 4.0 (TID 688). 5106 bytes result sent to driver
[2021-05-14 11:47:47,001] {docker.py:276} INFO - 21/05/14 14:47:47 INFO TaskSetManager: Starting task 120.0 in stage 4.0 (TID 692) (f0b8ef7ba22f, executor driver, partition 120, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:47:47,002] {docker.py:276} INFO - 21/05/14 14:47:47 INFO Executor: Running task 120.0 in stage 4.0 (TID 692)
[2021-05-14 11:47:47,002] {docker.py:276} INFO - 21/05/14 14:47:47 INFO TaskSetManager: Finished task 116.0 in stage 4.0 (TID 688) in 6755 ms on f0b8ef7ba22f (executor driver) (117/200)
[2021-05-14 11:47:47,012] {docker.py:276} INFO - 21/05/14 14:47:47 INFO ShuffleBlockFetcherIterator: Getting 9 (64.5 KiB) non-empty blocks including 9 (64.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
[2021-05-14 11:47:47,013] {docker.py:276} INFO - 21/05/14 14:47:47 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:47:47,025] {docker.py:276} INFO - 21/05/14 14:47:47 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:47:47 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/05/14 14:47:47 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
21/05/14 14:47:47 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443463227073329620328420_0004_m_000120_692, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443463227073329620328420_0004_m_000120_692}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443463227073329620328420_0004}; taskId=attempt_202105141443463227073329620328420_0004_m_000120_692, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@73355217}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
[2021-05-14 11:47:47,026] {docker.py:276} INFO - 21/05/14 14:47:47 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
21/05/14 14:47:47 INFO StagingCommitter: Starting: Task committer attempt_202105141443463227073329620328420_0004_m_000120_692: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443463227073329620328420_0004_m_000120_692
[2021-05-14 11:47:47,031] {docker.py:276} INFO - 21/05/14 14:47:47 INFO StagingCommitter: Task committer attempt_202105141443463227073329620328420_0004_m_000120_692: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443463227073329620328420_0004_m_000120_692 : duration 0:00.005s
[2021-05-14 11:47:48,970] {docker.py:276} INFO - 21/05/14 14:47:48 INFO StagingCommitter: Starting: Task committer attempt_202105141443466300556771503241493_0004_m_000117_689: needsTaskCommit() Task attempt_202105141443466300556771503241493_0004_m_000117_689
[2021-05-14 11:47:48,971] {docker.py:276} INFO - 21/05/14 14:47:48 INFO StagingCommitter: Task committer attempt_202105141443466300556771503241493_0004_m_000117_689: needsTaskCommit() Task attempt_202105141443466300556771503241493_0004_m_000117_689: duration 0:00.002s
[2021-05-14 11:47:48,972] {docker.py:276} INFO - 21/05/14 14:47:48 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443466300556771503241493_0004_m_000117_689
[2021-05-14 11:47:48,972] {docker.py:276} INFO - 21/05/14 14:47:48 INFO Executor: Finished task 117.0 in stage 4.0 (TID 689). 5149 bytes result sent to driver
[2021-05-14 11:47:48,973] {docker.py:276} INFO - 21/05/14 14:47:48 INFO TaskSetManager: Starting task 121.0 in stage 4.0 (TID 693) (f0b8ef7ba22f, executor driver, partition 121, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:47:48,974] {docker.py:276} INFO - 21/05/14 14:47:48 INFO Executor: Running task 121.0 in stage 4.0 (TID 693)
[2021-05-14 11:47:48,975] {docker.py:276} INFO - 21/05/14 14:47:48 INFO TaskSetManager: Finished task 117.0 in stage 4.0 (TID 689) in 7145 ms on f0b8ef7ba22f (executor driver) (118/200)
[2021-05-14 11:47:48,984] {docker.py:276} INFO - 21/05/14 14:47:48 INFO ShuffleBlockFetcherIterator: Getting 9 (67.2 KiB) non-empty blocks including 9 (67.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:47:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:47:48,993] {docker.py:276} INFO - 21/05/14 14:47:49 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:47:49 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/05/14 14:47:49 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
21/05/14 14:47:49 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443468984016258518964132_0004_m_000121_693, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443468984016258518964132_0004_m_000121_693}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443468984016258518964132_0004}; taskId=attempt_202105141443468984016258518964132_0004_m_000121_693, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@c95e368}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
[2021-05-14 11:47:48,994] {docker.py:276} INFO - 21/05/14 14:47:49 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
[2021-05-14 11:47:48,994] {docker.py:276} INFO - 21/05/14 14:47:49 INFO StagingCommitter: Starting: Task committer attempt_202105141443468984016258518964132_0004_m_000121_693: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443468984016258518964132_0004_m_000121_693
[2021-05-14 11:47:48,998] {docker.py:276} INFO - 21/05/14 14:47:49 INFO StagingCommitter: Task committer attempt_202105141443468984016258518964132_0004_m_000121_693: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443468984016258518964132_0004_m_000121_693 : duration 0:00.004s
[2021-05-14 11:47:51,270] {docker.py:276} INFO - 21/05/14 14:47:51 INFO StagingCommitter: Starting: Task committer attempt_202105141443469062619545074677798_0004_m_000119_691: needsTaskCommit() Task attempt_202105141443469062619545074677798_0004_m_000119_691
[2021-05-14 11:47:51,271] {docker.py:276} INFO - 21/05/14 14:47:51 INFO StagingCommitter: Task committer attempt_202105141443469062619545074677798_0004_m_000119_691: needsTaskCommit() Task attempt_202105141443469062619545074677798_0004_m_000119_691: duration 0:00.002s
21/05/14 14:47:51 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443469062619545074677798_0004_m_000119_691
[2021-05-14 11:47:51,271] {docker.py:276} INFO - 21/05/14 14:47:51 INFO Executor: Finished task 119.0 in stage 4.0 (TID 691). 5149 bytes result sent to driver
[2021-05-14 11:47:51,272] {docker.py:276} INFO - 21/05/14 14:47:51 INFO TaskSetManager: Starting task 122.0 in stage 4.0 (TID 694) (f0b8ef7ba22f, executor driver, partition 122, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:47:51,273] {docker.py:276} INFO - 21/05/14 14:47:51 INFO Executor: Running task 122.0 in stage 4.0 (TID 694)
21/05/14 14:47:51 INFO TaskSetManager: Finished task 119.0 in stage 4.0 (TID 691) in 6158 ms on f0b8ef7ba22f (executor driver) (119/200)
[2021-05-14 11:47:51,282] {docker.py:276} INFO - 21/05/14 14:47:51 INFO ShuffleBlockFetcherIterator: Getting 9 (66.3 KiB) non-empty blocks including 9 (66.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:47:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:47:51,290] {docker.py:276} INFO - 21/05/14 14:47:51 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:47:51 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2021-05-14 11:47:51,291] {docker.py:276} INFO - 21/05/14 14:47:51 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
[2021-05-14 11:47:51,292] {docker.py:276} INFO - 21/05/14 14:47:51 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443464359220714916890640_0004_m_000122_694, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443464359220714916890640_0004_m_000122_694}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443464359220714916890640_0004}; taskId=attempt_202105141443464359220714916890640_0004_m_000122_694, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@78e8a24a}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
21/05/14 14:47:51 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
21/05/14 14:47:51 INFO StagingCommitter: Starting: Task committer attempt_202105141443464359220714916890640_0004_m_000122_694: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443464359220714916890640_0004_m_000122_694
[2021-05-14 11:47:51,296] {docker.py:276} INFO - 21/05/14 14:47:51 INFO StagingCommitter: Task committer attempt_202105141443464359220714916890640_0004_m_000122_694: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443464359220714916890640_0004_m_000122_694 : duration 0:00.005s
[2021-05-14 11:47:51,626] {docker.py:276} INFO - 21/05/14 14:47:51 INFO StagingCommitter: Starting: Task committer attempt_202105141443461592461160496276047_0004_m_000118_690: needsTaskCommit() Task attempt_202105141443461592461160496276047_0004_m_000118_690
[2021-05-14 11:47:51,627] {docker.py:276} INFO - 21/05/14 14:47:51 INFO StagingCommitter: Task committer attempt_202105141443461592461160496276047_0004_m_000118_690: needsTaskCommit() Task attempt_202105141443461592461160496276047_0004_m_000118_690: duration 0:00.003s
[2021-05-14 11:47:51,627] {docker.py:276} INFO - 21/05/14 14:47:51 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443461592461160496276047_0004_m_000118_690
[2021-05-14 11:47:51,629] {docker.py:276} INFO - 21/05/14 14:47:51 INFO Executor: Finished task 118.0 in stage 4.0 (TID 690). 5149 bytes result sent to driver
[2021-05-14 11:47:51,630] {docker.py:276} INFO - 21/05/14 14:47:51 INFO TaskSetManager: Starting task 123.0 in stage 4.0 (TID 695) (f0b8ef7ba22f, executor driver, partition 123, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:47:51,631] {docker.py:276} INFO - 21/05/14 14:47:51 INFO Executor: Running task 123.0 in stage 4.0 (TID 695)
21/05/14 14:47:51 INFO TaskSetManager: Finished task 118.0 in stage 4.0 (TID 690) in 7268 ms on f0b8ef7ba22f (executor driver) (120/200)
[2021-05-14 11:47:51,640] {docker.py:276} INFO - 21/05/14 14:47:51 INFO ShuffleBlockFetcherIterator: Getting 9 (64.2 KiB) non-empty blocks including 9 (64.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
[2021-05-14 11:47:51,641] {docker.py:276} INFO - 21/05/14 14:47:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:47:51,650] {docker.py:276} INFO - 21/05/14 14:47:51 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:47:51 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/05/14 14:47:51 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
21/05/14 14:47:51 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443467333971284443062672_0004_m_000123_695, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443467333971284443062672_0004_m_000123_695}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443467333971284443062672_0004}; taskId=attempt_202105141443467333971284443062672_0004_m_000123_695, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@2f5ed581}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
21/05/14 14:47:51 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
[2021-05-14 11:47:51,651] {docker.py:276} INFO - 21/05/14 14:47:51 INFO StagingCommitter: Starting: Task committer attempt_202105141443467333971284443062672_0004_m_000123_695: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443467333971284443062672_0004_m_000123_695
[2021-05-14 11:47:51,654] {docker.py:276} INFO - 21/05/14 14:47:51 INFO StagingCommitter: Task committer attempt_202105141443467333971284443062672_0004_m_000123_695: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443467333971284443062672_0004_m_000123_695 : duration 0:00.003s
[2021-05-14 11:47:53,918] {docker.py:276} INFO - 21/05/14 14:47:53 INFO StagingCommitter: Starting: Task committer attempt_202105141443463227073329620328420_0004_m_000120_692: needsTaskCommit() Task attempt_202105141443463227073329620328420_0004_m_000120_692
[2021-05-14 11:47:53,919] {docker.py:276} INFO - 21/05/14 14:47:53 INFO StagingCommitter: Task committer attempt_202105141443463227073329620328420_0004_m_000120_692: needsTaskCommit() Task attempt_202105141443463227073329620328420_0004_m_000120_692: duration 0:00.003s
21/05/14 14:47:53 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443463227073329620328420_0004_m_000120_692
[2021-05-14 11:47:53,922] {docker.py:276} INFO - 21/05/14 14:47:53 INFO Executor: Finished task 120.0 in stage 4.0 (TID 692). 5149 bytes result sent to driver
[2021-05-14 11:47:53,923] {docker.py:276} INFO - 21/05/14 14:47:53 INFO TaskSetManager: Starting task 124.0 in stage 4.0 (TID 696) (f0b8ef7ba22f, executor driver, partition 124, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:47:53,923] {docker.py:276} INFO - 21/05/14 14:47:53 INFO Executor: Running task 124.0 in stage 4.0 (TID 696)
[2021-05-14 11:47:53,924] {docker.py:276} INFO - 21/05/14 14:47:53 INFO TaskSetManager: Finished task 120.0 in stage 4.0 (TID 692) in 6933 ms on f0b8ef7ba22f (executor driver) (121/200)
[2021-05-14 11:47:53,933] {docker.py:276} INFO - 21/05/14 14:47:53 INFO ShuffleBlockFetcherIterator: Getting 9 (65.0 KiB) non-empty blocks including 9 (65.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:47:53 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:47:53,942] {docker.py:276} INFO - 21/05/14 14:47:53 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:47:53 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/05/14 14:47:53 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
21/05/14 14:47:53 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443468663877872749107130_0004_m_000124_696, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443468663877872749107130_0004_m_000124_696}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443468663877872749107130_0004}; taskId=attempt_202105141443468663877872749107130_0004_m_000124_696, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@2c5cffa5}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
21/05/14 14:47:53 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
21/05/14 14:47:53 INFO StagingCommitter: Starting: Task committer attempt_202105141443468663877872749107130_0004_m_000124_696: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443468663877872749107130_0004_m_000124_696
[2021-05-14 11:47:53,946] {docker.py:276} INFO - 21/05/14 14:47:53 INFO StagingCommitter: Task committer attempt_202105141443468663877872749107130_0004_m_000124_696: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443468663877872749107130_0004_m_000124_696 : duration 0:00.004s
[2021-05-14 11:47:56,106] {docker.py:276} INFO - 21/05/14 14:47:56 INFO StagingCommitter: Starting: Task committer attempt_202105141443468984016258518964132_0004_m_000121_693: needsTaskCommit() Task attempt_202105141443468984016258518964132_0004_m_000121_693
[2021-05-14 11:47:56,107] {docker.py:276} INFO - 21/05/14 14:47:56 INFO StagingCommitter: Task committer attempt_202105141443468984016258518964132_0004_m_000121_693: needsTaskCommit() Task attempt_202105141443468984016258518964132_0004_m_000121_693: duration 0:00.001s
21/05/14 14:47:56 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443468984016258518964132_0004_m_000121_693
[2021-05-14 11:47:56,108] {docker.py:276} INFO - 21/05/14 14:47:56 INFO Executor: Finished task 121.0 in stage 4.0 (TID 693). 5106 bytes result sent to driver
[2021-05-14 11:47:56,109] {docker.py:276} INFO - 21/05/14 14:47:56 INFO TaskSetManager: Starting task 125.0 in stage 4.0 (TID 697) (f0b8ef7ba22f, executor driver, partition 125, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:47:56,110] {docker.py:276} INFO - 21/05/14 14:47:56 INFO TaskSetManager: Finished task 121.0 in stage 4.0 (TID 693) in 7145 ms on f0b8ef7ba22f (executor driver) (122/200)
21/05/14 14:47:56 INFO Executor: Running task 125.0 in stage 4.0 (TID 697)
[2021-05-14 11:47:56,120] {docker.py:276} INFO - 21/05/14 14:47:56 INFO ShuffleBlockFetcherIterator: Getting 9 (66.7 KiB) non-empty blocks including 9 (66.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:47:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:47:56,129] {docker.py:276} INFO - 21/05/14 14:47:56 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:47:56 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/05/14 14:47:56 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
21/05/14 14:47:56 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443466852618097035297071_0004_m_000125_697, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443466852618097035297071_0004_m_000125_697}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443466852618097035297071_0004}; taskId=attempt_202105141443466852618097035297071_0004_m_000125_697, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@4b608033}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
21/05/14 14:47:56 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
21/05/14 14:47:56 INFO StagingCommitter: Starting: Task committer attempt_202105141443466852618097035297071_0004_m_000125_697: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443466852618097035297071_0004_m_000125_697
[2021-05-14 11:47:56,132] {docker.py:276} INFO - 21/05/14 14:47:56 INFO StagingCommitter: Task committer attempt_202105141443466852618097035297071_0004_m_000125_697: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443466852618097035297071_0004_m_000125_697 : duration 0:00.004s
[2021-05-14 11:47:58,487] {docker.py:276} INFO - 21/05/14 14:47:58 INFO StagingCommitter: Starting: Task committer attempt_202105141443464359220714916890640_0004_m_000122_694: needsTaskCommit() Task attempt_202105141443464359220714916890640_0004_m_000122_694
[2021-05-14 11:47:58,487] {docker.py:276} INFO - 21/05/14 14:47:58 INFO StagingCommitter: Task committer attempt_202105141443464359220714916890640_0004_m_000122_694: needsTaskCommit() Task attempt_202105141443464359220714916890640_0004_m_000122_694: duration 0:00.002s
[2021-05-14 11:47:58,488] {docker.py:276} INFO - 21/05/14 14:47:58 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443464359220714916890640_0004_m_000122_694
[2021-05-14 11:47:58,488] {docker.py:276} INFO - 21/05/14 14:47:58 INFO Executor: Finished task 122.0 in stage 4.0 (TID 694). 5106 bytes result sent to driver
[2021-05-14 11:47:58,490] {docker.py:276} INFO - 21/05/14 14:47:58 INFO TaskSetManager: Starting task 126.0 in stage 4.0 (TID 698) (f0b8ef7ba22f, executor driver, partition 126, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:47:58,491] {docker.py:276} INFO - 21/05/14 14:47:58 INFO Executor: Running task 126.0 in stage 4.0 (TID 698)
[2021-05-14 11:47:58,491] {docker.py:276} INFO - 21/05/14 14:47:58 INFO TaskSetManager: Finished task 122.0 in stage 4.0 (TID 694) in 7227 ms on f0b8ef7ba22f (executor driver) (123/200)
[2021-05-14 11:47:58,500] {docker.py:276} INFO - 21/05/14 14:47:58 INFO ShuffleBlockFetcherIterator: Getting 9 (65.6 KiB) non-empty blocks including 9 (65.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:47:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:47:58,512] {docker.py:276} INFO - 21/05/14 14:47:58 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:47:58 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2021-05-14 11:47:58,512] {docker.py:276} INFO - 21/05/14 14:47:58 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
[2021-05-14 11:47:58,512] {docker.py:276} INFO - 21/05/14 14:47:58 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443464620845454954401120_0004_m_000126_698, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443464620845454954401120_0004_m_000126_698}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443464620845454954401120_0004}; taskId=attempt_202105141443464620845454954401120_0004_m_000126_698, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@5557f7e0}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
[2021-05-14 11:47:58,513] {docker.py:276} INFO - 21/05/14 14:47:58 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
[2021-05-14 11:47:58,513] {docker.py:276} INFO - 21/05/14 14:47:58 INFO StagingCommitter: Starting: Task committer attempt_202105141443464620845454954401120_0004_m_000126_698: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443464620845454954401120_0004_m_000126_698
[2021-05-14 11:47:58,517] {docker.py:276} INFO - 21/05/14 14:47:58 INFO StagingCommitter: Task committer attempt_202105141443464620845454954401120_0004_m_000126_698: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443464620845454954401120_0004_m_000126_698 : duration 0:00.004s
[2021-05-14 11:47:58,601] {docker.py:276} INFO - 21/05/14 14:47:58 INFO StagingCommitter: Starting: Task committer attempt_202105141443467333971284443062672_0004_m_000123_695: needsTaskCommit() Task attempt_202105141443467333971284443062672_0004_m_000123_695
[2021-05-14 11:47:58,601] {docker.py:276} INFO - 21/05/14 14:47:58 INFO StagingCommitter: Task committer attempt_202105141443467333971284443062672_0004_m_000123_695: needsTaskCommit() Task attempt_202105141443467333971284443062672_0004_m_000123_695: duration 0:00.002s
[2021-05-14 11:47:58,602] {docker.py:276} INFO - 21/05/14 14:47:58 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443467333971284443062672_0004_m_000123_695
[2021-05-14 11:47:58,602] {docker.py:276} INFO - 21/05/14 14:47:58 INFO Executor: Finished task 123.0 in stage 4.0 (TID 695). 5106 bytes result sent to driver
[2021-05-14 11:47:58,603] {docker.py:276} INFO - 21/05/14 14:47:58 INFO TaskSetManager: Starting task 127.0 in stage 4.0 (TID 699) (f0b8ef7ba22f, executor driver, partition 127, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:47:58,604] {docker.py:276} INFO - 21/05/14 14:47:58 INFO Executor: Running task 127.0 in stage 4.0 (TID 699)
21/05/14 14:47:58 INFO TaskSetManager: Finished task 123.0 in stage 4.0 (TID 695) in 6982 ms on f0b8ef7ba22f (executor driver) (124/200)
[2021-05-14 11:47:58,614] {docker.py:276} INFO - 21/05/14 14:47:58 INFO ShuffleBlockFetcherIterator: Getting 9 (65.0 KiB) non-empty blocks including 9 (65.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:47:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:47:58,624] {docker.py:276} INFO - 21/05/14 14:47:58 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:47:58 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2021-05-14 11:47:58,624] {docker.py:276} INFO - 21/05/14 14:47:58 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
[2021-05-14 11:47:58,625] {docker.py:276} INFO - 21/05/14 14:47:58 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443463903489117749548150_0004_m_000127_699, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443463903489117749548150_0004_m_000127_699}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443463903489117749548150_0004}; taskId=attempt_202105141443463903489117749548150_0004_m_000127_699, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@2c6edf3d}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
21/05/14 14:47:58 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
[2021-05-14 11:47:58,625] {docker.py:276} INFO - 21/05/14 14:47:58 INFO StagingCommitter: Starting: Task committer attempt_202105141443463903489117749548150_0004_m_000127_699: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443463903489117749548150_0004_m_000127_699
[2021-05-14 11:47:58,629] {docker.py:276} INFO - 21/05/14 14:47:58 INFO StagingCommitter: Task committer attempt_202105141443463903489117749548150_0004_m_000127_699: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443463903489117749548150_0004_m_000127_699 : duration 0:00.004s
[2021-05-14 11:48:00,900] {docker.py:276} INFO - 21/05/14 14:48:00 INFO StagingCommitter: Starting: Task committer attempt_202105141443468663877872749107130_0004_m_000124_696: needsTaskCommit() Task attempt_202105141443468663877872749107130_0004_m_000124_696
[2021-05-14 11:48:00,902] {docker.py:276} INFO - 21/05/14 14:48:00 INFO StagingCommitter: Task committer attempt_202105141443468663877872749107130_0004_m_000124_696: needsTaskCommit() Task attempt_202105141443468663877872749107130_0004_m_000124_696: duration 0:00.003s
21/05/14 14:48:00 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443468663877872749107130_0004_m_000124_696
[2021-05-14 11:48:00,904] {docker.py:276} INFO - 21/05/14 14:48:00 INFO Executor: Finished task 124.0 in stage 4.0 (TID 696). 5106 bytes result sent to driver
[2021-05-14 11:48:00,905] {docker.py:276} INFO - 21/05/14 14:48:00 INFO TaskSetManager: Starting task 128.0 in stage 4.0 (TID 700) (f0b8ef7ba22f, executor driver, partition 128, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:48:00,906] {docker.py:276} INFO - 21/05/14 14:48:00 INFO Executor: Running task 128.0 in stage 4.0 (TID 700)
[2021-05-14 11:48:00,906] {docker.py:276} INFO - 21/05/14 14:48:00 INFO TaskSetManager: Finished task 124.0 in stage 4.0 (TID 696) in 6992 ms on f0b8ef7ba22f (executor driver) (125/200)
[2021-05-14 11:48:00,917] {docker.py:276} INFO - 21/05/14 14:48:00 INFO ShuffleBlockFetcherIterator: Getting 9 (68.0 KiB) non-empty blocks including 9 (68.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:48:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:48:00,927] {docker.py:276} INFO - 21/05/14 14:48:00 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2021-05-14 11:48:00,927] {docker.py:276} INFO - 21/05/14 14:48:00 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2021-05-14 11:48:00,928] {docker.py:276} INFO - 21/05/14 14:48:00 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
[2021-05-14 11:48:00,928] {docker.py:276} INFO - 21/05/14 14:48:00 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443462330835103139050779_0004_m_000128_700, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443462330835103139050779_0004_m_000128_700}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443462330835103139050779_0004}; taskId=attempt_202105141443462330835103139050779_0004_m_000128_700, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@3f160f85}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
[2021-05-14 11:48:00,928] {docker.py:276} INFO - 21/05/14 14:48:00 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
[2021-05-14 11:48:00,929] {docker.py:276} INFO - 21/05/14 14:48:00 INFO StagingCommitter: Starting: Task committer attempt_202105141443462330835103139050779_0004_m_000128_700: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443462330835103139050779_0004_m_000128_700
[2021-05-14 11:48:00,933] {docker.py:276} INFO - 21/05/14 14:48:00 INFO StagingCommitter: Task committer attempt_202105141443462330835103139050779_0004_m_000128_700: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443462330835103139050779_0004_m_000128_700 : duration 0:00.004s
[2021-05-14 11:48:03,139] {docker.py:276} INFO - 21/05/14 14:48:03 INFO StagingCommitter: Starting: Task committer attempt_202105141443466852618097035297071_0004_m_000125_697: needsTaskCommit() Task attempt_202105141443466852618097035297071_0004_m_000125_697
[2021-05-14 11:48:03,141] {docker.py:276} INFO - 21/05/14 14:48:03 INFO StagingCommitter: Task committer attempt_202105141443466852618097035297071_0004_m_000125_697: needsTaskCommit() Task attempt_202105141443466852618097035297071_0004_m_000125_697: duration 0:00.002s
21/05/14 14:48:03 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443466852618097035297071_0004_m_000125_697
[2021-05-14 11:48:03,143] {docker.py:276} INFO - 21/05/14 14:48:03 INFO Executor: Finished task 125.0 in stage 4.0 (TID 697). 5106 bytes result sent to driver
[2021-05-14 11:48:03,144] {docker.py:276} INFO - 21/05/14 14:48:03 INFO TaskSetManager: Starting task 129.0 in stage 4.0 (TID 701) (f0b8ef7ba22f, executor driver, partition 129, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:48:03,145] {docker.py:276} INFO - 21/05/14 14:48:03 INFO TaskSetManager: Finished task 125.0 in stage 4.0 (TID 697) in 7045 ms on f0b8ef7ba22f (executor driver) (126/200)
[2021-05-14 11:48:03,145] {docker.py:276} INFO - 21/05/14 14:48:03 INFO Executor: Running task 129.0 in stage 4.0 (TID 701)
[2021-05-14 11:48:03,155] {docker.py:276} INFO - 21/05/14 14:48:03 INFO ShuffleBlockFetcherIterator: Getting 9 (62.7 KiB) non-empty blocks including 9 (62.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:48:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:48:03,165] {docker.py:276} INFO - 21/05/14 14:48:03 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:48:03 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/05/14 14:48:03 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
21/05/14 14:48:03 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443467234000353132997319_0004_m_000129_701, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443467234000353132997319_0004_m_000129_701}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443467234000353132997319_0004}; taskId=attempt_202105141443467234000353132997319_0004_m_000129_701, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@64909bdc}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
21/05/14 14:48:03 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
21/05/14 14:48:03 INFO StagingCommitter: Starting: Task committer attempt_202105141443467234000353132997319_0004_m_000129_701: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443467234000353132997319_0004_m_000129_701
[2021-05-14 11:48:03,168] {docker.py:276} INFO - 21/05/14 14:48:03 INFO StagingCommitter: Task committer attempt_202105141443467234000353132997319_0004_m_000129_701: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443467234000353132997319_0004_m_000129_701 : duration 0:00.004s
[2021-05-14 11:48:05,462] {docker.py:276} INFO - 21/05/14 14:48:05 INFO StagingCommitter: Starting: Task committer attempt_202105141443464620845454954401120_0004_m_000126_698: needsTaskCommit() Task attempt_202105141443464620845454954401120_0004_m_000126_698
[2021-05-14 11:48:05,463] {docker.py:276} INFO - 21/05/14 14:48:05 INFO StagingCommitter: Task committer attempt_202105141443464620845454954401120_0004_m_000126_698: needsTaskCommit() Task attempt_202105141443464620845454954401120_0004_m_000126_698: duration 0:00.001s
21/05/14 14:48:05 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443464620845454954401120_0004_m_000126_698
[2021-05-14 11:48:05,464] {docker.py:276} INFO - 21/05/14 14:48:05 INFO Executor: Finished task 126.0 in stage 4.0 (TID 698). 5106 bytes result sent to driver
[2021-05-14 11:48:05,466] {docker.py:276} INFO - 21/05/14 14:48:05 INFO TaskSetManager: Starting task 130.0 in stage 4.0 (TID 702) (f0b8ef7ba22f, executor driver, partition 130, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
21/05/14 14:48:05 INFO Executor: Running task 130.0 in stage 4.0 (TID 702)
21/05/14 14:48:05 INFO TaskSetManager: Finished task 126.0 in stage 4.0 (TID 698) in 6985 ms on f0b8ef7ba22f (executor driver) (127/200)
[2021-05-14 11:48:05,474] {docker.py:276} INFO - 21/05/14 14:48:05 INFO ShuffleBlockFetcherIterator: Getting 9 (69.3 KiB) non-empty blocks including 9 (69.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:48:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:48:05,484] {docker.py:276} INFO - 21/05/14 14:48:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:48:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/05/14 14:48:05 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
21/05/14 14:48:05 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443466528279468808526418_0004_m_000130_702, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443466528279468808526418_0004_m_000130_702}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443466528279468808526418_0004}; taskId=attempt_202105141443466528279468808526418_0004_m_000130_702, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@7ac03b85}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
21/05/14 14:48:05 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
[2021-05-14 11:48:05,484] {docker.py:276} INFO - 21/05/14 14:48:05 INFO StagingCommitter: Starting: Task committer attempt_202105141443466528279468808526418_0004_m_000130_702: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443466528279468808526418_0004_m_000130_702
[2021-05-14 11:48:05,488] {docker.py:276} INFO - 21/05/14 14:48:05 INFO StagingCommitter: Task committer attempt_202105141443466528279468808526418_0004_m_000130_702: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443466528279468808526418_0004_m_000130_702 : duration 0:00.004s
[2021-05-14 11:48:05,583] {docker.py:276} INFO - 21/05/14 14:48:05 INFO StagingCommitter: Starting: Task committer attempt_202105141443463903489117749548150_0004_m_000127_699: needsTaskCommit() Task attempt_202105141443463903489117749548150_0004_m_000127_699
[2021-05-14 11:48:05,585] {docker.py:276} INFO - 21/05/14 14:48:05 INFO StagingCommitter: Task committer attempt_202105141443463903489117749548150_0004_m_000127_699: needsTaskCommit() Task attempt_202105141443463903489117749548150_0004_m_000127_699: duration 0:00.004s
21/05/14 14:48:05 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443463903489117749548150_0004_m_000127_699
[2021-05-14 11:48:05,588] {docker.py:276} INFO - 21/05/14 14:48:05 INFO Executor: Finished task 127.0 in stage 4.0 (TID 699). 5106 bytes result sent to driver
[2021-05-14 11:48:05,588] {docker.py:276} INFO - 21/05/14 14:48:05 INFO TaskSetManager: Starting task 131.0 in stage 4.0 (TID 703) (f0b8ef7ba22f, executor driver, partition 131, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:48:05,589] {docker.py:276} INFO - 21/05/14 14:48:05 INFO TaskSetManager: Finished task 127.0 in stage 4.0 (TID 699) in 6994 ms on f0b8ef7ba22f (executor driver) (128/200)
[2021-05-14 11:48:05,591] {docker.py:276} INFO - 21/05/14 14:48:05 INFO Executor: Running task 131.0 in stage 4.0 (TID 703)
[2021-05-14 11:48:05,600] {docker.py:276} INFO - 21/05/14 14:48:05 INFO ShuffleBlockFetcherIterator: Getting 9 (65.4 KiB) non-empty blocks including 9 (65.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:48:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:48:05,609] {docker.py:276} INFO - 21/05/14 14:48:05 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:48:05 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/05/14 14:48:05 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
21/05/14 14:48:05 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443463510863856837918352_0004_m_000131_703, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443463510863856837918352_0004_m_000131_703}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443463510863856837918352_0004}; taskId=attempt_202105141443463510863856837918352_0004_m_000131_703, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@c4952af}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
21/05/14 14:48:05 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
21/05/14 14:48:05 INFO StagingCommitter: Starting: Task committer attempt_202105141443463510863856837918352_0004_m_000131_703: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443463510863856837918352_0004_m_000131_703
[2021-05-14 11:48:05,614] {docker.py:276} INFO - 21/05/14 14:48:05 INFO StagingCommitter: Task committer attempt_202105141443463510863856837918352_0004_m_000131_703: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443463510863856837918352_0004_m_000131_703 : duration 0:00.004s
[2021-05-14 11:48:07,132] {docker.py:276} INFO - 21/05/14 14:48:07 INFO StagingCommitter: Starting: Task committer attempt_202105141443462330835103139050779_0004_m_000128_700: needsTaskCommit() Task attempt_202105141443462330835103139050779_0004_m_000128_700
[2021-05-14 11:48:07,133] {docker.py:276} INFO - 21/05/14 14:48:07 INFO StagingCommitter: Task committer attempt_202105141443462330835103139050779_0004_m_000128_700: needsTaskCommit() Task attempt_202105141443462330835103139050779_0004_m_000128_700: duration 0:00.002s
[2021-05-14 11:48:07,133] {docker.py:276} INFO - 21/05/14 14:48:07 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443462330835103139050779_0004_m_000128_700
[2021-05-14 11:48:07,135] {docker.py:276} INFO - 21/05/14 14:48:07 INFO Executor: Finished task 128.0 in stage 4.0 (TID 700). 5106 bytes result sent to driver
[2021-05-14 11:48:07,136] {docker.py:276} INFO - 21/05/14 14:48:07 INFO TaskSetManager: Starting task 132.0 in stage 4.0 (TID 704) (f0b8ef7ba22f, executor driver, partition 132, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:48:07,137] {docker.py:276} INFO - 21/05/14 14:48:07 INFO Executor: Running task 132.0 in stage 4.0 (TID 704)
[2021-05-14 11:48:07,137] {docker.py:276} INFO - 21/05/14 14:48:07 INFO TaskSetManager: Finished task 128.0 in stage 4.0 (TID 700) in 6239 ms on f0b8ef7ba22f (executor driver) (129/200)
[2021-05-14 11:48:07,145] {docker.py:276} INFO - 21/05/14 14:48:07 INFO ShuffleBlockFetcherIterator: Getting 9 (65.1 KiB) non-empty blocks including 9 (65.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
[2021-05-14 11:48:07,145] {docker.py:276} INFO - 21/05/14 14:48:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:48:07,153] {docker.py:276} INFO - 21/05/14 14:48:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:48:07 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2021-05-14 11:48:07,154] {docker.py:276} INFO - 21/05/14 14:48:07 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
21/05/14 14:48:07 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443461456604981365462266_0004_m_000132_704, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443461456604981365462266_0004_m_000132_704}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443461456604981365462266_0004}; taskId=attempt_202105141443461456604981365462266_0004_m_000132_704, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@1aeab003}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
[2021-05-14 11:48:07,154] {docker.py:276} INFO - 21/05/14 14:48:07 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
[2021-05-14 11:48:07,154] {docker.py:276} INFO - 21/05/14 14:48:07 INFO StagingCommitter: Starting: Task committer attempt_202105141443461456604981365462266_0004_m_000132_704: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443461456604981365462266_0004_m_000132_704
[2021-05-14 11:48:07,159] {docker.py:276} INFO - 21/05/14 14:48:07 INFO StagingCommitter: Task committer attempt_202105141443461456604981365462266_0004_m_000132_704: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443461456604981365462266_0004_m_000132_704 : duration 0:00.006s
[2021-05-14 11:48:09,637] {docker.py:276} INFO - 21/05/14 14:48:09 INFO StagingCommitter: Starting: Task committer attempt_202105141443467234000353132997319_0004_m_000129_701: needsTaskCommit() Task attempt_202105141443467234000353132997319_0004_m_000129_701
21/05/14 14:48:09 INFO StagingCommitter: Task committer attempt_202105141443467234000353132997319_0004_m_000129_701: needsTaskCommit() Task attempt_202105141443467234000353132997319_0004_m_000129_701: duration 0:00.002s
21/05/14 14:48:09 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443467234000353132997319_0004_m_000129_701
[2021-05-14 11:48:09,638] {docker.py:276} INFO - 21/05/14 14:48:09 INFO Executor: Finished task 129.0 in stage 4.0 (TID 701). 5106 bytes result sent to driver
[2021-05-14 11:48:09,639] {docker.py:276} INFO - 21/05/14 14:48:09 INFO TaskSetManager: Starting task 133.0 in stage 4.0 (TID 705) (f0b8ef7ba22f, executor driver, partition 133, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:48:09,640] {docker.py:276} INFO - 21/05/14 14:48:09 INFO TaskSetManager: Finished task 129.0 in stage 4.0 (TID 701) in 6470 ms on f0b8ef7ba22f (executor driver) (130/200)
[2021-05-14 11:48:09,640] {docker.py:276} INFO - 21/05/14 14:48:09 INFO Executor: Running task 133.0 in stage 4.0 (TID 705)
[2021-05-14 11:48:09,648] {docker.py:276} INFO - 21/05/14 14:48:09 INFO ShuffleBlockFetcherIterator: Getting 9 (67.3 KiB) non-empty blocks including 9 (67.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:48:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:48:09,661] {docker.py:276} INFO - 21/05/14 14:48:09 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:48:09 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/05/14 14:48:09 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
[2021-05-14 11:48:09,661] {docker.py:276} INFO - 21/05/14 14:48:09 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443466768209372372450029_0004_m_000133_705, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443466768209372372450029_0004_m_000133_705}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443466768209372372450029_0004}; taskId=attempt_202105141443466768209372372450029_0004_m_000133_705, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@60936b2b}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
21/05/14 14:48:09 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
[2021-05-14 11:48:09,661] {docker.py:276} INFO - 21/05/14 14:48:09 INFO StagingCommitter: Starting: Task committer attempt_202105141443466768209372372450029_0004_m_000133_705: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443466768209372372450029_0004_m_000133_705
[2021-05-14 11:48:09,665] {docker.py:276} INFO - 21/05/14 14:48:09 INFO StagingCommitter: Task committer attempt_202105141443466768209372372450029_0004_m_000133_705: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443466768209372372450029_0004_m_000133_705 : duration 0:00.004s
[2021-05-14 11:48:12,510] {docker.py:276} INFO - 21/05/14 14:48:12 INFO StagingCommitter: Starting: Task committer attempt_202105141443463510863856837918352_0004_m_000131_703: needsTaskCommit() Task attempt_202105141443463510863856837918352_0004_m_000131_703
[2021-05-14 11:48:12,511] {docker.py:276} INFO - 21/05/14 14:48:12 INFO StagingCommitter: Task committer attempt_202105141443463510863856837918352_0004_m_000131_703: needsTaskCommit() Task attempt_202105141443463510863856837918352_0004_m_000131_703: duration 0:00.002s
21/05/14 14:48:12 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443463510863856837918352_0004_m_000131_703
[2021-05-14 11:48:12,514] {docker.py:276} INFO - 21/05/14 14:48:12 INFO Executor: Finished task 131.0 in stage 4.0 (TID 703). 5149 bytes result sent to driver
[2021-05-14 11:48:12,514] {docker.py:276} INFO - 21/05/14 14:48:12 INFO TaskSetManager: Starting task 134.0 in stage 4.0 (TID 706) (f0b8ef7ba22f, executor driver, partition 134, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:48:12,515] {docker.py:276} INFO - 21/05/14 14:48:12 INFO TaskSetManager: Finished task 131.0 in stage 4.0 (TID 703) in 6899 ms on f0b8ef7ba22f (executor driver) (131/200)
[2021-05-14 11:48:12,515] {docker.py:276} INFO - 21/05/14 14:48:12 INFO Executor: Running task 134.0 in stage 4.0 (TID 706)
[2021-05-14 11:48:12,524] {docker.py:276} INFO - 21/05/14 14:48:12 INFO ShuffleBlockFetcherIterator: Getting 9 (67.2 KiB) non-empty blocks including 9 (67.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:48:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:48:12,532] {docker.py:276} INFO - 21/05/14 14:48:12 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:48:12 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/05/14 14:48:12 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
21/05/14 14:48:12 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443464753073800386220401_0004_m_000134_706, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443464753073800386220401_0004_m_000134_706}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443464753073800386220401_0004}; taskId=attempt_202105141443464753073800386220401_0004_m_000134_706, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@655891c6}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
21/05/14 14:48:12 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
21/05/14 14:48:12 INFO StagingCommitter: Starting: Task committer attempt_202105141443464753073800386220401_0004_m_000134_706: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443464753073800386220401_0004_m_000134_706
[2021-05-14 11:48:12,536] {docker.py:276} INFO - 21/05/14 14:48:12 INFO StagingCommitter: Task committer attempt_202105141443464753073800386220401_0004_m_000134_706: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443464753073800386220401_0004_m_000134_706 : duration 0:00.003s
[2021-05-14 11:48:12,664] {docker.py:276} INFO - 21/05/14 14:48:12 INFO StagingCommitter: Starting: Task committer attempt_202105141443466528279468808526418_0004_m_000130_702: needsTaskCommit() Task attempt_202105141443466528279468808526418_0004_m_000130_702
21/05/14 14:48:12 INFO StagingCommitter: Task committer attempt_202105141443466528279468808526418_0004_m_000130_702: needsTaskCommit() Task attempt_202105141443466528279468808526418_0004_m_000130_702: duration 0:00.003s
21/05/14 14:48:12 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443466528279468808526418_0004_m_000130_702
[2021-05-14 11:48:12,666] {docker.py:276} INFO - 21/05/14 14:48:12 INFO Executor: Finished task 130.0 in stage 4.0 (TID 702). 5149 bytes result sent to driver
[2021-05-14 11:48:12,667] {docker.py:276} INFO - 21/05/14 14:48:12 INFO TaskSetManager: Starting task 135.0 in stage 4.0 (TID 707) (f0b8ef7ba22f, executor driver, partition 135, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:48:12,668] {docker.py:276} INFO - 21/05/14 14:48:12 INFO Executor: Running task 135.0 in stage 4.0 (TID 707)
21/05/14 14:48:12 INFO TaskSetManager: Finished task 130.0 in stage 4.0 (TID 702) in 7176 ms on f0b8ef7ba22f (executor driver) (132/200)
[2021-05-14 11:48:12,678] {docker.py:276} INFO - 21/05/14 14:48:12 INFO ShuffleBlockFetcherIterator: Getting 9 (67.2 KiB) non-empty blocks including 9 (67.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:48:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:48:12,687] {docker.py:276} INFO - 21/05/14 14:48:12 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:48:12 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/05/14 14:48:12 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
21/05/14 14:48:12 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443466728842630406282122_0004_m_000135_707, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443466728842630406282122_0004_m_000135_707}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443466728842630406282122_0004}; taskId=attempt_202105141443466728842630406282122_0004_m_000135_707, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@409d3f1f}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
21/05/14 14:48:12 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
[2021-05-14 11:48:12,687] {docker.py:276} INFO - 21/05/14 14:48:12 INFO StagingCommitter: Starting: Task committer attempt_202105141443466728842630406282122_0004_m_000135_707: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443466728842630406282122_0004_m_000135_707
[2021-05-14 11:48:12,691] {docker.py:276} INFO - 21/05/14 14:48:12 INFO StagingCommitter: Task committer attempt_202105141443466728842630406282122_0004_m_000135_707: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443466728842630406282122_0004_m_000135_707 : duration 0:00.004s
[2021-05-14 11:48:13,988] {docker.py:276} INFO - 21/05/14 14:48:13 INFO StagingCommitter: Starting: Task committer attempt_202105141443461456604981365462266_0004_m_000132_704: needsTaskCommit() Task attempt_202105141443461456604981365462266_0004_m_000132_704
[2021-05-14 11:48:13,989] {docker.py:276} INFO - 21/05/14 14:48:13 INFO StagingCommitter: Task committer attempt_202105141443461456604981365462266_0004_m_000132_704: needsTaskCommit() Task attempt_202105141443461456604981365462266_0004_m_000132_704: duration 0:00.002s
21/05/14 14:48:13 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443461456604981365462266_0004_m_000132_704
[2021-05-14 11:48:13,990] {docker.py:276} INFO - 21/05/14 14:48:13 INFO Executor: Finished task 132.0 in stage 4.0 (TID 704). 5149 bytes result sent to driver
[2021-05-14 11:48:13,992] {docker.py:276} INFO - 21/05/14 14:48:13 INFO TaskSetManager: Starting task 136.0 in stage 4.0 (TID 708) (f0b8ef7ba22f, executor driver, partition 136, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
21/05/14 14:48:13 INFO Executor: Running task 136.0 in stage 4.0 (TID 708)
21/05/14 14:48:13 INFO TaskSetManager: Finished task 132.0 in stage 4.0 (TID 704) in 6830 ms on f0b8ef7ba22f (executor driver) (133/200)
[2021-05-14 11:48:14,003] {docker.py:276} INFO - 21/05/14 14:48:14 INFO ShuffleBlockFetcherIterator: Getting 9 (63.6 KiB) non-empty blocks including 9 (63.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:48:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:48:14,011] {docker.py:276} INFO - 21/05/14 14:48:14 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:48:14 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/05/14 14:48:14 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
21/05/14 14:48:14 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443468041824368205833519_0004_m_000136_708, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443468041824368205833519_0004_m_000136_708}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443468041824368205833519_0004}; taskId=attempt_202105141443468041824368205833519_0004_m_000136_708, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@1b3ea69b}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
21/05/14 14:48:14 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
21/05/14 14:48:14 INFO StagingCommitter: Starting: Task committer attempt_202105141443468041824368205833519_0004_m_000136_708: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443468041824368205833519_0004_m_000136_708
[2021-05-14 11:48:14,015] {docker.py:276} INFO - 21/05/14 14:48:14 INFO StagingCommitter: Task committer attempt_202105141443468041824368205833519_0004_m_000136_708: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443468041824368205833519_0004_m_000136_708 : duration 0:00.004s
[2021-05-14 11:48:16,486] {docker.py:276} INFO - 21/05/14 14:48:16 INFO StagingCommitter: Starting: Task committer attempt_202105141443466768209372372450029_0004_m_000133_705: needsTaskCommit() Task attempt_202105141443466768209372372450029_0004_m_000133_705
[2021-05-14 11:48:16,487] {docker.py:276} INFO - 21/05/14 14:48:16 INFO StagingCommitter: Task committer attempt_202105141443466768209372372450029_0004_m_000133_705: needsTaskCommit() Task attempt_202105141443466768209372372450029_0004_m_000133_705: duration 0:00.002s
21/05/14 14:48:16 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443466768209372372450029_0004_m_000133_705
[2021-05-14 11:48:16,489] {docker.py:276} INFO - 21/05/14 14:48:16 INFO Executor: Finished task 133.0 in stage 4.0 (TID 705). 5149 bytes result sent to driver
[2021-05-14 11:48:16,492] {docker.py:276} INFO - 21/05/14 14:48:16 INFO TaskSetManager: Starting task 137.0 in stage 4.0 (TID 709) (f0b8ef7ba22f, executor driver, partition 137, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:48:16,493] {docker.py:276} INFO - 21/05/14 14:48:16 INFO Executor: Running task 137.0 in stage 4.0 (TID 709)
[2021-05-14 11:48:16,494] {docker.py:276} INFO - 21/05/14 14:48:16 INFO TaskSetManager: Finished task 133.0 in stage 4.0 (TID 705) in 6860 ms on f0b8ef7ba22f (executor driver) (134/200)
[2021-05-14 11:48:16,502] {docker.py:276} INFO - 21/05/14 14:48:16 INFO ShuffleBlockFetcherIterator: Getting 9 (69.0 KiB) non-empty blocks including 9 (69.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
[2021-05-14 11:48:16,503] {docker.py:276} INFO - 21/05/14 14:48:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:48:16,511] {docker.py:276} INFO - 21/05/14 14:48:16 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:48:16 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2021-05-14 11:48:16,511] {docker.py:276} INFO - 21/05/14 14:48:16 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
[2021-05-14 11:48:16,512] {docker.py:276} INFO - 21/05/14 14:48:16 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443467172201368101688244_0004_m_000137_709, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443467172201368101688244_0004_m_000137_709}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443467172201368101688244_0004}; taskId=attempt_202105141443467172201368101688244_0004_m_000137_709, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@127cc74b}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
[2021-05-14 11:48:16,512] {docker.py:276} INFO - 21/05/14 14:48:16 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
[2021-05-14 11:48:16,512] {docker.py:276} INFO - 21/05/14 14:48:16 INFO StagingCommitter: Starting: Task committer attempt_202105141443467172201368101688244_0004_m_000137_709: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443467172201368101688244_0004_m_000137_709
[2021-05-14 11:48:16,517] {docker.py:276} INFO - 21/05/14 14:48:16 INFO StagingCommitter: Task committer attempt_202105141443467172201368101688244_0004_m_000137_709: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443467172201368101688244_0004_m_000137_709 : duration 0:00.005s
[2021-05-14 11:48:19,410] {docker.py:276} INFO - 21/05/14 14:48:19 INFO StagingCommitter: Starting: Task committer attempt_202105141443464753073800386220401_0004_m_000134_706: needsTaskCommit() Task attempt_202105141443464753073800386220401_0004_m_000134_706
[2021-05-14 11:48:19,410] {docker.py:276} INFO - 21/05/14 14:48:19 INFO StagingCommitter: Task committer attempt_202105141443464753073800386220401_0004_m_000134_706: needsTaskCommit() Task attempt_202105141443464753073800386220401_0004_m_000134_706: duration 0:00.003s
21/05/14 14:48:19 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443464753073800386220401_0004_m_000134_706
[2021-05-14 11:48:19,411] {docker.py:276} INFO - 21/05/14 14:48:19 INFO Executor: Finished task 134.0 in stage 4.0 (TID 706). 5106 bytes result sent to driver
[2021-05-14 11:48:19,412] {docker.py:276} INFO - 21/05/14 14:48:19 INFO TaskSetManager: Starting task 138.0 in stage 4.0 (TID 710) (f0b8ef7ba22f, executor driver, partition 138, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:48:19,413] {docker.py:276} INFO - 21/05/14 14:48:19 INFO Executor: Running task 138.0 in stage 4.0 (TID 710)
[2021-05-14 11:48:19,414] {docker.py:276} INFO - 21/05/14 14:48:19 INFO TaskSetManager: Finished task 134.0 in stage 4.0 (TID 706) in 6908 ms on f0b8ef7ba22f (executor driver) (135/200)
[2021-05-14 11:48:19,424] {docker.py:276} INFO - 21/05/14 14:48:19 INFO ShuffleBlockFetcherIterator: Getting 9 (70.1 KiB) non-empty blocks including 9 (70.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:48:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:48:19,434] {docker.py:276} INFO - 21/05/14 14:48:19 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:48:19 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/05/14 14:48:19 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
21/05/14 14:48:19 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_20210514144346579320965098963007_0004_m_000138_710, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_20210514144346579320965098963007_0004_m_000138_710}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_20210514144346579320965098963007_0004}; taskId=attempt_20210514144346579320965098963007_0004_m_000138_710, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@41be35fe}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
[2021-05-14 11:48:19,435] {docker.py:276} INFO - 21/05/14 14:48:19 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
21/05/14 14:48:19 INFO StagingCommitter: Starting: Task committer attempt_20210514144346579320965098963007_0004_m_000138_710: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_20210514144346579320965098963007_0004_m_000138_710
[2021-05-14 11:48:19,438] {docker.py:276} INFO - 21/05/14 14:48:19 INFO StagingCommitter: Task committer attempt_20210514144346579320965098963007_0004_m_000138_710: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_20210514144346579320965098963007_0004_m_000138_710 : duration 0:00.004s
[2021-05-14 11:48:19,919] {docker.py:276} INFO - 21/05/14 14:48:19 INFO StagingCommitter: Starting: Task committer attempt_202105141443466728842630406282122_0004_m_000135_707: needsTaskCommit() Task attempt_202105141443466728842630406282122_0004_m_000135_707
21/05/14 14:48:19 INFO StagingCommitter: Task committer attempt_202105141443466728842630406282122_0004_m_000135_707: needsTaskCommit() Task attempt_202105141443466728842630406282122_0004_m_000135_707: duration 0:00.002s
21/05/14 14:48:19 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443466728842630406282122_0004_m_000135_707
[2021-05-14 11:48:19,920] {docker.py:276} INFO - 21/05/14 14:48:19 INFO Executor: Finished task 135.0 in stage 4.0 (TID 707). 5106 bytes result sent to driver
[2021-05-14 11:48:19,920] {docker.py:276} INFO - 21/05/14 14:48:19 INFO TaskSetManager: Starting task 139.0 in stage 4.0 (TID 711) (f0b8ef7ba22f, executor driver, partition 139, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:48:19,921] {docker.py:276} INFO - 21/05/14 14:48:19 INFO Executor: Running task 139.0 in stage 4.0 (TID 711)
[2021-05-14 11:48:19,922] {docker.py:276} INFO - 21/05/14 14:48:19 INFO TaskSetManager: Finished task 135.0 in stage 4.0 (TID 707) in 7264 ms on f0b8ef7ba22f (executor driver) (136/200)
[2021-05-14 11:48:19,929] {docker.py:276} INFO - 21/05/14 14:48:19 INFO ShuffleBlockFetcherIterator: Getting 9 (65.0 KiB) non-empty blocks including 9 (65.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
[2021-05-14 11:48:19,930] {docker.py:276} INFO - 21/05/14 14:48:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:48:19,940] {docker.py:276} INFO - 21/05/14 14:48:19 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:48:19 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/05/14 14:48:19 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
[2021-05-14 11:48:19,940] {docker.py:276} INFO - 21/05/14 14:48:19 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443461625160946401093649_0004_m_000139_711, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443461625160946401093649_0004_m_000139_711}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443461625160946401093649_0004}; taskId=attempt_202105141443461625160946401093649_0004_m_000139_711, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@eddebe4}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
21/05/14 14:48:19 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
21/05/14 14:48:19 INFO StagingCommitter: Starting: Task committer attempt_202105141443461625160946401093649_0004_m_000139_711: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443461625160946401093649_0004_m_000139_711
[2021-05-14 11:48:19,944] {docker.py:276} INFO - 21/05/14 14:48:19 INFO StagingCommitter: Task committer attempt_202105141443461625160946401093649_0004_m_000139_711: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443461625160946401093649_0004_m_000139_711 : duration 0:00.004s
[2021-05-14 11:48:20,807] {docker.py:276} INFO - 21/05/14 14:48:20 INFO StagingCommitter: Starting: Task committer attempt_202105141443468041824368205833519_0004_m_000136_708: needsTaskCommit() Task attempt_202105141443468041824368205833519_0004_m_000136_708
[2021-05-14 11:48:20,809] {docker.py:276} INFO - 21/05/14 14:48:20 INFO StagingCommitter: Task committer attempt_202105141443468041824368205833519_0004_m_000136_708: needsTaskCommit() Task attempt_202105141443468041824368205833519_0004_m_000136_708: duration 0:00.002s
21/05/14 14:48:20 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443468041824368205833519_0004_m_000136_708
[2021-05-14 11:48:20,810] {docker.py:276} INFO - 21/05/14 14:48:20 INFO Executor: Finished task 136.0 in stage 4.0 (TID 708). 5106 bytes result sent to driver
21/05/14 14:48:20 INFO TaskSetManager: Starting task 140.0 in stage 4.0 (TID 712) (f0b8ef7ba22f, executor driver, partition 140, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:48:20,812] {docker.py:276} INFO - 21/05/14 14:48:20 INFO Executor: Running task 140.0 in stage 4.0 (TID 712)
[2021-05-14 11:48:20,813] {docker.py:276} INFO - 21/05/14 14:48:20 INFO TaskSetManager: Finished task 136.0 in stage 4.0 (TID 708) in 6829 ms on f0b8ef7ba22f (executor driver) (137/200)
[2021-05-14 11:48:20,822] {docker.py:276} INFO - 21/05/14 14:48:20 INFO ShuffleBlockFetcherIterator: Getting 9 (63.1 KiB) non-empty blocks including 9 (63.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:48:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:48:20,830] {docker.py:276} INFO - 21/05/14 14:48:20 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:48:20 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/05/14 14:48:20 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
21/05/14 14:48:20 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443468282122297504740268_0004_m_000140_712, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443468282122297504740268_0004_m_000140_712}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443468282122297504740268_0004}; taskId=attempt_202105141443468282122297504740268_0004_m_000140_712, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@2b122b6f}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
[2021-05-14 11:48:20,831] {docker.py:276} INFO - 21/05/14 14:48:20 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
21/05/14 14:48:20 INFO StagingCommitter: Starting: Task committer attempt_202105141443468282122297504740268_0004_m_000140_712: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443468282122297504740268_0004_m_000140_712
[2021-05-14 11:48:20,834] {docker.py:276} INFO - 21/05/14 14:48:20 INFO StagingCommitter: Task committer attempt_202105141443468282122297504740268_0004_m_000140_712: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443468282122297504740268_0004_m_000140_712 : duration 0:00.004s
[2021-05-14 11:48:22,599] {docker.py:276} INFO - 21/05/14 14:48:22 INFO StagingCommitter: Starting: Task committer attempt_202105141443467172201368101688244_0004_m_000137_709: needsTaskCommit() Task attempt_202105141443467172201368101688244_0004_m_000137_709
[2021-05-14 11:48:22,600] {docker.py:276} INFO - 21/05/14 14:48:22 INFO StagingCommitter: Task committer attempt_202105141443467172201368101688244_0004_m_000137_709: needsTaskCommit() Task attempt_202105141443467172201368101688244_0004_m_000137_709: duration 0:00.003s
21/05/14 14:48:22 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443467172201368101688244_0004_m_000137_709
[2021-05-14 11:48:22,602] {docker.py:276} INFO - 21/05/14 14:48:22 INFO Executor: Finished task 137.0 in stage 4.0 (TID 709). 5106 bytes result sent to driver
[2021-05-14 11:48:22,603] {docker.py:276} INFO - 21/05/14 14:48:22 INFO TaskSetManager: Starting task 141.0 in stage 4.0 (TID 713) (f0b8ef7ba22f, executor driver, partition 141, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:48:22,604] {docker.py:276} INFO - 21/05/14 14:48:22 INFO TaskSetManager: Finished task 137.0 in stage 4.0 (TID 709) in 6121 ms on f0b8ef7ba22f (executor driver) (138/200)
[2021-05-14 11:48:22,605] {docker.py:276} INFO - 21/05/14 14:48:22 INFO Executor: Running task 141.0 in stage 4.0 (TID 713)
[2021-05-14 11:48:22,613] {docker.py:276} INFO - 21/05/14 14:48:22 INFO ShuffleBlockFetcherIterator: Getting 9 (63.0 KiB) non-empty blocks including 9 (63.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
[2021-05-14 11:48:22,614] {docker.py:276} INFO - 21/05/14 14:48:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:48:22,622] {docker.py:276} INFO - 21/05/14 14:48:22 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2021-05-14 11:48:22,623] {docker.py:276} INFO - 21/05/14 14:48:22 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2021-05-14 11:48:22,623] {docker.py:276} INFO - 21/05/14 14:48:22 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
[2021-05-14 11:48:22,624] {docker.py:276} INFO - 21/05/14 14:48:22 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443466362892040708691702_0004_m_000141_713, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443466362892040708691702_0004_m_000141_713}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443466362892040708691702_0004}; taskId=attempt_202105141443466362892040708691702_0004_m_000141_713, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@113f8c0b}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
[2021-05-14 11:48:22,624] {docker.py:276} INFO - 21/05/14 14:48:22 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
[2021-05-14 11:48:22,624] {docker.py:276} INFO - 21/05/14 14:48:22 INFO StagingCommitter: Starting: Task committer attempt_202105141443466362892040708691702_0004_m_000141_713: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443466362892040708691702_0004_m_000141_713
[2021-05-14 11:48:22,628] {docker.py:276} INFO - 21/05/14 14:48:22 INFO StagingCommitter: Task committer attempt_202105141443466362892040708691702_0004_m_000141_713: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443466362892040708691702_0004_m_000141_713 : duration 0:00.005s
[2021-05-14 11:48:26,688] {docker.py:276} INFO - 21/05/14 14:48:26 INFO StagingCommitter: Starting: Task committer attempt_20210514144346579320965098963007_0004_m_000138_710: needsTaskCommit() Task attempt_20210514144346579320965098963007_0004_m_000138_710
[2021-05-14 11:48:26,689] {docker.py:276} INFO - 21/05/14 14:48:26 INFO StagingCommitter: Task committer attempt_20210514144346579320965098963007_0004_m_000138_710: needsTaskCommit() Task attempt_20210514144346579320965098963007_0004_m_000138_710: duration 0:00.003s
21/05/14 14:48:26 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_20210514144346579320965098963007_0004_m_000138_710
[2021-05-14 11:48:26,691] {docker.py:276} INFO - 21/05/14 14:48:26 INFO Executor: Finished task 138.0 in stage 4.0 (TID 710). 5106 bytes result sent to driver
[2021-05-14 11:48:26,692] {docker.py:276} INFO - 21/05/14 14:48:26 INFO TaskSetManager: Starting task 142.0 in stage 4.0 (TID 714) (f0b8ef7ba22f, executor driver, partition 142, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:48:26,694] {docker.py:276} INFO - 21/05/14 14:48:26 INFO Executor: Running task 142.0 in stage 4.0 (TID 714)
[2021-05-14 11:48:26,694] {docker.py:276} INFO - 21/05/14 14:48:26 INFO TaskSetManager: Finished task 138.0 in stage 4.0 (TID 710) in 7290 ms on f0b8ef7ba22f (executor driver) (139/200)
[2021-05-14 11:48:26,703] {docker.py:276} INFO - 21/05/14 14:48:26 INFO ShuffleBlockFetcherIterator: Getting 9 (68.3 KiB) non-empty blocks including 9 (68.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:48:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:48:26,712] {docker.py:276} INFO - 21/05/14 14:48:26 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:48:26 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/05/14 14:48:26 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
21/05/14 14:48:26 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443464720980034522255236_0004_m_000142_714, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443464720980034522255236_0004_m_000142_714}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443464720980034522255236_0004}; taskId=attempt_202105141443464720980034522255236_0004_m_000142_714, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@554c604e}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
21/05/14 14:48:26 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
21/05/14 14:48:26 INFO StagingCommitter: Starting: Task committer attempt_202105141443464720980034522255236_0004_m_000142_714: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443464720980034522255236_0004_m_000142_714
[2021-05-14 11:48:26,716] {docker.py:276} INFO - 21/05/14 14:48:26 INFO StagingCommitter: Task committer attempt_202105141443464720980034522255236_0004_m_000142_714: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443464720980034522255236_0004_m_000142_714 : duration 0:00.004s
[2021-05-14 11:48:26,877] {docker.py:276} INFO - 21/05/14 14:48:26 INFO StagingCommitter: Starting: Task committer attempt_202105141443461625160946401093649_0004_m_000139_711: needsTaskCommit() Task attempt_202105141443461625160946401093649_0004_m_000139_711
21/05/14 14:48:26 INFO StagingCommitter: Task committer attempt_202105141443461625160946401093649_0004_m_000139_711: needsTaskCommit() Task attempt_202105141443461625160946401093649_0004_m_000139_711: duration 0:00.001s
21/05/14 14:48:26 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443461625160946401093649_0004_m_000139_711
[2021-05-14 11:48:26,880] {docker.py:276} INFO - 21/05/14 14:48:26 INFO Executor: Finished task 139.0 in stage 4.0 (TID 711). 5106 bytes result sent to driver
[2021-05-14 11:48:26,882] {docker.py:276} INFO - 21/05/14 14:48:26 INFO TaskSetManager: Starting task 143.0 in stage 4.0 (TID 715) (f0b8ef7ba22f, executor driver, partition 143, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:48:26,883] {docker.py:276} INFO - 21/05/14 14:48:26 INFO TaskSetManager: Finished task 139.0 in stage 4.0 (TID 711) in 6970 ms on f0b8ef7ba22f (executor driver) (140/200)
[2021-05-14 11:48:26,884] {docker.py:276} INFO - 21/05/14 14:48:26 INFO Executor: Running task 143.0 in stage 4.0 (TID 715)
[2021-05-14 11:48:26,894] {docker.py:276} INFO - 21/05/14 14:48:26 INFO ShuffleBlockFetcherIterator: Getting 9 (65.6 KiB) non-empty blocks including 9 (65.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:48:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:48:26,902] {docker.py:276} INFO - 21/05/14 14:48:26 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:48:26 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/05/14 14:48:26 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
21/05/14 14:48:26 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443466978821816054463480_0004_m_000143_715, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443466978821816054463480_0004_m_000143_715}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443466978821816054463480_0004}; taskId=attempt_202105141443466978821816054463480_0004_m_000143_715, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@298083ea}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
[2021-05-14 11:48:26,903] {docker.py:276} INFO - 21/05/14 14:48:26 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
21/05/14 14:48:26 INFO StagingCommitter: Starting: Task committer attempt_202105141443466978821816054463480_0004_m_000143_715: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443466978821816054463480_0004_m_000143_715
[2021-05-14 11:48:26,907] {docker.py:276} INFO - 21/05/14 14:48:26 INFO StagingCommitter: Task committer attempt_202105141443466978821816054463480_0004_m_000143_715: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443466978821816054463480_0004_m_000143_715 : duration 0:00.004s
[2021-05-14 11:48:27,747] {docker.py:276} INFO - 21/05/14 14:48:27 INFO StagingCommitter: Starting: Task committer attempt_202105141443468282122297504740268_0004_m_000140_712: needsTaskCommit() Task attempt_202105141443468282122297504740268_0004_m_000140_712
21/05/14 14:48:27 INFO StagingCommitter: Task committer attempt_202105141443468282122297504740268_0004_m_000140_712: needsTaskCommit() Task attempt_202105141443468282122297504740268_0004_m_000140_712: duration 0:00.001s
21/05/14 14:48:27 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443468282122297504740268_0004_m_000140_712
[2021-05-14 11:48:27,748] {docker.py:276} INFO - 21/05/14 14:48:27 INFO Executor: Finished task 140.0 in stage 4.0 (TID 712). 5106 bytes result sent to driver
[2021-05-14 11:48:27,750] {docker.py:276} INFO - 21/05/14 14:48:27 INFO TaskSetManager: Starting task 144.0 in stage 4.0 (TID 716) (f0b8ef7ba22f, executor driver, partition 144, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
21/05/14 14:48:27 INFO TaskSetManager: Finished task 140.0 in stage 4.0 (TID 712) in 6948 ms on f0b8ef7ba22f (executor driver) (141/200)
[2021-05-14 11:48:27,751] {docker.py:276} INFO - 21/05/14 14:48:27 INFO Executor: Running task 144.0 in stage 4.0 (TID 716)
[2021-05-14 11:48:27,760] {docker.py:276} INFO - 21/05/14 14:48:27 INFO ShuffleBlockFetcherIterator: Getting 9 (66.8 KiB) non-empty blocks including 9 (66.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:48:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:48:27,768] {docker.py:276} INFO - 21/05/14 14:48:27 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:48:27 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/05/14 14:48:27 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
21/05/14 14:48:27 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_20210514144346205809223510483723_0004_m_000144_716, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_20210514144346205809223510483723_0004_m_000144_716}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_20210514144346205809223510483723_0004}; taskId=attempt_20210514144346205809223510483723_0004_m_000144_716, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@b04f20b}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
21/05/14 14:48:27 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
[2021-05-14 11:48:27,768] {docker.py:276} INFO - 21/05/14 14:48:27 INFO StagingCommitter: Starting: Task committer attempt_20210514144346205809223510483723_0004_m_000144_716: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_20210514144346205809223510483723_0004_m_000144_716
[2021-05-14 11:48:27,772] {docker.py:276} INFO - 21/05/14 14:48:27 INFO StagingCommitter: Task committer attempt_20210514144346205809223510483723_0004_m_000144_716: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_20210514144346205809223510483723_0004_m_000144_716 : duration 0:00.004s
[2021-05-14 11:48:29,623] {docker.py:276} INFO - 21/05/14 14:48:29 INFO StagingCommitter: Starting: Task committer attempt_202105141443466362892040708691702_0004_m_000141_713: needsTaskCommit() Task attempt_202105141443466362892040708691702_0004_m_000141_713
[2021-05-14 11:48:29,624] {docker.py:276} INFO - 21/05/14 14:48:29 INFO StagingCommitter: Task committer attempt_202105141443466362892040708691702_0004_m_000141_713: needsTaskCommit() Task attempt_202105141443466362892040708691702_0004_m_000141_713: duration 0:00.002s
[2021-05-14 11:48:29,625] {docker.py:276} INFO - 21/05/14 14:48:29 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443466362892040708691702_0004_m_000141_713
[2021-05-14 11:48:29,625] {docker.py:276} INFO - 21/05/14 14:48:29 INFO Executor: Finished task 141.0 in stage 4.0 (TID 713). 5106 bytes result sent to driver
[2021-05-14 11:48:29,626] {docker.py:276} INFO - 21/05/14 14:48:29 INFO TaskSetManager: Starting task 145.0 in stage 4.0 (TID 717) (f0b8ef7ba22f, executor driver, partition 145, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:48:29,627] {docker.py:276} INFO - 21/05/14 14:48:29 INFO Executor: Running task 145.0 in stage 4.0 (TID 717)
[2021-05-14 11:48:29,628] {docker.py:276} INFO - 21/05/14 14:48:29 INFO TaskSetManager: Finished task 141.0 in stage 4.0 (TID 713) in 7034 ms on f0b8ef7ba22f (executor driver) (142/200)
[2021-05-14 11:48:29,636] {docker.py:276} INFO - 21/05/14 14:48:29 INFO ShuffleBlockFetcherIterator: Getting 9 (67.2 KiB) non-empty blocks including 9 (67.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:48:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:48:29,644] {docker.py:276} INFO - 21/05/14 14:48:29 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:48:29 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/05/14 14:48:29 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
21/05/14 14:48:29 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443466609347483202783011_0004_m_000145_717, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443466609347483202783011_0004_m_000145_717}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443466609347483202783011_0004}; taskId=attempt_202105141443466609347483202783011_0004_m_000145_717, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@60ec0a0f}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
[2021-05-14 11:48:29,644] {docker.py:276} INFO - 21/05/14 14:48:29 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
21/05/14 14:48:29 INFO StagingCommitter: Starting: Task committer attempt_202105141443466609347483202783011_0004_m_000145_717: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443466609347483202783011_0004_m_000145_717
[2021-05-14 11:48:29,648] {docker.py:276} INFO - 21/05/14 14:48:29 INFO StagingCommitter: Task committer attempt_202105141443466609347483202783011_0004_m_000145_717: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443466609347483202783011_0004_m_000145_717 : duration 0:00.003s
[2021-05-14 11:48:33,744] {docker.py:276} INFO - 21/05/14 14:48:33 INFO StagingCommitter: Starting: Task committer attempt_202105141443464720980034522255236_0004_m_000142_714: needsTaskCommit() Task attempt_202105141443464720980034522255236_0004_m_000142_714
[2021-05-14 11:48:33,745] {docker.py:276} INFO - 21/05/14 14:48:33 INFO StagingCommitter: Task committer attempt_202105141443464720980034522255236_0004_m_000142_714: needsTaskCommit() Task attempt_202105141443464720980034522255236_0004_m_000142_714: duration 0:00.002s
21/05/14 14:48:33 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443464720980034522255236_0004_m_000142_714
[2021-05-14 11:48:33,747] {docker.py:276} INFO - 21/05/14 14:48:33 INFO Executor: Finished task 142.0 in stage 4.0 (TID 714). 5106 bytes result sent to driver
[2021-05-14 11:48:33,748] {docker.py:276} INFO - 21/05/14 14:48:33 INFO TaskSetManager: Starting task 146.0 in stage 4.0 (TID 718) (f0b8ef7ba22f, executor driver, partition 146, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:48:33,749] {docker.py:276} INFO - 21/05/14 14:48:33 INFO Executor: Running task 146.0 in stage 4.0 (TID 718)
21/05/14 14:48:33 INFO TaskSetManager: Finished task 142.0 in stage 4.0 (TID 714) in 7065 ms on f0b8ef7ba22f (executor driver) (143/200)
[2021-05-14 11:48:33,759] {docker.py:276} INFO - 21/05/14 14:48:33 INFO ShuffleBlockFetcherIterator: Getting 9 (68.6 KiB) non-empty blocks including 9 (68.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:48:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:48:33,769] {docker.py:276} INFO - 21/05/14 14:48:33 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2021-05-14 11:48:33,769] {docker.py:276} INFO - 21/05/14 14:48:33 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2021-05-14 11:48:33,770] {docker.py:276} INFO - 21/05/14 14:48:33 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
[2021-05-14 11:48:33,770] {docker.py:276} INFO - 21/05/14 14:48:33 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443464425734199237749245_0004_m_000146_718, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443464425734199237749245_0004_m_000146_718}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443464425734199237749245_0004}; taskId=attempt_202105141443464425734199237749245_0004_m_000146_718, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@62b4511c}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
[2021-05-14 11:48:33,770] {docker.py:276} INFO - 21/05/14 14:48:33 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
[2021-05-14 11:48:33,770] {docker.py:276} INFO - 21/05/14 14:48:33 INFO StagingCommitter: Starting: Task committer attempt_202105141443464425734199237749245_0004_m_000146_718: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443464425734199237749245_0004_m_000146_718
[2021-05-14 11:48:33,773] {docker.py:276} INFO - 21/05/14 14:48:33 INFO StagingCommitter: Task committer attempt_202105141443464425734199237749245_0004_m_000146_718: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443464425734199237749245_0004_m_000146_718 : duration 0:00.004s
[2021-05-14 11:48:33,783] {docker.py:276} INFO - 21/05/14 14:48:33 INFO StagingCommitter: Starting: Task committer attempt_202105141443466978821816054463480_0004_m_000143_715: needsTaskCommit() Task attempt_202105141443466978821816054463480_0004_m_000143_715
[2021-05-14 11:48:33,784] {docker.py:276} INFO - 21/05/14 14:48:33 INFO StagingCommitter: Task committer attempt_202105141443466978821816054463480_0004_m_000143_715: needsTaskCommit() Task attempt_202105141443466978821816054463480_0004_m_000143_715: duration 0:00.001s
[2021-05-14 11:48:33,784] {docker.py:276} INFO - 21/05/14 14:48:33 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443466978821816054463480_0004_m_000143_715
[2021-05-14 11:48:33,785] {docker.py:276} INFO - 21/05/14 14:48:33 INFO Executor: Finished task 143.0 in stage 4.0 (TID 715). 5106 bytes result sent to driver
[2021-05-14 11:48:33,785] {docker.py:276} INFO - 21/05/14 14:48:33 INFO TaskSetManager: Starting task 147.0 in stage 4.0 (TID 719) (f0b8ef7ba22f, executor driver, partition 147, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:48:33,787] {docker.py:276} INFO - 21/05/14 14:48:33 INFO TaskSetManager: Finished task 143.0 in stage 4.0 (TID 715) in 6914 ms on f0b8ef7ba22f (executor driver) (144/200)
21/05/14 14:48:33 INFO Executor: Running task 147.0 in stage 4.0 (TID 719)
[2021-05-14 11:48:33,794] {docker.py:276} INFO - 21/05/14 14:48:33 INFO ShuffleBlockFetcherIterator: Getting 9 (67.6 KiB) non-empty blocks including 9 (67.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:48:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:48:33,802] {docker.py:276} INFO - 21/05/14 14:48:33 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:48:33 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/05/14 14:48:33 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
21/05/14 14:48:33 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443464373328845715213396_0004_m_000147_719, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443464373328845715213396_0004_m_000147_719}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443464373328845715213396_0004}; taskId=attempt_202105141443464373328845715213396_0004_m_000147_719, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@499e0f2d}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
21/05/14 14:48:33 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
[2021-05-14 11:48:33,802] {docker.py:276} INFO - 21/05/14 14:48:33 INFO StagingCommitter: Starting: Task committer attempt_202105141443464373328845715213396_0004_m_000147_719: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443464373328845715213396_0004_m_000147_719
[2021-05-14 11:48:33,819] {docker.py:276} INFO - 21/05/14 14:48:33 INFO StagingCommitter: Task committer attempt_202105141443464373328845715213396_0004_m_000147_719: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443464373328845715213396_0004_m_000147_719 : duration 0:00.018s
[2021-05-14 11:48:34,683] {docker.py:276} INFO - 21/05/14 14:48:34 INFO StagingCommitter: Starting: Task committer attempt_20210514144346205809223510483723_0004_m_000144_716: needsTaskCommit() Task attempt_20210514144346205809223510483723_0004_m_000144_716
[2021-05-14 11:48:34,684] {docker.py:276} INFO - 21/05/14 14:48:34 INFO StagingCommitter: Task committer attempt_20210514144346205809223510483723_0004_m_000144_716: needsTaskCommit() Task attempt_20210514144346205809223510483723_0004_m_000144_716: duration 0:00.003s
[2021-05-14 11:48:34,685] {docker.py:276} INFO - 21/05/14 14:48:34 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_20210514144346205809223510483723_0004_m_000144_716
[2021-05-14 11:48:34,687] {docker.py:276} INFO - 21/05/14 14:48:34 INFO Executor: Finished task 144.0 in stage 4.0 (TID 716). 5149 bytes result sent to driver
[2021-05-14 11:48:34,689] {docker.py:276} INFO - 21/05/14 14:48:34 INFO TaskSetManager: Starting task 148.0 in stage 4.0 (TID 720) (f0b8ef7ba22f, executor driver, partition 148, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:48:34,690] {docker.py:276} INFO - 21/05/14 14:48:34 INFO TaskSetManager: Finished task 144.0 in stage 4.0 (TID 716) in 6949 ms on f0b8ef7ba22f (executor driver) (145/200)
[2021-05-14 11:48:34,690] {docker.py:276} INFO - 21/05/14 14:48:34 INFO Executor: Running task 148.0 in stage 4.0 (TID 720)
[2021-05-14 11:48:34,700] {docker.py:276} INFO - 21/05/14 14:48:34 INFO ShuffleBlockFetcherIterator: Getting 9 (64.0 KiB) non-empty blocks including 9 (64.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:48:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:48:34,708] {docker.py:276} INFO - 21/05/14 14:48:34 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:48:34 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/05/14 14:48:34 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
21/05/14 14:48:34 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443469185007900597266784_0004_m_000148_720, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443469185007900597266784_0004_m_000148_720}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443469185007900597266784_0004}; taskId=attempt_202105141443469185007900597266784_0004_m_000148_720, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@48ee15cb}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
[2021-05-14 11:48:34,708] {docker.py:276} INFO - 21/05/14 14:48:34 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
21/05/14 14:48:34 INFO StagingCommitter: Starting: Task committer attempt_202105141443469185007900597266784_0004_m_000148_720: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443469185007900597266784_0004_m_000148_720
[2021-05-14 11:48:34,712] {docker.py:276} INFO - 21/05/14 14:48:34 INFO StagingCommitter: Task committer attempt_202105141443469185007900597266784_0004_m_000148_720: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443469185007900597266784_0004_m_000148_720 : duration 0:00.005s
[2021-05-14 11:48:36,396] {docker.py:276} INFO - 21/05/14 14:48:36 INFO StagingCommitter: Starting: Task committer attempt_202105141443466609347483202783011_0004_m_000145_717: needsTaskCommit() Task attempt_202105141443466609347483202783011_0004_m_000145_717
[2021-05-14 11:48:36,398] {docker.py:276} INFO - 21/05/14 14:48:36 INFO StagingCommitter: Task committer attempt_202105141443466609347483202783011_0004_m_000145_717: needsTaskCommit() Task attempt_202105141443466609347483202783011_0004_m_000145_717: duration 0:00.003s
21/05/14 14:48:36 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443466609347483202783011_0004_m_000145_717
[2021-05-14 11:48:36,400] {docker.py:276} INFO - 21/05/14 14:48:36 INFO Executor: Finished task 145.0 in stage 4.0 (TID 717). 5149 bytes result sent to driver
[2021-05-14 11:48:36,401] {docker.py:276} INFO - 21/05/14 14:48:36 INFO TaskSetManager: Starting task 149.0 in stage 4.0 (TID 721) (f0b8ef7ba22f, executor driver, partition 149, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:48:36,403] {docker.py:276} INFO - 21/05/14 14:48:36 INFO Executor: Running task 149.0 in stage 4.0 (TID 721)
[2021-05-14 11:48:36,403] {docker.py:276} INFO - 21/05/14 14:48:36 INFO TaskSetManager: Finished task 145.0 in stage 4.0 (TID 717) in 6784 ms on f0b8ef7ba22f (executor driver) (146/200)
[2021-05-14 11:48:36,414] {docker.py:276} INFO - 21/05/14 14:48:36 INFO ShuffleBlockFetcherIterator: Getting 9 (66.6 KiB) non-empty blocks including 9 (66.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:48:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:48:36,422] {docker.py:276} INFO - 21/05/14 14:48:36 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:48:36 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/05/14 14:48:36 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
21/05/14 14:48:36 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_20210514144346770822905042088357_0004_m_000149_721, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_20210514144346770822905042088357_0004_m_000149_721}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_20210514144346770822905042088357_0004}; taskId=attempt_20210514144346770822905042088357_0004_m_000149_721, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@bf71ec0}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
21/05/14 14:48:36 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
21/05/14 14:48:36 INFO StagingCommitter: Starting: Task committer attempt_20210514144346770822905042088357_0004_m_000149_721: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_20210514144346770822905042088357_0004_m_000149_721
[2021-05-14 11:48:36,427] {docker.py:276} INFO - 21/05/14 14:48:36 INFO StagingCommitter: Task committer attempt_20210514144346770822905042088357_0004_m_000149_721: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_20210514144346770822905042088357_0004_m_000149_721 : duration 0:00.005s
[2021-05-14 11:48:40,492] {docker.py:276} INFO - 21/05/14 14:48:40 INFO StagingCommitter: Starting: Task committer attempt_202105141443464425734199237749245_0004_m_000146_718: needsTaskCommit() Task attempt_202105141443464425734199237749245_0004_m_000146_718
[2021-05-14 11:48:40,493] {docker.py:276} INFO - 21/05/14 14:48:40 INFO StagingCommitter: Task committer attempt_202105141443464425734199237749245_0004_m_000146_718: needsTaskCommit() Task attempt_202105141443464425734199237749245_0004_m_000146_718: duration 0:00.002s
21/05/14 14:48:40 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443464425734199237749245_0004_m_000146_718
[2021-05-14 11:48:40,495] {docker.py:276} INFO - 21/05/14 14:48:40 INFO Executor: Finished task 146.0 in stage 4.0 (TID 718). 5149 bytes result sent to driver
[2021-05-14 11:48:40,496] {docker.py:276} INFO - 21/05/14 14:48:40 INFO TaskSetManager: Starting task 150.0 in stage 4.0 (TID 722) (f0b8ef7ba22f, executor driver, partition 150, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:48:40,496] {docker.py:276} INFO - 21/05/14 14:48:40 INFO Executor: Running task 150.0 in stage 4.0 (TID 722)
[2021-05-14 11:48:40,497] {docker.py:276} INFO - 21/05/14 14:48:40 INFO TaskSetManager: Finished task 146.0 in stage 4.0 (TID 718) in 6723 ms on f0b8ef7ba22f (executor driver) (147/200)
[2021-05-14 11:48:40,507] {docker.py:276} INFO - 21/05/14 14:48:40 INFO ShuffleBlockFetcherIterator: Getting 9 (66.4 KiB) non-empty blocks including 9 (66.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:48:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:48:40,515] {docker.py:276} INFO - 21/05/14 14:48:40 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:48:40 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/05/14 14:48:40 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
[2021-05-14 11:48:40,516] {docker.py:276} INFO - 21/05/14 14:48:40 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443465533088288784736698_0004_m_000150_722, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443465533088288784736698_0004_m_000150_722}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443465533088288784736698_0004}; taskId=attempt_202105141443465533088288784736698_0004_m_000150_722, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@6a3d81c1}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
21/05/14 14:48:40 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
[2021-05-14 11:48:40,516] {docker.py:276} INFO - 21/05/14 14:48:40 INFO StagingCommitter: Starting: Task committer attempt_202105141443465533088288784736698_0004_m_000150_722: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443465533088288784736698_0004_m_000150_722
[2021-05-14 11:48:40,521] {docker.py:276} INFO - 21/05/14 14:48:40 INFO StagingCommitter: Task committer attempt_202105141443465533088288784736698_0004_m_000150_722: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443465533088288784736698_0004_m_000150_722 : duration 0:00.005s
[2021-05-14 11:48:40,847] {docker.py:276} INFO - 21/05/14 14:48:40 INFO StagingCommitter: Starting: Task committer attempt_202105141443464373328845715213396_0004_m_000147_719: needsTaskCommit() Task attempt_202105141443464373328845715213396_0004_m_000147_719
[2021-05-14 11:48:40,848] {docker.py:276} INFO - 21/05/14 14:48:40 INFO StagingCommitter: Task committer attempt_202105141443464373328845715213396_0004_m_000147_719: needsTaskCommit() Task attempt_202105141443464373328845715213396_0004_m_000147_719: duration 0:00.001s
[2021-05-14 11:48:40,848] {docker.py:276} INFO - 21/05/14 14:48:40 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443464373328845715213396_0004_m_000147_719
[2021-05-14 11:48:40,849] {docker.py:276} INFO - 21/05/14 14:48:40 INFO Executor: Finished task 147.0 in stage 4.0 (TID 719). 5149 bytes result sent to driver
[2021-05-14 11:48:40,851] {docker.py:276} INFO - 21/05/14 14:48:40 INFO TaskSetManager: Starting task 151.0 in stage 4.0 (TID 723) (f0b8ef7ba22f, executor driver, partition 151, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:48:40,852] {docker.py:276} INFO - 21/05/14 14:48:40 INFO Executor: Running task 151.0 in stage 4.0 (TID 723)
[2021-05-14 11:48:40,852] {docker.py:276} INFO - 21/05/14 14:48:40 INFO TaskSetManager: Finished task 147.0 in stage 4.0 (TID 719) in 7040 ms on f0b8ef7ba22f (executor driver) (148/200)
[2021-05-14 11:48:40,860] {docker.py:276} INFO - 21/05/14 14:48:40 INFO ShuffleBlockFetcherIterator: Getting 9 (67.4 KiB) non-empty blocks including 9 (67.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:48:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:48:40,871] {docker.py:276} INFO - 21/05/14 14:48:40 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2021-05-14 11:48:40,872] {docker.py:276} INFO - 21/05/14 14:48:40 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2021-05-14 11:48:40,872] {docker.py:276} INFO - 21/05/14 14:48:40 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
[2021-05-14 11:48:40,873] {docker.py:276} INFO - 21/05/14 14:48:40 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443461261544368826896096_0004_m_000151_723, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443461261544368826896096_0004_m_000151_723}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443461261544368826896096_0004}; taskId=attempt_202105141443461261544368826896096_0004_m_000151_723, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@65e54368}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
[2021-05-14 11:48:40,873] {docker.py:276} INFO - 21/05/14 14:48:40 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
21/05/14 14:48:40 INFO StagingCommitter: Starting: Task committer attempt_202105141443461261544368826896096_0004_m_000151_723: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443461261544368826896096_0004_m_000151_723
[2021-05-14 11:48:40,877] {docker.py:276} INFO - 21/05/14 14:48:40 INFO StagingCommitter: Task committer attempt_202105141443461261544368826896096_0004_m_000151_723: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443461261544368826896096_0004_m_000151_723 : duration 0:00.004s
[2021-05-14 11:48:41,347] {docker.py:276} INFO - 21/05/14 14:48:41 INFO StagingCommitter: Starting: Task committer attempt_202105141443469185007900597266784_0004_m_000148_720: needsTaskCommit() Task attempt_202105141443469185007900597266784_0004_m_000148_720
[2021-05-14 11:48:41,347] {docker.py:276} INFO - 21/05/14 14:48:41 INFO StagingCommitter: Task committer attempt_202105141443469185007900597266784_0004_m_000148_720: needsTaskCommit() Task attempt_202105141443469185007900597266784_0004_m_000148_720: duration 0:00.002s
21/05/14 14:48:41 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443469185007900597266784_0004_m_000148_720
[2021-05-14 11:48:41,349] {docker.py:276} INFO - 21/05/14 14:48:41 INFO Executor: Finished task 148.0 in stage 4.0 (TID 720). 5106 bytes result sent to driver
[2021-05-14 11:48:41,350] {docker.py:276} INFO - 21/05/14 14:48:41 INFO TaskSetManager: Starting task 152.0 in stage 4.0 (TID 724) (f0b8ef7ba22f, executor driver, partition 152, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:48:41,351] {docker.py:276} INFO - 21/05/14 14:48:41 INFO Executor: Running task 152.0 in stage 4.0 (TID 724)
[2021-05-14 11:48:41,352] {docker.py:276} INFO - 21/05/14 14:48:41 INFO TaskSetManager: Finished task 148.0 in stage 4.0 (TID 720) in 6636 ms on f0b8ef7ba22f (executor driver) (149/200)
[2021-05-14 11:48:41,363] {docker.py:276} INFO - 21/05/14 14:48:41 INFO ShuffleBlockFetcherIterator: Getting 9 (65.1 KiB) non-empty blocks including 9 (65.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:48:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:48:41,374] {docker.py:276} INFO - 21/05/14 14:48:41 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:48:41 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/05/14 14:48:41 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
[2021-05-14 11:48:41,374] {docker.py:276} INFO - 21/05/14 14:48:41 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_20210514144346513001241746645758_0004_m_000152_724, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_20210514144346513001241746645758_0004_m_000152_724}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_20210514144346513001241746645758_0004}; taskId=attempt_20210514144346513001241746645758_0004_m_000152_724, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@17bd715a}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
21/05/14 14:48:41 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
[2021-05-14 11:48:41,375] {docker.py:276} INFO - 21/05/14 14:48:41 INFO StagingCommitter: Starting: Task committer attempt_20210514144346513001241746645758_0004_m_000152_724: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_20210514144346513001241746645758_0004_m_000152_724
[2021-05-14 11:48:41,378] {docker.py:276} INFO - 21/05/14 14:48:41 INFO StagingCommitter: Task committer attempt_20210514144346513001241746645758_0004_m_000152_724: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_20210514144346513001241746645758_0004_m_000152_724 : duration 0:00.004s
[2021-05-14 11:48:42,874] {docker.py:276} INFO - 21/05/14 14:48:42 INFO StagingCommitter: Starting: Task committer attempt_20210514144346770822905042088357_0004_m_000149_721: needsTaskCommit() Task attempt_20210514144346770822905042088357_0004_m_000149_721
[2021-05-14 11:48:42,875] {docker.py:276} INFO - 21/05/14 14:48:42 INFO StagingCommitter: Task committer attempt_20210514144346770822905042088357_0004_m_000149_721: needsTaskCommit() Task attempt_20210514144346770822905042088357_0004_m_000149_721: duration 0:00.003s
21/05/14 14:48:42 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_20210514144346770822905042088357_0004_m_000149_721
[2021-05-14 11:48:42,877] {docker.py:276} INFO - 21/05/14 14:48:42 INFO Executor: Finished task 149.0 in stage 4.0 (TID 721). 5106 bytes result sent to driver
[2021-05-14 11:48:42,879] {docker.py:276} INFO - 21/05/14 14:48:42 INFO TaskSetManager: Starting task 153.0 in stage 4.0 (TID 725) (f0b8ef7ba22f, executor driver, partition 153, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:48:42,881] {docker.py:276} INFO - 21/05/14 14:48:42 INFO Executor: Running task 153.0 in stage 4.0 (TID 725)
[2021-05-14 11:48:42,881] {docker.py:276} INFO - 21/05/14 14:48:42 INFO TaskSetManager: Finished task 149.0 in stage 4.0 (TID 721) in 6453 ms on f0b8ef7ba22f (executor driver) (150/200)
[2021-05-14 11:48:42,892] {docker.py:276} INFO - 21/05/14 14:48:42 INFO ShuffleBlockFetcherIterator: Getting 9 (66.2 KiB) non-empty blocks including 9 (66.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:48:42 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:48:42,900] {docker.py:276} INFO - 21/05/14 14:48:42 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:48:42 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/05/14 14:48:42 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
21/05/14 14:48:42 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443462829501691423540565_0004_m_000153_725, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443462829501691423540565_0004_m_000153_725}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443462829501691423540565_0004}; taskId=attempt_202105141443462829501691423540565_0004_m_000153_725, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@7e942dad}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
[2021-05-14 11:48:42,900] {docker.py:276} INFO - 21/05/14 14:48:42 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
21/05/14 14:48:42 INFO StagingCommitter: Starting: Task committer attempt_202105141443462829501691423540565_0004_m_000153_725: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443462829501691423540565_0004_m_000153_725
[2021-05-14 11:48:42,904] {docker.py:276} INFO - 21/05/14 14:48:42 INFO StagingCommitter: Task committer attempt_202105141443462829501691423540565_0004_m_000153_725: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443462829501691423540565_0004_m_000153_725 : duration 0:00.004s
[2021-05-14 11:48:47,678] {docker.py:276} INFO - 21/05/14 14:48:47 INFO StagingCommitter: Starting: Task committer attempt_202105141443461261544368826896096_0004_m_000151_723: needsTaskCommit() Task attempt_202105141443461261544368826896096_0004_m_000151_723
[2021-05-14 11:48:47,681] {docker.py:276} INFO - 21/05/14 14:48:47 INFO StagingCommitter: Task committer attempt_202105141443461261544368826896096_0004_m_000151_723: needsTaskCommit() Task attempt_202105141443461261544368826896096_0004_m_000151_723: duration 0:00.004s
21/05/14 14:48:47 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443461261544368826896096_0004_m_000151_723
[2021-05-14 11:48:47,683] {docker.py:276} INFO - 21/05/14 14:48:47 INFO Executor: Finished task 151.0 in stage 4.0 (TID 723). 5106 bytes result sent to driver
[2021-05-14 11:48:47,685] {docker.py:276} INFO - 21/05/14 14:48:47 INFO TaskSetManager: Starting task 154.0 in stage 4.0 (TID 726) (f0b8ef7ba22f, executor driver, partition 154, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:48:47,686] {docker.py:276} INFO - 21/05/14 14:48:47 INFO TaskSetManager: Finished task 151.0 in stage 4.0 (TID 723) in 6843 ms on f0b8ef7ba22f (executor driver) (151/200)
[2021-05-14 11:48:47,686] {docker.py:276} INFO - 21/05/14 14:48:47 INFO Executor: Running task 154.0 in stage 4.0 (TID 726)
[2021-05-14 11:48:47,695] {docker.py:276} INFO - 21/05/14 14:48:47 INFO ShuffleBlockFetcherIterator: Getting 9 (64.6 KiB) non-empty blocks including 9 (64.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:48:47 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:48:47,708] {docker.py:276} INFO - 21/05/14 14:48:47 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:48:47 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/05/14 14:48:47 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
21/05/14 14:48:47 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443461674287817645285515_0004_m_000154_726, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443461674287817645285515_0004_m_000154_726}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443461674287817645285515_0004}; taskId=attempt_202105141443461674287817645285515_0004_m_000154_726, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@27df23c}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
[2021-05-14 11:48:47,708] {docker.py:276} INFO - 21/05/14 14:48:47 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
21/05/14 14:48:47 INFO StagingCommitter: Starting: Task committer attempt_202105141443461674287817645285515_0004_m_000154_726: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443461674287817645285515_0004_m_000154_726
[2021-05-14 11:48:47,711] {docker.py:276} INFO - 21/05/14 14:48:47 INFO StagingCommitter: Task committer attempt_202105141443461674287817645285515_0004_m_000154_726: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443461674287817645285515_0004_m_000154_726 : duration 0:00.003s
[2021-05-14 11:48:47,856] {docker.py:276} INFO - 21/05/14 14:48:47 INFO StagingCommitter: Starting: Task committer attempt_20210514144346513001241746645758_0004_m_000152_724: needsTaskCommit() Task attempt_20210514144346513001241746645758_0004_m_000152_724
[2021-05-14 11:48:47,857] {docker.py:276} INFO - 21/05/14 14:48:47 INFO StagingCommitter: Task committer attempt_20210514144346513001241746645758_0004_m_000152_724: needsTaskCommit() Task attempt_20210514144346513001241746645758_0004_m_000152_724: duration 0:00.002s
21/05/14 14:48:47 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_20210514144346513001241746645758_0004_m_000152_724
[2021-05-14 11:48:47,859] {docker.py:276} INFO - 21/05/14 14:48:47 INFO Executor: Finished task 152.0 in stage 4.0 (TID 724). 5106 bytes result sent to driver
[2021-05-14 11:48:47,860] {docker.py:276} INFO - 21/05/14 14:48:47 INFO StagingCommitter: Starting: Task committer attempt_202105141443465533088288784736698_0004_m_000150_722: needsTaskCommit() Task attempt_202105141443465533088288784736698_0004_m_000150_722
21/05/14 14:48:47 INFO StagingCommitter: Task committer attempt_202105141443465533088288784736698_0004_m_000150_722: needsTaskCommit() Task attempt_202105141443465533088288784736698_0004_m_000150_722: duration 0:00.000s
21/05/14 14:48:47 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443465533088288784736698_0004_m_000150_722
[2021-05-14 11:48:47,861] {docker.py:276} INFO - 21/05/14 14:48:47 INFO TaskSetManager: Starting task 155.0 in stage 4.0 (TID 727) (f0b8ef7ba22f, executor driver, partition 155, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:48:47,862] {docker.py:276} INFO - 21/05/14 14:48:47 INFO Executor: Running task 155.0 in stage 4.0 (TID 727)
[2021-05-14 11:48:47,862] {docker.py:276} INFO - 21/05/14 14:48:47 INFO TaskSetManager: Finished task 152.0 in stage 4.0 (TID 724) in 6519 ms on f0b8ef7ba22f (executor driver) (152/200)
[2021-05-14 11:48:47,864] {docker.py:276} INFO - 21/05/14 14:48:47 INFO Executor: Finished task 150.0 in stage 4.0 (TID 722). 5106 bytes result sent to driver
[2021-05-14 11:48:47,865] {docker.py:276} INFO - 21/05/14 14:48:47 INFO TaskSetManager: Starting task 156.0 in stage 4.0 (TID 728) (f0b8ef7ba22f, executor driver, partition 156, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:48:47,869] {docker.py:276} INFO - 21/05/14 14:48:47 INFO TaskSetManager: Finished task 150.0 in stage 4.0 (TID 722) in 7381 ms on f0b8ef7ba22f (executor driver) (153/200)
[2021-05-14 11:48:47,870] {docker.py:276} INFO - 21/05/14 14:48:47 INFO Executor: Running task 156.0 in stage 4.0 (TID 728)
[2021-05-14 11:48:47,876] {docker.py:276} INFO - 21/05/14 14:48:47 INFO ShuffleBlockFetcherIterator: Getting 9 (66.1 KiB) non-empty blocks including 9 (66.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:48:47 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/05/14 14:48:47 INFO ShuffleBlockFetcherIterator: Getting 9 (66.5 KiB) non-empty blocks including 9 (66.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:48:47 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:48:47,884] {docker.py:276} INFO - 21/05/14 14:48:47 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:48:47 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/05/14 14:48:47 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
21/05/14 14:48:47 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443462527429719029607284_0004_m_000156_728, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443462527429719029607284_0004_m_000156_728}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443462527429719029607284_0004}; taskId=attempt_202105141443462527429719029607284_0004_m_000156_728, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@f825163}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
21/05/14 14:48:47 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
21/05/14 14:48:47 INFO StagingCommitter: Starting: Task committer attempt_202105141443462527429719029607284_0004_m_000156_728: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443462527429719029607284_0004_m_000156_728
[2021-05-14 11:48:47,885] {docker.py:276} INFO - 21/05/14 14:48:47 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2021-05-14 11:48:47,885] {docker.py:276} INFO - 21/05/14 14:48:47 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2021-05-14 11:48:47,885] {docker.py:276} INFO - 21/05/14 14:48:47 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
[2021-05-14 11:48:47,886] {docker.py:276} INFO - 21/05/14 14:48:47 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443467957406450107504006_0004_m_000155_727, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443467957406450107504006_0004_m_000155_727}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443467957406450107504006_0004}; taskId=attempt_202105141443467957406450107504006_0004_m_000155_727, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@63a35f4c}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
[2021-05-14 11:48:47,886] {docker.py:276} INFO - 21/05/14 14:48:47 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
[2021-05-14 11:48:47,886] {docker.py:276} INFO - 21/05/14 14:48:47 INFO StagingCommitter: Starting: Task committer attempt_202105141443467957406450107504006_0004_m_000155_727: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443467957406450107504006_0004_m_000155_727
[2021-05-14 11:48:47,889] {docker.py:276} INFO - 21/05/14 14:48:47 INFO StagingCommitter: Task committer attempt_202105141443462527429719029607284_0004_m_000156_728: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443462527429719029607284_0004_m_000156_728 : duration 0:00.005s
[2021-05-14 11:48:47,893] {docker.py:276} INFO - 21/05/14 14:48:47 INFO StagingCommitter: Task committer attempt_202105141443467957406450107504006_0004_m_000155_727: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443467957406450107504006_0004_m_000155_727 : duration 0:00.007s
[2021-05-14 11:48:49,644] {docker.py:276} INFO - 21/05/14 14:48:49 INFO StagingCommitter: Starting: Task committer attempt_202105141443462829501691423540565_0004_m_000153_725: needsTaskCommit() Task attempt_202105141443462829501691423540565_0004_m_000153_725
21/05/14 14:48:49 INFO StagingCommitter: Task committer attempt_202105141443462829501691423540565_0004_m_000153_725: needsTaskCommit() Task attempt_202105141443462829501691423540565_0004_m_000153_725: duration 0:00.000s
[2021-05-14 11:48:49,645] {docker.py:276} INFO - 21/05/14 14:48:49 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443462829501691423540565_0004_m_000153_725
[2021-05-14 11:48:49,646] {docker.py:276} INFO - 21/05/14 14:48:49 INFO Executor: Finished task 153.0 in stage 4.0 (TID 725). 5106 bytes result sent to driver
[2021-05-14 11:48:49,646] {docker.py:276} INFO - 21/05/14 14:48:49 INFO TaskSetManager: Starting task 157.0 in stage 4.0 (TID 729) (f0b8ef7ba22f, executor driver, partition 157, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:48:49,647] {docker.py:276} INFO - 21/05/14 14:48:49 INFO Executor: Running task 157.0 in stage 4.0 (TID 729)
[2021-05-14 11:48:49,648] {docker.py:276} INFO - 21/05/14 14:48:49 INFO TaskSetManager: Finished task 153.0 in stage 4.0 (TID 725) in 6779 ms on f0b8ef7ba22f (executor driver) (154/200)
[2021-05-14 11:48:49,655] {docker.py:276} INFO - 21/05/14 14:48:49 INFO ShuffleBlockFetcherIterator: Getting 9 (65.5 KiB) non-empty blocks including 9 (65.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:48:49 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:48:49,664] {docker.py:276} INFO - 21/05/14 14:48:49 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:48:49 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/05/14 14:48:49 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
21/05/14 14:48:49 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443465542668145593139091_0004_m_000157_729, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443465542668145593139091_0004_m_000157_729}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443465542668145593139091_0004}; taskId=attempt_202105141443465542668145593139091_0004_m_000157_729, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@15a975a4}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
[2021-05-14 11:48:49,664] {docker.py:276} INFO - 21/05/14 14:48:49 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
21/05/14 14:48:49 INFO StagingCommitter: Starting: Task committer attempt_202105141443465542668145593139091_0004_m_000157_729: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443465542668145593139091_0004_m_000157_729
[2021-05-14 11:48:49,668] {docker.py:276} INFO - 21/05/14 14:48:49 INFO StagingCommitter: Task committer attempt_202105141443465542668145593139091_0004_m_000157_729: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443465542668145593139091_0004_m_000157_729 : duration 0:00.004s
[2021-05-14 11:48:54,555] {docker.py:276} INFO - 21/05/14 14:48:54 INFO StagingCommitter: Starting: Task committer attempt_202105141443462527429719029607284_0004_m_000156_728: needsTaskCommit() Task attempt_202105141443462527429719029607284_0004_m_000156_728
[2021-05-14 11:48:54,556] {docker.py:276} INFO - 21/05/14 14:48:54 INFO StagingCommitter: Task committer attempt_202105141443462527429719029607284_0004_m_000156_728: needsTaskCommit() Task attempt_202105141443462527429719029607284_0004_m_000156_728: duration 0:00.000s
21/05/14 14:48:54 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443462527429719029607284_0004_m_000156_728
[2021-05-14 11:48:54,557] {docker.py:276} INFO - 21/05/14 14:48:54 INFO Executor: Finished task 156.0 in stage 4.0 (TID 728). 5106 bytes result sent to driver
[2021-05-14 11:48:54,558] {docker.py:276} INFO - 21/05/14 14:48:54 INFO TaskSetManager: Starting task 158.0 in stage 4.0 (TID 730) (f0b8ef7ba22f, executor driver, partition 158, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:48:54,558] {docker.py:276} INFO - 21/05/14 14:48:54 INFO Executor: Running task 158.0 in stage 4.0 (TID 730)
[2021-05-14 11:48:54,559] {docker.py:276} INFO - 21/05/14 14:48:54 INFO TaskSetManager: Finished task 156.0 in stage 4.0 (TID 728) in 6703 ms on f0b8ef7ba22f (executor driver) (155/200)
[2021-05-14 11:48:54,566] {docker.py:276} INFO - 21/05/14 14:48:54 INFO ShuffleBlockFetcherIterator: Getting 9 (64.4 KiB) non-empty blocks including 9 (64.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:48:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:48:54,574] {docker.py:276} INFO - 21/05/14 14:48:54 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:48:54 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/05/14 14:48:54 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
21/05/14 14:48:54 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443465623173645119805597_0004_m_000158_730, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443465623173645119805597_0004_m_000158_730}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443465623173645119805597_0004}; taskId=attempt_202105141443465623173645119805597_0004_m_000158_730, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@18aeb9ca}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
21/05/14 14:48:54 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
[2021-05-14 11:48:54,574] {docker.py:276} INFO - 21/05/14 14:48:54 INFO StagingCommitter: Starting: Task committer attempt_202105141443465623173645119805597_0004_m_000158_730: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443465623173645119805597_0004_m_000158_730
[2021-05-14 11:48:54,578] {docker.py:276} INFO - 21/05/14 14:48:54 INFO StagingCommitter: Task committer attempt_202105141443465623173645119805597_0004_m_000158_730: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443465623173645119805597_0004_m_000158_730 : duration 0:00.004s
[2021-05-14 11:48:54,941] {docker.py:276} INFO - 21/05/14 14:48:54 INFO StagingCommitter: Starting: Task committer attempt_202105141443461674287817645285515_0004_m_000154_726: needsTaskCommit() Task attempt_202105141443461674287817645285515_0004_m_000154_726
[2021-05-14 11:48:54,942] {docker.py:276} INFO - 21/05/14 14:48:54 INFO StagingCommitter: Task committer attempt_202105141443461674287817645285515_0004_m_000154_726: needsTaskCommit() Task attempt_202105141443461674287817645285515_0004_m_000154_726: duration 0:00.002s
21/05/14 14:48:54 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443461674287817645285515_0004_m_000154_726
[2021-05-14 11:48:54,945] {docker.py:276} INFO - 21/05/14 14:48:54 INFO Executor: Finished task 154.0 in stage 4.0 (TID 726). 5106 bytes result sent to driver
[2021-05-14 11:48:54,946] {docker.py:276} INFO - 21/05/14 14:48:54 INFO TaskSetManager: Starting task 159.0 in stage 4.0 (TID 731) (f0b8ef7ba22f, executor driver, partition 159, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:48:54,947] {docker.py:276} INFO - 21/05/14 14:48:54 INFO Executor: Running task 159.0 in stage 4.0 (TID 731)
[2021-05-14 11:48:54,947] {docker.py:276} INFO - 21/05/14 14:48:54 INFO TaskSetManager: Finished task 154.0 in stage 4.0 (TID 726) in 7271 ms on f0b8ef7ba22f (executor driver) (156/200)
[2021-05-14 11:48:54,956] {docker.py:276} INFO - 21/05/14 14:48:54 INFO ShuffleBlockFetcherIterator: Getting 9 (64.3 KiB) non-empty blocks including 9 (64.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:48:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:48:54,965] {docker.py:276} INFO - 21/05/14 14:48:54 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:48:54 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/05/14 14:48:54 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
[2021-05-14 11:48:54,965] {docker.py:276} INFO - 21/05/14 14:48:54 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443466714025202615334820_0004_m_000159_731, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443466714025202615334820_0004_m_000159_731}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443466714025202615334820_0004}; taskId=attempt_202105141443466714025202615334820_0004_m_000159_731, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@4a305be3}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
21/05/14 14:48:54 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
[2021-05-14 11:48:54,966] {docker.py:276} INFO - 21/05/14 14:48:54 INFO StagingCommitter: Starting: Task committer attempt_202105141443466714025202615334820_0004_m_000159_731: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443466714025202615334820_0004_m_000159_731
[2021-05-14 11:48:54,969] {docker.py:276} INFO - 21/05/14 14:48:54 INFO StagingCommitter: Task committer attempt_202105141443466714025202615334820_0004_m_000159_731: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443466714025202615334820_0004_m_000159_731 : duration 0:00.003s
[2021-05-14 11:48:55,009] {docker.py:276} INFO - 21/05/14 14:48:55 INFO StagingCommitter: Starting: Task committer attempt_202105141443467957406450107504006_0004_m_000155_727: needsTaskCommit() Task attempt_202105141443467957406450107504006_0004_m_000155_727
21/05/14 14:48:55 INFO StagingCommitter: Task committer attempt_202105141443467957406450107504006_0004_m_000155_727: needsTaskCommit() Task attempt_202105141443467957406450107504006_0004_m_000155_727: duration 0:00.002s
21/05/14 14:48:55 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443467957406450107504006_0004_m_000155_727
[2021-05-14 11:48:55,011] {docker.py:276} INFO - 21/05/14 14:48:55 INFO Executor: Finished task 155.0 in stage 4.0 (TID 727). 5106 bytes result sent to driver
[2021-05-14 11:48:55,012] {docker.py:276} INFO - 21/05/14 14:48:55 INFO TaskSetManager: Starting task 160.0 in stage 4.0 (TID 732) (f0b8ef7ba22f, executor driver, partition 160, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:48:55,013] {docker.py:276} INFO - 21/05/14 14:48:55 INFO TaskSetManager: Finished task 155.0 in stage 4.0 (TID 727) in 7162 ms on f0b8ef7ba22f (executor driver) (157/200)
[2021-05-14 11:48:55,013] {docker.py:276} INFO - 21/05/14 14:48:55 INFO Executor: Running task 160.0 in stage 4.0 (TID 732)
[2021-05-14 11:48:55,023] {docker.py:276} INFO - 21/05/14 14:48:55 INFO ShuffleBlockFetcherIterator: Getting 9 (67.8 KiB) non-empty blocks including 9 (67.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
[2021-05-14 11:48:55,023] {docker.py:276} INFO - 21/05/14 14:48:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:48:55,034] {docker.py:276} INFO - 21/05/14 14:48:55 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:48:55 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/05/14 14:48:55 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
21/05/14 14:48:55 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443465178836060881412131_0004_m_000160_732, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443465178836060881412131_0004_m_000160_732}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443465178836060881412131_0004}; taskId=attempt_202105141443465178836060881412131_0004_m_000160_732, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@7de33935}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
21/05/14 14:48:55 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
21/05/14 14:48:55 INFO StagingCommitter: Starting: Task committer attempt_202105141443465178836060881412131_0004_m_000160_732: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443465178836060881412131_0004_m_000160_732
[2021-05-14 11:48:55,038] {docker.py:276} INFO - 21/05/14 14:48:55 INFO StagingCommitter: Task committer attempt_202105141443465178836060881412131_0004_m_000160_732: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443465178836060881412131_0004_m_000160_732 : duration 0:00.004s
[2021-05-14 11:48:56,210] {docker.py:276} INFO - 21/05/14 14:48:56 INFO StagingCommitter: Starting: Task committer attempt_202105141443465542668145593139091_0004_m_000157_729: needsTaskCommit() Task attempt_202105141443465542668145593139091_0004_m_000157_729
[2021-05-14 11:48:56,211] {docker.py:276} INFO - 21/05/14 14:48:56 INFO StagingCommitter: Task committer attempt_202105141443465542668145593139091_0004_m_000157_729: needsTaskCommit() Task attempt_202105141443465542668145593139091_0004_m_000157_729: duration 0:00.002s
[2021-05-14 11:48:56,211] {docker.py:276} INFO - 21/05/14 14:48:56 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443465542668145593139091_0004_m_000157_729
[2021-05-14 11:48:56,213] {docker.py:276} INFO - 21/05/14 14:48:56 INFO Executor: Finished task 157.0 in stage 4.0 (TID 729). 5106 bytes result sent to driver
[2021-05-14 11:48:56,216] {docker.py:276} INFO - 21/05/14 14:48:56 INFO TaskSetManager: Starting task 161.0 in stage 4.0 (TID 733) (f0b8ef7ba22f, executor driver, partition 161, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:48:56,218] {docker.py:276} INFO - 21/05/14 14:48:56 INFO Executor: Running task 161.0 in stage 4.0 (TID 733)
[2021-05-14 11:48:56,219] {docker.py:276} INFO - 21/05/14 14:48:56 INFO TaskSetManager: Finished task 157.0 in stage 4.0 (TID 729) in 6580 ms on f0b8ef7ba22f (executor driver) (158/200)
[2021-05-14 11:48:56,228] {docker.py:276} INFO - 21/05/14 14:48:56 INFO ShuffleBlockFetcherIterator: Getting 9 (63.8 KiB) non-empty blocks including 9 (63.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:48:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:48:56,248] {docker.py:276} INFO - 21/05/14 14:48:56 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:48:56 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/05/14 14:48:56 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
21/05/14 14:48:56 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443465180372787911576102_0004_m_000161_733, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443465180372787911576102_0004_m_000161_733}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443465180372787911576102_0004}; taskId=attempt_202105141443465180372787911576102_0004_m_000161_733, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@4341dd00}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
21/05/14 14:48:56 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
21/05/14 14:48:56 INFO StagingCommitter: Starting: Task committer attempt_202105141443465180372787911576102_0004_m_000161_733: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443465180372787911576102_0004_m_000161_733
[2021-05-14 11:48:56,252] {docker.py:276} INFO - 21/05/14 14:48:56 INFO StagingCommitter: Task committer attempt_202105141443465180372787911576102_0004_m_000161_733: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443465180372787911576102_0004_m_000161_733 : duration 0:00.004s
[2021-05-14 11:49:01,828] {docker.py:276} INFO - 21/05/14 14:49:01 INFO StagingCommitter: Starting: Task committer attempt_202105141443465623173645119805597_0004_m_000158_730: needsTaskCommit() Task attempt_202105141443465623173645119805597_0004_m_000158_730
[2021-05-14 11:49:01,828] {docker.py:276} INFO - 21/05/14 14:49:01 INFO StagingCommitter: Task committer attempt_202105141443465623173645119805597_0004_m_000158_730: needsTaskCommit() Task attempt_202105141443465623173645119805597_0004_m_000158_730: duration 0:00.002s
21/05/14 14:49:01 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443465623173645119805597_0004_m_000158_730
[2021-05-14 11:49:01,830] {docker.py:276} INFO - 21/05/14 14:49:01 INFO Executor: Finished task 158.0 in stage 4.0 (TID 730). 5149 bytes result sent to driver
21/05/14 14:49:01 INFO TaskSetManager: Starting task 162.0 in stage 4.0 (TID 734) (f0b8ef7ba22f, executor driver, partition 162, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:49:01,831] {docker.py:276} INFO - 21/05/14 14:49:01 INFO TaskSetManager: Finished task 158.0 in stage 4.0 (TID 730) in 7282 ms on f0b8ef7ba22f (executor driver) (159/200)
[2021-05-14 11:49:01,831] {docker.py:276} INFO - 21/05/14 14:49:01 INFO Executor: Running task 162.0 in stage 4.0 (TID 734)
[2021-05-14 11:49:01,840] {docker.py:276} INFO - 21/05/14 14:49:01 INFO ShuffleBlockFetcherIterator: Getting 9 (66.1 KiB) non-empty blocks including 9 (66.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:49:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:49:01,849] {docker.py:276} INFO - 21/05/14 14:49:01 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:49:01 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/05/14 14:49:01 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
21/05/14 14:49:01 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443461422387748283117644_0004_m_000162_734, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443461422387748283117644_0004_m_000162_734}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443461422387748283117644_0004}; taskId=attempt_202105141443461422387748283117644_0004_m_000162_734, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@1cf268bc}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
21/05/14 14:49:01 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
[2021-05-14 11:49:01,850] {docker.py:276} INFO - 21/05/14 14:49:01 INFO StagingCommitter: Starting: Task committer attempt_202105141443461422387748283117644_0004_m_000162_734: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443461422387748283117644_0004_m_000162_734
[2021-05-14 11:49:01,853] {docker.py:276} INFO - 21/05/14 14:49:01 INFO StagingCommitter: Task committer attempt_202105141443461422387748283117644_0004_m_000162_734: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443461422387748283117644_0004_m_000162_734 : duration 0:00.004s
[2021-05-14 11:49:01,905] {docker.py:276} INFO - 21/05/14 14:49:01 INFO StagingCommitter: Starting: Task committer attempt_202105141443466714025202615334820_0004_m_000159_731: needsTaskCommit() Task attempt_202105141443466714025202615334820_0004_m_000159_731
[2021-05-14 11:49:01,906] {docker.py:276} INFO - 21/05/14 14:49:01 INFO StagingCommitter: Task committer attempt_202105141443466714025202615334820_0004_m_000159_731: needsTaskCommit() Task attempt_202105141443466714025202615334820_0004_m_000159_731: duration 0:00.002s
21/05/14 14:49:01 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443466714025202615334820_0004_m_000159_731
[2021-05-14 11:49:01,907] {docker.py:276} INFO - 21/05/14 14:49:01 INFO Executor: Finished task 159.0 in stage 4.0 (TID 731). 5149 bytes result sent to driver
[2021-05-14 11:49:01,908] {docker.py:276} INFO - 21/05/14 14:49:01 INFO TaskSetManager: Starting task 163.0 in stage 4.0 (TID 735) (f0b8ef7ba22f, executor driver, partition 163, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:49:01,909] {docker.py:276} INFO - 21/05/14 14:49:01 INFO Executor: Running task 163.0 in stage 4.0 (TID 735)
21/05/14 14:49:01 INFO TaskSetManager: Finished task 159.0 in stage 4.0 (TID 731) in 6971 ms on f0b8ef7ba22f (executor driver) (160/200)
[2021-05-14 11:49:01,918] {docker.py:276} INFO - 21/05/14 14:49:01 INFO ShuffleBlockFetcherIterator: Getting 9 (61.8 KiB) non-empty blocks including 9 (61.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:49:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:49:01,931] {docker.py:276} INFO - 21/05/14 14:49:01 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:49:01 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/05/14 14:49:01 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
21/05/14 14:49:01 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443462925879498565849348_0004_m_000163_735, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443462925879498565849348_0004_m_000163_735}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443462925879498565849348_0004}; taskId=attempt_202105141443462925879498565849348_0004_m_000163_735, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@5d592591}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
21/05/14 14:49:01 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
21/05/14 14:49:01 INFO StagingCommitter: Starting: Task committer attempt_202105141443462925879498565849348_0004_m_000163_735: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443462925879498565849348_0004_m_000163_735
[2021-05-14 11:49:01,938] {docker.py:276} INFO - 21/05/14 14:49:01 INFO StagingCommitter: Task committer attempt_202105141443462925879498565849348_0004_m_000163_735: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443462925879498565849348_0004_m_000163_735 : duration 0:00.010s
[2021-05-14 11:49:02,518] {docker.py:276} INFO - 21/05/14 14:49:02 INFO StagingCommitter: Starting: Task committer attempt_202105141443465178836060881412131_0004_m_000160_732: needsTaskCommit() Task attempt_202105141443465178836060881412131_0004_m_000160_732
[2021-05-14 11:49:02,519] {docker.py:276} INFO - 21/05/14 14:49:02 INFO StagingCommitter: Task committer attempt_202105141443465178836060881412131_0004_m_000160_732: needsTaskCommit() Task attempt_202105141443465178836060881412131_0004_m_000160_732: duration 0:00.003s
21/05/14 14:49:02 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443465178836060881412131_0004_m_000160_732
[2021-05-14 11:49:02,522] {docker.py:276} INFO - 21/05/14 14:49:02 INFO Executor: Finished task 160.0 in stage 4.0 (TID 732). 5149 bytes result sent to driver
[2021-05-14 11:49:02,523] {docker.py:276} INFO - 21/05/14 14:49:02 INFO TaskSetManager: Starting task 164.0 in stage 4.0 (TID 736) (f0b8ef7ba22f, executor driver, partition 164, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:49:02,524] {docker.py:276} INFO - 21/05/14 14:49:02 INFO TaskSetManager: Finished task 160.0 in stage 4.0 (TID 732) in 7522 ms on f0b8ef7ba22f (executor driver) (161/200)
[2021-05-14 11:49:02,525] {docker.py:276} INFO - 21/05/14 14:49:02 INFO Executor: Running task 164.0 in stage 4.0 (TID 736)
[2021-05-14 11:49:02,534] {docker.py:276} INFO - 21/05/14 14:49:02 INFO ShuffleBlockFetcherIterator: Getting 9 (64.9 KiB) non-empty blocks including 9 (64.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:49:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:49:02,545] {docker.py:276} INFO - 21/05/14 14:49:02 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:49:02 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/05/14 14:49:02 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
21/05/14 14:49:02 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443463398807617392536152_0004_m_000164_736, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443463398807617392536152_0004_m_000164_736}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443463398807617392536152_0004}; taskId=attempt_202105141443463398807617392536152_0004_m_000164_736, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@56feecd7}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
21/05/14 14:49:02 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
21/05/14 14:49:02 INFO StagingCommitter: Starting: Task committer attempt_202105141443463398807617392536152_0004_m_000164_736: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443463398807617392536152_0004_m_000164_736
[2021-05-14 11:49:02,552] {docker.py:276} INFO - 21/05/14 14:49:02 INFO StagingCommitter: Task committer attempt_202105141443463398807617392536152_0004_m_000164_736: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443463398807617392536152_0004_m_000164_736 : duration 0:00.007s
[2021-05-14 11:49:02,692] {docker.py:276} INFO - 21/05/14 14:49:02 INFO StagingCommitter: Starting: Task committer attempt_202105141443465180372787911576102_0004_m_000161_733: needsTaskCommit() Task attempt_202105141443465180372787911576102_0004_m_000161_733
21/05/14 14:49:02 INFO StagingCommitter: Task committer attempt_202105141443465180372787911576102_0004_m_000161_733: needsTaskCommit() Task attempt_202105141443465180372787911576102_0004_m_000161_733: duration 0:00.004s
21/05/14 14:49:02 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443465180372787911576102_0004_m_000161_733
[2021-05-14 11:49:02,695] {docker.py:276} INFO - 21/05/14 14:49:02 INFO Executor: Finished task 161.0 in stage 4.0 (TID 733). 5149 bytes result sent to driver
[2021-05-14 11:49:02,696] {docker.py:276} INFO - 21/05/14 14:49:02 INFO TaskSetManager: Starting task 165.0 in stage 4.0 (TID 737) (f0b8ef7ba22f, executor driver, partition 165, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:49:02,697] {docker.py:276} INFO - 21/05/14 14:49:02 INFO TaskSetManager: Finished task 161.0 in stage 4.0 (TID 733) in 6489 ms on f0b8ef7ba22f (executor driver) (162/200)
[2021-05-14 11:49:02,698] {docker.py:276} INFO - 21/05/14 14:49:02 INFO Executor: Running task 165.0 in stage 4.0 (TID 737)
[2021-05-14 11:49:02,707] {docker.py:276} INFO - 21/05/14 14:49:02 INFO ShuffleBlockFetcherIterator: Getting 9 (63.1 KiB) non-empty blocks including 9 (63.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:49:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:49:02,716] {docker.py:276} INFO - 21/05/14 14:49:02 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:49:02 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/05/14 14:49:02 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
21/05/14 14:49:02 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443466544027033216041661_0004_m_000165_737, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443466544027033216041661_0004_m_000165_737}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443466544027033216041661_0004}; taskId=attempt_202105141443466544027033216041661_0004_m_000165_737, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@798a67db}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
21/05/14 14:49:02 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
21/05/14 14:49:02 INFO StagingCommitter: Starting: Task committer attempt_202105141443466544027033216041661_0004_m_000165_737: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443466544027033216041661_0004_m_000165_737
[2021-05-14 11:49:02,720] {docker.py:276} INFO - 21/05/14 14:49:02 INFO StagingCommitter: Task committer attempt_202105141443466544027033216041661_0004_m_000165_737: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443466544027033216041661_0004_m_000165_737 : duration 0:00.003s
[2021-05-14 11:49:08,581] {docker.py:276} INFO - 21/05/14 14:49:08 INFO StagingCommitter: Starting: Task committer attempt_202105141443462925879498565849348_0004_m_000163_735: needsTaskCommit() Task attempt_202105141443462925879498565849348_0004_m_000163_735
21/05/14 14:49:08 INFO StagingCommitter: Task committer attempt_202105141443462925879498565849348_0004_m_000163_735: needsTaskCommit() Task attempt_202105141443462925879498565849348_0004_m_000163_735: duration 0:00.002s
21/05/14 14:49:08 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443462925879498565849348_0004_m_000163_735
[2021-05-14 11:49:08,583] {docker.py:276} INFO - 21/05/14 14:49:08 INFO Executor: Finished task 163.0 in stage 4.0 (TID 735). 5106 bytes result sent to driver
[2021-05-14 11:49:08,585] {docker.py:276} INFO - 21/05/14 14:49:08 INFO TaskSetManager: Starting task 166.0 in stage 4.0 (TID 738) (f0b8ef7ba22f, executor driver, partition 166, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:49:08,586] {docker.py:276} INFO - 21/05/14 14:49:08 INFO TaskSetManager: Finished task 163.0 in stage 4.0 (TID 735) in 6650 ms on f0b8ef7ba22f (executor driver) (163/200)
21/05/14 14:49:08 INFO Executor: Running task 166.0 in stage 4.0 (TID 738)
[2021-05-14 11:49:08,595] {docker.py:276} INFO - 21/05/14 14:49:08 INFO ShuffleBlockFetcherIterator: Getting 9 (65.5 KiB) non-empty blocks including 9 (65.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:49:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:49:08,604] {docker.py:276} INFO - 21/05/14 14:49:08 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:49:08 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/05/14 14:49:08 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
21/05/14 14:49:08 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443468875300781377618930_0004_m_000166_738, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443468875300781377618930_0004_m_000166_738}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443468875300781377618930_0004}; taskId=attempt_202105141443468875300781377618930_0004_m_000166_738, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@7c78362f}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
21/05/14 14:49:08 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
[2021-05-14 11:49:08,604] {docker.py:276} INFO - 21/05/14 14:49:08 INFO StagingCommitter: Starting: Task committer attempt_202105141443468875300781377618930_0004_m_000166_738: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443468875300781377618930_0004_m_000166_738
[2021-05-14 11:49:08,609] {docker.py:276} INFO - 21/05/14 14:49:08 INFO StagingCommitter: Task committer attempt_202105141443468875300781377618930_0004_m_000166_738: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443468875300781377618930_0004_m_000166_738 : duration 0:00.005s
[2021-05-14 11:49:08,859] {docker.py:276} INFO - 21/05/14 14:49:08 INFO StagingCommitter: Starting: Task committer attempt_202105141443461422387748283117644_0004_m_000162_734: needsTaskCommit() Task attempt_202105141443461422387748283117644_0004_m_000162_734
[2021-05-14 11:49:08,859] {docker.py:276} INFO - 21/05/14 14:49:08 INFO StagingCommitter: Task committer attempt_202105141443461422387748283117644_0004_m_000162_734: needsTaskCommit() Task attempt_202105141443461422387748283117644_0004_m_000162_734: duration 0:00.002s
21/05/14 14:49:08 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443461422387748283117644_0004_m_000162_734
[2021-05-14 11:49:08,860] {docker.py:276} INFO - 21/05/14 14:49:08 INFO Executor: Finished task 162.0 in stage 4.0 (TID 734). 5106 bytes result sent to driver
[2021-05-14 11:49:08,861] {docker.py:276} INFO - 21/05/14 14:49:08 INFO TaskSetManager: Starting task 167.0 in stage 4.0 (TID 739) (f0b8ef7ba22f, executor driver, partition 167, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:49:08,862] {docker.py:276} INFO - 21/05/14 14:49:08 INFO Executor: Running task 167.0 in stage 4.0 (TID 739)
[2021-05-14 11:49:08,863] {docker.py:276} INFO - 21/05/14 14:49:08 INFO TaskSetManager: Finished task 162.0 in stage 4.0 (TID 734) in 7005 ms on f0b8ef7ba22f (executor driver) (164/200)
[2021-05-14 11:49:08,872] {docker.py:276} INFO - 21/05/14 14:49:08 INFO ShuffleBlockFetcherIterator: Getting 9 (67.8 KiB) non-empty blocks including 9 (67.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
[2021-05-14 11:49:08,872] {docker.py:276} INFO - 21/05/14 14:49:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:49:08,881] {docker.py:276} INFO - 21/05/14 14:49:08 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2021-05-14 11:49:08,881] {docker.py:276} INFO - 21/05/14 14:49:08 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2021-05-14 11:49:08,881] {docker.py:276} INFO - 21/05/14 14:49:08 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
[2021-05-14 11:49:08,882] {docker.py:276} INFO - 21/05/14 14:49:08 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443467745228487823750116_0004_m_000167_739, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443467745228487823750116_0004_m_000167_739}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443467745228487823750116_0004}; taskId=attempt_202105141443467745228487823750116_0004_m_000167_739, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@22a3b3ad}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
21/05/14 14:49:08 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
[2021-05-14 11:49:08,882] {docker.py:276} INFO - 21/05/14 14:49:08 INFO StagingCommitter: Starting: Task committer attempt_202105141443467745228487823750116_0004_m_000167_739: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443467745228487823750116_0004_m_000167_739
[2021-05-14 11:49:08,884] {docker.py:276} INFO - 21/05/14 14:49:08 INFO StagingCommitter: Task committer attempt_202105141443467745228487823750116_0004_m_000167_739: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443467745228487823750116_0004_m_000167_739 : duration 0:00.003s
[2021-05-14 11:49:09,043] {docker.py:276} INFO - 21/05/14 14:49:09 INFO StagingCommitter: Starting: Task committer attempt_202105141443466544027033216041661_0004_m_000165_737: needsTaskCommit() Task attempt_202105141443466544027033216041661_0004_m_000165_737
[2021-05-14 11:49:09,044] {docker.py:276} INFO - 21/05/14 14:49:09 INFO StagingCommitter: Task committer attempt_202105141443466544027033216041661_0004_m_000165_737: needsTaskCommit() Task attempt_202105141443466544027033216041661_0004_m_000165_737: duration 0:00.002s
[2021-05-14 11:49:09,045] {docker.py:276} INFO - 21/05/14 14:49:09 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443466544027033216041661_0004_m_000165_737
[2021-05-14 11:49:09,045] {docker.py:276} INFO - 21/05/14 14:49:09 INFO Executor: Finished task 165.0 in stage 4.0 (TID 737). 5106 bytes result sent to driver
[2021-05-14 11:49:09,046] {docker.py:276} INFO - 21/05/14 14:49:09 INFO TaskSetManager: Starting task 168.0 in stage 4.0 (TID 740) (f0b8ef7ba22f, executor driver, partition 168, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:49:09,047] {docker.py:276} INFO - 21/05/14 14:49:09 INFO TaskSetManager: Finished task 165.0 in stage 4.0 (TID 737) in 6323 ms on f0b8ef7ba22f (executor driver) (165/200)
[2021-05-14 11:49:09,047] {docker.py:276} INFO - 21/05/14 14:49:09 INFO Executor: Running task 168.0 in stage 4.0 (TID 740)
[2021-05-14 11:49:09,058] {docker.py:276} INFO - 21/05/14 14:49:09 INFO ShuffleBlockFetcherIterator: Getting 9 (67.3 KiB) non-empty blocks including 9 (67.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:49:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:49:09,067] {docker.py:276} INFO - 21/05/14 14:49:09 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:49:09 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/05/14 14:49:09 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
21/05/14 14:49:09 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443466423204213619852123_0004_m_000168_740, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443466423204213619852123_0004_m_000168_740}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443466423204213619852123_0004}; taskId=attempt_202105141443466423204213619852123_0004_m_000168_740, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@58c3977b}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
21/05/14 14:49:09 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
21/05/14 14:49:09 INFO StagingCommitter: Starting: Task committer attempt_202105141443466423204213619852123_0004_m_000168_740: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443466423204213619852123_0004_m_000168_740
[2021-05-14 11:49:09,071] {docker.py:276} INFO - 21/05/14 14:49:09 INFO StagingCommitter: Task committer attempt_202105141443466423204213619852123_0004_m_000168_740: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443466423204213619852123_0004_m_000168_740 : duration 0:00.004s
[2021-05-14 11:49:09,165] {docker.py:276} INFO - 21/05/14 14:49:09 INFO StagingCommitter: Starting: Task committer attempt_202105141443463398807617392536152_0004_m_000164_736: needsTaskCommit() Task attempt_202105141443463398807617392536152_0004_m_000164_736
[2021-05-14 11:49:09,165] {docker.py:276} INFO - 21/05/14 14:49:09 INFO StagingCommitter: Task committer attempt_202105141443463398807617392536152_0004_m_000164_736: needsTaskCommit() Task attempt_202105141443463398807617392536152_0004_m_000164_736: duration 0:00.001s
21/05/14 14:49:09 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443463398807617392536152_0004_m_000164_736
[2021-05-14 11:49:09,166] {docker.py:276} INFO - 21/05/14 14:49:09 INFO Executor: Finished task 164.0 in stage 4.0 (TID 736). 5106 bytes result sent to driver
[2021-05-14 11:49:09,167] {docker.py:276} INFO - 21/05/14 14:49:09 INFO TaskSetManager: Starting task 169.0 in stage 4.0 (TID 741) (f0b8ef7ba22f, executor driver, partition 169, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:49:09,167] {docker.py:276} INFO - 21/05/14 14:49:09 INFO Executor: Running task 169.0 in stage 4.0 (TID 741)
[2021-05-14 11:49:09,168] {docker.py:276} INFO - 21/05/14 14:49:09 INFO TaskSetManager: Finished task 164.0 in stage 4.0 (TID 736) in 6619 ms on f0b8ef7ba22f (executor driver) (166/200)
[2021-05-14 11:49:09,175] {docker.py:276} INFO - 21/05/14 14:49:09 INFO ShuffleBlockFetcherIterator: Getting 9 (66.0 KiB) non-empty blocks including 9 (66.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:49:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:49:09,183] {docker.py:276} INFO - 21/05/14 14:49:09 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:49:09 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/05/14 14:49:09 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
21/05/14 14:49:09 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443461070353109369864704_0004_m_000169_741, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443461070353109369864704_0004_m_000169_741}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443461070353109369864704_0004}; taskId=attempt_202105141443461070353109369864704_0004_m_000169_741, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@d56000d}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
21/05/14 14:49:09 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
21/05/14 14:49:09 INFO StagingCommitter: Starting: Task committer attempt_202105141443461070353109369864704_0004_m_000169_741: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443461070353109369864704_0004_m_000169_741
[2021-05-14 11:49:09,187] {docker.py:276} INFO - 21/05/14 14:49:09 INFO StagingCommitter: Task committer attempt_202105141443461070353109369864704_0004_m_000169_741: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443461070353109369864704_0004_m_000169_741 : duration 0:00.004s
[2021-05-14 11:49:15,358] {docker.py:276} INFO - 21/05/14 14:49:15 INFO StagingCommitter: Starting: Task committer attempt_202105141443468875300781377618930_0004_m_000166_738: needsTaskCommit() Task attempt_202105141443468875300781377618930_0004_m_000166_738
[2021-05-14 11:49:15,360] {docker.py:276} INFO - 21/05/14 14:49:15 INFO StagingCommitter: Task committer attempt_202105141443468875300781377618930_0004_m_000166_738: needsTaskCommit() Task attempt_202105141443468875300781377618930_0004_m_000166_738: duration 0:00.002s
21/05/14 14:49:15 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443468875300781377618930_0004_m_000166_738
[2021-05-14 11:49:15,360] {docker.py:276} INFO - 21/05/14 14:49:15 INFO Executor: Finished task 166.0 in stage 4.0 (TID 738). 5106 bytes result sent to driver
[2021-05-14 11:49:15,361] {docker.py:276} INFO - 21/05/14 14:49:15 INFO TaskSetManager: Starting task 170.0 in stage 4.0 (TID 742) (f0b8ef7ba22f, executor driver, partition 170, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:49:15,362] {docker.py:276} INFO - 21/05/14 14:49:15 INFO Executor: Running task 170.0 in stage 4.0 (TID 742)
21/05/14 14:49:15 INFO TaskSetManager: Finished task 166.0 in stage 4.0 (TID 738) in 6787 ms on f0b8ef7ba22f (executor driver) (167/200)
[2021-05-14 11:49:15,370] {docker.py:276} INFO - 21/05/14 14:49:15 INFO ShuffleBlockFetcherIterator: Getting 9 (67.2 KiB) non-empty blocks including 9 (67.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:49:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:49:15,378] {docker.py:276} INFO - 21/05/14 14:49:15 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:49:15 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/05/14 14:49:15 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
21/05/14 14:49:15 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443464501773890415107094_0004_m_000170_742, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443464501773890415107094_0004_m_000170_742}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443464501773890415107094_0004}; taskId=attempt_202105141443464501773890415107094_0004_m_000170_742, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@6ef76e84}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
21/05/14 14:49:15 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
21/05/14 14:49:15 INFO StagingCommitter: Starting: Task committer attempt_202105141443464501773890415107094_0004_m_000170_742: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443464501773890415107094_0004_m_000170_742
[2021-05-14 11:49:15,382] {docker.py:276} INFO - 21/05/14 14:49:15 INFO StagingCommitter: Task committer attempt_202105141443464501773890415107094_0004_m_000170_742: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443464501773890415107094_0004_m_000170_742 : duration 0:00.004s
[2021-05-14 11:49:15,853] {docker.py:276} INFO - 21/05/14 14:49:15 INFO StagingCommitter: Starting: Task committer attempt_202105141443461070353109369864704_0004_m_000169_741: needsTaskCommit() Task attempt_202105141443461070353109369864704_0004_m_000169_741
21/05/14 14:49:15 INFO StagingCommitter: Task committer attempt_202105141443461070353109369864704_0004_m_000169_741: needsTaskCommit() Task attempt_202105141443461070353109369864704_0004_m_000169_741: duration 0:00.002s
[2021-05-14 11:49:15,854] {docker.py:276} INFO - 21/05/14 14:49:15 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443461070353109369864704_0004_m_000169_741
[2021-05-14 11:49:15,855] {docker.py:276} INFO - 21/05/14 14:49:15 INFO Executor: Finished task 169.0 in stage 4.0 (TID 741). 5106 bytes result sent to driver
[2021-05-14 11:49:15,857] {docker.py:276} INFO - 21/05/14 14:49:15 INFO TaskSetManager: Starting task 171.0 in stage 4.0 (TID 743) (f0b8ef7ba22f, executor driver, partition 171, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:49:15,857] {docker.py:276} INFO - 21/05/14 14:49:15 INFO Executor: Running task 171.0 in stage 4.0 (TID 743)
21/05/14 14:49:15 INFO TaskSetManager: Finished task 169.0 in stage 4.0 (TID 741) in 6698 ms on f0b8ef7ba22f (executor driver) (168/200)
[2021-05-14 11:49:15,866] {docker.py:276} INFO - 21/05/14 14:49:15 INFO ShuffleBlockFetcherIterator: Getting 9 (66.6 KiB) non-empty blocks including 9 (66.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:49:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:49:15,873] {docker.py:276} INFO - 21/05/14 14:49:15 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:49:15 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/05/14 14:49:15 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
21/05/14 14:49:15 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_20210514144346830728633139065010_0004_m_000171_743, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_20210514144346830728633139065010_0004_m_000171_743}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_20210514144346830728633139065010_0004}; taskId=attempt_20210514144346830728633139065010_0004_m_000171_743, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@355b03fb}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
[2021-05-14 11:49:15,874] {docker.py:276} INFO - 21/05/14 14:49:15 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
21/05/14 14:49:15 INFO StagingCommitter: Starting: Task committer attempt_20210514144346830728633139065010_0004_m_000171_743: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_20210514144346830728633139065010_0004_m_000171_743
[2021-05-14 11:49:15,877] {docker.py:276} INFO - 21/05/14 14:49:15 INFO StagingCommitter: Task committer attempt_20210514144346830728633139065010_0004_m_000171_743: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_20210514144346830728633139065010_0004_m_000171_743 : duration 0:00.004s
[2021-05-14 11:49:15,965] {docker.py:276} INFO - 21/05/14 14:49:15 INFO StagingCommitter: Starting: Task committer attempt_202105141443466423204213619852123_0004_m_000168_740: needsTaskCommit() Task attempt_202105141443466423204213619852123_0004_m_000168_740
[2021-05-14 11:49:15,965] {docker.py:276} INFO - 21/05/14 14:49:15 INFO StagingCommitter: Task committer attempt_202105141443466423204213619852123_0004_m_000168_740: needsTaskCommit() Task attempt_202105141443466423204213619852123_0004_m_000168_740: duration 0:00.001s
21/05/14 14:49:15 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443466423204213619852123_0004_m_000168_740
[2021-05-14 11:49:15,968] {docker.py:276} INFO - 21/05/14 14:49:15 INFO Executor: Finished task 168.0 in stage 4.0 (TID 740). 5106 bytes result sent to driver
[2021-05-14 11:49:15,969] {docker.py:276} INFO - 21/05/14 14:49:15 INFO TaskSetManager: Starting task 172.0 in stage 4.0 (TID 744) (f0b8ef7ba22f, executor driver, partition 172, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
21/05/14 14:49:15 INFO Executor: Running task 172.0 in stage 4.0 (TID 744)
21/05/14 14:49:15 INFO TaskSetManager: Finished task 168.0 in stage 4.0 (TID 740) in 6932 ms on f0b8ef7ba22f (executor driver) (169/200)
[2021-05-14 11:49:15,977] {docker.py:276} INFO - 21/05/14 14:49:15 INFO ShuffleBlockFetcherIterator: Getting 9 (66.2 KiB) non-empty blocks including 9 (66.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:49:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:49:15,986] {docker.py:276} INFO - 21/05/14 14:49:15 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:49:15 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/05/14 14:49:15 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
[2021-05-14 11:49:15,986] {docker.py:276} INFO - 21/05/14 14:49:15 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443468088219218312159534_0004_m_000172_744, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443468088219218312159534_0004_m_000172_744}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443468088219218312159534_0004}; taskId=attempt_202105141443468088219218312159534_0004_m_000172_744, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@50605c6d}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
21/05/14 14:49:15 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
21/05/14 14:49:15 INFO StagingCommitter: Starting: Task committer attempt_202105141443468088219218312159534_0004_m_000172_744: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443468088219218312159534_0004_m_000172_744
[2021-05-14 11:49:15,991] {docker.py:276} INFO - 21/05/14 14:49:15 INFO StagingCommitter: Task committer attempt_202105141443468088219218312159534_0004_m_000172_744: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443468088219218312159534_0004_m_000172_744 : duration 0:00.004s
[2021-05-14 11:49:16,436] {docker.py:276} INFO - 21/05/14 14:49:16 INFO StagingCommitter: Starting: Task committer attempt_202105141443467745228487823750116_0004_m_000167_739: needsTaskCommit() Task attempt_202105141443467745228487823750116_0004_m_000167_739
[2021-05-14 11:49:16,437] {docker.py:276} INFO - 21/05/14 14:49:16 INFO StagingCommitter: Task committer attempt_202105141443467745228487823750116_0004_m_000167_739: needsTaskCommit() Task attempt_202105141443467745228487823750116_0004_m_000167_739: duration 0:00.001s
21/05/14 14:49:16 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443467745228487823750116_0004_m_000167_739
[2021-05-14 11:49:16,438] {docker.py:276} INFO - 21/05/14 14:49:16 INFO Executor: Finished task 167.0 in stage 4.0 (TID 739). 5106 bytes result sent to driver
[2021-05-14 11:49:16,440] {docker.py:276} INFO - 21/05/14 14:49:16 INFO TaskSetManager: Starting task 173.0 in stage 4.0 (TID 745) (f0b8ef7ba22f, executor driver, partition 173, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
21/05/14 14:49:16 INFO Executor: Running task 173.0 in stage 4.0 (TID 745)
[2021-05-14 11:49:16,441] {docker.py:276} INFO - 21/05/14 14:49:16 INFO TaskSetManager: Finished task 167.0 in stage 4.0 (TID 739) in 7588 ms on f0b8ef7ba22f (executor driver) (170/200)
[2021-05-14 11:49:16,450] {docker.py:276} INFO - 21/05/14 14:49:16 INFO ShuffleBlockFetcherIterator: Getting 9 (67.2 KiB) non-empty blocks including 9 (67.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:49:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:49:16,459] {docker.py:276} INFO - 21/05/14 14:49:16 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:49:16 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2021-05-14 11:49:16,459] {docker.py:276} INFO - 21/05/14 14:49:16 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
[2021-05-14 11:49:16,460] {docker.py:276} INFO - 21/05/14 14:49:16 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443467322451912206110435_0004_m_000173_745, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443467322451912206110435_0004_m_000173_745}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443467322451912206110435_0004}; taskId=attempt_202105141443467322451912206110435_0004_m_000173_745, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@2262530b}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
21/05/14 14:49:16 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
21/05/14 14:49:16 INFO StagingCommitter: Starting: Task committer attempt_202105141443467322451912206110435_0004_m_000173_745: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443467322451912206110435_0004_m_000173_745
[2021-05-14 11:49:16,465] {docker.py:276} INFO - 21/05/14 14:49:16 INFO StagingCommitter: Task committer attempt_202105141443467322451912206110435_0004_m_000173_745: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443467322451912206110435_0004_m_000173_745 : duration 0:00.005s
[2021-05-14 11:49:21,774] {docker.py:276} INFO - 21/05/14 14:49:21 INFO StagingCommitter: Starting: Task committer attempt_202105141443468088219218312159534_0004_m_000172_744: needsTaskCommit() Task attempt_202105141443468088219218312159534_0004_m_000172_744
[2021-05-14 11:49:21,775] {docker.py:276} INFO - 21/05/14 14:49:21 INFO StagingCommitter: Task committer attempt_202105141443468088219218312159534_0004_m_000172_744: needsTaskCommit() Task attempt_202105141443468088219218312159534_0004_m_000172_744: duration 0:00.003s
21/05/14 14:49:21 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443468088219218312159534_0004_m_000172_744
[2021-05-14 11:49:21,777] {docker.py:276} INFO - 21/05/14 14:49:21 INFO Executor: Finished task 172.0 in stage 4.0 (TID 744). 5149 bytes result sent to driver
[2021-05-14 11:49:21,780] {docker.py:276} INFO - 21/05/14 14:49:21 INFO TaskSetManager: Starting task 174.0 in stage 4.0 (TID 746) (f0b8ef7ba22f, executor driver, partition 174, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
21/05/14 14:49:21 INFO TaskSetManager: Finished task 172.0 in stage 4.0 (TID 744) in 5818 ms on f0b8ef7ba22f (executor driver) (171/200)
[2021-05-14 11:49:21,780] {docker.py:276} INFO - 21/05/14 14:49:21 INFO Executor: Running task 174.0 in stage 4.0 (TID 746)
[2021-05-14 11:49:21,792] {docker.py:276} INFO - 21/05/14 14:49:21 INFO ShuffleBlockFetcherIterator: Getting 9 (63.4 KiB) non-empty blocks including 9 (63.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
[2021-05-14 11:49:21,793] {docker.py:276} INFO - 21/05/14 14:49:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:49:21,802] {docker.py:276} INFO - 21/05/14 14:49:21 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2021-05-14 11:49:21,802] {docker.py:276} INFO - 21/05/14 14:49:21 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2021-05-14 11:49:21,803] {docker.py:276} INFO - 21/05/14 14:49:21 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
[2021-05-14 11:49:21,803] {docker.py:276} INFO - 21/05/14 14:49:21 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443467580787969518974434_0004_m_000174_746, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443467580787969518974434_0004_m_000174_746}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443467580787969518974434_0004}; taskId=attempt_202105141443467580787969518974434_0004_m_000174_746, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@3913dac1}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
[2021-05-14 11:49:21,804] {docker.py:276} INFO - 21/05/14 14:49:21 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
[2021-05-14 11:49:21,804] {docker.py:276} INFO - 21/05/14 14:49:21 INFO StagingCommitter: Starting: Task committer attempt_202105141443467580787969518974434_0004_m_000174_746: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443467580787969518974434_0004_m_000174_746
[2021-05-14 11:49:21,809] {docker.py:276} INFO - 21/05/14 14:49:21 INFO StagingCommitter: Task committer attempt_202105141443467580787969518974434_0004_m_000174_746: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443467580787969518974434_0004_m_000174_746 : duration 0:00.005s
[2021-05-14 11:49:22,488] {docker.py:276} INFO - 21/05/14 14:49:22 INFO StagingCommitter: Starting: Task committer attempt_202105141443464501773890415107094_0004_m_000170_742: needsTaskCommit() Task attempt_202105141443464501773890415107094_0004_m_000170_742
[2021-05-14 11:49:22,489] {docker.py:276} INFO - 21/05/14 14:49:22 INFO StagingCommitter: Task committer attempt_202105141443464501773890415107094_0004_m_000170_742: needsTaskCommit() Task attempt_202105141443464501773890415107094_0004_m_000170_742: duration 0:00.002s
21/05/14 14:49:22 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443464501773890415107094_0004_m_000170_742
[2021-05-14 11:49:22,491] {docker.py:276} INFO - 21/05/14 14:49:22 INFO Executor: Finished task 170.0 in stage 4.0 (TID 742). 5149 bytes result sent to driver
[2021-05-14 11:49:22,492] {docker.py:276} INFO - 21/05/14 14:49:22 INFO TaskSetManager: Starting task 175.0 in stage 4.0 (TID 747) (f0b8ef7ba22f, executor driver, partition 175, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:49:22,492] {docker.py:276} INFO - 21/05/14 14:49:22 INFO TaskSetManager: Finished task 170.0 in stage 4.0 (TID 742) in 7141 ms on f0b8ef7ba22f (executor driver) (172/200)
[2021-05-14 11:49:22,493] {docker.py:276} INFO - 21/05/14 14:49:22 INFO Executor: Running task 175.0 in stage 4.0 (TID 747)
[2021-05-14 11:49:22,502] {docker.py:276} INFO - 21/05/14 14:49:22 INFO ShuffleBlockFetcherIterator: Getting 9 (65.0 KiB) non-empty blocks including 9 (65.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:49:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:49:22,510] {docker.py:276} INFO - 21/05/14 14:49:22 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:49:22 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/05/14 14:49:22 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
21/05/14 14:49:22 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_20210514144346557897114980199297_0004_m_000175_747, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_20210514144346557897114980199297_0004_m_000175_747}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_20210514144346557897114980199297_0004}; taskId=attempt_20210514144346557897114980199297_0004_m_000175_747, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@17aaa556}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
21/05/14 14:49:22 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
21/05/14 14:49:22 INFO StagingCommitter: Starting: Task committer attempt_20210514144346557897114980199297_0004_m_000175_747: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_20210514144346557897114980199297_0004_m_000175_747
[2021-05-14 11:49:22,514] {docker.py:276} INFO - 21/05/14 14:49:22 INFO StagingCommitter: Task committer attempt_20210514144346557897114980199297_0004_m_000175_747: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_20210514144346557897114980199297_0004_m_000175_747 : duration 0:00.004s
[2021-05-14 11:49:23,034] {docker.py:276} INFO - 21/05/14 14:49:23 INFO StagingCommitter: Starting: Task committer attempt_20210514144346830728633139065010_0004_m_000171_743: needsTaskCommit() Task attempt_20210514144346830728633139065010_0004_m_000171_743
21/05/14 14:49:23 INFO StagingCommitter: Task committer attempt_20210514144346830728633139065010_0004_m_000171_743: needsTaskCommit() Task attempt_20210514144346830728633139065010_0004_m_000171_743: duration 0:00.001s
21/05/14 14:49:23 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_20210514144346830728633139065010_0004_m_000171_743
[2021-05-14 11:49:23,036] {docker.py:276} INFO - 21/05/14 14:49:23 INFO Executor: Finished task 171.0 in stage 4.0 (TID 743). 5149 bytes result sent to driver
[2021-05-14 11:49:23,037] {docker.py:276} INFO - 21/05/14 14:49:23 INFO TaskSetManager: Starting task 176.0 in stage 4.0 (TID 748) (f0b8ef7ba22f, executor driver, partition 176, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:49:23,038] {docker.py:276} INFO - 21/05/14 14:49:23 INFO Executor: Running task 176.0 in stage 4.0 (TID 748)
[2021-05-14 11:49:23,039] {docker.py:276} INFO - 21/05/14 14:49:23 INFO TaskSetManager: Finished task 171.0 in stage 4.0 (TID 743) in 7191 ms on f0b8ef7ba22f (executor driver) (173/200)
[2021-05-14 11:49:23,047] {docker.py:276} INFO - 21/05/14 14:49:23 INFO ShuffleBlockFetcherIterator: Getting 9 (67.5 KiB) non-empty blocks including 9 (67.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:49:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:49:23,057] {docker.py:276} INFO - 21/05/14 14:49:23 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:49:23 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/05/14 14:49:23 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
[2021-05-14 11:49:23,057] {docker.py:276} INFO - 21/05/14 14:49:23 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443464325969304739748003_0004_m_000176_748, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443464325969304739748003_0004_m_000176_748}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443464325969304739748003_0004}; taskId=attempt_202105141443464325969304739748003_0004_m_000176_748, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@5e829868}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
21/05/14 14:49:23 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
21/05/14 14:49:23 INFO StagingCommitter: Starting: Task committer attempt_202105141443464325969304739748003_0004_m_000176_748: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443464325969304739748003_0004_m_000176_748
[2021-05-14 11:49:23,061] {docker.py:276} INFO - 21/05/14 14:49:23 INFO StagingCommitter: Task committer attempt_202105141443464325969304739748003_0004_m_000176_748: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443464325969304739748003_0004_m_000176_748 : duration 0:00.004s
[2021-05-14 11:49:23,326] {docker.py:276} INFO - 21/05/14 14:49:23 INFO StagingCommitter: Starting: Task committer attempt_202105141443467322451912206110435_0004_m_000173_745: needsTaskCommit() Task attempt_202105141443467322451912206110435_0004_m_000173_745
[2021-05-14 11:49:23,326] {docker.py:276} INFO - 21/05/14 14:49:23 INFO StagingCommitter: Task committer attempt_202105141443467322451912206110435_0004_m_000173_745: needsTaskCommit() Task attempt_202105141443467322451912206110435_0004_m_000173_745: duration 0:00.001s
21/05/14 14:49:23 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443467322451912206110435_0004_m_000173_745
[2021-05-14 11:49:23,327] {docker.py:276} INFO - 21/05/14 14:49:23 INFO Executor: Finished task 173.0 in stage 4.0 (TID 745). 5149 bytes result sent to driver
[2021-05-14 11:49:23,327] {docker.py:276} INFO - 21/05/14 14:49:23 INFO TaskSetManager: Starting task 177.0 in stage 4.0 (TID 749) (f0b8ef7ba22f, executor driver, partition 177, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:49:23,328] {docker.py:276} INFO - 21/05/14 14:49:23 INFO Executor: Running task 177.0 in stage 4.0 (TID 749)
[2021-05-14 11:49:23,329] {docker.py:276} INFO - 21/05/14 14:49:23 INFO TaskSetManager: Finished task 173.0 in stage 4.0 (TID 745) in 6898 ms on f0b8ef7ba22f (executor driver) (174/200)
[2021-05-14 11:49:23,335] {docker.py:276} INFO - 21/05/14 14:49:23 INFO ShuffleBlockFetcherIterator: Getting 9 (64.1 KiB) non-empty blocks including 9 (64.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:49:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:49:23,343] {docker.py:276} INFO - 21/05/14 14:49:23 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2021-05-14 11:49:23,344] {docker.py:276} INFO - 21/05/14 14:49:23 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2021-05-14 11:49:23,344] {docker.py:276} INFO - 21/05/14 14:49:23 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
21/05/14 14:49:23 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443465937451823620768983_0004_m_000177_749, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443465937451823620768983_0004_m_000177_749}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443465937451823620768983_0004}; taskId=attempt_202105141443465937451823620768983_0004_m_000177_749, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@60eaaf98}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
[2021-05-14 11:49:23,344] {docker.py:276} INFO - 21/05/14 14:49:23 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
21/05/14 14:49:23 INFO StagingCommitter: Starting: Task committer attempt_202105141443465937451823620768983_0004_m_000177_749: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443465937451823620768983_0004_m_000177_749
[2021-05-14 11:49:23,349] {docker.py:276} INFO - 21/05/14 14:49:23 INFO StagingCommitter: Task committer attempt_202105141443465937451823620768983_0004_m_000177_749: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443465937451823620768983_0004_m_000177_749 : duration 0:00.005s
[2021-05-14 11:49:28,265] {docker.py:276} INFO - 21/05/14 14:49:28 INFO StagingCommitter: Starting: Task committer attempt_202105141443467580787969518974434_0004_m_000174_746: needsTaskCommit() Task attempt_202105141443467580787969518974434_0004_m_000174_746
[2021-05-14 11:49:28,266] {docker.py:276} INFO - 21/05/14 14:49:28 INFO StagingCommitter: Task committer attempt_202105141443467580787969518974434_0004_m_000174_746: needsTaskCommit() Task attempt_202105141443467580787969518974434_0004_m_000174_746: duration 0:00.002s
[2021-05-14 11:49:28,267] {docker.py:276} INFO - 21/05/14 14:49:28 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443467580787969518974434_0004_m_000174_746
[2021-05-14 11:49:28,269] {docker.py:276} INFO - 21/05/14 14:49:28 INFO Executor: Finished task 174.0 in stage 4.0 (TID 746). 5106 bytes result sent to driver
[2021-05-14 11:49:28,270] {docker.py:276} INFO - 21/05/14 14:49:28 INFO TaskSetManager: Starting task 178.0 in stage 4.0 (TID 750) (f0b8ef7ba22f, executor driver, partition 178, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:49:28,270] {docker.py:276} INFO - 21/05/14 14:49:28 INFO TaskSetManager: Finished task 174.0 in stage 4.0 (TID 746) in 6500 ms on f0b8ef7ba22f (executor driver) (175/200)
[2021-05-14 11:49:28,271] {docker.py:276} INFO - 21/05/14 14:49:28 INFO Executor: Running task 178.0 in stage 4.0 (TID 750)
[2021-05-14 11:49:28,280] {docker.py:276} INFO - 21/05/14 14:49:28 INFO ShuffleBlockFetcherIterator: Getting 9 (64.0 KiB) non-empty blocks including 9 (64.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:49:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:49:28,289] {docker.py:276} INFO - 21/05/14 14:49:28 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:49:28 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/05/14 14:49:28 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
21/05/14 14:49:28 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443464080561842378184331_0004_m_000178_750, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443464080561842378184331_0004_m_000178_750}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443464080561842378184331_0004}; taskId=attempt_202105141443464080561842378184331_0004_m_000178_750, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@3fc28538}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
21/05/14 14:49:28 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
21/05/14 14:49:28 INFO StagingCommitter: Starting: Task committer attempt_202105141443464080561842378184331_0004_m_000178_750: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443464080561842378184331_0004_m_000178_750
[2021-05-14 11:49:28,293] {docker.py:276} INFO - 21/05/14 14:49:28 INFO StagingCommitter: Task committer attempt_202105141443464080561842378184331_0004_m_000178_750: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443464080561842378184331_0004_m_000178_750 : duration 0:00.004s
[2021-05-14 11:49:29,554] {docker.py:276} INFO - 21/05/14 14:49:29 INFO StagingCommitter: Starting: Task committer attempt_20210514144346557897114980199297_0004_m_000175_747: needsTaskCommit() Task attempt_20210514144346557897114980199297_0004_m_000175_747
21/05/14 14:49:29 INFO StagingCommitter: Task committer attempt_20210514144346557897114980199297_0004_m_000175_747: needsTaskCommit() Task attempt_20210514144346557897114980199297_0004_m_000175_747: duration 0:00.002s
21/05/14 14:49:29 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_20210514144346557897114980199297_0004_m_000175_747
[2021-05-14 11:49:29,555] {docker.py:276} INFO - 21/05/14 14:49:29 INFO Executor: Finished task 175.0 in stage 4.0 (TID 747). 5106 bytes result sent to driver
[2021-05-14 11:49:29,557] {docker.py:276} INFO - 21/05/14 14:49:29 INFO TaskSetManager: Starting task 179.0 in stage 4.0 (TID 751) (f0b8ef7ba22f, executor driver, partition 179, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:49:29,558] {docker.py:276} INFO - 21/05/14 14:49:29 INFO Executor: Running task 179.0 in stage 4.0 (TID 751)
[2021-05-14 11:49:29,559] {docker.py:276} INFO - 21/05/14 14:49:29 INFO TaskSetManager: Finished task 175.0 in stage 4.0 (TID 747) in 7075 ms on f0b8ef7ba22f (executor driver) (176/200)
[2021-05-14 11:49:29,568] {docker.py:276} INFO - 21/05/14 14:49:29 INFO ShuffleBlockFetcherIterator: Getting 9 (66.5 KiB) non-empty blocks including 9 (66.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
[2021-05-14 11:49:29,569] {docker.py:276} INFO - 21/05/14 14:49:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:49:29,577] {docker.py:276} INFO - 21/05/14 14:49:29 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:49:29 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/05/14 14:49:29 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
21/05/14 14:49:29 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443461974875120268759929_0004_m_000179_751, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443461974875120268759929_0004_m_000179_751}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443461974875120268759929_0004}; taskId=attempt_202105141443461974875120268759929_0004_m_000179_751, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@181887e}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
[2021-05-14 11:49:29,577] {docker.py:276} INFO - 21/05/14 14:49:29 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
[2021-05-14 11:49:29,578] {docker.py:276} INFO - 21/05/14 14:49:29 INFO StagingCommitter: Starting: Task committer attempt_202105141443461974875120268759929_0004_m_000179_751: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443461974875120268759929_0004_m_000179_751
[2021-05-14 11:49:29,582] {docker.py:276} INFO - 21/05/14 14:49:29 INFO StagingCommitter: Task committer attempt_202105141443461974875120268759929_0004_m_000179_751: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443461974875120268759929_0004_m_000179_751 : duration 0:00.004s
[2021-05-14 11:49:30,495] {docker.py:276} INFO - 21/05/14 14:49:30 INFO StagingCommitter: Starting: Task committer attempt_202105141443464325969304739748003_0004_m_000176_748: needsTaskCommit() Task attempt_202105141443464325969304739748003_0004_m_000176_748
[2021-05-14 11:49:30,496] {docker.py:276} INFO - 21/05/14 14:49:30 INFO StagingCommitter: Task committer attempt_202105141443464325969304739748003_0004_m_000176_748: needsTaskCommit() Task attempt_202105141443464325969304739748003_0004_m_000176_748: duration 0:00.002s
21/05/14 14:49:30 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443464325969304739748003_0004_m_000176_748
[2021-05-14 11:49:30,497] {docker.py:276} INFO - 21/05/14 14:49:30 INFO Executor: Finished task 176.0 in stage 4.0 (TID 748). 5106 bytes result sent to driver
[2021-05-14 11:49:30,498] {docker.py:276} INFO - 21/05/14 14:49:30 INFO TaskSetManager: Starting task 180.0 in stage 4.0 (TID 752) (f0b8ef7ba22f, executor driver, partition 180, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:49:30,499] {docker.py:276} INFO - 21/05/14 14:49:30 INFO TaskSetManager: Finished task 176.0 in stage 4.0 (TID 748) in 7471 ms on f0b8ef7ba22f (executor driver) (177/200)
21/05/14 14:49:30 INFO Executor: Running task 180.0 in stage 4.0 (TID 752)
[2021-05-14 11:49:30,510] {docker.py:276} INFO - 21/05/14 14:49:30 INFO ShuffleBlockFetcherIterator: Getting 9 (65.0 KiB) non-empty blocks including 9 (65.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:49:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:49:30,521] {docker.py:276} INFO - 21/05/14 14:49:30 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:49:30 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/05/14 14:49:30 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
21/05/14 14:49:30 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443461953512742842360201_0004_m_000180_752, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443461953512742842360201_0004_m_000180_752}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443461953512742842360201_0004}; taskId=attempt_202105141443461953512742842360201_0004_m_000180_752, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@48a7da21}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
[2021-05-14 11:49:30,535] {docker.py:276} INFO - 21/05/14 14:49:30 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
21/05/14 14:49:30 INFO StagingCommitter: Starting: Task committer attempt_202105141443461953512742842360201_0004_m_000180_752: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443461953512742842360201_0004_m_000180_752
[2021-05-14 11:49:30,536] {docker.py:276} INFO - 21/05/14 14:49:30 INFO StagingCommitter: Task committer attempt_202105141443461953512742842360201_0004_m_000180_752: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443461953512742842360201_0004_m_000180_752 : duration 0:00.005s
[2021-05-14 11:49:30,719] {docker.py:276} INFO - 21/05/14 14:49:30 INFO StagingCommitter: Starting: Task committer attempt_202105141443465937451823620768983_0004_m_000177_749: needsTaskCommit() Task attempt_202105141443465937451823620768983_0004_m_000177_749
[2021-05-14 11:49:30,720] {docker.py:276} INFO - 21/05/14 14:49:30 INFO StagingCommitter: Task committer attempt_202105141443465937451823620768983_0004_m_000177_749: needsTaskCommit() Task attempt_202105141443465937451823620768983_0004_m_000177_749: duration 0:00.004s
21/05/14 14:49:30 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443465937451823620768983_0004_m_000177_749
[2021-05-14 11:49:30,721] {docker.py:276} INFO - 21/05/14 14:49:30 INFO Executor: Finished task 177.0 in stage 4.0 (TID 749). 5106 bytes result sent to driver
[2021-05-14 11:49:30,722] {docker.py:276} INFO - 21/05/14 14:49:30 INFO TaskSetManager: Starting task 181.0 in stage 4.0 (TID 753) (f0b8ef7ba22f, executor driver, partition 181, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:49:30,724] {docker.py:276} INFO - 21/05/14 14:49:30 INFO Executor: Running task 181.0 in stage 4.0 (TID 753)
21/05/14 14:49:30 INFO TaskSetManager: Finished task 177.0 in stage 4.0 (TID 749) in 7404 ms on f0b8ef7ba22f (executor driver) (178/200)
[2021-05-14 11:49:30,734] {docker.py:276} INFO - 21/05/14 14:49:30 INFO ShuffleBlockFetcherIterator: Getting 9 (63.9 KiB) non-empty blocks including 9 (63.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:49:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:49:30,742] {docker.py:276} INFO - 21/05/14 14:49:30 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:49:30 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/05/14 14:49:30 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
21/05/14 14:49:30 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443467444488661388395108_0004_m_000181_753, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443467444488661388395108_0004_m_000181_753}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443467444488661388395108_0004}; taskId=attempt_202105141443467444488661388395108_0004_m_000181_753, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@6ccf06c3}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
21/05/14 14:49:30 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
21/05/14 14:49:30 INFO StagingCommitter: Starting: Task committer attempt_202105141443467444488661388395108_0004_m_000181_753: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443467444488661388395108_0004_m_000181_753
[2021-05-14 11:49:30,746] {docker.py:276} INFO - 21/05/14 14:49:30 INFO StagingCommitter: Task committer attempt_202105141443467444488661388395108_0004_m_000181_753: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443467444488661388395108_0004_m_000181_753 : duration 0:00.004s
[2021-05-14 11:49:35,116] {docker.py:276} INFO - 21/05/14 14:49:35 INFO StagingCommitter: Starting: Task committer attempt_202105141443464080561842378184331_0004_m_000178_750: needsTaskCommit() Task attempt_202105141443464080561842378184331_0004_m_000178_750
[2021-05-14 11:49:35,117] {docker.py:276} INFO - 21/05/14 14:49:35 INFO StagingCommitter: Task committer attempt_202105141443464080561842378184331_0004_m_000178_750: needsTaskCommit() Task attempt_202105141443464080561842378184331_0004_m_000178_750: duration 0:00.003s
21/05/14 14:49:35 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443464080561842378184331_0004_m_000178_750
[2021-05-14 11:49:35,119] {docker.py:276} INFO - 21/05/14 14:49:35 INFO Executor: Finished task 178.0 in stage 4.0 (TID 750). 5106 bytes result sent to driver
[2021-05-14 11:49:35,120] {docker.py:276} INFO - 21/05/14 14:49:35 INFO TaskSetManager: Starting task 182.0 in stage 4.0 (TID 754) (f0b8ef7ba22f, executor driver, partition 182, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:49:35,121] {docker.py:276} INFO - 21/05/14 14:49:35 INFO Executor: Running task 182.0 in stage 4.0 (TID 754)
21/05/14 14:49:35 INFO TaskSetManager: Finished task 178.0 in stage 4.0 (TID 750) in 6859 ms on f0b8ef7ba22f (executor driver) (179/200)
[2021-05-14 11:49:35,131] {docker.py:276} INFO - 21/05/14 14:49:35 INFO ShuffleBlockFetcherIterator: Getting 9 (68.2 KiB) non-empty blocks including 9 (68.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:49:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:49:35,141] {docker.py:276} INFO - 21/05/14 14:49:35 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:49:35 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/05/14 14:49:35 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
[2021-05-14 11:49:35,141] {docker.py:276} INFO - 21/05/14 14:49:35 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443463931079519215325983_0004_m_000182_754, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443463931079519215325983_0004_m_000182_754}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443463931079519215325983_0004}; taskId=attempt_202105141443463931079519215325983_0004_m_000182_754, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@3bcea05}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
21/05/14 14:49:35 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
21/05/14 14:49:35 INFO StagingCommitter: Starting: Task committer attempt_202105141443463931079519215325983_0004_m_000182_754: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443463931079519215325983_0004_m_000182_754
[2021-05-14 11:49:35,145] {docker.py:276} INFO - 21/05/14 14:49:35 INFO StagingCommitter: Task committer attempt_202105141443463931079519215325983_0004_m_000182_754: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443463931079519215325983_0004_m_000182_754 : duration 0:00.004s
[2021-05-14 11:49:36,304] {docker.py:276} INFO - 21/05/14 14:49:36 INFO StagingCommitter: Starting: Task committer attempt_202105141443461974875120268759929_0004_m_000179_751: needsTaskCommit() Task attempt_202105141443461974875120268759929_0004_m_000179_751
[2021-05-14 11:49:36,305] {docker.py:276} INFO - 21/05/14 14:49:36 INFO StagingCommitter: Task committer attempt_202105141443461974875120268759929_0004_m_000179_751: needsTaskCommit() Task attempt_202105141443461974875120268759929_0004_m_000179_751: duration 0:00.002s
21/05/14 14:49:36 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443461974875120268759929_0004_m_000179_751
[2021-05-14 11:49:36,307] {docker.py:276} INFO - 21/05/14 14:49:36 INFO Executor: Finished task 179.0 in stage 4.0 (TID 751). 5106 bytes result sent to driver
[2021-05-14 11:49:36,307] {docker.py:276} INFO - 21/05/14 14:49:36 INFO TaskSetManager: Starting task 183.0 in stage 4.0 (TID 755) (f0b8ef7ba22f, executor driver, partition 183, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:49:36,308] {docker.py:276} INFO - 21/05/14 14:49:36 INFO Executor: Running task 183.0 in stage 4.0 (TID 755)
[2021-05-14 11:49:36,309] {docker.py:276} INFO - 21/05/14 14:49:36 INFO TaskSetManager: Finished task 179.0 in stage 4.0 (TID 751) in 6760 ms on f0b8ef7ba22f (executor driver) (180/200)
[2021-05-14 11:49:36,317] {docker.py:276} INFO - 21/05/14 14:49:36 INFO ShuffleBlockFetcherIterator: Getting 9 (66.5 KiB) non-empty blocks including 9 (66.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:49:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:49:36,326] {docker.py:276} INFO - 21/05/14 14:49:36 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:49:36 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/05/14 14:49:36 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
21/05/14 14:49:36 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443468988081991752237213_0004_m_000183_755, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443468988081991752237213_0004_m_000183_755}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443468988081991752237213_0004}; taskId=attempt_202105141443468988081991752237213_0004_m_000183_755, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@742d3c25}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
21/05/14 14:49:36 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
21/05/14 14:49:36 INFO StagingCommitter: Starting: Task committer attempt_202105141443468988081991752237213_0004_m_000183_755: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443468988081991752237213_0004_m_000183_755
[2021-05-14 11:49:36,330] {docker.py:276} INFO - 21/05/14 14:49:36 INFO StagingCommitter: Task committer attempt_202105141443468988081991752237213_0004_m_000183_755: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443468988081991752237213_0004_m_000183_755 : duration 0:00.004s
[2021-05-14 11:49:37,317] {docker.py:276} INFO - 21/05/14 14:49:37 INFO StagingCommitter: Starting: Task committer attempt_202105141443467444488661388395108_0004_m_000181_753: needsTaskCommit() Task attempt_202105141443467444488661388395108_0004_m_000181_753
[2021-05-14 11:49:37,318] {docker.py:276} INFO - 21/05/14 14:49:37 INFO StagingCommitter: Task committer attempt_202105141443467444488661388395108_0004_m_000181_753: needsTaskCommit() Task attempt_202105141443467444488661388395108_0004_m_000181_753: duration 0:00.003s
[2021-05-14 11:49:37,319] {docker.py:276} INFO - 21/05/14 14:49:37 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443467444488661388395108_0004_m_000181_753
[2021-05-14 11:49:37,320] {docker.py:276} INFO - 21/05/14 14:49:37 INFO Executor: Finished task 181.0 in stage 4.0 (TID 753). 5106 bytes result sent to driver
[2021-05-14 11:49:37,321] {docker.py:276} INFO - 21/05/14 14:49:37 INFO TaskSetManager: Starting task 184.0 in stage 4.0 (TID 756) (f0b8ef7ba22f, executor driver, partition 184, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:49:37,322] {docker.py:276} INFO - 21/05/14 14:49:37 INFO TaskSetManager: Finished task 181.0 in stage 4.0 (TID 753) in 6607 ms on f0b8ef7ba22f (executor driver) (181/200)
[2021-05-14 11:49:37,322] {docker.py:276} INFO - 21/05/14 14:49:37 INFO Executor: Running task 184.0 in stage 4.0 (TID 756)
[2021-05-14 11:49:37,331] {docker.py:276} INFO - 21/05/14 14:49:37 INFO ShuffleBlockFetcherIterator: Getting 9 (67.8 KiB) non-empty blocks including 9 (67.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:49:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:49:37,340] {docker.py:276} INFO - 21/05/14 14:49:37 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:49:37 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/05/14 14:49:37 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
21/05/14 14:49:37 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443466146066795882773856_0004_m_000184_756, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443466146066795882773856_0004_m_000184_756}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443466146066795882773856_0004}; taskId=attempt_202105141443466146066795882773856_0004_m_000184_756, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@371a6d06}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
21/05/14 14:49:37 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
21/05/14 14:49:37 INFO StagingCommitter: Starting: Task committer attempt_202105141443466146066795882773856_0004_m_000184_756: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443466146066795882773856_0004_m_000184_756
[2021-05-14 11:49:37,345] {docker.py:276} INFO - 21/05/14 14:49:37 INFO StagingCommitter: Task committer attempt_202105141443466146066795882773856_0004_m_000184_756: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443466146066795882773856_0004_m_000184_756 : duration 0:00.004s
[2021-05-14 11:49:37,399] {docker.py:276} INFO - 21/05/14 14:49:37 INFO StagingCommitter: Starting: Task committer attempt_202105141443461953512742842360201_0004_m_000180_752: needsTaskCommit() Task attempt_202105141443461953512742842360201_0004_m_000180_752
[2021-05-14 11:49:37,400] {docker.py:276} INFO - 21/05/14 14:49:37 INFO StagingCommitter: Task committer attempt_202105141443461953512742842360201_0004_m_000180_752: needsTaskCommit() Task attempt_202105141443461953512742842360201_0004_m_000180_752: duration 0:00.002s
21/05/14 14:49:37 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443461953512742842360201_0004_m_000180_752
[2021-05-14 11:49:37,401] {docker.py:276} INFO - 21/05/14 14:49:37 INFO Executor: Finished task 180.0 in stage 4.0 (TID 752). 5106 bytes result sent to driver
[2021-05-14 11:49:37,403] {docker.py:276} INFO - 21/05/14 14:49:37 INFO TaskSetManager: Starting task 185.0 in stage 4.0 (TID 757) (f0b8ef7ba22f, executor driver, partition 185, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:49:37,404] {docker.py:276} INFO - 21/05/14 14:49:37 INFO Executor: Running task 185.0 in stage 4.0 (TID 757)
[2021-05-14 11:49:37,405] {docker.py:276} INFO - 21/05/14 14:49:37 INFO TaskSetManager: Finished task 180.0 in stage 4.0 (TID 752) in 6915 ms on f0b8ef7ba22f (executor driver) (182/200)
[2021-05-14 11:49:37,413] {docker.py:276} INFO - 21/05/14 14:49:37 INFO ShuffleBlockFetcherIterator: Getting 9 (65.2 KiB) non-empty blocks including 9 (65.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:49:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:49:37,421] {docker.py:276} INFO - 21/05/14 14:49:37 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:49:37 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/05/14 14:49:37 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
21/05/14 14:49:37 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443463867269863880688851_0004_m_000185_757, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443463867269863880688851_0004_m_000185_757}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443463867269863880688851_0004}; taskId=attempt_202105141443463867269863880688851_0004_m_000185_757, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@2b854277}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
21/05/14 14:49:37 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
21/05/14 14:49:37 INFO StagingCommitter: Starting: Task committer attempt_202105141443463867269863880688851_0004_m_000185_757: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443463867269863880688851_0004_m_000185_757
[2021-05-14 11:49:37,425] {docker.py:276} INFO - 21/05/14 14:49:37 INFO StagingCommitter: Task committer attempt_202105141443463867269863880688851_0004_m_000185_757: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443463867269863880688851_0004_m_000185_757 : duration 0:00.003s
[2021-05-14 11:49:41,470] {docker.py:276} INFO - 21/05/14 14:49:41 INFO StagingCommitter: Starting: Task committer attempt_202105141443463931079519215325983_0004_m_000182_754: needsTaskCommit() Task attempt_202105141443463931079519215325983_0004_m_000182_754
[2021-05-14 11:49:41,471] {docker.py:276} INFO - 21/05/14 14:49:41 INFO StagingCommitter: Task committer attempt_202105141443463931079519215325983_0004_m_000182_754: needsTaskCommit() Task attempt_202105141443463931079519215325983_0004_m_000182_754: duration 0:00.003s
21/05/14 14:49:41 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443463931079519215325983_0004_m_000182_754
[2021-05-14 11:49:41,473] {docker.py:276} INFO - 21/05/14 14:49:41 INFO Executor: Finished task 182.0 in stage 4.0 (TID 754). 5106 bytes result sent to driver
[2021-05-14 11:49:41,474] {docker.py:276} INFO - 21/05/14 14:49:41 INFO TaskSetManager: Starting task 186.0 in stage 4.0 (TID 758) (f0b8ef7ba22f, executor driver, partition 186, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:49:41,475] {docker.py:276} INFO - 21/05/14 14:49:41 INFO TaskSetManager: Finished task 182.0 in stage 4.0 (TID 754) in 6328 ms on f0b8ef7ba22f (executor driver) (183/200)
21/05/14 14:49:41 INFO Executor: Running task 186.0 in stage 4.0 (TID 758)
[2021-05-14 11:49:41,484] {docker.py:276} INFO - 21/05/14 14:49:41 INFO ShuffleBlockFetcherIterator: Getting 9 (66.3 KiB) non-empty blocks including 9 (66.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:49:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:49:41,492] {docker.py:276} INFO - 21/05/14 14:49:41 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2021-05-14 11:49:41,493] {docker.py:276} INFO - 21/05/14 14:49:41 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2021-05-14 11:49:41,493] {docker.py:276} INFO - 21/05/14 14:49:41 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
[2021-05-14 11:49:41,494] {docker.py:276} INFO - 21/05/14 14:49:41 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443466714573880090228778_0004_m_000186_758, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443466714573880090228778_0004_m_000186_758}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443466714573880090228778_0004}; taskId=attempt_202105141443466714573880090228778_0004_m_000186_758, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@2db903e}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
[2021-05-14 11:49:41,494] {docker.py:276} INFO - 21/05/14 14:49:41 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
[2021-05-14 11:49:41,495] {docker.py:276} INFO - 21/05/14 14:49:41 INFO StagingCommitter: Starting: Task committer attempt_202105141443466714573880090228778_0004_m_000186_758: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443466714573880090228778_0004_m_000186_758
[2021-05-14 11:49:41,499] {docker.py:276} INFO - 21/05/14 14:49:41 INFO StagingCommitter: Task committer attempt_202105141443466714573880090228778_0004_m_000186_758: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443466714573880090228778_0004_m_000186_758 : duration 0:00.005s
[2021-05-14 11:49:43,392] {docker.py:276} INFO - 21/05/14 14:49:43 INFO StagingCommitter: Starting: Task committer attempt_202105141443466146066795882773856_0004_m_000184_756: needsTaskCommit() Task attempt_202105141443466146066795882773856_0004_m_000184_756
[2021-05-14 11:49:43,393] {docker.py:276} INFO - 21/05/14 14:49:43 INFO StagingCommitter: Task committer attempt_202105141443466146066795882773856_0004_m_000184_756: needsTaskCommit() Task attempt_202105141443466146066795882773856_0004_m_000184_756: duration 0:00.002s
21/05/14 14:49:43 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443466146066795882773856_0004_m_000184_756
[2021-05-14 11:49:43,394] {docker.py:276} INFO - 21/05/14 14:49:43 INFO Executor: Finished task 184.0 in stage 4.0 (TID 756). 5106 bytes result sent to driver
[2021-05-14 11:49:43,409] {docker.py:276} INFO - 21/05/14 14:49:43 INFO TaskSetManager: Starting task 187.0 in stage 4.0 (TID 759) (f0b8ef7ba22f, executor driver, partition 187, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:49:43,410] {docker.py:276} INFO - 21/05/14 14:49:43 INFO Executor: Running task 187.0 in stage 4.0 (TID 759)
21/05/14 14:49:43 INFO TaskSetManager: Finished task 184.0 in stage 4.0 (TID 756) in 6062 ms on f0b8ef7ba22f (executor driver) (184/200)
[2021-05-14 11:49:43,417] {docker.py:276} INFO - 21/05/14 14:49:43 INFO ShuffleBlockFetcherIterator: Getting 9 (67.4 KiB) non-empty blocks including 9 (67.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:49:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:49:43,426] {docker.py:276} INFO - 21/05/14 14:49:43 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:49:43 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/05/14 14:49:43 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
21/05/14 14:49:43 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443461928015279678854718_0004_m_000187_759, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443461928015279678854718_0004_m_000187_759}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443461928015279678854718_0004}; taskId=attempt_202105141443461928015279678854718_0004_m_000187_759, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@5b922e41}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
[2021-05-14 11:49:43,427] {docker.py:276} INFO - 21/05/14 14:49:43 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
21/05/14 14:49:43 INFO StagingCommitter: Starting: Task committer attempt_202105141443461928015279678854718_0004_m_000187_759: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443461928015279678854718_0004_m_000187_759
[2021-05-14 11:49:43,430] {docker.py:276} INFO - 21/05/14 14:49:43 INFO StagingCommitter: Task committer attempt_202105141443461928015279678854718_0004_m_000187_759: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443461928015279678854718_0004_m_000187_759 : duration 0:00.004s
[2021-05-14 11:49:43,674] {docker.py:276} INFO - 21/05/14 14:49:43 INFO StagingCommitter: Starting: Task committer attempt_202105141443468988081991752237213_0004_m_000183_755: needsTaskCommit() Task attempt_202105141443468988081991752237213_0004_m_000183_755
[2021-05-14 11:49:43,675] {docker.py:276} INFO - 21/05/14 14:49:43 INFO StagingCommitter: Task committer attempt_202105141443468988081991752237213_0004_m_000183_755: needsTaskCommit() Task attempt_202105141443468988081991752237213_0004_m_000183_755: duration 0:00.004s
21/05/14 14:49:43 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443468988081991752237213_0004_m_000183_755
[2021-05-14 11:49:43,678] {docker.py:276} INFO - 21/05/14 14:49:43 INFO Executor: Finished task 183.0 in stage 4.0 (TID 755). 5149 bytes result sent to driver
[2021-05-14 11:49:43,678] {docker.py:276} INFO - 21/05/14 14:49:43 INFO TaskSetManager: Starting task 188.0 in stage 4.0 (TID 760) (f0b8ef7ba22f, executor driver, partition 188, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:49:43,679] {docker.py:276} INFO - 21/05/14 14:49:43 INFO TaskSetManager: Finished task 183.0 in stage 4.0 (TID 755) in 7347 ms on f0b8ef7ba22f (executor driver) (185/200)
[2021-05-14 11:49:43,681] {docker.py:276} INFO - 21/05/14 14:49:43 INFO Executor: Running task 188.0 in stage 4.0 (TID 760)
[2021-05-14 11:49:43,690] {docker.py:276} INFO - 21/05/14 14:49:43 INFO ShuffleBlockFetcherIterator: Getting 9 (68.3 KiB) non-empty blocks including 9 (68.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:49:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:49:43,699] {docker.py:276} INFO - 21/05/14 14:49:43 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:49:43 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2021-05-14 11:49:43,699] {docker.py:276} INFO - 21/05/14 14:49:43 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
[2021-05-14 11:49:43,699] {docker.py:276} INFO - 21/05/14 14:49:43 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443467707222630151844826_0004_m_000188_760, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443467707222630151844826_0004_m_000188_760}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443467707222630151844826_0004}; taskId=attempt_202105141443467707222630151844826_0004_m_000188_760, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@5772191f}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
[2021-05-14 11:49:43,700] {docker.py:276} INFO - 21/05/14 14:49:43 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
[2021-05-14 11:49:43,700] {docker.py:276} INFO - 21/05/14 14:49:43 INFO StagingCommitter: Starting: Task committer attempt_202105141443467707222630151844826_0004_m_000188_760: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443467707222630151844826_0004_m_000188_760
[2021-05-14 11:49:43,704] {docker.py:276} INFO - 21/05/14 14:49:43 INFO StagingCommitter: Task committer attempt_202105141443467707222630151844826_0004_m_000188_760: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443467707222630151844826_0004_m_000188_760 : duration 0:00.005s
[2021-05-14 11:49:44,393] {docker.py:276} INFO - 21/05/14 14:49:44 INFO StagingCommitter: Starting: Task committer attempt_202105141443463867269863880688851_0004_m_000185_757: needsTaskCommit() Task attempt_202105141443463867269863880688851_0004_m_000185_757
21/05/14 14:49:44 INFO StagingCommitter: Task committer attempt_202105141443463867269863880688851_0004_m_000185_757: needsTaskCommit() Task attempt_202105141443463867269863880688851_0004_m_000185_757: duration 0:00.002s
21/05/14 14:49:44 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443463867269863880688851_0004_m_000185_757
[2021-05-14 11:49:44,395] {docker.py:276} INFO - 21/05/14 14:49:44 INFO Executor: Finished task 185.0 in stage 4.0 (TID 757). 5149 bytes result sent to driver
21/05/14 14:49:44 INFO TaskSetManager: Starting task 189.0 in stage 4.0 (TID 761) (f0b8ef7ba22f, executor driver, partition 189, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:49:44,396] {docker.py:276} INFO - 21/05/14 14:49:44 INFO Executor: Running task 189.0 in stage 4.0 (TID 761)
21/05/14 14:49:44 INFO TaskSetManager: Finished task 185.0 in stage 4.0 (TID 757) in 6967 ms on f0b8ef7ba22f (executor driver) (186/200)
[2021-05-14 11:49:44,407] {docker.py:276} INFO - 21/05/14 14:49:44 INFO ShuffleBlockFetcherIterator: Getting 9 (69.3 KiB) non-empty blocks including 9 (69.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:49:44 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:49:44,417] {docker.py:276} INFO - 21/05/14 14:49:44 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:49:44 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/05/14 14:49:44 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
[2021-05-14 11:49:44,418] {docker.py:276} INFO - 21/05/14 14:49:44 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443467367051674229129075_0004_m_000189_761, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443467367051674229129075_0004_m_000189_761}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443467367051674229129075_0004}; taskId=attempt_202105141443467367051674229129075_0004_m_000189_761, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@13d9d1a9}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
21/05/14 14:49:44 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
21/05/14 14:49:44 INFO StagingCommitter: Starting: Task committer attempt_202105141443467367051674229129075_0004_m_000189_761: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443467367051674229129075_0004_m_000189_761
[2021-05-14 11:49:44,422] {docker.py:276} INFO - 21/05/14 14:49:44 INFO StagingCommitter: Task committer attempt_202105141443467367051674229129075_0004_m_000189_761: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443467367051674229129075_0004_m_000189_761 : duration 0:00.005s
[2021-05-14 11:49:48,436] {docker.py:276} INFO - 21/05/14 14:49:48 INFO StagingCommitter: Starting: Task committer attempt_202105141443466714573880090228778_0004_m_000186_758: needsTaskCommit() Task attempt_202105141443466714573880090228778_0004_m_000186_758
[2021-05-14 11:49:48,438] {docker.py:276} INFO - 21/05/14 14:49:48 INFO StagingCommitter: Task committer attempt_202105141443466714573880090228778_0004_m_000186_758: needsTaskCommit() Task attempt_202105141443466714573880090228778_0004_m_000186_758: duration 0:00.003s
21/05/14 14:49:48 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443466714573880090228778_0004_m_000186_758
[2021-05-14 11:49:48,439] {docker.py:276} INFO - 21/05/14 14:49:48 INFO Executor: Finished task 186.0 in stage 4.0 (TID 758). 5149 bytes result sent to driver
[2021-05-14 11:49:48,439] {docker.py:276} INFO - 21/05/14 14:49:48 INFO TaskSetManager: Starting task 190.0 in stage 4.0 (TID 762) (f0b8ef7ba22f, executor driver, partition 190, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:49:48,440] {docker.py:276} INFO - 21/05/14 14:49:48 INFO Executor: Running task 190.0 in stage 4.0 (TID 762)
21/05/14 14:49:48 INFO TaskSetManager: Finished task 186.0 in stage 4.0 (TID 758) in 6976 ms on f0b8ef7ba22f (executor driver) (187/200)
[2021-05-14 11:49:48,450] {docker.py:276} INFO - 21/05/14 14:49:48 INFO ShuffleBlockFetcherIterator: Getting 9 (69.3 KiB) non-empty blocks including 9 (69.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:49:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:49:48,459] {docker.py:276} INFO - 21/05/14 14:49:48 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:49:48 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2021-05-14 11:49:48,460] {docker.py:276} INFO - 21/05/14 14:49:48 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
[2021-05-14 11:49:48,461] {docker.py:276} INFO - 21/05/14 14:49:48 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443467223313087453393036_0004_m_000190_762, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443467223313087453393036_0004_m_000190_762}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443467223313087453393036_0004}; taskId=attempt_202105141443467223313087453393036_0004_m_000190_762, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@53da8743}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
21/05/14 14:49:48 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
21/05/14 14:49:48 INFO StagingCommitter: Starting: Task committer attempt_202105141443467223313087453393036_0004_m_000190_762: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443467223313087453393036_0004_m_000190_762
[2021-05-14 11:49:48,465] {docker.py:276} INFO - 21/05/14 14:49:48 INFO StagingCommitter: Task committer attempt_202105141443467223313087453393036_0004_m_000190_762: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443467223313087453393036_0004_m_000190_762 : duration 0:00.004s
[2021-05-14 11:49:49,329] {docker.py:276} INFO - 21/05/14 14:49:49 INFO StagingCommitter: Starting: Task committer attempt_202105141443461928015279678854718_0004_m_000187_759: needsTaskCommit() Task attempt_202105141443461928015279678854718_0004_m_000187_759
[2021-05-14 11:49:49,330] {docker.py:276} INFO - 21/05/14 14:49:49 INFO StagingCommitter: Task committer attempt_202105141443461928015279678854718_0004_m_000187_759: needsTaskCommit() Task attempt_202105141443461928015279678854718_0004_m_000187_759: duration 0:00.002s
21/05/14 14:49:49 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443461928015279678854718_0004_m_000187_759
[2021-05-14 11:49:49,331] {docker.py:276} INFO - 21/05/14 14:49:49 INFO Executor: Finished task 187.0 in stage 4.0 (TID 759). 5106 bytes result sent to driver
[2021-05-14 11:49:49,332] {docker.py:276} INFO - 21/05/14 14:49:49 INFO TaskSetManager: Starting task 191.0 in stage 4.0 (TID 763) (f0b8ef7ba22f, executor driver, partition 191, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:49:49,333] {docker.py:276} INFO - 21/05/14 14:49:49 INFO TaskSetManager: Finished task 187.0 in stage 4.0 (TID 759) in 5931 ms on f0b8ef7ba22f (executor driver) (188/200)
[2021-05-14 11:49:49,334] {docker.py:276} INFO - 21/05/14 14:49:49 INFO Executor: Running task 191.0 in stage 4.0 (TID 763)
[2021-05-14 11:49:49,345] {docker.py:276} INFO - 21/05/14 14:49:49 INFO ShuffleBlockFetcherIterator: Getting 9 (63.0 KiB) non-empty blocks including 9 (63.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
[2021-05-14 11:49:49,346] {docker.py:276} INFO - 21/05/14 14:49:49 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2021-05-14 11:49:49,355] {docker.py:276} INFO - 21/05/14 14:49:49 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:49:49 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/05/14 14:49:49 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
21/05/14 14:49:49 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443465153211975159406488_0004_m_000191_763, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443465153211975159406488_0004_m_000191_763}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443465153211975159406488_0004}; taskId=attempt_202105141443465153211975159406488_0004_m_000191_763, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@5cd5f0f8}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
21/05/14 14:49:49 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
21/05/14 14:49:49 INFO StagingCommitter: Starting: Task committer attempt_202105141443465153211975159406488_0004_m_000191_763: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443465153211975159406488_0004_m_000191_763
[2021-05-14 11:49:49,358] {docker.py:276} INFO - 21/05/14 14:49:49 INFO StagingCommitter: Task committer attempt_202105141443465153211975159406488_0004_m_000191_763: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443465153211975159406488_0004_m_000191_763 : duration 0:00.004s
[2021-05-14 11:49:50,623] {docker.py:276} INFO - 21/05/14 14:49:50 INFO StagingCommitter: Starting: Task committer attempt_202105141443467707222630151844826_0004_m_000188_760: needsTaskCommit() Task attempt_202105141443467707222630151844826_0004_m_000188_760
[2021-05-14 11:49:50,623] {docker.py:276} INFO - 21/05/14 14:49:50 INFO StagingCommitter: Task committer attempt_202105141443467707222630151844826_0004_m_000188_760: needsTaskCommit() Task attempt_202105141443467707222630151844826_0004_m_000188_760: duration 0:00.003s
21/05/14 14:49:50 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443467707222630151844826_0004_m_000188_760
[2021-05-14 11:49:50,625] {docker.py:276} INFO - 21/05/14 14:49:50 INFO Executor: Finished task 188.0 in stage 4.0 (TID 760). 5106 bytes result sent to driver
[2021-05-14 11:49:50,626] {docker.py:276} INFO - 21/05/14 14:49:50 INFO TaskSetManager: Starting task 192.0 in stage 4.0 (TID 764) (f0b8ef7ba22f, executor driver, partition 192, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:49:50,627] {docker.py:276} INFO - 21/05/14 14:49:50 INFO Executor: Running task 192.0 in stage 4.0 (TID 764)
21/05/14 14:49:50 INFO TaskSetManager: Finished task 188.0 in stage 4.0 (TID 760) in 6956 ms on f0b8ef7ba22f (executor driver) (189/200)
[2021-05-14 11:49:50,638] {docker.py:276} INFO - 21/05/14 14:49:50 INFO ShuffleBlockFetcherIterator: Getting 9 (66.7 KiB) non-empty blocks including 9 (66.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:49:50 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:49:50,647] {docker.py:276} INFO - 21/05/14 14:49:50 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:49:50 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/05/14 14:49:50 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
21/05/14 14:49:50 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443464540358690375575717_0004_m_000192_764, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443464540358690375575717_0004_m_000192_764}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443464540358690375575717_0004}; taskId=attempt_202105141443464540358690375575717_0004_m_000192_764, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@53e52503}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
21/05/14 14:49:50 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
21/05/14 14:49:50 INFO StagingCommitter: Starting: Task committer attempt_202105141443464540358690375575717_0004_m_000192_764: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443464540358690375575717_0004_m_000192_764
[2021-05-14 11:49:50,651] {docker.py:276} INFO - 21/05/14 14:49:50 INFO StagingCommitter: Task committer attempt_202105141443464540358690375575717_0004_m_000192_764: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443464540358690375575717_0004_m_000192_764 : duration 0:00.003s
[2021-05-14 11:49:52,228] {docker.py:276} INFO - 21/05/14 14:49:52 INFO StagingCommitter: Starting: Task committer attempt_202105141443467367051674229129075_0004_m_000189_761: needsTaskCommit() Task attempt_202105141443467367051674229129075_0004_m_000189_761
[2021-05-14 11:49:52,229] {docker.py:276} INFO - 21/05/14 14:49:52 INFO StagingCommitter: Task committer attempt_202105141443467367051674229129075_0004_m_000189_761: needsTaskCommit() Task attempt_202105141443467367051674229129075_0004_m_000189_761: duration 0:00.002s
[2021-05-14 11:49:52,229] {docker.py:276} INFO - 21/05/14 14:49:52 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443467367051674229129075_0004_m_000189_761
[2021-05-14 11:49:52,230] {docker.py:276} INFO - 21/05/14 14:49:52 INFO Executor: Finished task 189.0 in stage 4.0 (TID 761). 5106 bytes result sent to driver
[2021-05-14 11:49:52,231] {docker.py:276} INFO - 21/05/14 14:49:52 INFO TaskSetManager: Starting task 193.0 in stage 4.0 (TID 765) (f0b8ef7ba22f, executor driver, partition 193, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:49:52,232] {docker.py:276} INFO - 21/05/14 14:49:52 INFO Executor: Running task 193.0 in stage 4.0 (TID 765)
21/05/14 14:49:52 INFO TaskSetManager: Finished task 189.0 in stage 4.0 (TID 761) in 7847 ms on f0b8ef7ba22f (executor driver) (190/200)
[2021-05-14 11:49:52,241] {docker.py:276} INFO - 21/05/14 14:49:52 INFO ShuffleBlockFetcherIterator: Getting 9 (67.0 KiB) non-empty blocks including 9 (67.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:49:52 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:49:52,250] {docker.py:276} INFO - 21/05/14 14:49:52 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:49:52 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/05/14 14:49:52 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
[2021-05-14 11:49:52,250] {docker.py:276} INFO - 21/05/14 14:49:52 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_20210514144346514932755532608401_0004_m_000193_765, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_20210514144346514932755532608401_0004_m_000193_765}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_20210514144346514932755532608401_0004}; taskId=attempt_20210514144346514932755532608401_0004_m_000193_765, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@10bfd686}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
21/05/14 14:49:52 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
[2021-05-14 11:49:52,250] {docker.py:276} INFO - 21/05/14 14:49:52 INFO StagingCommitter: Starting: Task committer attempt_20210514144346514932755532608401_0004_m_000193_765: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_20210514144346514932755532608401_0004_m_000193_765
[2021-05-14 11:49:52,255] {docker.py:276} INFO - 21/05/14 14:49:52 INFO StagingCommitter: Task committer attempt_20210514144346514932755532608401_0004_m_000193_765: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_20210514144346514932755532608401_0004_m_000193_765 : duration 0:00.004s
[2021-05-14 11:49:55,611] {docker.py:276} INFO - 21/05/14 14:49:55 INFO StagingCommitter: Starting: Task committer attempt_202105141443467223313087453393036_0004_m_000190_762: needsTaskCommit() Task attempt_202105141443467223313087453393036_0004_m_000190_762
21/05/14 14:49:55 INFO StagingCommitter: Task committer attempt_202105141443467223313087453393036_0004_m_000190_762: needsTaskCommit() Task attempt_202105141443467223313087453393036_0004_m_000190_762: duration 0:00.001s
21/05/14 14:49:55 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443467223313087453393036_0004_m_000190_762
[2021-05-14 11:49:55,613] {docker.py:276} INFO - 21/05/14 14:49:55 INFO Executor: Finished task 190.0 in stage 4.0 (TID 762). 5106 bytes result sent to driver
[2021-05-14 11:49:55,616] {docker.py:276} INFO - 21/05/14 14:49:55 INFO TaskSetManager: Starting task 194.0 in stage 4.0 (TID 766) (f0b8ef7ba22f, executor driver, partition 194, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:49:55,617] {docker.py:276} INFO - 21/05/14 14:49:55 INFO Executor: Running task 194.0 in stage 4.0 (TID 766)
[2021-05-14 11:49:55,618] {docker.py:276} INFO - 21/05/14 14:49:55 INFO TaskSetManager: Finished task 190.0 in stage 4.0 (TID 762) in 7187 ms on f0b8ef7ba22f (executor driver) (191/200)
[2021-05-14 11:49:55,626] {docker.py:276} INFO - 21/05/14 14:49:55 INFO ShuffleBlockFetcherIterator: Getting 9 (68.5 KiB) non-empty blocks including 9 (68.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:49:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:49:55,635] {docker.py:276} INFO - 21/05/14 14:49:55 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:49:55 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/05/14 14:49:55 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
21/05/14 14:49:55 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443461195421378388512178_0004_m_000194_766, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443461195421378388512178_0004_m_000194_766}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443461195421378388512178_0004}; taskId=attempt_202105141443461195421378388512178_0004_m_000194_766, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@21499d77}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
21/05/14 14:49:55 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
21/05/14 14:49:55 INFO StagingCommitter: Starting: Task committer attempt_202105141443461195421378388512178_0004_m_000194_766: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443461195421378388512178_0004_m_000194_766
[2021-05-14 11:49:55,639] {docker.py:276} INFO - 21/05/14 14:49:55 INFO StagingCommitter: Task committer attempt_202105141443461195421378388512178_0004_m_000194_766: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443461195421378388512178_0004_m_000194_766 : duration 0:00.004s
[2021-05-14 11:49:55,894] {docker.py:276} INFO - 21/05/14 14:49:55 INFO StagingCommitter: Starting: Task committer attempt_202105141443465153211975159406488_0004_m_000191_763: needsTaskCommit() Task attempt_202105141443465153211975159406488_0004_m_000191_763
[2021-05-14 11:49:55,896] {docker.py:276} INFO - 21/05/14 14:49:55 INFO StagingCommitter: Task committer attempt_202105141443465153211975159406488_0004_m_000191_763: needsTaskCommit() Task attempt_202105141443465153211975159406488_0004_m_000191_763: duration 0:00.004s
[2021-05-14 11:49:55,897] {docker.py:276} INFO - 21/05/14 14:49:55 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443465153211975159406488_0004_m_000191_763
[2021-05-14 11:49:55,898] {docker.py:276} INFO - 21/05/14 14:49:55 INFO Executor: Finished task 191.0 in stage 4.0 (TID 763). 5106 bytes result sent to driver
[2021-05-14 11:49:55,900] {docker.py:276} INFO - 21/05/14 14:49:55 INFO TaskSetManager: Starting task 195.0 in stage 4.0 (TID 767) (f0b8ef7ba22f, executor driver, partition 195, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:49:55,901] {docker.py:276} INFO - 21/05/14 14:49:55 INFO TaskSetManager: Finished task 191.0 in stage 4.0 (TID 763) in 6577 ms on f0b8ef7ba22f (executor driver) (192/200)
[2021-05-14 11:49:55,902] {docker.py:276} INFO - 21/05/14 14:49:55 INFO Executor: Running task 195.0 in stage 4.0 (TID 767)
[2021-05-14 11:49:55,911] {docker.py:276} INFO - 21/05/14 14:49:55 INFO ShuffleBlockFetcherIterator: Getting 9 (64.3 KiB) non-empty blocks including 9 (64.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:49:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:49:55,920] {docker.py:276} INFO - 21/05/14 14:49:55 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:49:55 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2021-05-14 11:49:55,921] {docker.py:276} INFO - 21/05/14 14:49:55 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
[2021-05-14 11:49:55,921] {docker.py:276} INFO - 21/05/14 14:49:55 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443461279725433689366554_0004_m_000195_767, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443461279725433689366554_0004_m_000195_767}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443461279725433689366554_0004}; taskId=attempt_202105141443461279725433689366554_0004_m_000195_767, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@30b54ff7}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
[2021-05-14 11:49:55,921] {docker.py:276} INFO - 21/05/14 14:49:55 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
[2021-05-14 11:49:55,921] {docker.py:276} INFO - 21/05/14 14:49:55 INFO StagingCommitter: Starting: Task committer attempt_202105141443461279725433689366554_0004_m_000195_767: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443461279725433689366554_0004_m_000195_767
[2021-05-14 11:49:55,925] {docker.py:276} INFO - 21/05/14 14:49:55 INFO StagingCommitter: Task committer attempt_202105141443461279725433689366554_0004_m_000195_767: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443461279725433689366554_0004_m_000195_767 : duration 0:00.004s
[2021-05-14 11:49:57,428] {docker.py:276} INFO - 21/05/14 14:49:57 INFO StagingCommitter: Starting: Task committer attempt_202105141443464540358690375575717_0004_m_000192_764: needsTaskCommit() Task attempt_202105141443464540358690375575717_0004_m_000192_764
[2021-05-14 11:49:57,429] {docker.py:276} INFO - 21/05/14 14:49:57 INFO StagingCommitter: Task committer attempt_202105141443464540358690375575717_0004_m_000192_764: needsTaskCommit() Task attempt_202105141443464540358690375575717_0004_m_000192_764: duration 0:00.002s
21/05/14 14:49:57 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443464540358690375575717_0004_m_000192_764
[2021-05-14 11:49:57,431] {docker.py:276} INFO - 21/05/14 14:49:57 INFO Executor: Finished task 192.0 in stage 4.0 (TID 764). 5106 bytes result sent to driver
[2021-05-14 11:49:57,432] {docker.py:276} INFO - 21/05/14 14:49:57 INFO TaskSetManager: Starting task 196.0 in stage 4.0 (TID 768) (f0b8ef7ba22f, executor driver, partition 196, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:49:57,433] {docker.py:276} INFO - 21/05/14 14:49:57 INFO Executor: Running task 196.0 in stage 4.0 (TID 768)
[2021-05-14 11:49:57,434] {docker.py:276} INFO - 21/05/14 14:49:57 INFO TaskSetManager: Finished task 192.0 in stage 4.0 (TID 764) in 6817 ms on f0b8ef7ba22f (executor driver) (193/200)
[2021-05-14 11:49:57,444] {docker.py:276} INFO - 21/05/14 14:49:57 INFO ShuffleBlockFetcherIterator: Getting 9 (66.4 KiB) non-empty blocks including 9 (66.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:49:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:49:57,453] {docker.py:276} INFO - 21/05/14 14:49:57 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:49:57 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/05/14 14:49:57 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
21/05/14 14:49:57 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443462840473241460830019_0004_m_000196_768, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443462840473241460830019_0004_m_000196_768}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443462840473241460830019_0004}; taskId=attempt_202105141443462840473241460830019_0004_m_000196_768, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@7e1ecad0}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
21/05/14 14:49:57 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
21/05/14 14:49:57 INFO StagingCommitter: Starting: Task committer attempt_202105141443462840473241460830019_0004_m_000196_768: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443462840473241460830019_0004_m_000196_768
[2021-05-14 11:49:57,457] {docker.py:276} INFO - 21/05/14 14:49:57 INFO StagingCommitter: Task committer attempt_202105141443462840473241460830019_0004_m_000196_768: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443462840473241460830019_0004_m_000196_768 : duration 0:00.004s
[2021-05-14 11:49:58,355] {docker.py:276} INFO - 21/05/14 14:49:58 INFO StagingCommitter: Starting: Task committer attempt_20210514144346514932755532608401_0004_m_000193_765: needsTaskCommit() Task attempt_20210514144346514932755532608401_0004_m_000193_765
21/05/14 14:49:58 INFO StagingCommitter: Task committer attempt_20210514144346514932755532608401_0004_m_000193_765: needsTaskCommit() Task attempt_20210514144346514932755532608401_0004_m_000193_765: duration 0:00.002s
21/05/14 14:49:58 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_20210514144346514932755532608401_0004_m_000193_765
[2021-05-14 11:49:58,356] {docker.py:276} INFO - 21/05/14 14:49:58 INFO Executor: Finished task 193.0 in stage 4.0 (TID 765). 5106 bytes result sent to driver
[2021-05-14 11:49:58,358] {docker.py:276} INFO - 21/05/14 14:49:58 INFO TaskSetManager: Starting task 197.0 in stage 4.0 (TID 769) (f0b8ef7ba22f, executor driver, partition 197, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:49:58,359] {docker.py:276} INFO - 21/05/14 14:49:58 INFO TaskSetManager: Finished task 193.0 in stage 4.0 (TID 765) in 6134 ms on f0b8ef7ba22f (executor driver) (194/200)
[2021-05-14 11:49:58,360] {docker.py:276} INFO - 21/05/14 14:49:58 INFO Executor: Running task 197.0 in stage 4.0 (TID 769)
[2021-05-14 11:49:58,369] {docker.py:276} INFO - 21/05/14 14:49:58 INFO ShuffleBlockFetcherIterator: Getting 9 (63.8 KiB) non-empty blocks including 9 (63.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:49:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:49:58,377] {docker.py:276} INFO - 21/05/14 14:49:58 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:49:58 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/05/14 14:49:58 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
21/05/14 14:49:58 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_20210514144346540999946257713280_0004_m_000197_769, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_20210514144346540999946257713280_0004_m_000197_769}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_20210514144346540999946257713280_0004}; taskId=attempt_20210514144346540999946257713280_0004_m_000197_769, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@4f17d105}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
[2021-05-14 11:49:58,378] {docker.py:276} INFO - 21/05/14 14:49:58 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
21/05/14 14:49:58 INFO StagingCommitter: Starting: Task committer attempt_20210514144346540999946257713280_0004_m_000197_769: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_20210514144346540999946257713280_0004_m_000197_769
[2021-05-14 11:49:58,381] {docker.py:276} INFO - 21/05/14 14:49:58 INFO StagingCommitter: Task committer attempt_20210514144346540999946257713280_0004_m_000197_769: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_20210514144346540999946257713280_0004_m_000197_769 : duration 0:00.004s
[2021-05-14 11:50:02,492] {docker.py:276} INFO - 21/05/14 14:50:02 INFO StagingCommitter: Starting: Task committer attempt_202105141443461279725433689366554_0004_m_000195_767: needsTaskCommit() Task attempt_202105141443461279725433689366554_0004_m_000195_767
[2021-05-14 11:50:02,493] {docker.py:276} INFO - 21/05/14 14:50:02 INFO StagingCommitter: Task committer attempt_202105141443461279725433689366554_0004_m_000195_767: needsTaskCommit() Task attempt_202105141443461279725433689366554_0004_m_000195_767: duration 0:00.004s
21/05/14 14:50:02 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443461279725433689366554_0004_m_000195_767
[2021-05-14 11:50:02,505] {docker.py:276} INFO - 21/05/14 14:50:02 INFO Executor: Finished task 195.0 in stage 4.0 (TID 767). 5106 bytes result sent to driver
[2021-05-14 11:50:02,506] {docker.py:276} INFO - 21/05/14 14:50:02 INFO TaskSetManager: Starting task 198.0 in stage 4.0 (TID 770) (f0b8ef7ba22f, executor driver, partition 198, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:50:02,507] {docker.py:276} INFO - 21/05/14 14:50:02 INFO TaskSetManager: Finished task 195.0 in stage 4.0 (TID 767) in 6609 ms on f0b8ef7ba22f (executor driver) (195/200)
[2021-05-14 11:50:02,507] {docker.py:276} INFO - 21/05/14 14:50:02 INFO Executor: Running task 198.0 in stage 4.0 (TID 770)
[2021-05-14 11:50:02,527] {docker.py:276} INFO - 21/05/14 14:50:02 INFO ShuffleBlockFetcherIterator: Getting 9 (68.0 KiB) non-empty blocks including 9 (68.0 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:50:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:50:02,548] {docker.py:276} INFO - 21/05/14 14:50:02 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:50:02 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2021-05-14 11:50:02,549] {docker.py:276} INFO - 21/05/14 14:50:02 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
[2021-05-14 11:50:02,550] {docker.py:276} INFO - 21/05/14 14:50:02 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443467058613643638631089_0004_m_000198_770, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443467058613643638631089_0004_m_000198_770}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443467058613643638631089_0004}; taskId=attempt_202105141443467058613643638631089_0004_m_000198_770, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@559494b7}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
[2021-05-14 11:50:02,550] {docker.py:276} INFO - 21/05/14 14:50:02 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
21/05/14 14:50:02 INFO StagingCommitter: Starting: Task committer attempt_202105141443467058613643638631089_0004_m_000198_770: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443467058613643638631089_0004_m_000198_770
[2021-05-14 11:50:02,556] {docker.py:276} INFO - 21/05/14 14:50:02 INFO StagingCommitter: Task committer attempt_202105141443467058613643638631089_0004_m_000198_770: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443467058613643638631089_0004_m_000198_770 : duration 0:00.006s
[2021-05-14 11:50:02,878] {docker.py:276} INFO - 21/05/14 14:50:02 INFO StagingCommitter: Starting: Task committer attempt_202105141443461195421378388512178_0004_m_000194_766: needsTaskCommit() Task attempt_202105141443461195421378388512178_0004_m_000194_766
21/05/14 14:50:02 INFO StagingCommitter: Task committer attempt_202105141443461195421378388512178_0004_m_000194_766: needsTaskCommit() Task attempt_202105141443461195421378388512178_0004_m_000194_766: duration 0:00.001s
21/05/14 14:50:02 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443461195421378388512178_0004_m_000194_766
[2021-05-14 11:50:02,881] {docker.py:276} INFO - 21/05/14 14:50:02 INFO Executor: Finished task 194.0 in stage 4.0 (TID 766). 5106 bytes result sent to driver
[2021-05-14 11:50:02,884] {docker.py:276} INFO - 21/05/14 14:50:02 INFO TaskSetManager: Starting task 199.0 in stage 4.0 (TID 771) (f0b8ef7ba22f, executor driver, partition 199, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2021-05-14 11:50:02,884] {docker.py:276} INFO - 21/05/14 14:50:02 INFO TaskSetManager: Finished task 194.0 in stage 4.0 (TID 766) in 7277 ms on f0b8ef7ba22f (executor driver) (196/200)
[2021-05-14 11:50:02,886] {docker.py:276} INFO - 21/05/14 14:50:02 INFO Executor: Running task 199.0 in stage 4.0 (TID 771)
[2021-05-14 11:50:02,902] {docker.py:276} INFO - 21/05/14 14:50:02 INFO ShuffleBlockFetcherIterator: Getting 9 (68.4 KiB) non-empty blocks including 9 (68.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/05/14 14:50:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2021-05-14 11:50:02,918] {docker.py:276} INFO - 21/05/14 14:50:02 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/05/14 14:50:02 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/05/14 14:50:02 INFO AbstractS3ACommitterFactory: Using committer partitioned to output data to s3a://udac-forex-project/consolidated_data
[2021-05-14 11:50:02,918] {docker.py:276} INFO - 21/05/14 14:50:02 INFO AbstractS3ACommitterFactory: Using Commmitter PartitionedStagingCommitter{StagingCommitter{AbstractS3ACommitter{role=Task committer attempt_202105141443465052624376596008724_0004_m_000199_771, name=partitioned, outputPath=s3a://udac-forex-project/consolidated_data, workPath=file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443465052624376596008724_0004_m_000199_771}, conflictResolution=REPLACE, wrappedCommitter=FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202105141443465052624376596008724_0004}; taskId=attempt_202105141443465052624376596008724_0004_m_000199_771, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@cef393c}; outputPath=file:/home/jovyan/tmp/staging/jovyan/1a39c1aa-2513-41a1-b578-ba79885b7c30/staging-uploads, workPath=null, algorithmVersion=1, skipCleanup=false, ignoreCleanupFailures=false}}} for s3a://udac-forex-project/consolidated_data
21/05/14 14:50:02 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.fs.s3a.commit.staging.PartitionedStagingCommitter
21/05/14 14:50:02 INFO StagingCommitter: Starting: Task committer attempt_202105141443465052624376596008724_0004_m_000199_771: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443465052624376596008724_0004_m_000199_771
[2021-05-14 11:50:02,925] {docker.py:276} INFO - 21/05/14 14:50:02 INFO StagingCommitter: Task committer attempt_202105141443465052624376596008724_0004_m_000199_771: setup task attempt path file:/tmp/hadoop-jovyan/s3a/1a39c1aa-2513-41a1-b578-ba79885b7c30/_temporary/0/_temporary/attempt_202105141443465052624376596008724_0004_m_000199_771 : duration 0:00.006s
[2021-05-14 11:50:04,563] {docker.py:276} INFO - 21/05/14 14:50:04 INFO StagingCommitter: Starting: Task committer attempt_202105141443462840473241460830019_0004_m_000196_768: needsTaskCommit() Task attempt_202105141443462840473241460830019_0004_m_000196_768
[2021-05-14 11:50:04,564] {docker.py:276} INFO - 21/05/14 14:50:04 INFO StagingCommitter: Task committer attempt_202105141443462840473241460830019_0004_m_000196_768: needsTaskCommit() Task attempt_202105141443462840473241460830019_0004_m_000196_768: duration 0:00.003s
21/05/14 14:50:04 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443462840473241460830019_0004_m_000196_768
[2021-05-14 11:50:04,567] {docker.py:276} INFO - 21/05/14 14:50:04 INFO Executor: Finished task 196.0 in stage 4.0 (TID 768). 5106 bytes result sent to driver
[2021-05-14 11:50:04,568] {docker.py:276} INFO - 21/05/14 14:50:04 INFO TaskSetManager: Finished task 196.0 in stage 4.0 (TID 768) in 7144 ms on f0b8ef7ba22f (executor driver) (197/200)
[2021-05-14 11:50:04,968] {docker.py:276} INFO - 21/05/14 14:50:04 INFO StagingCommitter: Starting: Task committer attempt_20210514144346540999946257713280_0004_m_000197_769: needsTaskCommit() Task attempt_20210514144346540999946257713280_0004_m_000197_769
[2021-05-14 11:50:04,969] {docker.py:276} INFO - 21/05/14 14:50:04 INFO StagingCommitter: Task committer attempt_20210514144346540999946257713280_0004_m_000197_769: needsTaskCommit() Task attempt_20210514144346540999946257713280_0004_m_000197_769: duration 0:00.001s
21/05/14 14:50:04 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_20210514144346540999946257713280_0004_m_000197_769
[2021-05-14 11:50:04,971] {docker.py:276} INFO - 21/05/14 14:50:05 INFO Executor: Finished task 197.0 in stage 4.0 (TID 769). 5106 bytes result sent to driver
[2021-05-14 11:50:04,972] {docker.py:276} INFO - 21/05/14 14:50:05 INFO TaskSetManager: Finished task 197.0 in stage 4.0 (TID 769) in 6623 ms on f0b8ef7ba22f (executor driver) (198/200)
[2021-05-14 11:50:08,531] {docker.py:276} INFO - 21/05/14 14:50:08 INFO StagingCommitter: Starting: Task committer attempt_202105141443465052624376596008724_0004_m_000199_771: needsTaskCommit() Task attempt_202105141443465052624376596008724_0004_m_000199_771
21/05/14 14:50:08 INFO StagingCommitter: Task committer attempt_202105141443465052624376596008724_0004_m_000199_771: needsTaskCommit() Task attempt_202105141443465052624376596008724_0004_m_000199_771: duration 0:00.000s
21/05/14 14:50:08 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443465052624376596008724_0004_m_000199_771
[2021-05-14 11:50:08,533] {docker.py:276} INFO - 21/05/14 14:50:08 INFO Executor: Finished task 199.0 in stage 4.0 (TID 771). 5106 bytes result sent to driver
[2021-05-14 11:50:08,534] {docker.py:276} INFO - 21/05/14 14:50:08 INFO TaskSetManager: Finished task 199.0 in stage 4.0 (TID 771) in 5622 ms on f0b8ef7ba22f (executor driver) (199/200)
[2021-05-14 11:50:09,032] {docker.py:276} INFO - 21/05/14 14:50:09 INFO StagingCommitter: Starting: Task committer attempt_202105141443467058613643638631089_0004_m_000198_770: needsTaskCommit() Task attempt_202105141443467058613643638631089_0004_m_000198_770
21/05/14 14:50:09 INFO StagingCommitter: Task committer attempt_202105141443467058613643638631089_0004_m_000198_770: needsTaskCommit() Task attempt_202105141443467058613643638631089_0004_m_000198_770: duration 0:00.000s
21/05/14 14:50:09 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202105141443467058613643638631089_0004_m_000198_770
[2021-05-14 11:50:09,033] {docker.py:276} INFO - 21/05/14 14:50:09 INFO Executor: Finished task 198.0 in stage 4.0 (TID 770). 5106 bytes result sent to driver
[2021-05-14 11:50:09,034] {docker.py:276} INFO - 21/05/14 14:50:09 INFO TaskSetManager: Finished task 198.0 in stage 4.0 (TID 770) in 6508 ms on f0b8ef7ba22f (executor driver) (200/200)
21/05/14 14:50:09 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool
[2021-05-14 11:50:09,034] {docker.py:276} INFO - 21/05/14 14:50:09 INFO DAGScheduler: ResultStage 4 (csv at NativeMethodAccessorImpl.java:0) finished in 347.268 s
[2021-05-14 11:50:09,035] {docker.py:276} INFO - 21/05/14 14:50:09 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
21/05/14 14:50:09 INFO TaskSchedulerImpl: Killing all running tasks in stage 4: Stage finished
[2021-05-14 11:50:09,036] {docker.py:276} INFO - 21/05/14 14:50:09 INFO DAGScheduler: Job 3 finished: csv at NativeMethodAccessorImpl.java:0, took 383.032274 s
[2021-05-14 11:50:09,038] {docker.py:276} INFO - 21/05/14 14:50:09 INFO AbstractS3ACommitter: Starting: Task committer attempt_202105141443457583537712105147781_0000_m_000000_0: commitJob((no job ID))
[2021-05-14 11:50:09,059] {docker.py:276} INFO - 21/05/14 14:50:09 WARN AbstractS3ACommitter: Task committer attempt_202105141443457583537712105147781_0000_m_000000_0: No pending uploads to commit
[2021-05-14 11:50:11,170] {docker.py:276} INFO - 21/05/14 14:50:11 INFO AbstractS3ACommitter: Starting: Cleanup job (no job ID)
21/05/14 14:50:11 INFO AbstractS3ACommitter: Starting: Aborting all pending commits under s3a://udac-forex-project/consolidated_data
[2021-05-14 11:50:11,352] {docker.py:276} INFO - 21/05/14 14:50:11 INFO AbstractS3ACommitter: Aborting all pending commits under s3a://udac-forex-project/consolidated_data: duration 0:00.182s
21/05/14 14:50:11 INFO AbstractS3ACommitter: Cleanup job (no job ID): duration 0:00.183s
[2021-05-14 11:50:11,353] {docker.py:276} INFO - 21/05/14 14:50:11 INFO AbstractS3ACommitter: Task committer attempt_202105141443457583537712105147781_0000_m_000000_0: commitJob((no job ID)): duration 0:02.318s
[2021-05-14 11:50:11,876] {docker.py:276} INFO - 21/05/14 14:50:11 INFO FileFormatWriter: Write Job 1a39c1aa-2513-41a1-b578-ba79885b7c30 committed.
[2021-05-14 11:50:11,886] {docker.py:276} INFO - 21/05/14 14:50:11 INFO FileFormatWriter: Finished processing stats for write job 1a39c1aa-2513-41a1-b578-ba79885b7c30.
[2021-05-14 11:50:11,993] {docker.py:276} INFO - 21/05/14 14:50:11 INFO SparkContext: Invoking stop() from shutdown hook
[2021-05-14 11:50:12,010] {docker.py:276} INFO - 21/05/14 14:50:12 INFO SparkUI: Stopped Spark web UI at http://f0b8ef7ba22f:4040
[2021-05-14 11:50:12,039] {docker.py:276} INFO - 21/05/14 14:50:12 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
[2021-05-14 11:50:12,061] {docker.py:276} INFO - 21/05/14 14:50:12 INFO MemoryStore: MemoryStore cleared
[2021-05-14 11:50:12,061] {docker.py:276} INFO - 21/05/14 14:50:12 INFO BlockManager: BlockManager stopped
[2021-05-14 11:50:12,065] {docker.py:276} INFO - 21/05/14 14:50:12 INFO BlockManagerMaster: BlockManagerMaster stopped
[2021-05-14 11:50:12,069] {docker.py:276} INFO - 21/05/14 14:50:12 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
[2021-05-14 11:50:12,078] {docker.py:276} INFO - 21/05/14 14:50:12 INFO SparkContext: Successfully stopped SparkContext
[2021-05-14 11:50:12,079] {docker.py:276} INFO - 21/05/14 14:50:12 INFO ShutdownHookManager: Shutdown hook called
[2021-05-14 11:50:12,079] {docker.py:276} INFO - 21/05/14 14:50:12 INFO ShutdownHookManager: Deleting directory /tmp/spark-7566cbcf-bedd-411c-b31c-0d1ea3b7f22a
[2021-05-14 11:50:12,084] {docker.py:276} INFO - 21/05/14 14:50:12 INFO ShutdownHookManager: Deleting directory /tmp/spark-c417219b-d9ce-4527-a115-a7a3e40a9481
[2021-05-14 11:50:12,086] {docker.py:276} INFO - 21/05/14 14:50:12 INFO ShutdownHookManager: Deleting directory /tmp/spark-7566cbcf-bedd-411c-b31c-0d1ea3b7f22a/pyspark-f32960aa-7ee8-4aa6-b249-0ef1b080da95
[2021-05-14 11:50:12,092] {docker.py:276} INFO - 21/05/14 14:50:12 INFO MetricsSystemImpl: Stopping s3a-file-system metrics system...
[2021-05-14 11:50:12,093] {docker.py:276} INFO - 21/05/14 14:50:12 INFO MetricsSystemImpl: s3a-file-system metrics system stopped.
[2021-05-14 11:50:12,094] {docker.py:276} INFO - 21/05/14 14:50:12 INFO MetricsSystemImpl: s3a-file-system metrics system shutdown complete.
[2021-05-14 11:50:12,403] {taskinstance.py:1192} INFO - Marking task as SUCCESS. dag_id=etl, task_id=run_spark_job, execution_date=20210514T144155, start_date=20210514T144250, end_date=20210514T145012
[2021-05-14 11:50:12,476] {taskinstance.py:1246} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2021-05-14 11:50:12,485] {local_task_job.py:146} INFO - Task exited with return code 0
